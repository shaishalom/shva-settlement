

file Read:C:\Users\AP068\git\documentum\rest-cd-prod\.git\config
-----------------------------------------------------
[core]
	repositoryformatversion = 0
	filemode = false
	bare = false
	logallrefupdates = true
	symlinks = false
	ignorecase = true
[remote "origin"]
	url = ssh://git@gitlab.devops.poalim.bank:31007/m28008doc/rest-cd-prod.git
	fetch = +refs/heads/*:refs/remotes/origin/*
[branch "master"]
	remote = origin
	merge = refs/heads/master


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\.git\hooks\applypatch-msg.sample
-----------------------------------------------------
#!/bin/sh
#
# An example hook script to check the commit log message taken by
# applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.  The hook is
# allowed to edit the commit message file.
#
# To enable this hook, rename this file to "applypatch-msg".

. git-sh-setup
commitmsg="$(git rev-parse --git-path hooks/commit-msg)"
test -x "$commitmsg" && exec "$commitmsg" ${1+"$@"}
:


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\.git\hooks\commit-msg.sample
-----------------------------------------------------
#!/bin/sh
#
# An example hook script to check the commit log message.
# Called by "git commit" with one argument, the name of the file
# that has the commit message.  The hook should exit with non-zero
# status after issuing an appropriate message if it wants to stop the
# commit.  The hook is allowed to edit the commit message file.
#
# To enable this hook, rename this file to "commit-msg".

# Uncomment the below to add a Signed-off-by line to the message.
# Doing this in a hook is a bad idea in general, but the prepare-commit-msg
# hook is more suited to it.
#
# SOB=$(git var GIT_AUTHOR_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
# grep -qs "^$SOB" "$1" || echo "$SOB" >> "$1"

# This example catches duplicate Signed-off-by lines.

test "" = "$(grep '^Signed-off-by: ' "$1" |
	 sort | uniq -c | sed -e '/^[ 	]*1[ 	]/d')" || {
	echo >&2 Duplicate Signed-off-by lines.
	exit 1
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\.git\hooks\fsmonitor-watchman.sample
-----------------------------------------------------
#!/usr/bin/perl

use strict;
use warnings;
use IPC::Open2;

# An example hook script to integrate Watchman
# (https://facebook.github.io/watchman/) with git to speed up detecting
# new and modified files.
#
# The hook is passed a version (currently 1) and a time in nanoseconds
# formatted as a string and outputs to stdout all files that have been
# modified since the given time. Paths must be relative to the root of
# the working tree and separated by a single NUL.
#
# To enable this hook, rename this file to "query-watchman" and set
# 'git config core.fsmonitor .git/hooks/query-watchman'
#
my ($version, $time) = @ARGV;

# Check the hook interface version

if ($version == 1) {
	# convert nanoseconds to seconds
	$time = int $time / 1000000000;
} else {
	die "Unsupported query-fsmonitor hook version '$version'.\n" .
	    "Falling back to scanning...\n";
}

my $git_work_tree;
if ($^O =~ 'msys' || $^O =~ 'cygwin') {
	$git_work_tree = Win32::GetCwd();
	$git_work_tree =~ tr/\\/\//;
} else {
	require Cwd;
	$git_work_tree = Cwd::cwd();
}

my $retry = 1;

launch_watchman();

sub launch_watchman {

	my $pid = open2(\*CHLD_OUT, \*CHLD_IN, 'watchman -j --no-pretty')
	    or die "open2() failed: $!\n" .
	    "Falling back to scanning...\n";

	# In the query expression below we're asking for names of files that
	# changed since $time but were not transient (ie created after
	# $time but no longer exist).
	#
	# To accomplish this, we're using the "since" generator to use the
	# recency index to select candidate nodes and "fields" to limit the
	# output to file names only. Then we're using the "expression" term to
	# further constrain the results.
	#
	# The category of transient files that we want to ignore will have a
	# creation clock (cclock) newer than $time_t value and will also not
	# currently exist.

	my $query = <<"	END";
		["query", "$git_work_tree", {
			"since": $time,
			"fields": ["name"],
			"expression": ["not", ["allof", ["since", $time, "cclock"], ["not", "exists"]]]
		}]
	END

	print CHLD_IN $query;
	close CHLD_IN;
	my $response = do {local $/; <CHLD_OUT>};

	die "Watchman: command returned no output.\n" .
	    "Falling back to scanning...\n" if $response eq "";
	die "Watchman: command returned invalid output: $response\n" .
	    "Falling back to scanning...\n" unless $response =~ /^\{/;

	my $json_pkg;
	eval {
		require JSON::XS;
		$json_pkg = "JSON::XS";
		1;
	} or do {
		require JSON::PP;
		$json_pkg = "JSON::PP";
	};

	my $o = $json_pkg->new->utf8->decode($response);

	if ($retry > 0 and $o->{error} and $o->{error} =~ m/unable to resolve root .* directory (.*) is not watched/) {
		print STDERR "Adding '$git_work_tree' to watchman's watch list.\n";
		$retry--;
		qx/watchman watch "$git_work_tree"/;
		die "Failed to make watchman watch '$git_work_tree'.\n" .
		    "Falling back to scanning...\n" if $? != 0;

		# Watchman will always return all files on the first query so
		# return the fast "everything is dirty" flag to git and do the
		# Watchman query just to get it over with now so we won't pay
		# the cost in git to look up each individual file.
		print "/\0";
		eval { launch_watchman() };
		exit 0;
	}

	die "Watchman: $o->{error}.\n" .
	    "Falling back to scanning...\n" if $o->{error};

	binmode STDOUT, ":utf8";
	local $, = "\0";
	print @{$o->{files}};
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\.git\hooks\post-update.sample
-----------------------------------------------------
#!/bin/sh
#
# An example hook script to prepare a packed repository for use over
# dumb transports.
#
# To enable this hook, rename this file to "post-update".

exec git update-server-info


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\.git\hooks\pre-applypatch.sample
-----------------------------------------------------
#!/bin/sh
#
# An example hook script to verify what is about to be committed
# by applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-applypatch".

. git-sh-setup
precommit="$(git rev-parse --git-path hooks/pre-commit)"
test -x "$precommit" && exec "$precommit" ${1+"$@"}
:


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\.git\hooks\pre-commit.sample
-----------------------------------------------------
#!/bin/sh
#
# An example hook script to verify what is about to be committed.
# Called by "git commit" with no arguments.  The hook should
# exit with non-zero status after issuing an appropriate message if
# it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-commit".

if git rev-parse --verify HEAD >/dev/null 2>&1
then
	against=HEAD
else
	# Initial commit: diff against an empty tree object
	against=$(git hash-object -t tree /dev/null)
fi

# If you want to allow non-ASCII filenames set this variable to true.
allownonascii=$(git config --bool hooks.allownonascii)

# Redirect output to stderr.
exec 1>&2

# Cross platform projects tend to avoid non-ASCII filenames; prevent
# them from being added to the repository. We exploit the fact that the
# printable range starts at the space character and ends with tilde.
if [ "$allownonascii" != "true" ] &&
	# Note that the use of brackets around a tr range is ok here, (it's
	# even required, for portability to Solaris 10's /usr/bin/tr), since
	# the square bracket bytes happen to fall in the designated range.
	test $(git diff --cached --name-only --diff-filter=A -z $against |
	  LC_ALL=C tr -d '[ -~]\0' | wc -c) != 0
then
	cat <<\EOF
Error: Attempt to add a non-ASCII file name.

This can cause problems if you want to work with people on other platforms.

To be portable it is advisable to rename the file.

If you know what you are doing you can disable this check using:

  git config hooks.allownonascii true
EOF
	exit 1
fi

# If there are whitespace errors, print the offending file names and fail.
exec git diff-index --check --cached $against --


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\.git\hooks\pre-push.sample
-----------------------------------------------------
#!/bin/sh

# An example hook script to verify what is about to be pushed.  Called by "git
# push" after it has checked the remote status, but before anything has been
# pushed.  If this script exits with a non-zero status nothing will be pushed.
#
# This hook is called with the following parameters:
#
# $1 -- Name of the remote to which the push is being done
# $2 -- URL to which the push is being done
#
# If pushing without using a named remote those arguments will be equal.
#
# Information about the commits which are being pushed is supplied as lines to
# the standard input in the form:
#
#   <local ref> <local sha1> <remote ref> <remote sha1>
#
# This sample shows how to prevent push of commits where the log message starts
# with "WIP" (work in progress).

remote="$1"
url="$2"

z40=0000000000000000000000000000000000000000

while read local_ref local_sha remote_ref remote_sha
do
	if [ "$local_sha" = $z40 ]
	then
		# Handle delete
		:
	else
		if [ "$remote_sha" = $z40 ]
		then
			# New branch, examine all commits
			range="$local_sha"
		else
			# Update to existing branch, examine new commits
			range="$remote_sha..$local_sha"
		fi

		# Check for WIP commit
		commit=`git rev-list -n 1 --grep '^WIP' "$range"`
		if [ -n "$commit" ]
		then
			echo >&2 "Found WIP commit in $local_ref, not pushing"
			exit 1
		fi
	fi
done

exit 0


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\.git\hooks\pre-rebase.sample
-----------------------------------------------------
#!/bin/sh
#
# Copyright (c) 2006, 2008 Junio C Hamano
#
# The "pre-rebase" hook is run just before "git rebase" starts doing
# its job, and can prevent the command from running by exiting with
# non-zero status.
#
# The hook is called with the following parameters:
#
# $1 -- the upstream the series was forked from.
# $2 -- the branch being rebased (or empty when rebasing the current branch).
#
# This sample shows how to prevent topic branches that are already
# merged to 'next' branch from getting rebased, because allowing it
# would result in rebasing already published history.

publish=next
basebranch="$1"
if test "$#" = 2
then
	topic="refs/heads/$2"
else
	topic=`git symbolic-ref HEAD` ||
	exit 0 ;# we do not interrupt rebasing detached HEAD
fi

case "$topic" in
refs/heads/??/*)
	;;
*)
	exit 0 ;# we do not interrupt others.
	;;
esac

# Now we are dealing with a topic branch being rebased
# on top of master.  Is it OK to rebase it?

# Does the topic really exist?
git show-ref -q "$topic" || {
	echo >&2 "No such branch $topic"
	exit 1
}

# Is topic fully merged to master?
not_in_master=`git rev-list --pretty=oneline ^master "$topic"`
if test -z "$not_in_master"
then
	echo >&2 "$topic is fully merged to master; better remove it."
	exit 1 ;# we could allow it, but there is no point.
fi

# Is topic ever merged to next?  If so you should not be rebasing it.
only_next_1=`git rev-list ^master "^$topic" ${publish} | sort`
only_next_2=`git rev-list ^master           ${publish} | sort`
if test "$only_next_1" = "$only_next_2"
then
	not_in_topic=`git rev-list "^$topic" master`
	if test -z "$not_in_topic"
	then
		echo >&2 "$topic is already up to date with master"
		exit 1 ;# we could allow it, but there is no point.
	else
		exit 0
	fi
else
	not_in_next=`git rev-list --pretty=oneline ^${publish} "$topic"`
	/usr/bin/perl -e '
		my $topic = $ARGV[0];
		my $msg = "* $topic has commits already merged to public branch:\n";
		my (%not_in_next) = map {
			/^([0-9a-f]+) /;
			($1 => 1);
		} split(/\n/, $ARGV[1]);
		for my $elem (map {
				/^([0-9a-f]+) (.*)$/;
				[$1 => $2];
			} split(/\n/, $ARGV[2])) {
			if (!exists $not_in_next{$elem->[0]}) {
				if ($msg) {
					print STDERR $msg;
					undef $msg;
				}
				print STDERR " $elem->[1]\n";
			}
		}
	' "$topic" "$not_in_next" "$not_in_master"
	exit 1
fi

<<\DOC_END

This sample hook safeguards topic branches that have been
published from being rewound.

The workflow assumed here is:

 * Once a topic branch forks from "master", "master" is never
   merged into it again (either directly or indirectly).

 * Once a topic branch is fully cooked and merged into "master",
   it is deleted.  If you need to build on top of it to correct
   earlier mistakes, a new topic branch is created by forking at
   the tip of the "master".  This is not strictly necessary, but
   it makes it easier to keep your history simple.

 * Whenever you need to test or publish your changes to topic
   branches, merge them into "next" branch.

The script, being an example, hardcodes the publish branch name
to be "next", but it is trivial to make it configurable via
$GIT_DIR/config mechanism.

With this workflow, you would want to know:

(1) ... if a topic branch has ever been merged to "next".  Young
    topic branches can have stupid mistakes you would rather
    clean up before publishing, and things that have not been
    merged into other branches can be easily rebased without
    affecting other people.  But once it is published, you would
    not want to rewind it.

(2) ... if a topic branch has been fully merged to "master".
    Then you can delete it.  More importantly, you should not
    build on top of it -- other people may already want to
    change things related to the topic as patches against your
    "master", so if you need further changes, it is better to
    fork the topic (perhaps with the same name) afresh from the
    tip of "master".

Let's look at this example:

		   o---o---o---o---o---o---o---o---o---o "next"
		  /       /           /           /
		 /   a---a---b A     /           /
		/   /               /           /
	       /   /   c---c---c---c B         /
	      /   /   /             \         /
	     /   /   /   b---b C     \       /
	    /   /   /   /             \     /
    ---o---o---o---o---o---o---o---o---o---o---o "master"


A, B and C are topic branches.

 * A has one fix since it was merged up to "next".

 * B has finished.  It has been fully merged up to "master" and "next",
   and is ready to be deleted.

 * C has not merged to "next" at all.

We would want to allow C to be rebased, refuse A, and encourage
B to be deleted.

To compute (1):

	git rev-list ^master ^topic next
	git rev-list ^master        next

	if these match, topic has not merged in next at all.

To compute (2):

	git rev-list master..topic

	if this is empty, it is fully merged to "master".

DOC_END


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\.git\hooks\pre-receive.sample
-----------------------------------------------------
#!/bin/sh
#
# An example hook script to make use of push options.
# The example simply echoes all push options that start with 'echoback='
# and rejects all pushes when the "reject" push option is used.
#
# To enable this hook, rename this file to "pre-receive".

if test -n "$GIT_PUSH_OPTION_COUNT"
then
	i=0
	while test "$i" -lt "$GIT_PUSH_OPTION_COUNT"
	do
		eval "value=\$GIT_PUSH_OPTION_$i"
		case "$value" in
		echoback=*)
			echo "echo from the pre-receive-hook: ${value#*=}" >&2
			;;
		reject)
			exit 1
		esac
		i=$((i + 1))
	done
fi


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\.git\hooks\prepare-commit-msg.sample
-----------------------------------------------------
#!/bin/sh
#
# An example hook script to prepare the commit log message.
# Called by "git commit" with the name of the file that has the
# commit message, followed by the description of the commit
# message's source.  The hook's purpose is to edit the commit
# message file.  If the hook fails with a non-zero status,
# the commit is aborted.
#
# To enable this hook, rename this file to "prepare-commit-msg".

# This hook includes three examples. The first one removes the
# "# Please enter the commit message..." help message.
#
# The second includes the output of "git diff --name-status -r"
# into the message, just before the "git status" output.  It is
# commented because it doesn't cope with --amend or with squashed
# commits.
#
# The third example adds a Signed-off-by line to the message, that can
# still be edited.  This is rarely a good idea.

COMMIT_MSG_FILE=$1
COMMIT_SOURCE=$2
SHA1=$3

/usr/bin/perl -i.bak -ne 'print unless(m/^. Please enter the commit message/..m/^#$/)' "$COMMIT_MSG_FILE"

# case "$COMMIT_SOURCE,$SHA1" in
#  ,|template,)
#    /usr/bin/perl -i.bak -pe '
#       print "\n" . `git diff --cached --name-status -r`
# 	 if /^#/ && $first++ == 0' "$COMMIT_MSG_FILE" ;;
#  *) ;;
# esac

# SOB=$(git var GIT_COMMITTER_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
# git interpret-trailers --in-place --trailer "$SOB" "$COMMIT_MSG_FILE"
# if test -z "$COMMIT_SOURCE"
# then
#   /usr/bin/perl -i.bak -pe 'print "\n" if !$first_line++' "$COMMIT_MSG_FILE"
# fi


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\.git\hooks\update.sample
-----------------------------------------------------
#!/bin/sh
#
# An example hook script to block unannotated tags from entering.
# Called by "git receive-pack" with arguments: refname sha1-old sha1-new
#
# To enable this hook, rename this file to "update".
#
# Config
# ------
# hooks.allowunannotated
#   This boolean sets whether unannotated tags will be allowed into the
#   repository.  By default they won't be.
# hooks.allowdeletetag
#   This boolean sets whether deleting tags will be allowed in the
#   repository.  By default they won't be.
# hooks.allowmodifytag
#   This boolean sets whether a tag may be modified after creation. By default
#   it won't be.
# hooks.allowdeletebranch
#   This boolean sets whether deleting branches will be allowed in the
#   repository.  By default they won't be.
# hooks.denycreatebranch
#   This boolean sets whether remotely creating branches will be denied
#   in the repository.  By default this is allowed.
#

# --- Command line
refname="$1"
oldrev="$2"
newrev="$3"

# --- Safety check
if [ -z "$GIT_DIR" ]; then
	echo "Don't run this script from the command line." >&2
	echo " (if you want, you could supply GIT_DIR then run" >&2
	echo "  $0 <ref> <oldrev> <newrev>)" >&2
	exit 1
fi

if [ -z "$refname" -o -z "$oldrev" -o -z "$newrev" ]; then
	echo "usage: $0 <ref> <oldrev> <newrev>" >&2
	exit 1
fi

# --- Config
allowunannotated=$(git config --bool hooks.allowunannotated)
allowdeletebranch=$(git config --bool hooks.allowdeletebranch)
denycreatebranch=$(git config --bool hooks.denycreatebranch)
allowdeletetag=$(git config --bool hooks.allowdeletetag)
allowmodifytag=$(git config --bool hooks.allowmodifytag)

# check for no description
projectdesc=$(sed -e '1q' "$GIT_DIR/description")
case "$projectdesc" in
"Unnamed repository"* | "")
	echo "*** Project description file hasn't been set" >&2
	exit 1
	;;
esac

# --- Check types
# if $newrev is 0000...0000, it's a commit to delete a ref.
zero="0000000000000000000000000000000000000000"
if [ "$newrev" = "$zero" ]; then
	newrev_type=delete
else
	newrev_type=$(git cat-file -t $newrev)
fi

case "$refname","$newrev_type" in
	refs/tags/*,commit)
		# un-annotated tag
		short_refname=${refname##refs/tags/}
		if [ "$allowunannotated" != "true" ]; then
			echo "*** The un-annotated tag, $short_refname, is not allowed in this repository" >&2
			echo "*** Use 'git tag [ -a | -s ]' for tags you want to propagate." >&2
			exit 1
		fi
		;;
	refs/tags/*,delete)
		# delete tag
		if [ "$allowdeletetag" != "true" ]; then
			echo "*** Deleting a tag is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/tags/*,tag)
		# annotated tag
		if [ "$allowmodifytag" != "true" ] && git rev-parse $refname > /dev/null 2>&1
		then
			echo "*** Tag '$refname' already exists." >&2
			echo "*** Modifying a tag is not allowed in this repository." >&2
			exit 1
		fi
		;;
	refs/heads/*,commit)
		# branch
		if [ "$oldrev" = "$zero" -a "$denycreatebranch" = "true" ]; then
			echo "*** Creating a branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/heads/*,delete)
		# delete branch
		if [ "$allowdeletebranch" != "true" ]; then
			echo "*** Deleting a branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/remotes/*,commit)
		# tracking branch
		;;
	refs/remotes/*,delete)
		# delete tracking branch
		if [ "$allowdeletebranch" != "true" ]; then
			echo "*** Deleting a tracking branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	*)
		# Anything else (is there anything else?)
		echo "*** Update hook: unknown type of update to ref $refname of type $newrev_type" >&2
		exit 1
		;;
esac

# --- Finished
exit 0


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\.gitignore
-----------------------------------------------------
/target/
documentum
**/cache
/cache
**/logs
.idea
*~
.classpath
.eclim
.project
.settings
.*.sw[pon]
#.vault-password
indices/
*.log
*.jar
*.tmp
*.lck
# certs
*.p12
# ansible
*.retry


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\.gitlab-ci.yml
-----------------------------------------------------
image: "docker-28008-repo.repo.devops.poalim.bank/dctm-build-full:0.0.4"
before_script:
  - echo "Before script started"
  - export ENV="prod"
#  - echo "** ENV LIST"
#  - set
#  - echo "Before script finished"

stages:
  - genarate_ssh_and_deploy
    
variables:
    IMAGE: "${DOCKER_REPO}/$CI_PROJECT_NAME:$CI_COMMIT_SHORT_SHA"

genarate_ssh_and_deploy:
  stage: genarate_ssh_and_deploy
  environment:
    name: ${ENV}
  script:
    - echo "job ssh and deploy started"
#    - if [ "${DFS_HOST}" == "" ]; then 
#        echo "you must fill DFS_HOST. program will exit "; 
#        exit 1; 
#       fi
    - if [ "${ENV}" == "" ]; then 
        echo "you must fill ENV. dev or test. program will exit "; 
        exit 1; 
       fi
    #- set -x  
    - umask 077
    - mkdir -p "${HOME}/.ssh"
    - echo "${SSH_KEY}" > "${HOME}/.ssh/id_rsa"
    - echo "${SSH_PUBLIC_KEY}" > "${HOME}/.ssh/id_rsa.pub"
#    - ssh-keyscan -t rsa  -p 22 ${DFS_HOST} > "${HOME}/.ssh/known_hosts"
    
    - if [ "${REST_VERSION}" == "" ]; then 
        echo "you must fill REST_VERSION "; 
        echo "program will exit "; 
        exit 1; 
        fi
#    - export LAST_VERSION=$(git describe --match "BnhpInfraDctmRest-[0-9].*" --tags --always )
    - git checkout master
    - git pull
#    - export REST_VERSION=$(git tag | grep "^BnhpInfraDctmRest" | sort -V | tail -1  | sed -e 's/^[0-9A-Za-z_]\+-//g')
#    - echo "last version of BnhpInfraDctmRest is ${REST_VERSION}" 
#    - export REST_VERSION="0.0.5"    
#    - export DFS_VERSION=$(git tag | grep "^BnhpInfraDFServices" | sort -V | tail -1 )
#    - export GENERAL_VERSION=$(git tag | grep "^BnhpEcmGeneralDocServices" | sort -V | tail -1 )
    - mvn dependency:copy -Dartifact="com.poalim.documentum:BnhpInfraDctmRest:${REST_VERSION}:pom" -DoutputDirectory="." -s ./settings.xml  
    - mv "BnhpInfraDctmRest-${REST_VERSION}.pom" pom.xml
            
    - mkdir -p target/lib
    - mvn dependency:copy -Dartifact="com.poalim.documentum:BnhpInfraDctmRest:${REST_VERSION}" -s ./settings.xml -DoutputDirectory="./target" 
    - mvn dependency:copy-dependencies -Dartifact="com.poalim.documentum:BnhpInfraDctmRest:${REST_VERSION}" -s ./settings.xml -DoutputDirectory="./target/lib"
    - ls -l target/lib/*.jar
    
    - export dfs_version=$(mvn dependency:tree | grep com.poalim.documentum:BnhpInfraDFServices:jar:basic | grep -oP '(?<=com.poalim.documentum:BnhpInfraDFServices:jar:basic:).*?(?=:)')
    - echo "dfs_version=${dfs_version}"
#    - mvn dependency:copy -Dartifact="com.poalim.documentum:BnhpInfraDctmRest:${LAST_VERSION}" -s ./settings.xml -DoutputDirectory="./target" 
#    - mvn dependency:copy -Dartifact="com.poalim.documentum:BnhpInfraDFServices:${DFS_VERSION}" -s ./settings.xml -DoutputDirectory="./target" 
#    - mvn dependency:copy -Dartifact="com.poalim.documentum:BnhpEcmGeneralDocServices:${GENERAL_VERSION}" -s ./settings.xml -DoutputDirectory="./target" 
    

    - echo "deploy it with gitlab server on documentum dev "
#    - ansible ${ENV} -v -m ping  -i ansible/hosts --extra-vars "env=${ENV}  ansible_ssh_pass=${ANSIBLE_PASSWORD} ansible_become_pass=${ANSIBLE_PASSWORD}" 
    - ansible-playbook  -v --vault-id .vault-password -i ansible/hosts ansible/app-install.yml  --extra-vars "appversion=${REST_VERSION}  env=${ENV}  dfs_version=${dfs_version} ansible_ssh_pass=${ANSIBLE_PASSWORD} ansible_become_pass=${BECOME_PASSWORD}" 
    - echo "job ssh and deploy finished"
  only:
    - master    
  tags:
    - documentum-prod


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\.tag
-----------------------------------------------------
dudctmrest:0.0.1


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\.vault-password
-----------------------------------------------------
ans0001cool99


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\ansible\app-install.yml
-----------------------------------------------------
---
# playbook to install application instance
# Please see README.md on how to use this playbook
- hosts: "{{ env }}"
  gather_facts: "no" 
  vars: 
#   - dfs_version : "1.0.3"
    - appdir: "{{envdir}}/duecmrest"
    - java_home: "{{envdir}}/java/jdk1.8.0_152"
    - jar_name: "BnhpInfraDctmRest-{{appversion}}.jar"
    - service_name: "duecmrest"
  tasks:
    - fail: msg="required variables env must be set!"
      when: env is undefined
    - fail: msg="required variables dfs_version must be set!"
      when: dfs_version is undefined
    - fail: msg="required variables appversion must be set!"
      when: appversion is undefined
    - name: ssh to pdcmdfs-7
      local_action: shell ssh-keyscan -t rsa -p {{ansible_port}} {{inventory_hostname}} >> ~/.ssh/known_hosts
    - name: include env. specific vars from file
      include_vars:
        file: ../resources-{{env}}/env_vars.yaml
    - name: ensure target directory
      file:
        path: "{{appdir}}"
        state: directory
        mode: 0700
        owner: "{{app_user}}"
      become_method: "{{use_become_method}}"
      become: "{{need_become}}"
    - name: ensure logs directory
      file:
        path: "{{appdir}}/logs"
        state: directory
        mode: 0700
        owner: "{{app_user}}"
      become_method: "{{use_become_method}}"
      become: "{{need_become}}"
    - name: ensure lib directory
      file:
        path: "{{appdir}}/lib"
        state: directory
        mode: 0700
        owner: "{{app_user}}"
      become_method: "{{use_become_method}}"
      become: "{{need_become}}"
    - name: copy jar to server
      copy:
        backup: "{{need_backup}}"
        dest: "{{appdir}}/"
        src: ../target/{{jar_name}}
        force: yes
        mode: 0600
      become_user: "{{app_user}}"
      become_method: "{{use_become_method}}"
      become: "{{need_become}}"
    - name: ensure resources directory
      file:
        path: "{{appdir}}/resources"
        state: directory
        mode: 0700
        owner: "{{app_user}}"
      become_method: "{{use_become_method}}"
      become: "{{need_become}}"
    - name: ensure resources {{env}} directory
      file:
        path: "{{appdir}}/resources-{{env}}"
        state: directory
        mode: 0700
        owner: "{{app_user}}"
      become_method: "{{use_become_method}}"
      become: "{{need_become}}"
    - name: ensure basic-classes directory
      file:
        path: "{{appdir}}/basic-classes"
        state: directory
        mode: 0700
        owner: "{{app_user}}"
      become_method: "{{use_become_method}}"
      become: "{{need_become}}"
    - name: copy dependencies to server
      synchronize:
        dest: "{{appdir}}/lib/"
        src: ../target/lib/
      # set_remote_user: "no"
      # become_user: "{{app_user}}"
      become_method: "{{use_become_method}}"
      become: "{{need_become}}"
    - name: copy shared resources to server
      synchronize:
        dest: "{{appdir}}/resources/"
        src: ../resources/
        rsync_opts: [ "--exclude" , "dfc*.properties", "--exclude" ,"*.keystore" ]
      #become_user: "{{app_user}}"
      become_method: "{{use_become_method}}"
      become: "{{need_become}}"
    - name: copy env specific resources
      synchronize:
        dest: "{{appdir}}/resources-{{env}}/"
        src: "../resources-{{env}}/"
        # exclude encrypted files
        rsync_opts: [ "--exclude" , "server.keystore.jks", --exclude ,"DctmRestSecrets.yml" ]
      #become_user: "{{app_user}}"
      become_method: "{{use_become_method}}"
      become: "{{need_become}}"
    - name: unarchive basic module
      unarchive:
        dest: "{{appdir}}/basic-classes/"
        src: "../target/lib/BnhpInfraDFServices-{{dfs_version}}-basic.jar"   
      become_user: "{{app_user}}"
      become_method: "{{use_become_method}}"
      become: "{{need_become}}"
#    - name: copy dfc extended properties (per host)
#      template:
#        dest: "{{appdir}}/resources-{{env}}/dfc_extended.properties"
#        src: dfc_extended.properties.template
#        mode: 0644
#        force: yes
#      become_method: "{{use_become_method}}"
#      become: "{{need_become}}"
    - name: copy secrets to server
      copy:
        backup: "{{need_backup}}"
        dest: "{{appdir}}/resources-{{env}}/"
        src: ../resources-{{env}}/DctmRestSecrets.yml
        force: yes
        mode: 0600
      become_user: "{{app_user}}"
      become_method: "{{use_become_method}}"
      become: "{{need_become}}"
    - name: copy secrets to server
      copy:
        backup: "{{need_backup}}"
        dest: "{{appdir}}/resources-{{env}}/"
        src: ../resources-{{env}}/server.keystore.jks
        force: yes
        mode: 0600
      become_user: "{{app_user}}"
      become_method: "{{use_become_method}}"
      become: "{{need_become}}"
#    - name: copy extra config to server
#      copy:
#        backup: "{{need_backup}}"
#        dest: "{{appdir}}/resources-{{env}}/"
#        src: ../resources-{{env}}/DctmRestAppExtra.yml
#        force: yes
#        mode: 0600
#      become_user: "{{app_user}}"
#      become_method: "{{use_become_method}}"
#      become: "{{need_become}}"
    - name: copy application startup script
      template:
        dest: "{{appdir}}/{{service_name}}"
        src: ../scripts/{{service_name}}.template.sh
        mode: 0755
        force: yes
      become_method: "{{use_become_method}}"
      become: "{{need_become}}"
#    - name: change owner
#      command: /bin/chown -R "{{app_user}}.{{app_user}}" "{{appdir}}"
#      become: yes
#      become_method: "{{use_become_method}}"
#      become_user: root
#    - name: copy SYSV startup script
#      template:
#        dest: "/etc/init.d/{{service_name}}"
#        src: ../scripts/{{service_name}}.template.init.sh
#        mode: 0700
#        force: yes
#      become: yes
#      become_method: "{{use_become_method}}"
    - name: copy backup_logs script
      template:
        dest: "."
        src: ../scripts/backup_logs.sh
        mode: 0700
        force: yes
    - name: copy curl-dev scripts
      copy:
        dest: "{{appdir}}/"
        src: ../scripts/curl-dev
        force: yes
        mode: 0755
    - name: copy curl-st scripts
      copy:
        dest: "{{appdir}}/"
        src: ../scripts/curl-st
        force: yes
        mode: 0755
    - name: copy curl-prod scripts
      copy:
        dest: "{{appdir}}/"
        src: ../scripts/curl-prod
        force: yes
        mode: 0755
#    - name: copy SYSV defaults file
#      template:
#        backup: no
#        dest: "/etc/default/{{service_name}}"
#        src: ../scripts/default.template.sh
#        mode: 0600
#        force: yes
#      become: yes
#      become_method: "{{use_become_method}}"      

#    - name: register SYSV init script
#      command: /sbin/chkconfig --add "/etc/init.d/{{service_name}}"
#      become: yes
#      become_method: "{{use_become_method}}"
#    - name: configure service for auto startup
#      command: /sbin/chkconfig "{{service_name}}" on
#      become: yes
#      become_method: "{{use_become_method}}"
#    - name: run backup logs script
#      command: "{{appdir}}/backup_logs.sh"
#    - name: restart service 
#      command: /etc/init.d/{{service_name}} restart
#      become: yes
#      become_method: "{{use_become_method}}"

      


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\ansible\dfc_extended.properties.template
-----------------------------------------------------
# sets local dfc instance name (per app instance)
#dfc.name={{ansible_facts['nodename']}}_{{service_name}}
dfc.name={{inventory_hostname_short}}_{{service_name}}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\ansible\docbase-install.yml
-----------------------------------------------------
---
# playbook to install documentum and oracle objects
# Please see README.md on how to use this playbook
# **** WARNING! *****
# this script will drop and recreate documentum type
# and all it's existing objects
- hosts: "{{env}}_cs"
  remote_user: dctm
  vars:
    - appversion: "0.0.1-SNAPSHOT"
    - appdir: "{{envdir}}/duecmrest"
    - dqldir: "{{appdir}}/dql"
    - dctm_user: "dctm"
  tasks:
    - fail: msg="required variables env must be set!"
      when: env is undefined
    - name: include env. specific vars from file
      include_vars:
        file: ../resources-{{env}}/env_vars.yaml
    - name: ensure target directory
      file:
        path: "{{appdir}}"
        state: directory
        mode: 0700
        owner: "{{app_user}}"
      become_method: "{{use_become_method}}"
      become: "{{need_become}}"      
    - name: ensure dql directory
      file:
        path: "{{dqldir}}"
        state: directory
        mode: 0700
      become_user: "{{app_user}}"
      become_method: "{{use_become_method}}"
      become: "{{need_become}}"
    - name: copy dql scripts
      synchronize:
        dest: "{{appdir}}/dql/"
        src: "../dql/"
      become_user: "{{app_user}}"
      become_method: "{{use_become_method}}"
      become: "{{need_become}}"
    - name: drop SQL stored procedure/indices
      command: sqlplus "{{orauser}}/{{orapass}}@{{orainstance}}" "@" "{{dqldir}}/drop_BNHP_ASYNC_REQUEST_objects.sql"
      become_user: "{{app_user}}"
      become_method: "{{use_become_method}}"
      become: "{{need_become}}"
    - name: drop/create document type
      command:  $DM_HOME/bin/idql "{{docbase}}" "-U{{app_user}}" -P "-R{{dqldir}}/create_BNHP_ASYNC_REQUEST_type.dql"
      register: dqlresult
      failed_when: dqlresult.rc>=2 or dqlresult.rc<0
      become_user: "{{app_user}}"
      become_method: "{{use_become_method}}"
      become: "{{need_become}}"
    - name: create SQL stored procedure/indices
      command: sqlplus "{{orauser}}/{{orapass}}@{{orainstance}}" "@" "{{dqldir}}/create_BNHP_ASYNC_REQUEST_objects.sql"
      become_user: "{{app_user}}"
      become_method: "{{use_become_method}}"
      become: "{{need_become}}"

      


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\ansible\hosts
-----------------------------------------------------

[test]

sdcmdfs01-7.restest.bank

#ansible_user=wasadm

[test:vars]
envdir=/usr/SDC
ansible_user=dctm
need_become=yes
use_become_method=su
need_backup=yes
app_user=dctm

[test_cs]
sdcmcs01.restest.bank

[test_cs:vars]
envdir=/home/dctm
ansible_user=dctm
need_become=no
use_become_method=su
need_backup=no
app_user=dctm


[dev]

tdcmdfs01-7.restest.bank

[dev:vars]
envdir=/usr/TDC
ansible_user=wasadm
need_become=no
use_become_method=su
need_backup=no
app_user=wasadm

[dev_cs]
tdcmcs01-7.restest.bank

[dev_cs:vars]
envdir=/home/dctm
ansible_user=dctm
need_become=no
use_become_method=su
need_backup=no
app_user=dctm



[prod]
pdcmdfs01-7.resource.bank
pdcmdfs02-7.resource.bank
pdcmdfs03-7.resource.bank
pdcmdfs04-7.resource.bank

[prod:vars]
envdir=/usr/PDC/PDCSHAI
ansible_user=wasadm
ansible_port=22
need_become=no
use_become_method=su
need_backup=no
app_user=wasadm

[prod_cs]
pdcmcs01.resource.bank

[prod_cs:vars]
envdir=/home/dctm
ansible_user=dctm
need_become=no
use_become_method=su
need_backup=no
app_user=dctm

[all:vars]





file Read:C:\Users\AP068\git\documentum\rest-cd-prod\Dockerfile
-----------------------------------------------------
FROM docker-ext.repo.devops.poalim.bank/maven:3.6.2-jdk-8
ARG ARTIFACTORY_USER
ARG ARTIFACTORY_PASSWORD
VOLUME /tmp
WORKDIR /app
COPY . /app
RUN mvn -X -s ./settings.xml  install -q  -DskipTests


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\pom.xml
-----------------------------------------------------
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<artifactId>BnhpInfraDctmRest</artifactId>
	<groupId>com.poalim.documentum</groupId>
	<packaging>jar</packaging>
	<name>BnhpInfraDctmRest</name>
	<description>BnhpInfraDctmRest</description>
	<version>0.0.7</version>

	<properties>
		<java.version>1.8</java.version>
		<maven.compiler.target>1.8</maven.compiler.target>
		<maven.compiler.source>1.8</maven.compiler.source>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
		<!--version.framework>0.1.1</version.framework -->
		<version.jackson>2.8.11</version.jackson>
		<version.jackson.databind>2.8.11.2</version.jackson.databind>
		<version.jackson.jsr310>2.8.10</version.jackson.jsr310>
		<!--version.slf4j>1.7.21</version.slf4j> <version.jose4j>0.5.2</version.jose4j> 
			<version.antlr4>4.5.3</version.antlr4> <version.commons-lang>2.6</version.commons-lang> 
			<version.commons.io>2.5</version.commons.io> <version.commons.codec>1.10</version.commons.codec> 
			<version.encoder>1.2</version.encoder> <version.metrics>3.1.2</version.metrics> 
			<version.logback>1.1.7</version.logback -->
		<version.junit>4.12</version.junit>
		<!--version.mockito>2.1.0-beta.124</version.mockito -->
		<version.undertow>1.4.25.Final</version.undertow>
		<!--version.jsonpath>2.2.0</version.jsonpath> <version.httpclient>4.5.2</version.httpclient> 
			<version.httpasyncclient>4.1.2</version.httpasyncclient -->
		<version.swagger>1.5.10</version.swagger>
	</properties>

	<dependencies>
		<!--dependency> <groupId>com.networknt</groupId> <artifactId>config</artifactId> 
			<version>${version.framework}</version> </dependency> <dependency> <groupId>com.networknt</groupId> 
			<artifactId>utility</artifactId> <version>${version.framework}</version> 
			</dependency> <dependency> <groupId>com.networknt</groupId> <artifactId>security</artifactId> 
			<version>${version.framework}</version> </dependency> <dependency> <groupId>com.networknt</groupId> 
			<artifactId>client</artifactId> <version>${version.framework}</version> </dependency> 
			<dependency> <groupId>com.networknt</groupId> <artifactId>audit</artifactId> 
			<version>${version.framework}</version> </dependency> <dependency> <groupId>com.networknt</groupId> 
			<artifactId>info</artifactId> <version>${version.framework}</version> </dependency> 
			<dependency> <groupId>com.networknt</groupId> <artifactId>validator</artifactId> 
			<version>${version.framework}</version> </dependency> <dependency> <groupId>com.networknt</groupId> 
			<artifactId>server</artifactId> <version>${version.framework}</version> </dependency -->
		<dependency>
			<groupId>org.apache.pdfbox</groupId>
			<artifactId>pdfbox</artifactId>
			<version>1.6.0</version>
		</dependency>
		<dependency>
			<groupId>com.fasterxml.jackson.core</groupId>
			<artifactId>jackson-databind</artifactId>
			<version>${version.jackson.databind}</version>
		</dependency>
		<dependency>
			<groupId>com.fasterxml.jackson.core</groupId>
			<artifactId>jackson-core</artifactId>
			<version>${version.jackson}</version>
		</dependency>
		<dependency>
			<groupId>com.fasterxml.jackson.datatype</groupId>
			<artifactId>jackson-datatype-jsr310</artifactId>
			<version>${version.jackson.jsr310}</version>
		</dependency>
		<dependency>
			<groupId>com.fasterxml.jackson.core</groupId>
			<artifactId>jackson-annotations</artifactId>
			<version>${version.jackson}</version>
		</dependency>
		<!--dependency> <groupId>com.jayway.jsonpath</groupId> <artifactId>json-path</artifactId> 
			<version>${version.jsonpath}</version> </dependency> <dependency> <groupId>ch.qos.logback</groupId> 
			<artifactId>logback-classic</artifactId> <version>${version.logback}</version> 
			</dependency -->
		<dependency>
			<groupId>io.undertow</groupId>
			<artifactId>undertow-core</artifactId>
			<version>${version.undertow}</version>
		</dependency>
		<dependency>
			<groupId>io.swagger</groupId>
			<artifactId>swagger-annotations</artifactId>
			<version>${version.swagger}</version>
		</dependency>
		<dependency>
			<groupId>org.cfg4j</groupId>
			<artifactId>cfg4j-core</artifactId>
			<version>4.4.0</version>
		</dependency>
		<!-- Test Dependencies -->
		<dependency>
			<groupId>junit</groupId>
			<artifactId>junit</artifactId>
			<version>${version.junit}</version>
			<scope>test</scope>
		</dependency>
		<!--dependency> <groupId>org.apache.httpcomponents</groupId> <artifactId>httpclient</artifactId> 
			<version>${version.httpclient}</version> <scope>test</scope> </dependency -->
		<!--dependency> <groupId>com.poalim.log</groupId> <artifactId>logger-log4j2</artifactId> 
			<version>1.1</version> <exclusions> <exclusion> <groupId>org.slf4j</groupId> 
			<artifactId>jcl-over-slf4j</artifactId> </exclusion> <exclusion> <groupId>org.slf4j</groupId> 
			<artifactId>jul-to-slf4j</artifactId> </exclusion> </exclusions> </dependency -->
		<dependency>
			<groupId>org.python</groupId>
			<artifactId>jython-standalone</artifactId>
			<version>2.7.1</version>
		</dependency>
		<dependency>
			<artifactId>jwtutil</artifactId>
			<!-- packaging plugin cannot deal with clasifier and snapshot version 
				at the same time! -->
			<version>0.0.1</version>
			<groupId>com.poalim.documentum</groupId>
			<classifier>uber</classifier>
			<exclusions>
				<exclusion>
					<groupId>commons-codec</groupId>
					<artifactId>commons-codec</artifactId>
				</exclusion>
			</exclusions>
		</dependency>
		<dependency>
			<artifactId>BnhpInfraDFServices</artifactId>
			<version>1.0.3</version>
			<groupId>com.poalim.documentum</groupId>
			<classifier>basic</classifier>
			<exclusions>
				<exclusion>
					<groupId>com.ibm</groupId>
					<artifactId>javax.j2ee.jms</artifactId>
				</exclusion>


				<!--exclusion> <groupId>com.ibm</groupId> <artifactId>org.apache.axis2</artifactId> 
					</exclusion -->
				<exclusion>
					<groupId>com.ibm.websphere.jython</groupId>
					<artifactId>jython</artifactId>
				</exclusion>
				<exclusion>
					<groupId>com.ibm.websphere.jython</groupId>
					<artifactId>jython-lib</artifactId>
				</exclusion>

				<exclusion>
					<groupId>was</groupId>
					<artifactId>jaxws_thinclient</artifactId>
				</exclusion>

				<exclusion>
					<groupId>nopagingbranch-remote</groupId>
					<artifactId>nopagingbranch-remote</artifactId>
				</exclusion>

				<!--exclusion> <groupId>org.apache.velocity</groupId> <artifactId>velocity</artifactId> 
					</exclusion -->

				<exclusion>
					<groupId>org.slf4j</groupId>
					<artifactId>slf4j-api</artifactId>
				</exclusion>

				<exclusion>
					<groupId>ch.qos.logback</groupId>
					<artifactId>logback-core</artifactId>
				</exclusion>

				<exclusion>
					<groupId>ch.qos.logback</groupId>
					<artifactId>logback-classic</artifactId>
				</exclusion>

				<!--exclusion> <groupId>org.apache.logging.log4j</groupId> <artifactId>log4j-core</artifactId> 
					</exclusion> <exclusion> <groupId>org.apache.logging.log4j</groupId> <artifactId>log4j-api</artifactId> 
					</exclusion -->
				<exclusion>
					<groupId>com.poalim.dependencies</groupId>
					<artifactId>documentum-71-deps</artifactId>
				</exclusion>


				<exclusion>
					<groupId>com.poalim.saf.services</groupId>
					<artifactId>to-cyberark-transfer</artifactId>
				</exclusion>

				<exclusion>
					<groupId>com.poalim.saf.services</groupId>
					<artifactId>du-ecm-customer-temp</artifactId>
				</exclusion>

				<exclusion>
					<groupId>com.poalim.ht</groupId>
					<artifactId>saf-core</artifactId>
				</exclusion>

				<exclusion>
					<groupId>com.poalim.documentum</groupId>
					<artifactId>fundamentalDocsV2</artifactId>
				</exclusion>


			</exclusions>
		</dependency>

		<dependency>
			<artifactId>BnhpInfraDFServices</artifactId>
			<version>1.0-SNAPSHOT</version>
			<groupId>com.poalim.documentum</groupId>
			<classifier>tests</classifier>
			<exclusions>
				<exclusion>
					<groupId>com.ibm</groupId>
					<artifactId>javax.j2ee.jms</artifactId>
				</exclusion>


				<!--exclusion> <groupId>com.ibm</groupId> <artifactId>org.apache.axis2</artifactId> 
					</exclusion -->
				<exclusion>
					<groupId>com.ibm.websphere.jython</groupId>
					<artifactId>jython</artifactId>
				</exclusion>
				<exclusion>
					<groupId>com.ibm.websphere.jython</groupId>
					<artifactId>jython-lib</artifactId>
				</exclusion>

				<exclusion>
					<groupId>was</groupId>
					<artifactId>jaxws_thinclient</artifactId>
				</exclusion>

				<exclusion>
					<groupId>nopagingbranch-remote</groupId>
					<artifactId>nopagingbranch-remote</artifactId>
				</exclusion>

				<!--exclusion> <groupId>org.apache.velocity</groupId> <artifactId>velocity</artifactId> 
					</exclusion -->

				<exclusion>
					<groupId>org.slf4j</groupId>
					<artifactId>slf4j-api</artifactId>
				</exclusion>

				<exclusion>
					<groupId>ch.qos.logback</groupId>
					<artifactId>logback-core</artifactId>
				</exclusion>

				<exclusion>
					<groupId>ch.qos.logback</groupId>
					<artifactId>logback-classic</artifactId>
				</exclusion>

				<!--exclusion> <groupId>org.apache.logging.log4j</groupId> <artifactId>log4j-core</artifactId> 
					</exclusion> <exclusion> <groupId>org.apache.logging.log4j</groupId> <artifactId>log4j-api</artifactId> 
					</exclusion -->
				<exclusion>
					<groupId>com.poalim.dependencies</groupId>
					<artifactId>documentum-71-deps</artifactId>
				</exclusion>


				<exclusion>
					<groupId>com.poalim.saf.services</groupId>
					<artifactId>to-cyberark-transfer</artifactId>
				</exclusion>

				<exclusion>
					<groupId>com.poalim.saf.services</groupId>
					<artifactId>du-ecm-customer-temp</artifactId>
				</exclusion>

				<exclusion>
					<groupId>com.poalim.ht</groupId>
					<artifactId>saf-core</artifactId>
				</exclusion>

				<exclusion>
					<groupId>com.poalim.documentum</groupId>
					<artifactId>fundamentalDocsV2</artifactId>
				</exclusion>


			</exclusions>
		</dependency>


		<dependency>
			<groupId>org.apache.logging.log4j</groupId>
			<artifactId>log4j-core</artifactId>
			<version>2.3</version>
		</dependency>
		<dependency>
			<groupId>org.apache.logging.log4j</groupId>
			<artifactId>log4j-api</artifactId>
			<version>2.3</version>
		</dependency>

		<!-- documentumn dependencies -->
		<dependency>
			<groupId>com.poalim.dependencies</groupId>
			<artifactId>documentum-71-deps</artifactId>
			<type>pom</type>
			<version>1.0-SNAPSHOT</version>
			<!-- <exclusion><groupId>emc.dfs.sdk</groupId><artifactId>jaxb-api</artifactId></exclusion> 
				<exclusion><groupId>emc.dfs.sdk</groupId><artifactId>jaxb-impl</artifactId></exclusion> 
				<exclusion><groupId>emc.dfs.sdk</groupId><artifactId>jaxb-xjc</artifactId></exclusion> 
				<exclusion><groupId>emc.dfs.sdk</groupId><artifactId>jaxb1-impl</artifactId></exclusion> 
				<exclusion><groupId>emc.dfs.sdk</groupId><artifactId>jaxr-api</artifactId></exclusion> 
				<exclusion><groupId>emc.dfs.sdk</groupId><artifactId>jaxr-impl</artifactId></exclusion> 
				<exclusion><groupId>emc.dfs.sdk</groupId><artifactId>jaxws-api</artifactId></exclusion> 
				<exclusion><groupId>emc.dfs.sdk</groupId><artifactId>jaxws-rt</artifactId></exclusion> 
				<exclusion><groupId>emc.dfs.sdk</groupId><artifactId>jaxws-tools</artifactId></exclusion> -->
			<exclusions>
				<exclusion>
					<groupId>emc.dfs.sdk</groupId>
					<artifactId>commons-codec-1.3</artifactId>
				</exclusion>
			</exclusions>
		</dependency>

		<!--dependency> <groupId>emc.dfs.sdk</groupId> <artifactId>emc-dfs-rt</artifactId> 
			<version>${dctm.version}</version> </dependency> <dependency> <groupId>emc.dfs.sdk.dfc</groupId> 
			<artifactId>dfc</artifactId> <version>${dctm.version}</version> </dependency -->

		<!-- FIXME: LIOR STUFF - not really needed! -->
		<dependency>
			<groupId>bnhp.infra.dfs.services</groupId>
			<artifactId>BHInputObjectContexts</artifactId>
			<version>1.0</version>
		</dependency>

		<dependency>
			<groupId>bnhp.infra.dfs.services</groupId>
			<artifactId>BHSearchContexts</artifactId>
			<version>1.0</version>
		</dependency>

		<dependency>
			<groupId>bnhp.infra.dfs.services</groupId>
			<artifactId>BHObjectContexts</artifactId>
			<version>1.0</version>
		</dependency>

		<dependency>
			<groupId>bnhp.infra.dfs.services</groupId>
			<artifactId>BHAuthorization</artifactId>
			<version>1.0</version>
		</dependency>

		<dependency>
			<groupId>bnhp.infra.dfs.services</groupId>
			<artifactId>BHGeneralUtil</artifactId>
			<version>1.0</version>
		</dependency>

		<dependency>
			<groupId>bnhp.infra.dfs.services</groupId>
			<artifactId>BHPeulaException</artifactId>
			<version>1.0</version>
		</dependency>

		<dependency>
			<groupId>com.poalim.documentum</groupId>
			<artifactId>BnhpEcmGeneralDocServices</artifactId>
			<version>1.0.14</version>
			<exclusions>
				<exclusion>
					<groupId>com.poalim.documentum</groupId>
					<artifactId>BnhpInfraDFServices</artifactId>
				</exclusion>
			</exclusions>
		</dependency>

		<!--dependency> <groupId>com.auth0</groupId> <artifactId>java-jwt</artifactId> 
			<version>3.4.0</version> </dependency -->

	</dependencies>





	<build>
		<defaultGoal>install</defaultGoal>
		<directory>target</directory>
		<finalName>${project.artifactId}-${project.version}</finalName>
		<plugins>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-enforcer-plugin</artifactId>
				<version>3.0.0-M1</version>
				<executions>
					<execution>
						<id>enforce-maven</id>
						<goals>
							<goal>enforce</goal>
						</goals>
						<configuration>
							<rules>
								<requireMavenVersion>
									<version>2.2.0</version>
								</requireMavenVersion>
							</rules>
						</configuration>
					</execution>
				</executions>
			</plugin>
			<!--plugin> <groupId>org.apache.maven.plugins</groupId> <artifactId>maven-shade-plugin</artifactId> 
				<version>2.4.3</version> <executions> <execution> <phase>package</phase> 
				<goals> <goal>shade</goal> </goals> <configuration> <transformers> <transformer implementation="org.apache.maven.plugins.shade.resource.ServicesResourceTransformer" /> </transformers> <filters> <filter> <artifact>*:*</artifact> <excludes> 
				<exclude>META-INF/*.SF</exclude> <exclude>META-INF/*.DSA</exclude> <exclude>META-INF/*.RSA</exclude> 
				</excludes> </filter> </filters> </configuration> </execution> </executions> 
				</plugin -->
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-jar-plugin</artifactId>
				<version>2.6</version>
				<configuration>
					<archive>
						<manifest>
							<addClasspath>true</addClasspath>
							<classpathPrefix>lib/</classpathPrefix>
							<!--mainClass>com.networknt.server.Server</mainClass -->
							<mainClass>bnhp.dctmrest.DctmRestApp</mainClass>
							<useUniqueVersions>false</useUniqueVersions>
						</manifest>
						<manifestEntries>
							<Class-Path>lib/ resources/ resources-env/</Class-Path>
						</manifestEntries>
					</archive>
				</configuration>
			</plugin>
			<plugin>
				<groupId>org.codehaus.mojo</groupId>
				<artifactId>exec-maven-plugin</artifactId>
				<version>1.4.0</version>
				<configuration>
					<executable>java</executable>
					<arguments>
						<argument>-jar</argument>
						<argument>target/${project.build.finalName}.jar</argument>
					</arguments>
				</configuration>
			</plugin>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-dependency-plugin</artifactId>
				<executions>
					<execution>
						<id>copy-dependencies</id>
						<phase>prepare-package</phase>
						<goals>
							<goal>copy-dependencies</goal>
						</goals>
						<configuration>
							<outputDirectory>${project.build.directory}/lib</outputDirectory>
							<overWriteReleases>true</overWriteReleases>
							<overWriteSnapshots>true</overWriteSnapshots>
							<overWriteIfNewer>true</overWriteIfNewer>
							<useBaseVersion>true</useBaseVersion>
						</configuration>
					</execution>
				</executions>
			</plugin>
			<plugin>
				<groupId>org.codehaus.mojo</groupId>
				<artifactId>build-helper-maven-plugin</artifactId>
				<executions>
					<execution>
						<id>add-source</id>
						<phase>generate-sources</phase>
						<goals>
							<goal>add-source</goal>
						</goals>
						<configuration>
							<sources>
								<source>src/generated/java</source>
							</sources>
						</configuration>
					</execution>
				</executions>
			</plugin>

			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-release-plugin</artifactId>
				<configuration>
					<checkModificationExcludes>
						<checkModificationExclude>pom.xml</checkModificationExclude>
					</checkModificationExcludes>
				</configuration>
			</plugin>
  
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-javadoc-plugin</artifactId>
				<version>2.9.1</version>
				<configuration>
					<failOnError>false</failOnError>
				</configuration>
				<dependencies>
					<dependency>
						<groupId>org.codehaus.plexus</groupId>
						<artifactId>plexus-java</artifactId>
						<version>1.0.1</version>
					</dependency>
					<dependency>
						<groupId>org.apache.maven.shared</groupId>
						<artifactId>maven-artifact-transfer</artifactId>
						<version>0.10.0</version>
					</dependency>
				</dependencies>
			</plugin>

			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-source-plugin</artifactId>
				<version>3.0.1</version>
				<executions>
					<execution>
						<id>attach-sources</id>
						<phase>verify</phase>
						<goals>
							<goal>jar-no-fork</goal>
						</goals>
					</execution>
				</executions>
			</plugin>


		</plugins>
	</build>

	<distributionManagement>
		<repository>
			<id>artifactory</id>
			<name>documentum-test</name>
			<url>https://repo.devops.poalim.bank/artifactory/s-28008-local</url>
		</repository>		
	</distributionManagement>

	<scm>
		<developerConnection>scm:git:ssh://git@gitlab.devops.poalim.bank:31007/m28008doc/dudctmrest.git</developerConnection>
		<tag>BnhpInfraDctmRest-0.0.6</tag>
	</scm>


</project>



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\README.md
-----------------------------------------------------
parameters required
REST_VERSION=0.0.7 (or later)


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\release.properties
-----------------------------------------------------
#release configuration
#Sun Mar 07 10:54:00 IST 2021
project.scm.com.poalim.documentum\:BnhpInfraDctmRest.tag=dudctmrest-0.1
scm.tagNameFormat=@{project.artifactId}-@{project.version}
scm.tag=BnhpInfraDctmRest-0.0.2
pushChanges=true
scm.url=scm\:git\:ssh\://git@gitlab.devops.poalim.bank\:31007/m28008doc/dudctmrest.git
preparationGoals=clean verify
project.rel.com.poalim.documentum\:BnhpInfraDctmRest=0.0.2
project.dev.com.poalim.documentum\:BnhpInfraDctmRest=0.0.3-SNAPSHOT
remoteTagging=true
scm.commentPrefix=[ci skip]
project.scm.com.poalim.documentum\:BnhpInfraDctmRest.developerConnection=scm\:git\:ssh\://git@gitlab.devops.poalim.bank\:31007/m28008doc/dudctmrest.git
exec.additionalArguments=-DskipTests -P artifactory
exec.snapshotReleasePluginAllowed=false
completedPhase=end-release


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\acc.l
-----------------------------------------------------
;;; acc : accounts operations

(DEFUN acc-equal-triple (accobj bank branch accno)
  "checks if java BankAccount object matches 
 three given numeric attributes: bank branch accno."
  (WITH-BINDINGS  (BEAN accobj "doc.")
				  (IF (AND doc.accountNbr doc.branchId doc.accountBankId)
					  (AND (= doc.accountNbr (INT AccountNbr))
						   (= doc.branchId	 (INT BranchId))
						   (= (% doc.accountBankId 900) (% (INT AccountBankId) 900)))
					  false)))

(DEFUN ddfr-accounts (ddfrObj)
  (IF ddfrObj
	  (. ddfrObj "getDocData().getDocCustomerData().getBankAccounts()")))

(DEFUN docData-accounts (docDataObj)
  (IF docDataObj
	  (. docDataObj "getDocCustomerData().getBankAccounts()")))


(DEFUN acceq? (a1 a2)
  (IF (AND a1 a2)
	  (WITH-BINDINGS (BEAN a1 "a1.")
					 (WITH-BINDINGS (BEAN a2 "a2.")
									(AND a1.accountNbr
										 a2.accountNbr
										 a1.branchId
										 a2.branchId
										 (= a1.accountNbr a2.accountNbr)
										 (= a1.branchId	 a2.branchId)
										 (= (% a1.accountBankId 900)  (% a2.accountBankId 900))))))) 

(DEFUN accmatch? (acclist1 acclist2)
  (APPLY (FUNCTION OR)
		 (MAPPROD (FUNCTION acceq?) acclist1 acclist2)))

(DEFUN accounts-check? ()
  (accmatch? (ddfr-accounts ddfr) (docData-accounts docDataCheck))) 

(DEFUN docDataCheck-has-accounts? ()
  (docData-accounts docDataCheck))


(LOG "INFO" "loaded acc.l")
;;; end of acc.l


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\ashrai-tests.l
-----------------------------------------------------

(DEFUN test-ashrai-sort-doc ()
  (LET ((doc1 (test-ashrai-make-ddfr (LIST 1000L)))
		(doc2 (test-ashrai-make-ddfr (LIST 1000 2000 )))
		(lst (LIST doc1 doc2)))
	   (SORT! (FUNCTION ashrai-comp-on-doc-event-date) lst)
	   lst))


(DEFUN test-ashrai-make-ddfr (tslist)
  "make ddfr with given document time (first) and events (rest)"
  (LET ((ddfr (.N "bnhp.infra.dfs.model.service.DocDataForRetrieve"))
		(dd (.N "bnhp.infra.dfs.model.business.DocData"))
		(dcd (.N "bnhp.infra.dfs.model.business.DocCustomerData"))
		(ddet (.N "bnhp.infra.dfs.model.business.DocDetails"))
		(docdate (.N "java.util.Date" (LIST (FIRST tslist)) (LIST "long")))
		(events (MAP
				 (LAMBDA (ts)
						 (LET ((event (.N  "bnhp.infra.dfs.model.business.DocEventData"))
							   (evdate (.N  "java.util.Date" (LIST ts) (LIST "long"))))
							  (. event "setLegacyEventEntryDttm" (LIST evdate))
							  event))
				 (REST tslist))))
	   (. ddet "setProjectId" (LIST 26))
	   (. ddfr "setDocData" (LIST dd))
	   (. dd "setDocCustomerData" (LIST dcd))
	   (. dcd "setDocDetails" (LIST ddet))
	   (. ddet "setLegacyDocumentEntryDttm" (LIST docdate))
	   (. ddfr "setDocEventsDataList" (LIST events) (LIST "java.util.List"))
	   ddfr))


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\ashrai.l
-----------------------------------------------------
;;; ashrai - things related to ashrai - tik lve	   

(DEFUN ashrai-get-doc-date (doc)
  (. doc "getDocData().getDocCustomerData().getDocDetails().getLegacyDocumentEntryDttm().getTime()"))

(DEFUN ashrai-get-max-ev-date (doc)
  "returns maximal event date for a ddfr object"
  (LET ((reslt (utl-num-max
				(LET ((evlist (. doc "getDocEventsDataList()")))
					 (LOG "INFO" (STR "*** evlist=" evlist))
					 (IF evlist 
						 (MAP (LAMBDA (ev)
									  (IF ev (. ev "getLegacyEventEntryDttm().getTime()") NIL))
							  evlist)
 						 (LIST
						  (ashrai-get-doc-date doc)))))))
	   (LOG "INFO" (STR "utl-num-max returned " reslt))
	   reslt))
		 


;; ashrai - specific to ashrai project
;;  compares two DocData instances
(DEFUN ashrai-comp-on-doc-event-date (d1 d2)
  ;;(LET ((diffres
  (INT
   (SIGNUM
	(LET ((dd2 (ashrai-get-doc-date d2))
		  (dd1 (ashrai-get-doc-date d1))
		  (docdiff (- dd2 dd1)))
		 (LOG "INFO" (STR "*** dd2=" dd2
						  " dd1=" dd1
						  " docdiff=" docdiff))
		 (IF docdiff
			 docdiff
			 (- (ashrai-get-max-ev-date d2)
				(ashrai-get-max-ev-date d1))))))
  ;;(LOG "INFO" (STR "*** diffres=" diffres))
  ;;diffres))
  )


(DEFUN ashrai-SearchByparamGroupIdForDocData-pre-return-hook ()
  (LOG  "DEBUG" "running ashrai-SearchByparamGroupIdForDocData-pre-return-hook")
  (LET ((documents     (. searchResult "getDocuments()")) ; list of ddfr (DocDataForRetrieve) objects
		(params	       (. preparedQuery "getParams()"))  ; list of NamedQueryParams
		(bba           (LIST "AccountBankId" "BranchId" "AccountNbr"))
		(filtered-by-acc 
		 (WITH-BINDINGS ;; bind map contents to variables
		  (pquery-params-to-map params bba)
		  (IF (APPLY (FUNCTION BOUNDP) bba) ; request with bank-branch-account
			  ;; need to filter list of documents
			  (PROGN 
			   (LOG  "DEBUG" (STR "PAR ACC: " AccountBankId "-" BranchId "-" AccountNbr))
			   (LOG  "DEBUG" (STR "documents=" documents))
			   (LET ((AccountBankId (INT AccountBankId))  ; the triples will be string when called from MF
					 (BranchId (INT BranchId))
					 (AccountNbr (INT AccountNbr))
					 (filtered  ;; filtered array of documents after search
					  (FILTER   
					   (LAMBDA (ddfr)
							   (LET ((accounts (. ddfr  "getDocData().getDocCustomerData().getBankAccounts()")))
									(LOG  "DEBUG" (STR "ACC=" accounts))
									(IF accounts ; document has accounts 
										(IF (<= (LENGTH accounts) 1) ;; if the first and and single account matches
											true
											;; or account that matched is not the first one in the document:
											;; at least one account must match here, so the list won't be empty
											(FILTER 
											 (LAMBDA (acc)
													 (acc-equal-triple acc AccountBankId BranchId AccountNbr))
											 (REST accounts)))
										;; anyway return it if we got documents w/o accounts:
										;; in fact it won't really happen since we do not filter
										;; when search parameters do not contain bank-branch-account
										true)))
					   documents)))
					(LOG  "DEBUG" (STR "filtered-by-acc=" filtered))
					filtered))
			  ;; do not filter documents if they are extracted w/o bank-branch-account (among other parameters)
			  (PROGN
			   (LOG  "DEBUG" (STR "search not by bank-branch-account: not filtering by account"))
			   documents))))
		(results-list (FILTER
							  (LAMBDA (ddfr)
									  (LET ((hasContent (. ddfr "getDoesFileContentExist()")))
										   (LOG "INFO" (STR "hasContent=" hasContent))
										   hasContent))
							 filtered-by-acc)))
	   (SORT! (FUNCTION ashrai-comp-on-doc-event-date) results-list)
	   (. searchResult "setDocuments"
		  (LIST results-list)
		  (LIST (CLASS "java.util.List")))
	   (LOG  "DEBUG" (STR "sorted-results=" results-list ))
	   searchResult))

  
(LOG "INFO" "loaded ashrai.l")


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\aspectInfo.properties
-----------------------------------------------------
bnhp_paper_doc=archive_box_nbr:INTEGER,archive_date:DATE,bank_archive_id:INTEGER,bar_code:STRING,box_batch_nbr:INTEGER,box_doc_serial_nbr:INTEGER,doc_location_code:INTEGER,document_page_cnt:INTEGER,paper_destruction_dttm:DATE,film_frame_nbr:INTEGER,archive_film_nbr:INTEGER
bnhp_division_business=number_deal:INTEGER,number_branch_confidence:INTEGER,number_confidence:INTEGER,serial_nbr_loan_guarantee:INTEGER,original_document:INTEGER,expiration_date:DATE,credit_type:INTEGER,deposit_number:DOUBLE,car_number:INTEGER,gush_number:INTEGER,helka_number:DOUBLE,tathelka_number:INTEGER,property_type:INTEGER


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\BnhpDFS-log.xml
-----------------------------------------------------
<!--  >beans:beans xmlns:beans="http://www.springframework.org/schema/beans"
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xmlns="http://www.bnhp.com/schema/bnhplogger"
	xsi:schemaLocation="
http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.0.xsd
http://www.bnhp.com/schema/bnhplogger spring/bnhplogger.xsd">

	<logger id="BnhpDFSBusinessLogger">
	    <printConfiguration>true</printConfiguration>
		<threshold>ALL</threshold>
		<handlers>
			<rollingFileHandler>
				<fileName>./logs/BnhpDFSServices.log</fileName>
				<maxFileSize>10MB</maxFileSize>
				<maxBackupIndex>5</maxBackupIndex>
				<formatter>
					<pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} %p [%t] logger_id=%c %m%n</pattern>
				</formatter>
			</rollingFileHandler>
		</handlers>
	</logger>
	<logger id="BnhpDFSServices">
	    <printConfiguration>true</printConfiguration>
	    <propertiesResourceBundle>default-log-messages.properties</propertiesResourceBundle>
		<threshold>ALL</threshold>
		<handlers>
			<rollingFileHandler>
				<fileName>./logs/BnhpDFSServices.log</fileName>
				<maxFileSize>10MB</maxFileSize>
				<maxBackupIndex>5</maxBackupIndex>
				<formatter>
					<pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} %p [%t] logger_id=%c %m%n</pattern>
				</formatter>
			</rollingFileHandler>
		</handlers>
	</logger>
		<logger id="BnhpDFSPensionFund">
		<printConfiguration>true</printConfiguration>
		<threshold>ALL</threshold>
		<handlers>
			<rollingFileHandler>
				<fileName>./logs/BnhpDFSPensionFund.log</fileName>
				<maxFileSize>10MB</maxFileSize>
				<maxBackupIndex>5</maxBackupIndex>
			</rollingFileHandler>
		</handlers>
	</logger>
	
	<logger id="BnhpDFSOperator">
		<threshold>ALL</threshold>
		<printConfiguration>true</printConfiguration>
		<handlers>
			<rollingFileHandler>
				<fileName>./logs/BnhpDFSOperator.log</fileName>
				<maxFileSize>10MB</maxFileSize>
				<maxBackupIndex>5</maxBackupIndex>
				<formatter>
					<pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} %p [%t] logger_id=%c %m%n</pattern>
				</formatter>
			</rollingFileHandler>
		</handlers>
	</logger>
</beans:beans-->


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\bnhp_velocity.properties
-----------------------------------------------------
resource.loader=class
class.resource.loader.description=Velocity class loader (for production)
class.resource.loader.class=org.apache.velocity.runtime.resource.loader.ClasspathResourceLoader






file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\commons-logging.properties
-----------------------------------------------------

org.apache.commons.logging.Log=org.apache.commons.logging.impl.SimpleLog
org.apache.commons.logging.simplelog.log.org.apche=debug
#org.apache.commons.logging.Log=org.apache.commons.logging.impl.Log4JLogger
#handlers=java.util.logging.ConsoleHandler
#.level=ALL




file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\customer.l
-----------------------------------------------------
;;; cust : customer operations

(DEFUN normalize-id (idstring)
  (. idstring "trim().toUpperCase().replaceFirst" (LIST "^[0]+" "")))

(DEFUN ddfr-customers (ddfrObj)
  (IF ddfrObj
	  (. ddfrObj "getDocData().getDocCustomerData().getCustomerKeys()")))

(DEFUN docData-customers (docDataObj)
  (IF docDataObj
	  (. docDataObj "getDocCustomerData().getCustomerKeys()")))



(DEFUN customereq? (c1 c2)
  (LOG "DEBUG" (STR "customereq?: c1=" c1 " c2=" c2))
  (IF (AND c1 c2)
	  (WITH-BINDINGS
	   (BEAN c1 "c1.")
	   (WITH-BINDINGS
		(BEAN c2 "c2.")
		(IF (AND c1.completeCustomerIdCode c2.completeCustomerIdCode)
			(LET ((n1 (normalize-id c1.completeCustomerIdCode)))
				 (AND (NOT (. n1 "isEmpty()"))
					  (EQUAL n1 (normalize-id c2.completeCustomerIdCode)))))))))

(DEFUN clnumbereq? (c1 c2)
  (LOG "DEBUG" (STR "clnumbereq?: c1=" c1 " c2=" c2))
  (IF (AND c1 c2)
	  (WITH-BINDINGS
	   (BEAN c1 "c1.")
	   (WITH-BINDINGS
		(BEAN c2 "c2.")
		(IF (AND c1.customerId c2.customerId)
			(EQUAL c1.customerId c2.customerId))))))



(DEFUN customers-match? (clist1 clist2)
  (LOG "DEBUG" (STR "customers-match?: clist1=" clist1 " clist2=" clist2))
  (APPLY (FUNCTION OR)
		 (MAPPROD (FUNCTION customereq?) clist1 clist2)))

(DEFUN clnumbers-match? (clist1 clist2)
  (LOG "DEBUG" (STR "clnumbers-match?: clist1=" clist1 " clist2=" clist2))
  (APPLY (FUNCTION OR)
		 (MAPPROD (FUNCTION clnumbereq?) clist1 clist2)))

(DEFUN clnumbers-check? ()
  (clnumbers-match? (ddfr-customers ddfr) (docData-customers docDataCheck)))


(DEFUN customers-check? ()
  (customers-match? (ddfr-customers ddfr) (docData-customers docDataCheck))) 


(DEFUN docDataCheck-has-customers? ()
  (docData-customers docDataCheck))

(LOG "INFO" "loaded customer.l")


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\default-log.xml
-----------------------------------------------------
<?xml version="1.0" encoding="UTF-8"?>

	<beans xmlns="http://www.springframework.org/schema/beans"
		xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
		xsi:schemaLocation="
	http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd" default-lazy-init="true">
	
		<bean id="default" scope="prototype"
			class="com.poalim.commons.log.config.LogDefinitionBean">
			<property name="threshold" value="DEBUG" />
			<property name="delegateToParent" value="false" />
			<property name="printConfiguration" value="true" />
			<property name="handlers">
				<list>
					<ref bean="fileHandler" />
					<ref bean="tivoliFileHandler" />
				</list>
			</property>
		</bean>
	
		<bean id="arutz" scope="prototype"
			class="com.poalim.commons.log.config.LogDefinitionBean" lazy-init="true">
			<property name="threshold" value="ALL" />
			<property name="delegateToParent" value="false" />
			<property name="handlers">
				<list>
					<ref bean="arutzFileHandler" />
				</list>
			</property>
		</bean>
	
		<bean id="consoleHandler"
			class="com.poalim.commons.log.config.handler.ConsoleLogHandlerDefinitionBean" scope="singleton" lazy-init="true">
			<property name="consoleType" value="SYSTEM_OUT" />
			<property name="threshold" value="DEBUG" />
			<property name="formatter">
				<bean
					class="com.poalim.commons.log.config.FormatterDefinitionBean">
					<property name="pattern" value="sysoutTest: %x %m%n" />
				</bean>
			</property>
		</bean>
	
		<bean id="tivoliFileHandler"
			class="com.poalim.commons.log.config.handler.TivoliFileLogHandlerDefinitionBean">
			<property name="fileName" value="./logs/default-tivoli.log" />
			<property name="name" value="TivoliDefault" />
			<property name="threshold" value="WARN" />
			<property name="append" value="true" />
			<property name="async" value="true" />
			<property name="maxFileSize" value="1KB" />
			<property name="maxBackupIndex" value="2" />
			<property name="formatter">
				<ref bean="tivoliFormatter" />
			</property>
			<property name="filters">
				<list>
					<ref bean="tivoliFilter" />
				</list>
			</property>
		</bean>
	
		<bean id="tivoliFilter"
				class="com.poalim.commons.log.config.filter.TivoliFilterDefinition">
				<property name="msgTimeout" value="3600000"></property>
		</bean>
		
		
		<bean id="tivoliFormatter"
			class="com.poalim.commons.log.config.TivoliFormatterDefinitionBean" lazy-init="true">
			<property name="projectCode" value="stamTestProject1" />
			<property name="pattern" value="%d{yyyy-MM-dd HH:mm:ss} %t %s %x %m%n" />
			<property name="encoding" value="windows-1255" />
		</bean>
	
	
	
		<bean id="rollingFileHandler"
			class="com.poalim.commons.log.config.handler.RollingFileLogHandlerDefinitionBean" lazy-init="true">
			<property name="fileName" value="./logs/default-developer.log" />
			<property name="threshold" value="DEBUG" />
			<property name="append" value="true" />
			<property name="async" value="true" />
			<property name="maxFileSize" value="1KB" />
			<property name="maxBackupIndex" value="0" />
			<property name="name" value="DeveloperDefault" />
			<property name="formatter">
				<ref bean="formatter" />
			</property>
		</bean>
	
		<bean id="formatter"
				class="com.poalim.commons.log.config.FormatterDefinitionBean" lazy-init="true">
				<property name="pattern"
					value="%d{yyyy-MM-dd HH:mm:ss} %-5p [%t] %m%n" />
				<property name="encoding" value="windows-1255" />
		</bean>
		
		
		<bean id="fileHandler"
			class="com.poalim.commons.log.config.handler.FileLogHandlerDefinitionBean" lazy-init="true">
			<property name="fileName" value="./logs/default-developer.log" />
			<property name="threshold" value="DEBUG" />
			<property name="append" value="true" />
			<property name="async" value="true" />
			<property name="name" value="DeveloperDefault" />
			<property name="formatter">
				<ref bean="formatter" />
			</property>
		</bean>
		
		<bean id="stableFileHandler"
			class="com.poalim.commons.log.config.handler.StableFileLogHandlerDefinitionBean" lazy-init="true">
			<property name="fileName" value="./logs/default-stable-developer.log" />
			<property name="threshold" value="DEBUG" />
			<property name="append" value="true" />
			<property name="async" value="false" />
			<property name="name" value="DeveloperDefault" />
			<property name="formatter">
				<ref bean="formatter" />
			</property>
		</bean>
	
		<bean id="arutzFileHandler"
			class="com.poalim.commons.log.config.handler.ArutzDailyRollingHandlerDefinitionBean" lazy-init="true">
			<property name="filePath" value="./logs/" />
			<property name="systemCode" value="000" />
			<property name="threshold" value="ALL" />
			<property name="append" value="true" />
			<property name="maxFileSize" value="10MB" />
			<property name="async" value="true" />
			<property name="formatter">
				<bean
					class="com.poalim.commons.log.config.FormatterDefinitionBean">
					<property name="pattern" value="%m%n" />
					<property name="encoding" value="windows-1255" />
				</bean>
			</property>
		</bean>
	
	
		<bean id="sysoutTest"
			class="com.poalim.commons.log.config.LogDefinitionBean" lazy-init="true">
			<property name="threshold" value="DEBUG" />
			<property name="delegateToParent" value="false" />
			<property name="handlers">
				<list>
					<bean
						class="com.poalim.commons.log.config.handler.ConsoleLogHandlerDefinitionBean">
						<property name="consoleType" value="SYSTEM_OUT" />
						<property name="threshold" value="DEBUG" />
						<property name="formatter">
							<bean
								class="com.poalim.commons.log.config.FormatterDefinitionBean">
								<property name="pattern"
									value="sysoutTest> %x %m%n" />
							</bean>
						</property>
					</bean>
				</list>
			</property>
		</bean>
	
		<!-- ============ -->
		<!-- Spring infra -->
		<!-- ============ -->
	<bean id="conversionService" class=
        "org.springframework.context.support.ConversionServiceFactoryBean">
    	<property name="converters">
    	    <list>
	            <bean class="com.poalim.commons.log.config.converters.LevelConverter" />
	            <bean class="com.poalim.commons.log.config.converters.ConsoleTypeConverter" />
	            <bean class="com.poalim.commons.log.config.converters.ResourceBundleConverter" />
	            <bean class="com.poalim.commons.log.config.converters.PathListsConverter" />
	            <bean class="com.poalim.commons.log.config.converters.PropertiesConverter" />
        	</list>
    	</property>
	</bean> 
	
	
	</beans>


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\dfswrapper.l
-----------------------------------------------------
;;
(LOG "INFO" "Initializing EXPLANG profile")

(LOADR "/utl.l")
(LOADR "/pquery.l")

(LOADR "/acc.l")
(LOADR "/customer.l")

(LOADR "/faxes.l")
(LOADR "/ashrai.l")
(LOADR "/digitaldocs.l")
(LOADR "/minhali.l")

(LOG "INFO" "EXPLANG profile initialized")



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\digitaldocs.l
-----------------------------------------------------
;;; thigs related to mismachim digitaliim

(DEFUN ddc-digitaldocs? ()
  (IF docDataCheck
	  (EQUAL "DIGITALDOCS" (. docDataCheck "getTypeName()"))
	  false))
(LOG "INFO" "loaded digitaldocs.l")


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\documentum-log.xml
-----------------------------------------------------
<beans:beans xmlns:beans="http://www.springframework.org/schema/beans"
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xmlns="http://www.bnhp.com/schema/bnhplogger"
	xsi:schemaLocation="
http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.0.xsd
http://www.bnhp.com/schema/bnhplogger spring/bnhplogger.xsd">

	<logger id="bhNehalimLogger">
		<threshold>ALL</threshold>
		<handlers>
			<rollingFileHandler>
				<fileName>./logs/BHNehalimLogger.log</fileName>
				<maxFileSize>10MB</maxFileSize>
				<maxBackupIndex>5</maxBackupIndex>
			</rollingFileHandler>
		</handlers>
	</logger>
		<logger id="bhPeulaLogger">
		<threshold>ALL</threshold>
		<handlers>
			<rollingFileHandler>
				<fileName>./logs/BHNoPagingBranchLogger.log</fileName>
				<maxFileSize>10MB</maxFileSize>
				<maxBackupIndex>5</maxBackupIndex>
			</rollingFileHandler>
		</handlers>
	</logger>
	<logger id="bhPeulaOfflineLogger">
		<threshold>ALL</threshold>
		<handlers>
			<rollingFileHandler>
				<fileName>./logs/BHOfflineNoPagingBranchLogger.log</fileName>
				<maxFileSize>10MB</maxFileSize>
				<maxBackupIndex>5</maxBackupIndex>
			</rollingFileHandler>
		</handlers>
	</logger>
	<logger id="bhPeulaOfflineErrorLogger">
		<threshold>ALL</threshold>
		<handlers>
			<rollingFileHandler>
				<fileName>./logs/BHErrorOfflineNoPagingBranchLogger.log</fileName>
				<maxFileSize>10MB</maxFileSize>
				<maxBackupIndex>5</maxBackupIndex>
			</rollingFileHandler>
		</handlers>
	</logger>
	<logger id="bhSyncTableLogger">
		<threshold>ALL</threshold>
		<handlers>
			<rollingFileHandler>
				<fileName>./logs/bhSyncTableLogger.log</fileName>
				<maxFileSize>10MB</maxFileSize>
				<maxBackupIndex>5</maxBackupIndex>
			</rollingFileHandler>
		</handlers>
	</logger>
	<logger id="bhFundamentalDocsLogger">
		<threshold>ALL</threshold>
		<handlers>
			<rollingFileHandler>
				<fileName>./logs/BHOfflineFundamentalDocsLogger.log</fileName>
				<maxFileSize>10MB</maxFileSize>
				<maxBackupIndex>5</maxBackupIndex>
			</rollingFileHandler>
		</handlers>
	</logger>
	<logger id="bhFundamentalDocsErrorLogger">
		<threshold>ALL</threshold>
		<handlers>
			<rollingFileHandler>
				<fileName>./logs/BHErrorOfflineFundamentalDocsLogger.log</fileName>
				<maxFileSize>10MB</maxFileSize>
				<maxBackupIndex>5</maxBackupIndex>
			</rollingFileHandler>
		</handlers>
	</logger>
	<logger id="bhFundamentalDocsOnlineLogger">
		<threshold>ALL</threshold>
		<handlers>
			<rollingFileHandler>
				<fileName>./logs/bhFundamentalDocsOnlineLogger.log</fileName>
				<maxFileSize>210MB</maxFileSize>
				<maxBackupIndex>5</maxBackupIndex>
			</rollingFileHandler>
		</handlers>
	</logger>
</beans:beans>


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\ErrorTypeLookup.properties
-----------------------------------------------------
# these keys are mandatory:
default_error_type=GENERAL_ERROR
error_types=GENERAL_ERROR,VALIDATION_ERROR,TEMPORARY_ERROR
max_rule_number=100

# lookup sequence for throwables:
# 
# one should place here
# more specific exceptions before their less specific parents
#
# the throwables are looked bottom-up on the cause chain.
# On each causational leve lookup is peformed first on 
# the exception itself, after that on it's superclass and so on.
# if not matched, search is continued on upper causation level 
# 

throwable[3]=bnhp.infra.dfs.exceptions.DFSValidationException,VALIDATION_ERROR
throwable[5]=java.lang.OutOfMemoryError,TEMPORARY_ERROR
throwable[7]=java.lang.Error,TEMPORARY_ERROR

throwable[10]=com.documentum.fc.client.DfAttributeValueException,GENERAL_ERROR
throwable[20]=com.documentum.fc.common.DfException
throwable[30]=com.emc.documentum.fs.services.core.CoreServiceException



# lookups for specific throwable messages
# if same exception has several rules, they will be matched according the index
com.documentum.fc.client.DfAttributeValueException[10]=VALIDATION_ERROR,message_contains=value is too big for attribute

com.documentum.fc.common.DfException[10]=VALIDATION_ERROR,regex=.*Format\\s\\w+\\sis\\sinvalid.*

com.emc.documentum.fs.services.core.CoreServiceException[10]=TEMPORARY_ERROR,message_contains=___TeSt_Of_Temporary_Error___




file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\faxes.l
-----------------------------------------------------
;;; specific to faxes/ digital documents handling

(DEFUN faxes-update-pre-update-hook ()
  (LET ((ddfu (NTH docNum ddful))
		(updatePackage (NTH docNum updatePackages))
		(vDoc (. updatePackage "vDoc"))
		(needDFSUpdate (. updatePackage "needDFSUpdate")))
	   (LOG  "DEBUG" (STR "faxes-update_pre_update_hook: "
						  " docNum=" docNum
						  " ddfu=" ddfu
						  " updatePackage=" updatePackage))
	   (IF (AND vDoc needDFSUpdate) 
		   (PROGN (LOG  "INFO" "updating virtual document")
				  (LET ((props (. needDFSUpdate "getProperties()"))
						(arint0   (make-array "Integer" 0))
						(arstr0   (make-array "String" 0))
						(ardbl0   (make-array "Double" 0))
						(tspec    (LIST "String" "Object")))
					   (LOG "INFO" (STR "vdoc_predicate=" vDoc))
					   ;;(. props "get" (LIST "r_is_virtual_doc" ))))
					   (. props "set"  (LIST "scan_status_code" 7) tspec)
					   (. props "set"  (LIST "complete_customer_id_code" arstr0) tspec)
					   (. props "set"  (LIST "customer_full_name"  arstr0) tspec)
					   (. props "set"  (LIST "customer_id" ardbl0) tspec)
					   (. props "set"  (LIST "document_group_id"  arstr0) tspec)
					   (MAP (LAMBDA (pname)
									(. props "set"  (LIST pname arint0) tspec))
							(LIST "customer_id_doc_type_code" 		  "customer_serial_nbr"  "occasional_customer_ind"
								  "account_bank_id" "branch_id" "account_nbr" "special_handling_code"
								  "division_id" "account_type"))
					   (LOG "INFO" (STR "properties: " props)))))))

(LOG "INFO" "loaded faxes.l")


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\field_categories.properties
-----------------------------------------------------

# CustomerKey
CustomerKeyDescr.customerIdDocTypeCode=107

# DocDetails
#DocDetailsDescr.projectId=xxx
DocDetailsDescr.ongoingOrHistoryCode=100
DocDetailsDescr.docCompletenessCode=101
DocDetailsDescr.scanStatusCode=104
DocDetailsDescr.signatureStatusCode=106
DocDetailsDescr.channelId=112

# ExecutorDetails
ExecutorDetailsDescr.empIdDocumentTypeCode=108
ExecutorDetailsDescr.instructionReceiveTypeCode=105

# DocEventData
DocEventDataDescr.channelId=112
DocEventDataDescr.empIdDocumentTypeCode=108
DocEventDataDescr.autoEventInd=202
DocEventDataDescr.eventCategoryCode=200
DocEventDataDescr.eventCategoryTypeCode=201


# aspects
bnhp_paper_doc@doc_location_code=103


#Categories of BHPeulaYomanDataContext fields
#ofenTipulErua4Heara=203

#projectId=105







file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\HELLO.xml
-----------------------------------------------------
<?xml version="1.0" encoding="UTF-8"?>
<sometag>
	<somesubtag mail="foo">content</somesubtag>
</sometag>


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\log4j.properties
-----------------------------------------------------
log4j.rootLogger=DEBUG

#log4j.logger.com.documentum.fc=DEBUG,SESS_LEAK_DETECT
log4j.logger.com.documentum.fc.client.DfSessionManagerPool=ERROR,SESS_LEAK_DETECT
log4j.logger.com.documentum.fc.client.DfSessionmanager=ERROR,SESS_LEAK_DETECT
log4j.logger.com.documentum.fc.client.DfDisposableCollection=ERROR,SESS_LEAK_DETECT

log4j.appender.SESS_LEAK_DETECT=org.apache.log4j.RollingFileAppender
log4j.appender.SESS_LEAK_DETECT.File=C\:/Documentum/logs/sessLeakDetector.log
log4j.appender.SESS_LEAK_DETECT.MaxFileSize=100MB
log4j.appender.SESS_LEAK_DETECT.MaxBackupIndex=5
log4j.appender.SESS_LEAK_DETECT.layout=org.apache.log4j.PatternLayout
log4j.appender.SESS_LEAK_DETECT.layout.ConversionPattern=%d{ABSOLUTE} %5p [%t] %c - %m%n


log4j.logger.com.emc.documentum.fs.rt = WARN, A1, F1
log4j.logger.com.emc.documentum.fs.datamodel = WARN, A1, F1
log4j.logger.com.emc.documentum.fs.services = WARN, A1, F1
log4j.logger.com.emc.documentum.fs.tools = WARN, A1, F1
log4j.logger.com.emc.documentum.fs.tracing = WARN, ASPECT_TRACE
#log4j.logger.com.documentum.fc.client.impl.session = DEBUG, A1, F1
log4j.logger.bnhp.infra.base.tbo= WARN, A1, F1
#------------------- CONSOLE --------------------------
log4j.appender.A1=org.apache.log4j.ConsoleAppender
log4j.appender.A1.layout=org.apache.log4j.PatternLayout
log4j.appender.A1.layout.ConversionPattern=%d{ABSOLUTE} %5p [DFS] %c - %m%n

#------------------- FILE --------------------------
log4j.appender.F1=org.apache.log4j.RollingFileAppender
log4j.appender.F1.File=C\:/Documentum/logs/dfs-runtime.log
log4j.appender.F1.MaxFileSize=10MB
log4j.appender.F1.layout=org.apache.log4j.PatternLayout
log4j.appender.F1.layout.ConversionPattern=%d{ABSOLUTE} %5p [DFS] %c - %m%n


#------------------- FILE Operator--------------------------
log4j.appender.Operator=org.apache.log4j.RollingFileAppender
log4j.appender.Operator.File=./logs/dfs_operator.log
log4j.appender.Operator.MaxFileSize=100MB
log4j.appender.Operator.layout=org.apache.log4j.PatternLayout
log4j.appender.Operator.layout.ConversionPattern=%d [DFS-OPERATOR] - %m%n

#------------------- ASPECT_TRACE --------------------------
log4j.appender.ASPECT_TRACE=org.apache.log4j.RollingFileAppender
log4j.appender.ASPECT_TRACE.File=C\:/Documentum/logs/dfs-runtime-trace.log
log4j.appender.ASPECT_TRACE.MaxFileSize=100MB
log4j.appender.ASPECT_TRACE.layout=org.apache.log4j.PatternLayout
log4j.appender.ASPECT_TRACE.layout.ConversionPattern=%d{ABSOLUTE} [ASPECTS] %m%n


#------------------- BNHP LOG --------------------------
log4j.logger.bnhp.infra.dfs=DEBUG, BNHPDFS,A1
log4j.logger.bnhp.operator=INFO,Operator

log4j.appender.BNHPDFS=org.apache.log4j.RollingFileAppender
log4j.appender.BNHPDFS.File=./logs/bnhpdfs.log
log4j.appender.BNHPDFS.MaxFileSize=100MB
log4j.appender.BNHPDFS.layout=org.apache.log4j.PatternLayout
log4j.appender.BNHPDFS.layout.ConversionPattern=%d{ABSOLUTE} [BNHP] %m%n


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\log4j2.xml
-----------------------------------------------------
<?xml version="1.0" encoding="UTF-8"?>

<Configuration monitorInterval="30">
	<Appenders>
		<RollingFile name="BnhpDFSServicesAppender" fileName="./logs/BnhpDFSServices.log"
			append="true" filePattern="./logs/BnhpDFSServices.log.%i">
			<PatternLayout
				pattern="%d{yyyy-MM-dd HH:mm:ss.SSS z} %p [%t] logger_id=%c %m%n" />
			<Policies>
				<SizeBasedTriggeringPolicy size="10 MB" />
			</Policies>
			<DefaultRolloverStrategy max="5" />
		</RollingFile>
		<RollingFile name="BnhpDFSBusinessAppender" fileName="./logs/BnhpDFSBusiness.log"
			append="true" filePattern="./logs/BnhpDFSBusiness.log.%i">
			<PatternLayout
				pattern="%d{yyyy-MM-dd HH:mm:ss.SSS z} %p [%t] logger_id=%c %m%n" />
			<Policies>
				<SizeBasedTriggeringPolicy size="10 MB" />
			</Policies>
			<DefaultRolloverStrategy max="5" />
		</RollingFile>
		<RollingFile name="BnhpDFSOperatorAppender" fileName="./logs/BnhpDFSOperator.log"
			append="true" filePattern="./logs/BnhpDFSOperator.log.%i">
			<PatternLayout
				pattern="%d{yyyy-MM-dd HH:mm:ss.SSS} %p [%t] logger_id=%c %m%n" />
			<Policies>
				<SizeBasedTriggeringPolicy size="10 MB" />
			</Policies>
			<DefaultRolloverStrategy max="5" />
		</RollingFile>
		<Console name="STDOUT" target="SYSTEM_OUT">
			<PatternLayout
				pattern="%d{yyyy-MM-dd HH:mm:ss.SSS} %p [%t] logger_id=%c %m%n" />
		</Console>
	</Appenders>
	<Loggers>
		<Logger name="BnhpDFSBusinessLogger" level="debug">
			<AppenderRef ref="BnhpDFSBusinessAppender" />
		</Logger>
		<Logger name="BnhpDFSServices" level="debug">
			<AppenderRef ref="BnhpDFSServicesAppender" />
		</Logger>
		<Logger name="BnhpDFSOperator" level="debug">
			<AppenderRef ref="BnhpDFSOperatorAppender" />
		</Logger>

		<Root level="info">
			<AppenderRef ref="STDOUT" />
		</Root>
	</Loggers>
</Configuration>


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\minhali.l
-----------------------------------------------------
;;; 

(DEFUN prop-get (prop-name)
  (LET ((loader (.S "bnhp.infra.dfs.utils.basic.properties.PropertyLoader" "getInstance()")))
	   (IF (. loader "hasProperty" (LIST prop-name))
		   (. loader "getProperty" (LIST prop-name))
		   NIL)))
	   


(DEFUN minhali-appreq-pre-xact-hook ()
  (LOG "DEBUG" "running minhali-appreq-hook")
  (LOG "DEBUG" (STR "sysUser=" sysUser))
  (IF (OR (EQUAL "minhali@JMS" sysUser)
		  (EQUAL "safinvo@JMS" sysUser))
	  (IF (EQUAL (. preparedQuery "getName()") "CancelAccountDocs")
		  (PROGN
		   (LET ((defdb (prop-get "default_docbase"))
				 (env (IF (EQUAL defdb "banhap_prd") "PRD"
						  (IF (EQUAL defdb "banhap_qa1") "TST"
							  "DEV")))
				 (orguser (. securityContext "getUserName()" ))
				 (substuser (. orguser "replaceAll" (LIST "[$][{]ENV[}]" env)))
				 (init (.S "bnhp.infra.dfs.init.ApplicationInitializer" "getInstance()"))
				 (ticket (. init "getTicket" (LIST substuser ))))
				(LOG "DEBUG" "SECURITY CONTEXT UPDATE: ")
				(LOG "DEBUG" (STR "BEFORE: " securityContext))
				(. securityContext "setUserName" (LIST substuser))
				(. securityContext "setPassword" (LIST ticket))
				(LOG "DEBUG" (STR "AFTER: " securityContext)))))
	  (LOG "DEBUG" "nothing to do!")))

(LOG "INFO" "loaded minhali.l")


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\mount_shared_folder.xml
-----------------------------------------------------
<?xml version="1.0" encoding="ISO-8859-1" ?>
<project name="switch project to dev" default="switch">
	<target name="switch">
		<echo>Switching project to the DEV configuration:</echo>
		<exec executable="cmd">
			<arg value="/C"/>
			<arg value="net"/>
			<arg value="use"/>
			<arg value="S:"/>
			<arg value="/d"/>
		</exec>
		<exec executable="cmd">
			<arg value="/C"/>
			<arg value="net"/>
			<arg value="use"/>
			<arg value="S:"/>
			<arg value="\\172.31.198.55\SysProjectsUnix01\dctm_projects\Development"/>
		</exec>
		<exec executable="cmd">
			<arg value="/C"/>
			<arg value="dir"/>
			<arg value="S:"/>
		</exec>
		<echo>FINISHED</echo>
	</target>
</project>


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\pquery.l
-----------------------------------------------------
;; pquery ; related to prepared queries

(DEFUN pquery-params-to-map (params param-names)
  (LOG "INFO" (STR "pquery-params-to-map: SRC:" params "->" param-names))
  (LET ((extracted
		 (REDUCE  (LAMBDA (acclist named-query-param)
						  ;;(LOG (STR "REDUCE: acc=" acclist " arg=" named-query-param))
						  (LET ((param-name (. named-query-param "getName()")))
							   ;;(LOG (STR "REDUCE: param-name=" param-name))
							   (IF (. param-names "contains" (LIST param-name) (LIST "Object") )
								   (APPEND acclist
								   (LIST param-name
										 (. named-query-param
											"getParamValue().getValue()")))
								   acclist)))
				  (LIST)  params)))
	   (LOG "INFO" (STR "pquery-params-to-map: extracted:" extracted))
	   (APPLY (FUNCTION HASHMAP) extracted)))

(LOG "INFO" "loaded pquery.l")


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\python.properties
-----------------------------------------------------
python.path=./target/lib/jython-lib.jar:.
#python.path=/AppServer/optionalLibraries/jython/Lib:/usr/TDC/WebSphere/AppServer/optionalLibraries/jython/jython.jar:/usr/TDC/SharedLibs/documentum/dfc.jar:/usr/TDC/WebSphere/AppServer/profiles/AppSrv01/installedApps/tdcmdfs01-7Node01Cell/BnhpDFSWrapperEAR.ear/BnhpInfraDFServices-1.0-SNAPSHOT-basic.jar


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\saf-init.properties
-----------------------------------------------------
# saf initial configuration for Process Server in SystemTest
# generated by mqweb at 16/09/2013 16:54:49
#systemId = document
#environment = TST
#mqconn1 = 172.31.22.121:1414:TSTGEN01:SAFCONFIG.TSTGEN01
#mqconn2 = 172.31.22.142:1415:TSTGEN02:SAFCONFIG.TSTGEN02
#requestQueue = FW.MBDEPLOY.SAFCONFIG.REQUEST
#replyQueue = FW.SAFCONFIG.MBDEPLOY.REPLY
#logFile=c:\\LocalEnv\\saf\\saf.log


# saf initial configuration for Process Server in Test
# generated by mqweb at 07/11/2012 17:53:31
#systemId = document
#environment = DEV
#mqconn1 = 172.31.35.181:1417:DEVGEN01:SAFCONFIG.DEVGEN01
#mqconn2 = 172.31.22.121:1418:DEVGEN03:SAFCONFIG.DEVGEN03

# saf initial configuration for Documentum in Test
# generated by mqweb for Test at 10/04/2019 16:15:57
systemId = document
environment = DEV
#mqconn1 = 172.31.35.181:1417:DEVGEN01:SAFCONFIG.DEVGEN01
mqconn1 = 172.31.22.121:1418:DEVGEN03:SAFCONFIG.DEVGEN03
requestQueue = FW.MBDEPLOY.SAFCONFIG.REQUEST
replyQueue = FW.SAFCONFIG.MBDEPLOY.REPLY


#environment = TST
#mqconn1 = 172.31.35.185:1415:TSTGEN04:SAFCONFIG.TSTGEN04
#mqconn2 = 172.31.22.142:1415:TSTGEN02:SAFCONFIG.TSTGEN02
requestQueue = FW.MBDEPLOY.SAFCONFIG.REQUEST
replyQueue = FW.SAFCONFIG.MBDEPLOY.REPLY

preferredIpPerfix=172.21.0.193

#logFile=c:\\saf\\saf.log


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\simplelog.properties
-----------------------------------------------------
org.apache.commons.logging.simplelog.defaultlog=debug


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\templates\AppendDocByParam.txt
-----------------------------------------------------
#set($interp=$scripting.run_jython("python/AppendDocByParam.py"))
-- QUERY TYPE=DQL RESULT="docIdData" SINGLE_ROW="true" COL_NAMES="dctmDocumentId,versionLabel"
select dctm_document_id , r_version_label as versionLabel
from bnhp_customer_doc where legacy_document_id='$utl.esc(${par.LegacyDocumentId})' order by r_version_Label  ENABLE(ROW_BASED, RETURN_TOP 1)
 


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\templates\appx_test_APIMulti.txt
-----------------------------------------------------
-- QUERY TYPE=API RESULT="RESULT1" CALL="get" METHOD="create" ARGUMENTS="${par.Type}"
-- QUERY TYPE=API RESULT="RESULT2" CALL="set" METHOD="set" ARGUMENTS="l,object_name" VALUE="${par.Name}"
-- QUERY TYPE=API RESULT="RESULT3" CALL="exec" METHOD="save" ARGUMENTS="l"
-- QUERY TYPE=API RESULT="RESULT4" CALL="get" METHOD="dump" ARGUMENTS="l"




file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\templates\appx_test_APISingleGet.txt
-----------------------------------------------------
-- QUERY TYPE=API RESULT="RESULT" CALL="get" METHOD="create" ARGUMENTS="${par.Type}"



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\templates\appx_test_DQLQuerySelect.txt
-----------------------------------------------------
-- QUERY TYPE=DQL RESULT="RESULT"
SELECT * FROM BNHP_CUSTOMER_DOC WHERE 
project_id=${par.ProjectId} AND
document_form_id='${par.DocumentFormId}' 
ENABLE(RETURN_TOP ${par.MaxCount})



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\templates\appx_test_DQLQueryTwoSelects.txt
-----------------------------------------------------
-- QUERY TYPE=DQL RESULT="RESULT1"
SELECT * FROM BNHP_CUSTOMER_DOC WHERE 
project_id=${par.ProjectId} AND
document_form_id='${par.DocumentFormId1}' 
ENABLE(RETURN_TOP ${par.MaxCount})
-- QUERY TYPE=DQL RESULT="RESULT2"
SELECT * FROM BNHP_CUSTOMER_DOC WHERE 
project_id=${par.ProjectId} AND
document_form_id='${par.DocumentFormId2}' 
ENABLE(RETURN_TOP ${par.MaxCount})



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\templates\appx_test_DummyTextResult.txt
-----------------------------------------------------
[${par.ParamA}_${par.ParamB}]


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\templates\appx_test_DummyTextResultEmpty.txt
-----------------------------------------------------


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\templates\appx_test_ExecScriptJython.txt
-----------------------------------------------------
##$scripting.run_jython("AAA/home/FW0/projects/M28008_DocumentumProjects/duecmcustomerdfservices/test/resources-dev/templates/python/test.py")
$scripting.run_jython("python/test.py")



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\templates\appx_test_NOOP_METHOD.txt
-----------------------------------------------------
-- QUERY TYPE=METHOD RESULT="RESULT" METHOD="echo"  RUN_ASYNC="false" SAVE_RESULTS="true"  TRACE_LAUNCH="true" RUN_AS_SERVER="true"
"HELLO FROM SERVER Par1=${par.Par1} Par2=${par.Par2} BY"


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\templates\appx_test_ReturnResult.txt
-----------------------------------------------------
#set($interp=$scripting.run_jython("python/ReturnResult.py"))
#set($RESULTVAR=${interp.get("result")})
-- QUERY TYPE=RETURNRESULT RESULT="RESULTLIST"



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\templates\appx_test_UpdateContent.txt
-----------------------------------------------------
-- QUERY TYPE=UPLOAD RESULT="RESULT" DOCTYPE="bnhp_customer_doc"  DOCURL="${par.DocURL}" DOCSIZE="${par.DocSize}" DOCFORMAT="${par.DocFormat}" DOCOLDFORMAT="%par.DocOldFormat%"
 dctm_document_id='${par.DctmDocumentId}'


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\templates\appx_test_UpdateContentServerDelete.txt
-----------------------------------------------------
-- QUERY TYPE=UPLOAD RESULT="UPDATE_RESULT" DOCTYPE="bnhp_customer_doc"  DOCURL="${par.DocURL}" DOCSIZE="${par.DocSize}" DOCFORMAT="${par.DocFormat}" DOCOLDFORMAT="%par.DocOldFormat%"
 dctm_document_id='${par.DctmDocumentId}'
 #set($upload_dirs=$utl.configGetUserString("server_file_upload_base_dir","${user}").split("\s*,\s*"))
 -- QUERY TYPE=METHOD RESULT="DELETE_RESULT" METHOD="bnhp_async_clean" RUN_ASYNC="true"
#foreach(${upload_dir} in ${upload_dirs}) -file ${par.DocURL.replaceFirst("^file:///",${upload_dir})} #end 


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\templates\ConcatenateDocsByParams.txt
-----------------------------------------------------
#set($interp=$scripting.run_jython("python/ConcatenateDocsByParams.py"))
#set($filekey=${interp.get("filekey").toString()})
#set($retrieve_profile=${interp.get("retrieve_profile").toString()})
#set($is_pass_thru=${interp.get("is_pass_thru").toString()})
#if (${is_pass_thru} == "true")
#set($RESULTVAR=${interp.get("result")})
-- QUERY TYPE=RETURNRESULT RESULT="__PASSTHRU"
#else
-- QUERY TYPE=DOWNLOAD PREDICATE="dm_sysobject where OBJECT_NAME='${filekey}' AND FOLDER('/Temp/bnhp_concatenate_docs_by_params')" DOCTYPE="dm_sysobject" PROFILE="$utl.esc(${retrieve_profile})" RESULT="*" RETURNTYPE="contentOnly"
#end



 


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\templates\countDocumentsPages.txt
-----------------------------------------------------
#set($interp=$scripting.run_jython("python/countDocumentsPages.py"))
#set($RESULTVAR=${interp.get("result")})
-- QUERY TYPE=RETURNRESULT RESULT="RESULTLIST"


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\templates\python\AppendDocByParam.py
-----------------------------------------------------
## adding library on command line
# -Dpython.path=PYTHONPATH=/home/FW0/projects/M28008_DocumentumProjects/duecm3rdpartydeps/jython-lib.jar
import sys

def log(msg):
    print >>sys.stderr, msg
    #utl.info(msg)

log("*** jython shalom! ***")
log("*** sys.path="+str(sys.path))
log("*** user="+user)
log("*** par="+str(par))

from urllib import urlencode
#from xml.sax.saxutils import XMLGenerator
#from xml.sax.saxutils import escape
from xml.sax.xmlreader import AttributesImpl
from urlparse import urlparse
from java.lang import Boolean

from java.util import UUID
from java.io import File
from java.io import FileOutputStream

from bnhp.infra.dfs.utils.dfc import ServerMethodUtils
from bnhp.infra.dfs.model.business import DocFile

from com.documentum.fc.client.acs.impl import DfAcsTransferPreferences

def get_one_arg(parmap, *keys):
    for key in keys:
        if key in parmap:
            return (key, parmap[key])
    error = "at least one of the "+str(keys) +" parameters must be specified"
    utl.error(error)

def get_mandatory_val(parname, parmap, *valset):
    global par
    global utl
    value=parmap[parname]
    if not value:
        utl.error("Mandatory parameter "+ parname + " not set!")
    if valset:
        if not value in valset:
            utl.error("Value of "+ parname + " must be one of "+str(valset))
    return value

def nv2string(nv):
    if nv and str(nv).strip():
        #log("nv="+str(nv))
        return str(nv).strip()
    else:
        return None

def nv2bytes(nv):
    if nv and str(nv).strip():
        #log("nv="+str(nv))
        return utl.getBase64().getDecoder().decode(str(nv).strip())
    else:
        return None

def get_cfg_entry(name):
    return utl.configGetString(name).split(",")[0]

def normalize_format(format):
    # FIXME!
    return "pdf"

def escape_method_arg(arg):
    # does not work because of CS bugs
    # ' inside single quoted string maps to '"'"'
    #
    # return "'"+ str(arg).replace("'","'\"'\"'") +"'"
    argstr = str(arg)
    # CS is buggy with splitting args!
    if argstr.find('"') > -1 or argstr.find("'") > -1:
        utl.error("Invalid argument value '"+argstr+"'")
    return '"'+ str(arg) +'"'


def docStream2file(b64, format):
    bytes = nv2bytes(b64)
    filename = "appbp_" + str(UUID.randomUUID()) + "_in."+format
    source_file = local_upload_root + "/" + project_dir +"/" +filename
    log("*** will write source_file='" + source_file +"'")
    fd = None;
    try:
        fd=FileOutputStream(File(source_file))
        fd.write(bytes)
    finally:
        if (fd):
            fd.close()
    log("*** write finished")

    return source_file

def docURL2file(urlStr, format):
    parsed=urlparse(urlStr)
    server_file_path= server_upload_root + "/" + parsed[2]
    #local_file_path= local_upload_root + "/" + parsed[2]
    return server_file_path

def str_cat2(str1,str2):
    if (str1):
        return str1 + " " +  str2
    else:
        return str2

def list_join(lst):
    return reduce(str_cat2, lst, None)


def retrieveObjIdSpec(idtype, idval):
    if idtype == "LegacyDocumentId":
        attr = "legacy_document_id"
    elif idtype == "DctmDocumentId":
        attr = "dctm_document_id"
    else:
        utl.error("Invalid kind of document id is given: " +  idtype)
    dql_query = "bnhp_customer_doc where "+attr+"='" + utl.esc(idval) +"'"
    id = session.getIdByQualification(dql_query);
    if not id:
        utl.error("Document with "+idtype+"="+idval+" not found or not enough rights to retrieve")
    return ("-o", id.toString())
    


def entry2method_args(entry):
    (arg, val, ddc) = entry
    if arg == "DocFile":
        arg="-f"
        format = normalize_format(val)
        log("format=" + format)
        if "docStream" in val:
            val = docStream2file(val["docStream"], format)
        elif "docURL" in val:
            val = docURL2file(val["docURL"], format)
    else:
        (arg, val) = retrieveObjIdSpec(arg, val)
    return (arg, val)

def check_call_result(call_result):
    if not call_result.methodReturnVal == 251:
        utl.error("server method returned error status: "+str(call_result.methodReturnVal))

    if call_result.timeout:
        utl.error("server method timed out ")

    if call_result.launchFailed:
        utl.error("server method launch failed ")

log("*** parsing arguments...")
(srcIdType, srcIdVal) = get_one_arg(par, "SrcLegacyDocumentId", "SrcDctmDocumentId")
srcIdType = "legacy_document_id" if srcIdType == "SrcLegacyDocumentId" else "dctm_document_id"

log("srcIdType="+srcIdType+", srcIdVal="+srcIdVal)

legacyDocumentId = get_mandatory_val("LegacyDocumentId", par)
log("LegacyDocumentId="+legacyDocumentId)

documentFormId = get_mandatory_val("DocumentFormId", par)
log("DocumentFormId="+documentFormId)

documentDate = get_mandatory_val("LegacyDocumentEntryDttm", par)
log("DocumentDate="+str(documentDate))

log("securityContext="+str(bctx.getSecurityContext()))

appendPathLst = [ x for x in parlist if x.name == "AppendPath"]
if not appendPathLst:
    utl.error("AppendPath list parameter is mandatory!")
log("appendPathLst="+str(appendPathLst))

session = dfc.getSharedSession()

def parse_entry(entry):
    errmsg = "AppendPath entry must have exactly one of LegacyDocumentId or DctmDocumentId or DocFile"
    result = None
    ddc = None
    if "DocDataCheck" in entry:
        ddc = entry["DocDataCheck"]
    if  "LegacyDocumentId" in entry:
        result = ("LegacyDocumentId", entry["LegacyDocumentId"], ddc)
    if  "DctmDocumentId" in entry:
        if result:
            utl.error(errmsg)
        result = ("DctmDocumentId", entry["DctmDocumentId"], ddc)
    if  "DocFile" in entry:
        if result:
            utl.error(errmsg)
        result = ("DocFile", entry["DocFile"], ddc)
    if result:
        log("parsed entry: "+str(result))
        return result
    else:
        utl.error(errmsg)

entries = map(parse_entry, par["AppendPath"])
log(" entries=" + str(entries))

local_upload_root=get_cfg_entry("local_file_upload_base_dir")
server_upload_root=get_cfg_entry("server_file_upload_base_dir")
log("*** using upload dir '"+local_upload_root)

# FIXME: get real project dir!
project_dir = "internal"

session = dfc.getSharedSession()
sc=bctx.getSecurityContext()

method_args = [ "-T", srcIdType, "-S",  srcIdVal, "-L",  legacyDocumentId, "-F", documentFormId, "-D", documentDate, "-U", sc.getUserName(), "-R", sc.getRepositoryName(), "-P", session.getLoginTicket() ]

for entry in entries:
    (eType, eVal, ddc) = entry
    log("eType="+eType +" eVal="+str(eVal))
    marg = entry2method_args(entry)
    log("marg="+str(marg))
    method_args.extend(marg)

log("METHOD ARGS: "+str(method_args))

method_args_str = list_join(map(escape_method_arg, method_args))

log("calling server method with args: "+method_args_str)


call_result = ServerMethodUtils.runServerMethod(session,
                                                "bnhp_version_with_append_pdf2",
                                                method_args_str,
                                                # launch_async=F,  save_result=F
                                                0, 0)
log("call result="+str(call_result))
check_call_result(call_result)

log("python method finished")
#DocURL="file:///FAKEURL"
#DocSize=1024
# DocURL and DocSize are return values, will be read by velocity
#log("returning DocURL="+DocURL)
#log("returning DocSize="+str(DocSize))
#
# FIXME
# check URLS
# escapes
# create versions
# DocdataCheck
#


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\templates\python\ConcatenateDocsByParams.py
-----------------------------------------------------
## adding library on command line
# -Dpython.path=PYTHONPATH=/home/FW0/projects/M28008_DocumentumProjects/duecm3rdpartydeps/jython-lib.jar
import sys
import re

def log(msg):
    print >>sys.stderr, msg
    #utl.info(msg)

log("*** jython shalom! ***")
log("*** sys.path="+str(sys.path))
log("*** user="+user)

from urllib import urlencode
#from xml.sax.saxutils import XMLGenerator
#from xml.sax.saxutils import escape
from xml.sax.xmlreader import AttributesImpl
from urlparse import urlparse
from java.lang import Boolean
from java.lang import String
from java.util import List

from java.util import UUID
from java.io import File
from java.io import FileOutputStream

from bnhp.infra.dfs.utils.dfc import ServerMethodUtils
from bnhp.infra.dfs.model.business import DocFile
#from bnhp.infra.dfs.utils.content import Base64

from com.documentum.fc.client.acs.impl import DfAcsTransferPreferences
from com.documentum.fc.common import DfId
### Parameter  handling functions
def get_val_with_default(parname, parmap, defval):
    if parmap.has_key(parname):
        return parmap[parname]
    else:
        return defval

def get_mandatory_val(parname, parmap, *valset):
    global par
    global utl
    value=parmap[parname]
    if not value:
        utl.error("Mandatory parameter "+ parname + " not set!")
    if valset:
        if not value in valset:
            utl.error("Value of "+ parname + " must be one of "+str(valset))
    return value

def nv2string(nv):
    if nv and str(nv).strip():
        #log("nv="+str(nv))
        return str(nv).strip()
    else:
        return None

def nv2bytes(nv):
    if nv and str(nv).strip():
        #log("nv="+str(nv))
        return utl.getBase64().getDecoder().decode(str(nv).strip())
    else:
        return None

def parse_entry(entry):
    errmsg = "DocList entry must have exactly one of LegacyDocumentId or DctmDocumentId or DocFile"
    result = None
    ddc = None
    if "DocDataCheck" in entry:
        ddc = entry["DocDataCheck"]
    if  "LegacyDocumentId" in entry:
        result = ("LegacyDocumentId", entry["LegacyDocumentId"], ddc)
    if  "DctmDocumentId" in entry:
        if result:
            utl.error(errmsg)
        result = ("DctmDocumentId", entry["DctmDocumentId"], ddc)
    if  "DocFile" in entry:
        if result:
            utl.error(errmsg)
        result = ("DocFile", entry["DocFile"], ddc)
    if not result:
        utl.error(errmsg)
    if not ddc and not (result[0] == "DocFile"):
        utl.error("DocDataCheck is mandatory, but not provided for the entry: "+str(entry))
    elif ddc and result[0] == "DocFile":
        utl.error("DocDataCheck cannot be used with a DocFile entry: "+str(entry))
    return result

def check_known_params(pardict, knownParams):
    knownSet=set(knownParams)
    parSet = set(par.keys())
    unknowns=parSet.difference(knownSet)
    if not len(unknowns) == 0:
        utl.error("Unknown parameters provided: "+str(unknowns))

# FIXME: only first alt. path is supported
def get_cfg_entry(name):
    return utl.configGetString(name).split(",")[0]

def normalize_format(format):
    # FIXME!
    return "pdf"

def escape_method_arg(arg):
    # does not work because of CS bugs
    # ' inside single quoted string maps to '"'"'
    #
    # return "'"+ str(arg).replace("'","'\"'\"'") +"'"
    argstr = str(arg)
    # CS is buggy with splitting args!
    if argstr.find('"') > -1 or argstr.find("'") > -1:
        utl.error("Invalid argument value '"+argstr+"'")
    return '"'+ str(arg) +'"'


def docStream2file(b64, format):
    bytes=utl.getBase64().getDecoder().decode(b64)
    filename = "appbp_" + str(UUID.randomUUID()) + "_in."+format
    source_file = local_upload_root + "/" + project_dir +"/" +filename
    fd = None;
    try:
        fd=FileOutputStream(File(source_file))
        fd.write(bytes)
    finally:
        if (fd):
            fd.close()
    log("*** will write source_file='" + source_file +"'")
    return source_file

urlRegex = re.compile('^file:///[\/A-Za-z0-9_]+\\.[0-9A-Za-z_]+$')

def checkURL(urlStr):
    if (not urlRegex.match(urlStr)) or (".." in urlStr):
        utl.error("Unauthorized URL provided: "+str(urlStr))

def docURL2file(urlStr, format):
    parsed=urlparse(urlStr)
    checkURL(urlStr)
    server_file_path= server_upload_root + "/" + parsed[2]
    #local_file_path= local_upload_root + "/" + parsed[2]
    return server_file_path

def str_cat2(str1,str2):
    if (str1):
        return str1 + " " +  str2
    else:
        return str2

def list_join(lst):
    return reduce(str_cat2, lst, None)

# map entry to tuple
def me2t(e,*attrs):
    vals=map(lambda a : e[a] if a in e else None, attrs)
    return tuple(vals)

def obj_rep_int_tuples(obj,*attrs):
    tuples=[]
    mincount=None
    for attr in attrs:
        vc = obj.getValueCount(attr)
        if not mincount or vc < mincount:
            mincount = vc
    log("mincount = "+str(mincount))
    for idx in range (0, mincount):
        lst = []
        for attr in attrs:
            lst.append(obj.getRepeatingInt(attr,idx))
        tuples.append(tuple(lst))
    return tuples

def obj_rep_str_tuples(obj,*attrs):
    tuples=[]
    mincount=None
    for attr in attrs:
        vc = obj.getValueCount(attr)
        if not mincount or vc < mincount:
            mincount = vc
    log("mincount = "+str(mincount))
    for idx in range (0, mincount):
        lst = []
        for attr in attrs:
            lst.append(obj.getRepeatingString(attr,idx))
        tuples.append(tuple(lst))
    return tuples

def docdata_check(s, id, ddcs):
    if not ddcs:
        log("skip doc data check: no DocDataCheck provided")
        return
    log("perform docDataCheck for "+str(id)+" with: "+str(ddcs))
    obj = session.getObject(id);
    log("got obj"+str(obj.getObjectId().getId()))
    # FIXME: read per user config if DDC is mandatory
    if True:
        if "bankAccounts" in ddc:
            bank_accounts=ddc["bankAccounts"]
            log("check bankAccounts="+str(bank_accounts))
            check_tuples = filter( lambda x : x[1] > 0 and x[2]>0 , 
                                   map( lambda e : me2t(e,"accountBankId","branchId","accountNbr"),
                                        bank_accounts))
            log("check bankAccounts tuples="+str(check_tuples))
            doc_tuples = obj_rep_int_tuples(obj, "account_bank_id","branch_id","account_nbr")
            log("doc accounts tuples="+str(doc_tuples))
            common_tuples = list(set(check_tuples) & set(doc_tuples))
            if (len(common_tuples) > 0):
                log("Doc data check matched on accounts "+str(common_tuples))
                return
        if "customers" in ddc:
            customers = ddc["customers"]
            check_tuples = filter( lambda x: x[0] and len(x[0].strip()) > 0,
                                                          map( lambda e : me2t(e,"completeCustomerIdCode"),
                                                               customers))
            log("check customers tuples="+str(check_tuples))
            doc_tuples = obj_rep_str_tuples(obj, "complete_customer_id_code")
            log("doc customers tuples="+str(doc_tuples))
            common_tuples = list(set(check_tuples) & set(doc_tuples))
            if (len(common_tuples) > 0):
                log("Doc data check matched on customers "+str(common_tuples))
                return
    utl.error("DocDataCheck mismatch")

def retrieveObjIdSpec(idtype, idval, ddc):
    if idtype == "LegacyDocumentId":
        attr = "legacy_document_id"
    elif idtype == "DctmDocumentId":
        attr = "dctm_document_id"
    else:
        utl.error("Invalid kind of document id is given: " +  idtype)
    dql_query = "bnhp_customer_doc where "+attr+"='" + utl.esc(idval) +"'"
    id = session.getIdByQualification(dql_query);
    if not id or id.isNull() or not id.isObjectId():
        utl.error("Document with "+idtype+"="+idval+" not found or not enough rights to retrieve")
    docdata_check(session, id, ddc);
    return ("-o", id.toString())

def entry2method_args(arg, val, ddc):
    if arg == "DocFile":
        arg="-f"
        format = normalize_format(val)
        log("format=" + format)
        if "docStream" in val.keys():
            val = docStream2file(val["docStream"], format)
        elif "docURL" in val.keys():
            val = docURL2file(val["docURL"], format)
    else:
        (arg, val) = retrieveObjIdSpec(arg, val, ddc)
    return (arg, val)

def check_call_result(call_result):
    if not call_result.methodReturnVal == 251:
        utl.error("server method returned error status: "+str(call_result.methodReturnVal))

    if call_result.timeout:
        utl.error("server method timed out ")

    if call_result.launchFailed:
        utl.error("server method launch failed ")

log("*** parsing arguments...")
log("parlist="+str(parlist)+" type="+str(type(parlist)))
log("par="+str(par)+" type="+str(type(par)))

check_known_params(par, [ "DocList", "PageRenumbering", "RetrieveProfile","HTTP_HEADERS" ])

docList = get_mandatory_val("DocList", par)
if len(docList) < 1:
    utl.error("DocList cannot be empty ")

page_renumbering = get_val_with_default("PageRenumbering", par, "")
log("PageRenumbering='" + page_renumbering +"'")
retrieve_profile = get_val_with_default("RetrieveProfile", par, "STREAM")
log("RetrieveProfile='" + retrieve_profile +"'")

headers=get_val_with_default("HTTP_HEADERS",par, {})
accept=get_val_with_default("Accept", headers, "application/json")
log("accept="+str(accept))


local_upload_root=get_cfg_entry("local_file_upload_base_dir")
server_upload_root=get_cfg_entry("server_file_upload_base_dir")
log("*** using upload dir '"+local_upload_root)

# # FIXME: get real project dir!
project_dir = "internal"
filekey="concat_"+str(UUID.randomUUID())
log("filekey="+filekey)

session = dfc.getSharedSession()
sc=bctx.getSecurityContext()
log("securityContext="+str(sc))

# rawEntries=docList[0].paramValue.params
# log("entries="+str(rawEntries)+ " of type "+str(rawEntries.__class__))
# entries = map(parse_entry, rawEntries)
# log(" entries=" + str(entries))


# session = dfc.getSharedSession()
#

method_args = [  "-U", sc.getUserName(), "-R", sc.getRepositoryName(), "-P", session.getLoginTicket() , "-k" , filekey ]

if page_renumbering:
    method_args.extend(["-c" ,
                        String(utl.getBase64().getEncoder().encode(String(page_renumbering).getBytes())) ])

for entry in docList:
    log("adding entry: "+ str(entry))
    (eType, eVal, ddc) = parse_entry(entry)
    log("eType="+eType +" eVal="+str(eVal) + " ddc"+str(ddc))
    marg = entry2method_args(eType, eVal, ddc)
    log("marg="+str(marg))
    method_args.extend(marg)

log("METHOD ARGS: "+str(method_args))

method_args_str = list_join(map(escape_method_arg, method_args))

log("calling server method with args: "+method_args_str)


call_result = ServerMethodUtils.runServerMethod(session,
                                                 "bnhp_concatenate_docs_by_params",
                                                 method_args_str,
                                                 # launch_async=F,  save_result=F
                                                 0, 0)
log("call result="+str(call_result))
check_call_result(call_result)

log("python method finished")

# DocURL and DocSize are return values, will be read by velocity
#log("returning DocURL="+DocURL)
#log("returning DocSize="+str(DocSize))

#if "HTTP" == retrieve_profile.upper():
#    mime_type = "application/json"
#else:

if accept == "application/pdf" or accept=="application/*" or accept=="*/*":
    log("pass_thru enabled")
    is_pass_thru="true"
else:
    log("pass_thru disabled")
    is_pass_thru="false"

mime_type = "application/pdf"
result = { "OBJECT_PATH" :  "/Temp/bnhp_concatenate_docs_by_params/" + filekey,
           "RETRIEVE_PROFILE" : retrieve_profile,
           "MIMETYPE" : mime_type,
           "CLEANUP" : False }
log("RETURN result="+str(result))



## FIXME
## * return link
## * docdatacheck requirement configured per user
##  docdatacheck to ignore match between invalid entries (all zero)
##  docdatacheck to ignore leading zeros
## * url input
## * input directories for url input according to policies
## * error handling from method error codes
## * cleanup of old files (method)
## * logging
## URL output
## base64 string output



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\templates\python\countDocumentsPages.py
-----------------------------------------------------
import logging
import io
import sys
import collections
import numbers

from urllib import urlencode
from urlparse import urlparse

from com.fasterxml.jackson.core import JsonParser
from com.fasterxml.jackson.core import JsonFactory
from com.fasterxml.jackson.core import JsonToken
from com.fasterxml.jackson.core import JsonGenerator
from com.fasterxml.jackson.core import JsonEncoding

from java.io import FileOutputStream 
from java.io import File
from java.io import FileInputStream

from java.util import HashMap
from java.util import ArrayList
from java.util import List

print "*** HELLO FROM PYTHON ***"

class Errors:
    OK = "OK"
    TE = "TemporaryError"
    FE = "FatalError"
    GE = "GeneralError"
    
    NO_ERROR                   =  (0, OK,  "No error")
    T_NO_PAGE_COUNT_DATA       =  (1, TE,  "No page count data")
    I_MORE_THAN_ONE_RECORD     =  (2, FE,  "Internal error: more than one record found: {}")
    F_FAILED_RETRIEVE_CONTENT  =  (3, FE,  "Failed to retrieve content object {}")
    F_NO_MATCHING_CONTENT      =  (4, FE,  "No matching content object for document {}")
    I_NOT_A_CONTENT_ID         =  (5, FE,  "Internal error: not a content id {}")
    G_ERROR_GETTING_PAGE_COUNT =  (6, GE,  "Failed to get page count: {}")
    I_INV_PAGE_COUNT_ATTR      =  (7, FE,  "Page count attribute of wrong type {}")
    F_INV_ID_TYPE              =  (8, FE,  "Invalid id type: {}")
    F_DOCUMENT_NOT_FOUND       =  (9, FE,  "Document not found")
    G_ERROR_GETTING_DOC        =  (10, GE, "Failed to get document: {}")
    G_ERROR_GETTING_CONTENT    =  (11, GE, "Failed to get content: {}")
    F_INV_ID_VALUE             =  (12, FE, "Invalid id value: '{}'")    

err = Errors()    

class ExtraRecError(Exception):
    pass

def log(msg):
    print >>sys.stderr, msg

### file input functions    
def safe_close_stream(stream):
    try:
        if stream:
            print("closing "+str(stream))
            stream.close()
    except:
        logging.exception("Exception closing stream" , exc_info=True)


def init_file_input(filename):
    fis = None
    success = None    
    try:
        file = File(filename)
        fis = FileInputStream(file)
        factory = JsonFactory()
        parser = factory.createParser(fis)

        def expect_tokens(expected_tokens):
            next_token = parser.nextToken()
            if not next_token in expected_tokens:
                raise Exception("unexpected token "+str(next_token)+
                                ", expected one of "+str(expected_tokens));
            return next_token
        
        def close_input():
            safe_close_stream(fis)

        def read_entry():
            entry = HashMap()
            token = expect_tokens([JsonToken.START_OBJECT, JsonToken.END_ARRAY])
            if token == JsonToken.END_ARRAY:
                return None
            while parser.nextToken() != JsonToken.END_OBJECT:
                name = parser.getCurrentName()
                parser.nextToken()
                if name in [ "idType", "id" ]:
                    value = parser.getText()
                elif name in ["count"]:
                    value = parser.getIntValue()
                else:
                    raise Exception("Unknown field: '"+name+"'")
                entry.put(name, value)
            return entry

        expect_tokens([JsonToken.START_ARRAY])
        success=True
        
        return close_input, read_entry
    finally:
        if not success:
            safe_close_stream(fis)

### File Output Functions

def init_file_output(filename):
    try:
        file = File(filename)
        fos = FileOutputStream(file)
        factory = JsonFactory()
        gen = factory.createGenerator(fos, JsonEncoding.UTF8)
        gen.writeStartArray()

        def safe_close_os():
            if fos:
                try:
                    fos.close()
                except:
                    print("Exception closing output stream: " +  errinfo())
        
        def close_output():
            try:
                gen.writeEndArray()
                gen.flush()
                gen.close()
            except:
                print("Exception closing output: " + errinfo())
            finally:
                safe_close_os()
                
        def write_entry(entry):
            gen.writeStartObject()
            for member in entry.entrySet():
                val = member.getValue()
                if isinstance(val,numbers.Number):
                    gen.writeNumberField(member.getKey(), val)
                else:
                    gen.writeStringField(member.getKey(), str(val))
            gen.writeEndObject()
            gen.writeRaw("\n")
        return close_output, write_entry
    except BaseException as ex:
        print("Exception initializing output: " +   errinfo())
        raise(ex)

### Parameter  handling functions

def get_val_with_default(parname, parmap, defval):
    if parmap.has_key(parname):
        return parmap[parname]
    else:
        return defval

def get_mandatory_val(parname, parmap, *valset):
    global par
    global utl

    if not parmap.has_key(parname):
        utl.error("Mandatory parameter "+ parname + " not set!")
    value=parmap[parname]            
    if valset:
        if not value in valset:
            utl.error("Value of "+ parname + " must be one of "+str(valset))
    return value


def doc_err(doc, err, arg):
    doc.put("status", err[1])
    doc.put("errorDetails", err[2].format(arg))
    doc.put("errorCode", err[0])
    return doc

def errinfo():
    return str(sys.exc_info()[0])+": "+str(sys.exc_info()[1])

def fetch_doc_data(doc, id_field, docid):
    dql_query = "SELECT r_object_id, i_vstamp, r_content_size, a_content_type, r_aspect_name, i_is_reference, i_is_replica " \
        "FROM bnhp_customer_doc WHERE \"" + id_field + "\"='"+utl.esc(docid)+"'"
    log("DQL: "+dql_query)
    doc_data = None    
    try:
        doc_data=retrieve_single_entry(dql_query,  "bnhp_customer_doc", "document "+ id_field + "\"='"+utl.esc(docid)+"'")
    except ExtraRecError:
        doc_err(doc, err.I_MORE_THAN_ONE_RECORD, "document "+ id_field + "\"='"+utl.esc(docid)+"'")
    except:
        doc_err(doc, err.G_ERROR_GETTING_DOC, "getting documents " +  errinfo())
    return doc_data


def retrieve_single_entry(dql, object_type, desc):
    #FIXME: different exceptions, not just description
    log("retrieve_single_entry of type "+object_type+": "+dql)
    obj_enum = session.getObjectsByQuery(dql, object_type)
    obj_data = None
    while obj_enum.hasMoreElements():
        if obj_data:
            raise ExtraRecError("Unexpected record(s) for "+str(desc))
        obj_data = obj_enum.nextElement()
        break;
    return obj_data

# doc_data: persistent object
def get_page_count(doc, doc_data):
    # FIXME: hardcoded format
    r_object_id = doc_data.getString("r_object_id")
    if not r_object_id[0:2] == "09":
        doc_fatal(doc, 6, "Internal error: not a document id id: '" + str(r_object_id) + "'")
        return 0
    dql = "SELECT r_object_id, i_vstamp, i_is_replica " \
        "FROM dmr_content WHERE any parent_id='" + utl.esc(r_object_id) + "' " \
        "AND full_format='pdf' AND page=0 AND page_modifier=' ' ENABLE(ROW_BASED)"
    cont_data = None
    try:
        cont_data = retrieve_single_entry(dql, "dmr_content", "content object for document with "+r_object_id)
    except ExtraRecError:
        doc_err(doc, err.I_MORE_THAN_ONE_RECORD, "content object for document with "+r_object_id)
        return 0
    except:
        doc_err(doc, err.G_ERROR_GETTING_CONTENT, errinfo())
        return 0
    log("retrieve succeeded")
    if not cont_data:
        doc_err(doc, err.F_NO_MATCHING_CONTENT, "r_object_id+")
        return 0

    content_object_id = cont_data.getString("r_object_id")
    
    if not content_object_id[0:2] == "06":
        doc_err(doc, err.I_NOT_A_CONTENT_ID, str(content_object_id))
        return 0

    print("CONTENT ID="+cont_data.dump())

    page_count_data = None
    dql = "SELECT content_attr_num_value, r_object_id,  i_vstamp, i_is_replica FROM dmr_content WHERE r_object_id='"+content_object_id+"' "+\
        " AND content_attr_name='page_count' and  content_attr_data_type=5 ENABLE(ROW_BASED)"
    try:
        page_count_data = retrieve_single_entry(dql, "dmr_content", "page count for "+content_object_id)
    except:
        doc_err(doc, err.G_ERROR_GETTING_PAGE_COUNT, errinfo())
        return 0

    if not page_count_data:
        doc_err(doc, err.T_NO_PAGE_COUNT_DATA ,"")
        return 0

    page_count = page_count_data.getInt("content_attr_num_value")
    log("got page_count="+str(page_count))
    
    if isinstance(page_count, numbers.Number):
        return page_count

    doc_err(doc, err.I_INV_PAGE_COUNT_ATTR, type(page_count))
    return 0


# FIXME: check for unknown fields!
def process_doc(doc):
    if doc.get("idType") == "legacyDocumentId":
        id_field = "legacy_document_id"
    elif  doc.get("idType") == "dctmDocumentId":
        id_field = "dctm_document_id"
    else:
        return doc_err(doc, err.F_INV_ID_TYPE, str(doc.get("idType")))
    docid = doc.get("id")
    if not docid or docid in [ "",  " " ]:
        return doc_err(doc, err.F_INV_ID_VALUE, str(docid))
    try:
        log("running fetch_doc_data")
        doc_data = fetch_doc_data(doc, id_field, doc.get("id"))
        if not doc_data:
            return doc_err(doc, err.F_DOCUMENT_NOT_FOUND, "")
        log("running get_page_count")
        count = get_page_count(doc, doc_data)
        doc.put("count", count)
        if not doc.get("status"):
            doc.put("status", "OK")
    # FIXME: exc handling
    # need to separate between really unexpected errors (python errors of all kinds)
    # dfc errors and those from them that are known to be temporary
    except:
        return doc_err(doc, err.G_ERROR_GETTING_PAGE_COUNT, errinfo())
    return doc

### inline "input"

def init_inline_input(par):
    in_par = par
    in_size = par.size()
    in_idx = [ 0 ]
    def inline_close_input():
        pass

    def inline_read_entry():
        if in_idx[0] >= in_size:
            return None
        entry = in_par.get(in_idx[0])
        print(type(entry))
        in_idx[0] = 1 + in_idx[0]
        return entry

    return inline_close_input, inline_read_entry


### inline "output"

def init_inline_output( outlist ):
    def close_output():
        pass
    def write_entry(entry):
        py_entry = {}
        for key in entry.keySet():
            py_entry[key] = entry.get(key)
        outlist.append(py_entry)
    return close_output, write_entry

### configuration and parameters handling

def docURL2file(urlStr):
    parsed=urlparse(urlStr)
    server_file_path= server_upload_root + "/" + parsed[2]
    #local_file_path= local_upload_root + "/" + parsed[2]
    return server_file_path

# FIXME: only first alt. path is supported
def get_cfg_entry(name):
    return utl.configGetString(name).split(",")[0]

#### document processing

# returns list of doument entries
def process_documents(documents_par, target_par):
    results = []
    if isinstance(documents_par, str) or isinstance(documents_par, unicode):
        # read from URL
        input_filename = docURL2file(documents_par)
        log("reading input from file '"+input_filename+"'")
        closeif,readif= init_file_input(input_filename)
    elif isinstance(documents_par, List):
        log("list of input documents is inline")
        closeif,readif= init_inline_input(documents_par)
    else:
        utl.error("unknown type of documents parameter: "+ str(type(documents_par)))

    # We use java objects as list element, so let's be consistent and use java list
    results=[]
    #ArrayList()
    if target_par:
        output_filename = docURL2file(target_par)
        log("writing output to file '"+output_filename+"'")
        closeof,writeof= init_file_output(output_filename)
    else:
        log("service output is inline")
        closeof,writeof= init_inline_output(results)

    while True:
        in_entry = readif()
        if not in_entry:
            break
        out_entry = process_doc(in_entry)
        writeof(out_entry)
    # these won't fail
    closeif()
    closeof()
    return results

#def process_documents_list(doc_list):

log("securityContext="+str(bctx.getSecurityContext()))

server_upload_root=get_cfg_entry("server_file_upload_base_dir")
log("server upload root: "+server_upload_root)

documents_par = get_mandatory_val("documents", par)
log("type(documents_par)=" + str(type(documents_par)))

target_url = get_val_with_default("targetURL", par, None)

session = dfc.getSharedSession()

sizes_list = process_documents(documents_par, target_url)

log("results: "+str(sizes_list))
result = sizes_list

def get_script_result():
    return result

    
    


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\templates\python\retrieveDocumentsByZip.py
-----------------------------------------------------
## adding library on command line
# -Dpython.path=PYTHONPATH=/home/FW0/projects/M28008_DocumentumProjects/duecm3rdpartydeps/jython-lib.jar
import logging
import io
import sys
import collections
import numbers
from java.util import HashMap
from java.util import ArrayList
from java.util import List

def log(msg):
    print >>sys.stderr, msg

log("*** jython shalom! ***")
log("*** sys.path="+str(sys.path))
log("*** user="+user)


from urllib import urlencode
from urlparse import urlparse
from java.lang import Boolean

from urllib import urlencode
from urlparse import urlparse

from com.fasterxml.jackson.core import JsonParser
from com.fasterxml.jackson.core import JsonFactory
from com.fasterxml.jackson.core import JsonToken
from com.fasterxml.jackson.core import JsonGenerator
from com.fasterxml.jackson.core import JsonEncoding
from com.fasterxml.jackson.core import ObjectCodec
from com.fasterxml.jackson.databind import ObjectMapper


from java.util import UUID
from java.io import FileOutputStream 
from java.io import File

from bnhp.infra.dfs.utils.dfc import ServerMethodUtils
from bnhp.infra.dfs.model.business import DocFile

from com.documentum.fc.client.acs.impl import DfAcsTransferPreferences

### Error info
def errinfo():
    return str(sys.exc_info()[0])+": "+str(sys.exc_info()[1])

### Parameter  handling functions
def get_val_with_default(parname, parmap, defval):
    if parmap.has_key(parname):
        return parmap[parname]
    else:
        return defval

def get_mandatory_val(parname, parmap, *valset):
    global par
    global utl

    if not parmap.has_key(parname):
        utl.error("Mandatory parameter "+ parname + " not set!")
    value=parmap[parname]            
    if valset:
        if not value in valset:
            utl.error("Value of "+ parname + " must be one of "+str(valset))
    return value


### File Output Functions
def init_file_output(filename):
    safe_close_os = None
    try:
        file = File(filename)
        fos = FileOutputStream(file)
           
        def safe_close_os():
            if fos:
                try:
                    fos.close()
                except:
                    print("Exception closing output stream: " +  errinfo())
                    

        factory = JsonFactory()
        gen = factory.createGenerator(fos, JsonEncoding.UTF8)
        gen.writeStartArray()
                   
        
        def close_output():
            try:
                log("***close output!!!")
                gen.writeEndArray()
                gen.flush()
                gen.close()
                fos = None
            except:
                print("Exception closing output: " + errinfo())
            finally:
                safe_close_os()
                return None
                
        def write_entry(entry):
            log("type(entry)=" + str(type(entry)))
            om=ObjectMapper()
            gen.writeStartObject()
            for member in entry.entrySet():
                val = member.getValue()
                key = member.getKey()
                log ("field = "+str(key) + " -> " + str(val) )
                if isinstance(val,numbers.Number):
                    gen.writeNumberField(key, val)
                elif isinstance(val,str): 
                    gen.writeStringField(key, str(val))                    
                else:
                   gen.setCodec(om);
                   gen.writeObjectField(key,val)
            gen.writeEndObject()
            gen.writeRaw("\n")
        return close_output, write_entry
    except BaseException as ex:
        print("Exception initializing output: " +   errinfo())
        raise(ex)

def make_file_url(project_dir, filename):
    # FIXME: urlencode
    return "file:///" + project_dir +"/"+ filename
        

def get_one_val(parname, *args):
    global par
    global utl
    value=par[parname]
    if not value in args:
        utl.error("Value of "+ parname + " must be one of "+str(args))
    if not value:
        utl.error("Mandatory parameter "+ parname + " not set!")
    return value

def get_cfg_entry(name, username):
    return utl.configGetUserString(name,username).split(",")[0]

def docURL2file(urlStr):
    parsed=urlparse(urlStr)
    server_file_path= server_upload_root + "/" + parsed[2]
    return server_file_path

def get_method_result_desc(cc):
    # FIXME: must be a way to share the enum
    # between python and java code
    method_errmap = { 0  : 'SUCCESS(0)',
	              1  : 'WARN_SOME_FILES_FAILED(1)',
	              10 : 'TEMP_ERROR(10)',
	              11 : 'TEMP_INPUT_FILE_IO_ERROR(11)',
	              12 : 'TEMP_OUTPUT_FILE_IO_ERROR(12)',
	              13 : 'TEMP_DOCUMENT_NOT_FOUND(13)',
	              14 : 'TEMP_DOCUMENTUM_ERROR(14)',
	              15 : 'TEMP_CONFIGURATION_ERROR(15)',
	              20 : 'ERROR_GENERAL(20)',	
	              21 : 'ERROR_ENTRY_NAME_NOT_SPECIFIED(21)',
	              22 : 'ERROR_ENTRY_TYPE_NOT_SPECIFIED(22)',
	              30 : 'FATAL_ERROR(30)',
	              31 : 'FATAL_WRONG_USAGE(31)',
	              32 : 'FATAL_ARGUMENT_VALIDATION(32)',
	              33 : 'FATAL_INPUT_FILE_NOT_FOUND(33)',
	              34 : 'FATAL_INPUT_PARSING_ERROR(34)',
	              35 : 'FATAL_CONFIG_ERROR(35)',
	              36 : 'FATAL_INTERNAL_ERROR(100)' };
    desc = method_errmap[cc]
    if not desc:
        desc = "UNKNOWN("+str(cc)+")"
    return desc

TOP_LEVEL_TAG="zipfile"
# FIXME: get real project dir!
project_dir = "internal"

session = dfc.getSharedSession()    
#dctm_user = dfc.getSharedSession().getLoginUserName()
dctm_user = dfc.getSharedSession().getLoginInfo().getUser()
dctm_repo = dfc.getSharedSession().getDocbaseName()
dctm_pass = dfc.getSharedSession().getLoginTicket()

local_upload_root=get_cfg_entry("local_file_upload_base_dir", dctm_user)
server_upload_root=get_cfg_entry("server_file_upload_base_dir", dctm_user)
log("*** using upload dir '"+local_upload_root)

def make_temp_file(prefix, suffix):
    global project_dir
    global local_upload_root
    filename = str(prefix) + str(UUID.randomUUID()) + str(suffix)
    filepath = local_upload_root + "/" + project_dir +"/" +filename
    fileurl = make_file_url(project_dir, filename)
    return filepath, fileurl

log("*** parsing arguments...")
file_name_source = get_one_val("fileNameSource","legacyDocumentId","dctmDocumentId","explicit", None)
if not file_name_source:
    file_name_source = "legacyDocymentId"
    
dos_extension = get_val_with_default("dosExtension", par, "pdf")

#URL of file with array of document statuses.
# If not given the service will return the array in the response.
# File format is same as DocumentsStatusList
target_status_url = get_val_with_default("targetStatusURL", par, None)

# URL of target zip file. If not set the service will attempt to return zip in response
target_url = get_val_with_default("targetURL", par, None)

documents_par = get_mandatory_val("documents", par)
log("type(documents_par)=" + str(type(documents_par)))

if isinstance(documents_par, str) or isinstance(documents_par, unicode):
    method_input_file = docURL2file(documents_par)
else:
    # make input file for server method
    method_input_file, method_input_url = make_temp_file( "retrievezip_", "_in.json")
    log("*** will write method_input_file='" + method_input_file +"'")
    log("*** method input url is "+method_input_url)
    inclose, inwrite = init_file_output(method_input_file)
    for entry in documents_par:
        log("*** writing entry " + str(entry))
        inwrite(entry)
    inclose()
    documents_par = method_input_url
    
inline_result = 0
if target_url:
    # FIXME: checks!
    log("*** using provided targetUrl='"+ str(target_url)+"'")
else:
    inline_result = 1
    zip_filename = "retrievezip_" + str(UUID.randomUUID()) + "_out.zip"
    target_url=make_file_url(project_dir, zip_filename)
    log("*** generated temporary target_url='"+ str(target_url)+"'")

target_file = docURL2file(target_url)    
log("*** target_file='" + str(target_file)+"'")
    
status_file, status_url =  make_temp_file("retrievezip_", "status.json")


    
# # FIXME: check urls according to project, user!!!!
# # FIXME: escapes!
# # call server method
#  make_file_url(project_dir, method_input_file)
method_args = "--source-url \"" + documents_par  +"\" " + \
     " --readers 2" + \
     " --zip-url \"" + target_url +"\"" +\
     " --file-name-source \"" + file_name_source +"\"" +\
     " --upload-root \"" + server_upload_root +"\"" + \
     " --dctm-user \""+dctm_user +"\"" + \
     " --dctm-pass \""+dctm_pass +"\"" + \
     " --dctm-repo \""+dctm_repo +"\""
if not inline_result:
     method_args += " --status-file-url \""+status_url+"\""  

log("calling server method with args: "+method_args)

call_result = ServerMethodUtils.runServerMethod(session,
                                                "bnhp_retrieve_zip",
                                                method_args,
                                                0, 0)
log("method result "+str(call_result))
log("method return val " + str(call_result.methodReturnVal))
if call_result.methodReturnVal > 1:
    status_desc = get_method_result_desc(call_result.methodReturnVal);
    utl.error("server method returned error status: " + status_desc)

if call_result.timeout:
     utl.error("server method timed out")
if call_result.launchFailed:
     utl.error("server method launch failed")

log("produced zip file "+target_file)


if inline_result:
    result = { "FILE" : target_file,
               "MIMETYPE" : "application/zip",
               "CLEANUP" : True }
    
else:
    result = { "FILE" : status_file,
               "MIMETYPE" : "application/json",
               "CLEANUP" : True }
        


# parsed=urlparse(zip_url)
# server_file_path= server_upload_root + "/" + parsed[2]
# local_file_path= local_upload_root + "/" + parsed[2]


# if acs_result:
#     zip_file_paths=[server_file_path]
#     log("creating temp object")
#     temp_obj = session.newObject("dm_sysobject");
#     temp_object_id = temp_obj.getObjectId().getId()
#     log("created temp object id="+temp_object_id)
#     temp_obj.setObjectName(server_file_path);
#     temp_obj.link("/Temp/bnhp_retrieve_zip")
    
#     #zip_file = File(zip_file_path)
#     fbu = bctx.getUploadUtils().getFileBasedUploadUtils()
#     doc_file = DocFile()
#     doc_file.setDocURL(zip_url)
#     doc_file.setDocFormat("zip")
#     temp_obj.save();
#     log("temp object saved")
#     fbu.uploadOnServer(doc_file,
#                        "r_object_id=\'"+temp_object_id+"\'",
#                        "dm_sysobject",
#                        zip_file_paths,
#                        "")
#     log("content uploaded")
#     temp_obj.save()
#     acs_prefs = DfAcsTransferPreferences()
#     acs_prefs.preferAcsTransfer(1)
#     acs_enum = temp_obj.getAcsRequests("zip",0,None,acs_prefs)
#     acs_req=None
#     while acs_enum.hasMoreElements():
#         # FIXME: match according config!
#         log("setting DocURL")
#         acs_req=acs_enum.nextElement()
#         break
#     if not acs_req:
#         utl.error("Failed to retrieve content URL from ACS server")
#     DocURL=acs_req.makeURL()
#     DocSize=acs_req.getContentLength()
# else:    
#     DocURL=zip_url
#     zip_file=File(local_file_path)
#     DocSize=zip_file.length()

# # DocURL and DocSize are return values, will be read by velocity
DocURL=""
DocSize=0
log("returning DocURL="+DocURL)
log("returning DocSize="+str(DocSize))







file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\templates\python\ReturnResult.py
-----------------------------------------------------
print "*** HELLO FROM PYTHON ***"
print "*** user="+user
print "*** par:"+str(par)
print "*** par.getClass:"+str(par.getClass())
for item in par.keySet():
    print "**** "+str(item)
    print "***** "+str(par[item])
print "*** executor="+str(executor)

#result="This is a python result!"
result=[ "foo" ,"bar", 0.1, 112, [ "bz sss" ]]
#result = { "foo" : "bar", "moo" : 1 , "gooo" : [ 1, 2, 3, 4] , "arrayofmaps" : [ { "a" : "b", "c": "d"}, {"e" : "f", "g" : "h"}]}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\templates\retrieveDocumentsByZip.txt
-----------------------------------------------------
#set($interp=$scripting.run_jython("python/retrieveDocumentsByZip.py"))
#set($RESULTVAR=${interp.get("result")})
-- QUERY TYPE=RETURNRESULT RESULT="__PASSTHRU"





file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\templates\searchCustomerDocuments.txt
-----------------------------------------------------
## VALIDATION
#if(${context}) ## require null context
#set($server_paging=false)
$utl.error("template is not supposed to use the given context")## throw error
#end
$lv.define("validParams",["customers","accounts","startDate","endDate","fulltext","systemCode","dosExtension"])

## check for unsupported params
#foreach($param in $par.keySet())##  
	$lv.validate("validParams",${param})## user validation
#end

## need a least one account or customer
#if (!((${par.accounts} and ${par.accounts.size()}>0) or (${par.customers} and ${par.customers.size()}>0)))
	$utl.error("Need at least one account or at least one customer for search to work")## throw error
#end

## check type of received values
#if (${par.EndDate})
	$vv.date(${par.EndDate},"EndDate")
#end

#if (${par.StartDate})
   $vv.date(${par.StartDate},"StartDate")
#end

## check all entries for validity

#if (${par.accounts} and ${par.accounts.size()}>0)
	#foreach(${Account} in ${par.accounts})## 
		$vv.integer(${Account.accountNbr},"accountNbr")## In-loop validation 
		$vv.integer(${Account.branchId},"branchId")## In-loop validation
		$vv.integer(${Account.accountBankId},"accountBankId")## In-loop validation
	#end
#end

#if (${par.customers} and ${par.customers.size()}>0)
	#foreach(${CustomerKey} in ${par.customers})## 
 		$vv.nonempty(${CustomerKey.completeCustomerIdCode},"CompleteCustomerIdCode")
 	#end
#end

## QUERY
-- SELECT_COUNT
SELECT COUNT(DISTINCT r_object_id) 

-- SELECT
SELECT DISTINCT r_object_id AS r_object_id, legacy_document_entry_dttm AS legacy_document_entry_dttm   

-- FROM
FROM dm_dbo.BNHP_CUSTOMER_DOC_BUSINESS_V doc WHERE
## current non cancelled versions only
i_has_folder=1 AND i_is_deleted=0
AND project_id in (1,2,3,6,7,9,10,11,12,13,14,18,20,21,25,29,31,43,51)
#if (${par.StartDate})
	AND legacy_document_entry_dttm>=$utl.ddls(${par.startDate}) 
#end
#if (${par.EndDate})
	AND legacy_document_entry_dttm<=$utl.ddle(${par.endDate})
#end

## AND executing_bank_id IN (12,912)
#if(${par.accounts} and ${par.accounts.size()}>0)
AND ( ##
	#foreach(${Account} in ${par.accounts})## 
		(account_nbr=${Account.accountNbr} AND branch_id=${Account.branchId} AND account_bank_id=${Account.accountBankId}
		)
		#if($foreach.hasNext ) OR#end## do not put OR at end
	#end ## foreach par.accounts
)
#end
#if (${par.customers} and ${par.customers.size()}>0)
AND  (
	#foreach(${CustomerKey} in ${par.customers})## 
 			( 
  				(
 				#foreach(${variant} in $utl.extrazeros(${CustomerKey.completeCustomerIdCode},9))##
					complete_customer_id_code='${variant}'
					#if($foreach.hasNext) OR #end 
 				#end
  				) 
			#if(${CustomerKey.customerIdDocTypeCode}) $vv.integer(${CustomerKey.customerIdDocTypeCode},"CustomerIdDocTypeCode")
   				AND customer_id_doc_type_code in (${CustomerKey.customerIdDocTypeCode},0,-1)
			#end
			#if(${CustomerKey.customerId}) $vv.real(${CustomerKey.customerId},"CustomerId")
				AND customer_id=${CustomerKey.customerId}
			#end
			) 
			#if($foreach.hasNext) OR#end## do not put OR at end
		#end ## foreach par.customers
		)
#end

#if  (${par.fulltext} and ${par.fulltext.length()} > 0)
	AND EXISTS (
		 SELECT ALL r_object_id FROM bnhp_customer_doc ftd 
		   SEARCH LAST DOCUMENT CONTAINS '$utl.esc(${par.fulltext})'
		     WHERE ftd.r_object_id=doc.r_object_id
			 )
#end

## ORDER BY PART, keep the following line, otherwise generation of count query won't work
-- ORDER BY

#if (${sd.start_index})
#set($server_paging=true)
$hints.add("RETURN_RANGE ${sd.start_index}  ${sd.end_index} 'doc.legacy_document_entry_dttm ASC,doc.r_object_id ASC'")
#else
ORDER BY legacy_document_entry_dttm, r_object_id ASC
#if (${sd.return_top})
#set($server_paging=true)
$hints.add("RETURN_TOP ${sd.return_top}")
#end
#end

## HINTS PART, keep the following line, otherwise generation of count query won't work
-- HINTS
## additional hints for this query
$hints.add("ROW_BASED")
ENABLE($hints)
-- HINTS_COUNT

ENABLE($hints.outNonPaging())




file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\utl-tests.l
-----------------------------------------------------



(DEFUN test-project-eq? ()
  (LET ((ddfr (test-ashrai-make-ddfr (LIST 1000L))))
	   (project-eq? 27)))

(DEFUN test-project-make-ddfr (project-id clnum)
  "make ddfr with given project id and client number"
  (LET ((ddfr (.N "bnhp.infra.dfs.model.service.DocDataForRetrieve"))
		(dd (.N "bnhp.infra.dfs.model.business.DocData"))
		(dcd (.N "bnhp.infra.dfs.model.business.DocCustomerData"))
		(ckey (.N "bnhp.infra.dfs.model.business.CustomerKey"))
		(ddet (.N "bnhp.infra.dfs.model.business.DocDetails"))
		(docdate (.N "java.util.Date" (LIST) )))
	   (. ckey "setCustomerId" (LIST clnum))
	   (. dcd "setCustomerKeys" (LIST (LIST ckey)) (LIST "java.util.List"))
	   (. ddet "setProjectId" (LIST project-id))
	   (. ddfr "setDocData" (LIST dd))
	   (. dd "setDocCustomerData" (LIST dcd))
	   (. dcd "setDocDetails" (LIST ddet))
	   (. ddet "setLegacyDocumentEntryDttm" (LIST docdate))
	   ddfr))

(DEFUN test-customer-clnumbers-check ()
  (LET ((clnt1 (test-project-make-ddfr 3 22222L))
		(clnt2 (test-project-make-ddfr 3 22222L))
		(clnt3 (test-project-make-ddfr 3 0L))
		(clnt4 (test-project-make-ddfr 3 33L)))
	   (LIST
		(LET ((docDataCheck (. clnt1 "getDocData()"))
			  (ddfr clnt2))
			 (clnumbers-check? ))
		(LET ((docDataCheck (. clnt1 "getDocData()"))
			  (ddfr clnt3))
			 (clnumbers-check? ))
		(LET ((docDataCheck (. clnt1 "getDocData()"))
			  (ddfr clnt4))
			 (clnumbers-check? ))
		(LET ((docDataCheck (. clnt3 "getDocData()"))
			  (ddfr clnt3))
			 (clnumbers-check? ))
		)))
		


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\utl.l
-----------------------------------------------------
;;; utl.l ; generally useful utilities

(DEFUN utl-num-max (lst)
  "return maximal value for list of numbers, NILs are OK"
  (REDUCE (LAMBDA (accum  num)
				  (IF accum 
					  (IF (> num accum) num accum)
					  num))
		  NIL  lst))

(DEFUN throw-validation-error (msg)
  (THROW (.N "bnhp.infra.dfs.exceptions.DFSValidationException" (LIST msg))))

(DEFUN throw-dfsdoc-error (msg)
  (THROW (.N "bnhp.infra.dfs.exceptions.DFSDocumentumException" (LIST msg))))

(DEFUN project-eq? (project-id)
  (LET ((doc-project (. ddfr "getDocData().getDocCustomerData().getDocDetails().getProjectId()")))
	   (= doc-project project-id)))


;; FIXME: must be builtin
(DEFUN make-array (typestr size)
	   (.S "java.lang.reflect.Array" "newInstance" (LIST (CLASS typestr) size) (LIST "Class" "int")))

(LOG "INFO" "loaded utl.l")


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources\velocity_test_properties.properties
-----------------------------------------------------

resource.loader=string
string.resource.loader.description=Velocity StringResource loader (for tests)
string.resource.loader.class=org.apache.velocity.runtime.resource.loader.StringResourceLoader
string.resource.loader.repository.class=org.apache.velocity.runtime.resource.util.StringResourceRepositoryImpl





file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources-dev\bhEnvProperty.properties
-----------------------------------------------------
# vanilla
#repository_name=banhap_qa1
#folder_id=0b00000a801e5f84
#folder_id_4_reprints=0b00000a801e5f85
# preprod
#repository_name = banhap_preprd1
#folder_id = 0b000009800bb5a6
#folder_id_4_reprints=0b000009800bb5a5
# s
#repository_name = banhap_qa1
#folder_id = 0b00000a800927c7
#folder_id_4_reprints=0b00000a800927c6


# DEV
repository_name = banhap_dev1
folder_id = 0b00000a8004e6d2
folder_id_4_reprints=0b00000a8004e6d4

context_root = http://localhost:9080/services

module_name = core
doc_type = bnhp_tfs_peula_doc
doc_type_alias = doc
erua_type=bnhp_yoman_eruim_table
heara_type=bnhp_yoman_eruim_table
doc_type_pb = bnhp_tfs_peula_reprint
central_code_table_doc_type = bnhp_central_code_table
bnhp_yoman_eruim_table_doc_type = bnhp_yoman_eruim_table
reprint_relation_type = bnhp_tofes_reprint_relation
#MF tables
kesher_type = DPT.DPT2042
makat_type = DPT.DPT2040
tchum_type = DPT.DPT2044
tat_type = DPT.DPT2043
matbea_type = DPT.DPT0484

user_name = dctm
user_pass = AAAAEFJMk9QntvpBhsRyNsXgyDBZ//4n3Q7zJK/xjgjMxeio

#For create/update object service - properties not to be updated 
pakid_unupdatable_properties=
customer_unupdatable_properties=kodCheshbonMutzpan,misparHativa,misparBank,misparCheshbon,mprZihuyLakoach,mprSiduriLakoach,misparSnif,misparAmit,misparKupatGemel,sugMismachMezaheLak,sifrurLakoach,shemLakoach
tofes_unupdatable_properties=misparMahadura,misparTofes,docType,docSubType
appl_unupdatable_properties=docKey,appId,projectId,shotefOrHistory
scan_unupdatable_properties=pageCount

#For create/update object service - to validate their values before populate them, and throw exception in case of not valid
centralCodesProperties=projectId,docStatus,shotefOrHistory,incomplete,archive,physicalLocation,scanStatus
peulaMFCodesProperties=misparTofes,docType,docSubType
peulaMFCurrencyCodesProperties=shemIvri,shemLoazi

#Categories of BHPeulaDocDataContext fields
projectId=105
docStatus=106
shotefOrHistory=100
incomplete=101
archive=102
physicalLocation=103
scanStatus=104
mezahePak=108
mezaheLak=107
arutz=112

#Categories of BHPeulaYomanDataContext fields
kodSugErua=200
ofenTipulErua=201
ofenTipulErua4Heara=203
createTypeErua=202

#Categories of scan status and doc_status fields
scanStatusCategory=104
docStatusCategory=106

# For extended debug log
printInput2LogMode=true

# For Harigim Screen Initialization
defaultOfenTipulCodes=1,2

# For Search Screen Initialization
statusCategories=104,106

#For Search results
category_scan_status=104
category_sign_status=106

# ofen tipul for kod sug tofes
ofenTipulForKodSug_1=2,3,4,6
ofenTipulForKodSug_2=2,3,4,5,6
ofenTipulForKodSug_3=2,3,4,5,6
ofenTipulForKodSug_4=2,3,4,5,6

#
heara_4_cheshbon_mushhe= 
pakid_def_shem= 
pakid_def_mispar_tachana=0
pakid_def_mispar_bankol=0

#keystoreLocation = /usr/IBM/SSL/tdcmdfs.p12
storepass = tdcmdfs
keyalias = tdcmdfs
keypassword = XXXXXX

#performance hints
search_archive_by_customer_use_hints=true
search_archive_by_customer_index=HO_ BNHP_BASE_LAKOACH_DOC_S_I1

search_by_account_use_hints=true
search_by_account_index=HO_ BNHP_BASE_LAKOACH_DOC_S_I3

search_by_status_use_hints=false
search_by_status_index=HO_ BNHP_BASE_LAKOACH_DOC_S_I1

search_by_amit_use_hints=true
search_by_amit_index=HO_ BNHP_BASE_LAKOACH_DOC_S_I4

search_by_customer_use_hints=true
search_by_customer_index=HO_ BNHP_BASE_LAKOACH_DOC_S_I1

search_by_official_use_hints=false
search_by_official_index=

search_by_process_use_hints=false
search_by_process_index=




file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources-dev\BnhpInfraDFSServicesTests.properties
-----------------------------------------------------
test_user=testfaxuser
test_password=1234
#test_docbase=banhap_dev1

http_test_user=httpfaxuser
http_test_password=AES128:U2FsdGVkX1/eQrJzL/nWNJBTQV70+Ak5oUTkz21P47Y=

#test_user=TSTBO14
#test_user=faxuser
test_docbase=banhap_dev1
#test_docbase=banhapvan_kg
#test_docbase=banhap_qa1
#test_docbase=banhap_preprd1

legacy_test_user=testtfspeula
legacy_test_password=AES128:U2FsdGVkX18vlnqRWqvypOXKpZ1lTcysRk2JA/QWk/0=

http_legacy_test_user=httptfspeula
http_legacy_test_password=AES128:U2FsdGVkX1+ZVMC03i/lclKdh1jsMMLAQBda4xYugIQ=

safe_test_user=safetfspeula
safe_test_password=AES128:U2FsdGVkX1/MsNNbfuQ9tTFHp/HsYT6jrolo6vxmsBo=


#legacy_test_user=tofespeulausrtst

pension_test_user=pensionfundtest
pension_test_password=AES128:U2FsdGVkX1/AVm7b1njgyKDYCAJBOqRFUx7khxK7oW0=

# users for file based upload testing
fileupload_test_user=httpfaxuser
fileupload_test_password=AES128:U2FsdGVkX18BiHSaO4f4tNQ/9WhlaN0HyMAF7leqqKo=

server_api_fileupload_test_user=apifaxuser
server_api_fileupload_test_password=AES128:U2FsdGVkX1/DVJ9yzPfflQd7iT8tOZwk/eJYxdGHLL4=

nofileupload_test_user=testfaxuser
nofileupload_test_password=AES128:U2FsdGVkX1/X7bqvheAVj4237Emvc5U12PG88n1JgwQ=

nocontentshare_test_user=testfaxuser
nocontentshare_test_password=AES128:U2FsdGVkX198dd+1pnnUlYq2qFnRPF/fPIuvv5x3uK8=

no_privs_user=no_privs_user
no_privs_password=AES128:U2FsdGVkX18MTe9YB3VlKlHoBzU/KpPfToyYxJKQD0Y=

# user that has R/O rights but member of susperusers_dynamic
view_only_user=testfaxview
view_only_password=AES128:U2FsdGVkX19TAXWra5wbSF2n37Xzl644imljpvu3/NI=




# a non-administrative user, which can perform server based upload
# (privilages are elevated for server based upload to be performed)
server_fileupload_test_user=uploadfaxuser
server_fileupload_test_password=AES128:U2FsdGVkX1/iltKtbUPbYnpqjgWNKvPd1gcHfdPI6Rc=

server_zc_fileupload_test_user=zcfaxuser
server_zc_fileupload_test_password=AES128:U2FsdGVkX19FI9PPDYGSLaVoS3XsEvwWFg0WL6ljShI=

server_upload_tfs_test_user=uploadtfspeula
server_upload_tfs_test_password=AES128:U2FsdGVkX19q0b9ET7OtnWQgaTTBex6YABTzXiNxtT8=

server_zc_upload_tfs_test_user=zctfspeula
server_zc_upload_tfs_test_password=AES128:U2FsdGVkX19lLUcXKdOKKR+jTSXhJgJUfEg4h50e6lY=

server_api_upload_tfs_test_user=apitfspeula
server_api_upload_tfs_test_password=AES128:U2FsdGVkX1+mzma4sUofimMUuh1QNsVc0hOBKb4KBiU=


server_fb_upload_tfs_test_user=fbtfspeula
server_fb_upload_tfs_test_password=AES128:U2FsdGVkX19UnVk6GNfO4spLr5p/tHLsYGneczPYeo0=


# an administrative user, which can perform server based upload
server_fileupload_admin_test_user=dctm
server_fileupload_admin_test_password=AES128:U2FsdGVkX19OotyyD4C7ibHKSRAs26wYcOyoebod/18=

# user, which can access bot legacy and non-legacy project
both_test_user=dctm
both_test_password=AES128:U2FsdGVkX1+eEb2JGCPnrETxzAABGTUaL4JBpMSL0zI=

local_offline_input_dir=S:/Offline_Service_DEV/Faxes
server_offline_input_dir=/DocumentumAsync/Offline_Service_DEV/Faxes

bnhp_customer_doc_mv_name=BNHP_CUSTOMER_DOC_MV

bad_makats=0000011460,0000019970,0000022542,0000022545,0000022546,0000062001,0000062011,0000062012,0000062013,0000062014,0000063126,0000083812,0000084024,0000084030,0000084031,0000089001,0000130766,4444400050,4444400052,4444404000,5000000100,5000000101,5000000102,5444448967,5444466124,6000000000,9999912385,9999917260,9999918652,9999919450


cyberark_auth_user=DocumentumUser
cyberarc_auth_password=AES128:U2FsdGVkX19MqMz7ucY6zPdwPnXPEqXB/VU+LImHyB8=
cyberarc_auth_url_prefix=https://ttoapp02.restest.bank/SFE/WebServices/auth/Cyberark/CyberArkAuthenticationService.svc

          


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources-dev\cache\7.1.0000.0115\bof\banhap_dev1\content.xml
-----------------------------------------------------
<?xml version="1.0"?>
<CacheContent MasterVersionStamp="32173"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="CacheContent.xsd">
    <Entries>
        <Entry ObjectId="0b00000a8033abb0" ObjectName="bnhp_customer_doc">
            <ImplClass>com.documentum.fc.client.customerdoc.tbo.CustomerDoc</ImplClass>
            <VersionStamp>158</VersionStamp>
            <BofVersion>1.0</BofVersion>
            <ObjectType>TBO</ObjectType>
            <Files>
                <File
                    FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-dev\cache\7.1.0000.0115\bof\banhap_dev1\0900000a8033abc0.jar"
                    IsArchive="true" IsSandboxed="false"/>
                <File
                    FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-dev\cache\7.1.0000.0115\bof\banhap_dev1\0900000a8033abba.jar"
                    IsArchive="true" IsSandboxed="false"/>
                <File
                    FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-dev\cache\7.1.0000.0115\bof\banhap_dev1\0900000a804a5179.jar"
                    IsArchive="true" IsSandboxed="true"/>
                <File
                    FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-dev\cache\7.1.0000.0115\bof\banhap_dev1\0900000a803c1ed3.jar"
                    IsArchive="true" IsSandboxed="false"/>
            </Files>
            <Interfaces>
                <Interface>com.documentum.fc.client.customerdoc.tbo.ICustomerDoc</Interface>
                <Interface>com.documentum.fc.client.IDfDocument</Interface>
                <Interface>com.documentum.fc.client.IDfSysObject</Interface>
                <Interface>com.documentum.fc.client.IDfPersistentObject</Interface>
                <Interface>com.documentum.fc.client.IDfTypedObject</Interface>
                <Interface>bnhp.infra.base.tbo.ISyncObject</Interface>
                <Interface>com.documentum.fc.client.impl.ISysObject</Interface>
                <Interface>com.documentum.fc.client.impl.IPersistentObject</Interface>
                <Interface>com.documentum.fc.client.impl.ITypedObject</Interface>
                <Interface>com.documentum.fc.client.internal.ITypedObjectInternal</Interface>
                <Interface>com.documentum.fc.tracing.IUserIdentifyingObject</Interface>
                <Interface>com.documentum.fc.client.internal.IPersistentObjectInternal</Interface>
                <Interface>com.documentum.fc.client.internal.ISysObjectInternal</Interface>
                <Interface>com.documentum.fc.client.impl.IAliasResolution</Interface>
                <Interface>com.documentum.fc.client.IDfSysObjectInternal</Interface>
                <Interface>com.documentum.fc.client.IDfPersistentObjectInternal</Interface>
                <Interface>com.documentum.fc.client.IDfSysObjectRetention</Interface>
                <Interface>com.documentum.fc.impl.util.reflection.proxy.IProxyTarget</Interface>
                <Interface>com.documentum.fc.client.relationship.IDfRelatable</Interface>
                <Interface>com.documentum.fc.client.aspect.IDfAspects</Interface>
                <Interface>java.lang.Cloneable</Interface>
                <Interface>com.documentum.fc.client.IDfTypedObjectInternal</Interface>
            </Interfaces>
            <Dependencies>
                <Dependency>bnhp.infra.base.sbo.IMigrationConfigService</Dependency>
            </Dependencies>
            <Privileged>false</Privileged>
            <PrivilegeRoles/>
            <MinDFCVersion/>
            <ClassLoadingFilters/>
        </Entry>
        <Entry ObjectId="0b00000a8010cd71" ObjectName="general_doc_aspect">
            <ImplClass>bnhp.infra.base.aspect.GeneralDocAspect</ImplClass>
            <VersionStamp>395</VersionStamp>
            <BofVersion>1.0</BofVersion>
            <ObjectType>Aspect</ObjectType>
            <Files>
                <File
                    FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-dev\cache\7.1.0000.0115\bof\banhap_dev1\0900000a8019b920.jar"
                    IsArchive="true" IsSandboxed="false"/>
                <File
                    FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-dev\cache\7.1.0000.0115\bof\banhap_dev1\0900000a804a94d1.jar"
                    IsArchive="true" IsSandboxed="true"/>
            </Files>
            <Interfaces>
                <Interface>com.documentum.fc.client.IDfDocument</Interface>
                <Interface>com.documentum.fc.client.IDfSysObject</Interface>
                <Interface>com.documentum.fc.client.IDfPersistentObject</Interface>
                <Interface>com.documentum.fc.client.IDfTypedObject</Interface>
                <Interface>com.documentum.fc.client.impl.ISysObject</Interface>
                <Interface>com.documentum.fc.client.impl.IPersistentObject</Interface>
                <Interface>com.documentum.fc.client.impl.ITypedObject</Interface>
                <Interface>com.documentum.fc.client.internal.ITypedObjectInternal</Interface>
                <Interface>com.documentum.fc.tracing.IUserIdentifyingObject</Interface>
                <Interface>com.documentum.fc.client.internal.IPersistentObjectInternal</Interface>
                <Interface>com.documentum.fc.client.internal.ISysObjectInternal</Interface>
                <Interface>com.documentum.fc.client.impl.IAliasResolution</Interface>
                <Interface>com.documentum.fc.client.IDfSysObjectInternal</Interface>
                <Interface>com.documentum.fc.client.IDfPersistentObjectInternal</Interface>
                <Interface>com.documentum.fc.client.IDfSysObjectRetention</Interface>
                <Interface>com.documentum.fc.impl.util.reflection.proxy.IProxyTarget</Interface>
                <Interface>com.documentum.fc.client.relationship.IDfRelatable</Interface>
                <Interface>com.documentum.fc.client.aspect.IDfAspects</Interface>
                <Interface>java.lang.Cloneable</Interface>
                <Interface>com.documentum.fc.client.IDfTypedObjectInternal</Interface>
            </Interfaces>
            <Dependencies/>
            <Privileged>false</Privileged>
            <PrivilegeRoles/>
            <MinDFCVersion/>
            <ClassLoadingFilters/>
        </Entry>
        <Entry ObjectId="0b00000a8019b8c0" ObjectName="bnhp.infra.base.storage.iface.IBnhpStorageSelectionService">
            <ImplClass>bnhp.infra.base.storage.impl.BnhpStorageSelectionService</ImplClass>
            <VersionStamp>42</VersionStamp>
            <BofVersion>1.0</BofVersion>
            <ObjectType>SBO</ObjectType>
            <Files>
                <File
                    FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-dev\cache\7.1.0000.0115\bof\banhap_dev1\0900000a803d7cfc.jar"
                    IsArchive="true" IsSandboxed="false"/>
                <File
                    FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-dev\cache\7.1.0000.0115\bof\banhap_dev1\0900000a803d7cf4.jar"
                    IsArchive="true" IsSandboxed="true"/>
            </Files>
            <Interfaces>
                <Interface>bnhp.infra.base.storage.iface.IBnhpStorageSelectionService</Interface>
                <Interface>com.documentum.fc.client.IDfService</Interface>
                <Interface>com.documentum.fc.client.IDfModule</Interface>
            </Interfaces>
            <Dependencies/>
            <Privileged>false</Privileged>
            <PrivilegeRoles/>
            <MinDFCVersion/>
            <ClassLoadingFilters/>
        </Entry>
        <Entry ObjectId="0b00000a8033abb3" ObjectName="bnhp.infra.base.sbo.IMigrationConfigService">
            <ImplClass>bnhp.infra.base.sbo.MigrationConfigService</ImplClass>
            <VersionStamp>148</VersionStamp>
            <BofVersion>1.0</BofVersion>
            <ObjectType>SBO</ObjectType>
            <Files>
                <File
                    FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-dev\cache\7.1.0000.0115\bof\banhap_dev1\0900000a803c1ed3.jar"
                    IsArchive="true" IsSandboxed="false"/>
                <File
                    FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-dev\cache\7.1.0000.0115\bof\banhap_dev1\0900000a804a5181.jar"
                    IsArchive="true" IsSandboxed="true"/>
            </Files>
            <Interfaces>
                <Interface>bnhp.infra.base.sbo.IMigrationConfigService</Interface>
                <Interface>com.documentum.fc.client.IDfService</Interface>
                <Interface>com.documentum.fc.client.IDfModule</Interface>
            </Interfaces>
            <Dependencies/>
            <Privileged>false</Privileged>
            <PrivilegeRoles/>
            <MinDFCVersion/>
            <ClassLoadingFilters/>
        </Entry>
        <Entry ObjectId="0b00000a803b00a9" ObjectName="bnhp_tfs_peula_doc">
            <ImplClass>com.documentum.fc.client.tfspeula.tbo.TfsPeulaDoc</ImplClass>
            <VersionStamp>92</VersionStamp>
            <BofVersion>1.0</BofVersion>
            <ObjectType>TBO</ObjectType>
            <Files>
                <File
                    FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-dev\cache\7.1.0000.0115\bof\banhap_dev1\0900000a803b00b4.jar"
                    IsArchive="true" IsSandboxed="false"/>
                <File
                    FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-dev\cache\7.1.0000.0115\bof\banhap_dev1\0900000a803c1ed7.jar"
                    IsArchive="true" IsSandboxed="false"/>
                <File
                    FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-dev\cache\7.1.0000.0115\bof\banhap_dev1\0900000a803c1ed9.jar"
                    IsArchive="true" IsSandboxed="true"/>
                <File
                    FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-dev\cache\7.1.0000.0115\bof\banhap_dev1\0900000a803c1ed3.jar"
                    IsArchive="true" IsSandboxed="false"/>
            </Files>
            <Interfaces>
                <Interface>com.documentum.fc.client.tfspeula.tbo.ITfsPeulaDoc</Interface>
                <Interface>com.documentum.fc.client.IDfDocument</Interface>
                <Interface>com.documentum.fc.client.IDfSysObject</Interface>
                <Interface>com.documentum.fc.client.IDfPersistentObject</Interface>
                <Interface>com.documentum.fc.client.IDfTypedObject</Interface>
                <Interface>bnhp.infra.base.tbo.ISyncObject</Interface>
                <Interface>com.documentum.fc.client.impl.ISysObject</Interface>
                <Interface>com.documentum.fc.client.impl.IPersistentObject</Interface>
                <Interface>com.documentum.fc.client.impl.ITypedObject</Interface>
                <Interface>com.documentum.fc.client.internal.ITypedObjectInternal</Interface>
                <Interface>com.documentum.fc.tracing.IUserIdentifyingObject</Interface>
                <Interface>com.documentum.fc.client.internal.IPersistentObjectInternal</Interface>
                <Interface>com.documentum.fc.client.internal.ISysObjectInternal</Interface>
                <Interface>com.documentum.fc.client.impl.IAliasResolution</Interface>
                <Interface>com.documentum.fc.client.IDfSysObjectInternal</Interface>
                <Interface>com.documentum.fc.client.IDfPersistentObjectInternal</Interface>
                <Interface>com.documentum.fc.client.IDfSysObjectRetention</Interface>
                <Interface>com.documentum.fc.impl.util.reflection.proxy.IProxyTarget</Interface>
                <Interface>com.documentum.fc.client.relationship.IDfRelatable</Interface>
                <Interface>com.documentum.fc.client.aspect.IDfAspects</Interface>
                <Interface>java.lang.Cloneable</Interface>
                <Interface>com.documentum.fc.client.IDfTypedObjectInternal</Interface>
            </Interfaces>
            <Dependencies>
                <Dependency>bnhp.infra.base.sbo.IMigrationConfigService</Dependency>
            </Dependencies>
            <Privileged>false</Privileged>
            <PrivilegeRoles/>
            <MinDFCVersion/>
            <ClassLoadingFilters/>
        </Entry>
        <Entry ObjectId="0b00000a803b00ab" ObjectName="bnhp_yoman_eruim_table">
            <ImplClass>com.documentum.fc.client.tfspeula.tbo.TfsPeulaErua</ImplClass>
            <VersionStamp>83</VersionStamp>
            <BofVersion>1.0</BofVersion>
            <ObjectType>TBO</ObjectType>
            <Files>
                <File
                    FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-dev\cache\7.1.0000.0115\bof\banhap_dev1\0900000a803c1edb.jar"
                    IsArchive="true" IsSandboxed="false"/>
                <File
                    FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-dev\cache\7.1.0000.0115\bof\banhap_dev1\0900000a803b00b4.jar"
                    IsArchive="true" IsSandboxed="false"/>
                <File
                    FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-dev\cache\7.1.0000.0115\bof\banhap_dev1\0900000a803c1ecf.jar"
                    IsArchive="true" IsSandboxed="true"/>
                <File
                    FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-dev\cache\7.1.0000.0115\bof\banhap_dev1\0900000a803c1ed3.jar"
                    IsArchive="true" IsSandboxed="false"/>
            </Files>
            <Interfaces>
                <Interface>com.documentum.fc.client.tfspeula.tbo.ITfsPeulaErua</Interface>
                <Interface>com.documentum.fc.client.IDfPersistentObject</Interface>
                <Interface>com.documentum.fc.client.IDfTypedObject</Interface>
                <Interface>bnhp.infra.base.tbo.ISyncObject</Interface>
                <Interface>com.documentum.fc.client.impl.IPersistentObject</Interface>
                <Interface>com.documentum.fc.client.impl.ITypedObject</Interface>
                <Interface>com.documentum.fc.client.internal.ITypedObjectInternal</Interface>
                <Interface>com.documentum.fc.tracing.IUserIdentifyingObject</Interface>
                <Interface>com.documentum.fc.client.internal.IPersistentObjectInternal</Interface>
                <Interface>com.documentum.fc.client.IDfPersistentObjectInternal</Interface>
                <Interface>com.documentum.fc.impl.util.reflection.proxy.IProxyTarget</Interface>
                <Interface>com.documentum.fc.client.relationship.IDfRelatable</Interface>
                <Interface>com.documentum.fc.client.aspect.IDfAspects</Interface>
                <Interface>java.lang.Cloneable</Interface>
                <Interface>com.documentum.fc.client.IDfTypedObjectInternal</Interface>
            </Interfaces>
            <Dependencies>
                <Dependency>bnhp.infra.base.sbo.IMigrationConfigService</Dependency>
            </Dependencies>
            <Privileged>false</Privileged>
            <PrivilegeRoles/>
            <MinDFCVersion/>
            <ClassLoadingFilters/>
        </Entry>
        <Entry ObjectId="0b00000a80185d66" ObjectName="bnhp_paper_doc">
            <ImplClass>bnhp.infra.base.aspect.EmptyDocAspect</ImplClass>
            <VersionStamp>374</VersionStamp>
            <BofVersion>1.0</BofVersion>
            <ObjectType>Aspect</ObjectType>
            <Files>
                <File
                    FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-dev\cache\7.1.0000.0115\bof\banhap_dev1\0900000a804a517d.jar"
                    IsArchive="true" IsSandboxed="true"/>
            </Files>
            <Interfaces/>
            <Dependencies/>
            <Privileged>false</Privileged>
            <PrivilegeRoles/>
            <MinDFCVersion/>
            <ClassLoadingFilters/>
        </Entry>
    </Entries>
    <FilesInventory>
        <File
            FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-dev\cache\7.1.0000.0115\bof\banhap_dev1\0900000a8033abc0.jar" ObjectLastAccessed="1622124615832"/>
        <File
            FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-dev\cache\7.1.0000.0115\bof\banhap_dev1\0900000a8033abba.jar" ObjectLastAccessed="1622124615832"/>
        <File
            FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-dev\cache\7.1.0000.0115\bof\banhap_dev1\0900000a804a5179.jar" ObjectLastAccessed="1622124615821"/>
        <File
            FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-dev\cache\7.1.0000.0115\bof\banhap_dev1\0900000a803c1ed3.jar" ObjectLastAccessed="1622124615832"/>
        <File
            FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-dev\cache\7.1.0000.0115\bof\banhap_dev1\0900000a8019b920.jar" ObjectLastAccessed="1622040229750"/>
        <File
            FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-dev\cache\7.1.0000.0115\bof\banhap_dev1\0900000a804a94d1.jar" ObjectLastAccessed="1622124616047"/>
        <File
            FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-dev\cache\7.1.0000.0115\bof\banhap_dev1\0900000a803d7cfc.jar" ObjectLastAccessed="1622040229750"/>
        <File
            FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-dev\cache\7.1.0000.0115\bof\banhap_dev1\0900000a803d7cf4.jar" ObjectLastAccessed="1622124616186"/>
        <File
            FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-dev\cache\7.1.0000.0115\bof\banhap_dev1\0900000a804a5181.jar" ObjectLastAccessed="1622124616695"/>
        <File
            FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-dev\cache\7.1.0000.0115\bof\banhap_dev1\0900000a803b00b4.jar" ObjectLastAccessed="1622040229750"/>
        <File
            FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-dev\cache\7.1.0000.0115\bof\banhap_dev1\0900000a803c1ed7.jar" ObjectLastAccessed="1622040229750"/>
        <File
            FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-dev\cache\7.1.0000.0115\bof\banhap_dev1\0900000a803c1ed9.jar" ObjectLastAccessed="1622124617038"/>
        <File
            FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-dev\cache\7.1.0000.0115\bof\banhap_dev1\0900000a803c1edb.jar" ObjectLastAccessed="1622040229750"/>
        <File
            FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-dev\cache\7.1.0000.0115\bof\banhap_dev1\0900000a803c1ecf.jar" ObjectLastAccessed="1622124617343"/>
        <File
            FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-dev\cache\7.1.0000.0115\bof\banhap_dev1\0900000a804a517d.jar" ObjectLastAccessed="1622040229722"/>
    </FilesInventory>
</CacheContent>


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources-dev\DctmRestApp.yml
-----------------------------------------------------
---
configEnvironment: DEV
extraClasspath: [ "resources-dev" ]

#messageInputs: [  "definput"]
messageInputs: [  "definput",  "asyncinput", "asyncreply" ]
#messageInputs: [ "asyncinput" ]
  
definput:
  implementation: bnhp.dctmrest.msginput.HttpInput
  port: 9033
  host: 0.0.0.0
  ssl: false
  ksPath: resources-dev/server.keystore.jks
  ksPass: secret
  ksCertPass: secret
  tsPath: resources-dev/server.truststore.jks
  tsPass: secret
  dumpRequests: true

asyncreply:
  implementation: bnhp.dctmrest.msginput.AsyncInput
  threads: 1
  task:
    implementation: bnhp.dctmrest.msginput.AsyncReplyTask
    replySenders: [ nop, file, wso2 ]
    nop:
      implementation: bnhp.dctmrest.reply.NOPReplySender
    file:
      implementation: bnhp.dctmrest.reply.FileReplySender
      regex: "^file:///.*$"
    wso2:
      implementation: bnhp.dctmrest.reply.HttpReplySender
      regex: "^https://twsodev01.restest.bank:8243/.*$"
      authenticators: [ oauth2 ]
      oauth2:
        implementation: bnhp.dctmrest.reply.Oauth2Auth
    

  
asyncinput:
  implementation: bnhp.dctmrest.msginput.AsyncInput
  threads: 1
  task:
    implementation: bnhp.dctmrest.msginput.AsyncWorkerTask
    


handlerFactory: 
  cancelObjectById: bnhp.dctmrest.handlers.CancelObjectById
  createDocumentById: bnhp.dctmrest.handlers.CreateDocumentById
  putDocumentById: bnhp.dctmrest.handlers.PutDocumentById
  retrieveObjectById: bnhp.dctmrest.handlers.RetrieveDocumentById
  appRequest: bnhp.dctmrest.handlers.AppRequest
  search: bnhp.dctmrest.handlers.Search
  getAsyncRequestStatus: bnhp.dctmrest.handlers.GetAsyncRequestStatus
  whoami: bnhp.dctmrest.handlers.Whoami


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources-dev\DctmRestSecrets.yml
-----------------------------------------------------
$ANSIBLE_VAULT;1.1;AES256
66386265323236653261626161363165393262333261326537333030363766363239336164623736
3761323661613562383836393535303864333637323061370a376133633934633434343830646265
61623363653964343532666264393137373564383165613830346562363261636237656438306330
3566626466636635350a366366363731386533353463643230303932383939653833306566396333
37373430383633643661616234316535343365653263353237313337316130333238616630636134
36626539616631646137613731626139633136323961623138363234306165663938396565633665
39653964336466623332346434616130386262346531366132313565323163393430653930393965
32393632623634623262303130353864613736343237633766653361363937366638393738313236
64643937386337343933336366623164383565333339323036636331323733663732653532333165
31356530626431303964373835373230316530336534636466356363633366393738373932643739
64316663386230366332346139633466656431383461343164396131343437336631663136323031
31636365333633616630363366343366636132646465323865386535383233663733313339646366
36313362646632346464326264643761643231313433323863323666363433613837623836666533
64326436363139326433343330386433666338336537336330336431643266613161396366623930
66616135376563383766346235356362343430346133646236656230623862666661393338393461
34666237323233636565623532323636313637366162316465336339636666373463356432376362
30396364353061333036666635396465613539373563636436613462663634303766363637363330
6634373166323065633830383938373134643663336233386438


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources-dev\DctmRestSecretsDecrypted.yml
-----------------------------------------------------
---
asyncreply:
  task:
    wso2:
      oauth2:
        consumerKey: "NjCDNf38gU0fkrXg5BBaOAnYu8Ya"
        consumerSecret: "pL4yJN42IfF5xXpcnfUwagrlIaga"
        content: "grant_type=client_credentials"
        authURL: "https://twsodev01.restest.bank:8243/token"
    




file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources-dev\dfc.properties
-----------------------------------------------------
dfc.registry.mode=file

dfc.data.dir=C:/Users/AP068/git/documentum/dudctmrest/resources-dev

dfc.globalregistry.password=AAAAEKw7B0IXFxhPNzIXJmMIFytVkvJ5WznHy/qSbKs76Xbf
dfc.globalregistry.repository=banhap_dev1
dfc.globalregistry.username=dm_bof_registry

#dfc.globalregistry.password=GrRNPhLJrkoTDAZE0RGJow\=\=
#dfc.globalregistry.repository=banhap_qa1
#dfc.globalregistry.username=dm_bof_registry

dfc.name=dev_sdcmdfs01-7-duecmrest
#dfc.name=FW0_DUECMREST_DEV_W
dfc.privilege.enable=true
#dfc.security.keystore.file=C:/Documentum/config/dfc.keystore
dfc.tokenstorage.dir=/usr/TDC/duecmrest/documentum/apptoken

#dfc.verify_registration=true


# dev 7.1
dfc.docbroker.host[0]=tdcmcs01-7.restest.bank
dfc.docbroker.port[0]=1489

#dfc.docbroker.host[0]=sdcmcs01.restest.bank
#dfc.docbroker.port[0]=1489
#dfc.session.max_count = 20

#dfc.search.max_results=500
#dfc.search.max_results_per_source=500
#dfc.session.max_collection_count = 200
#dfc.session.max_count = 200
#dfc.session.pool.enable = false
#dfc.compatibility.truncate_long_values=false
#dfc.exception.include_id=false
#dfc.exception.include_decoration=false

#dfc.resources.diagnostics.enabled = false
#dfc.search.docbase.broker_count=400

#dfc.name=tdcmdfs01-duecmrest


dfc.tracing.enable = false


# Determines the trace file creation policy for tracing. By default, all tracing 
# information is logged to a single file. Using this property, tracing can be 
# configured so it creates a separate log file for each user, or for each thread 
# valid values: standard,thread,user
# 
dfc.tracing.file_creation_mode = standard


# Sets a specific file path to use for tracing output. Normally DFC 
# automatically generates a trace file path based on the other settings 
# (directory, prefix, mode, time, etc). When this preference has a non-null 
# value then it is used as the explicit trace file path.                        
# 
dfc.tracing.file_override =  


# Specifies the prefix string to place in from of trace file names when in 
# standard filecreation mode. In standard file creation mode, the tracing 
# infrastructure names log files <file_prefix>.<timestamp>.log.                 
# 
#dfc.tracing.file_prefix = 


# When this property is set to true, each entry in the trace log will record the 
# current RPC count for that connection. The RPC count is ascertainable only 
# after a method is called on an object which has an associated session. Hence, 
# many entries in the trace log will have the value N/A for the RPC count.      
# 
dfc.tracing.include_rpc_count = false


# Controls whether RPC information is included in the trace.                    
# 
dfc.tracing.include_rpcs = false


# Controls whether session ID information is included in the trace. By default, 
# all entries in the trace log will record the associated user (if that 
# information is available from the call context). When this property is set to 
# true, the external session ID (e.g.: s1, s2) and the identity hash code of the 
# associated session manager is printed along with the user.                    
# 
dfc.tracing.include_session_id = true


# For each additional logging category defined in dfc.tracing.log.category this 
# specifies thelog4j additivity setting. Normally you do not need to set this 
# preference. The default is normally the correct setting.                      
# prototype value: false
# 
dfc.tracing.log.additivity = false


# Defines additional logging categories to be included in the trace output.     
# default values: com,documentum,fc,client,impl,session,com,documentum,fc,client,impl,connection
# 
dfc.tracing.log.category = {"com.documentum"}

#dfc.tracing.file_override = /tmp/dfctrace

# 
dfc.tracing.log.level =TRACE  


# The number of backups that DFC will keep. Whenever the trace file rolls over, 
# DFC will backup the old one. The oldest backup files get deleted first when 
# the configured number of backups has been exceeded.                           
# 
dfc.tracing.max_backup_index = 1


# Specifies the maximum size that the trace file can reach before it rolls over. 
# 
dfc.tracing.max_file_size = 100MB




file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources-dev\documentum.ini
-----------------------------------------------------
[documentum]
[documentum\Common]
[documentum\Common\ApplicationSupportDocuments]
[documentum\Common\HouseKeeping]
LastHouseKeeping=05262021
[documentum\Common\ViewFiles]


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources-dev\EnvProperty.properties
-----------------------------------------------------
# DEV - DEVELOPMENT CONFIGURATION
kesher_type = DPT.DPT2042
makat_type = DPT.DPT2040
tchum_type = DPT.DPT2044
tat_type = DPT.DPT2043
matbea_type = DPT.DPT0484
central_code_table_doc_type=bnhp_central_code_table

# empty temporary entry until we have the table
kupot_gemel_type =
# dm_dbo.DPT200TMP
kupot_gemel_field_code=num
kupot_gemel_field_descr=descr

dfs_logger_id=BnhpDFSServices
wrapper_logger_id=BnhpDFSWrapper
err_logger_id=BnhpDFSWrapperErr
business_logger_id=BnhpDFSBusiness
operator_logger_id=BnhpDFSOperator

log_dctm_session=true

user_name=dctm
#user_pass=m6m+6h1w1ZB5SWILs6pydQ==
user_pass=AAAAEFJMk9QntvpBhsRyNsXgyDBZ//4n3Q7zJK/xjgjMxeio

perform_audit=false

# override entity for tofes peula, set (account or customer or pension)
fixed_entity_for_project[1]=7
fixed_entity_for_project[2]=7
fixed_entity_for_project[42]=7
fixed_entity_for_project[44]=7

# switch warn/failure on several validity checks
fail_on_codes_error=true
fail_on_currency_error=true
fail_on_dpt_error=false

#default_docbase=banhapvan_kg
#default_docbase=banhap_preprd1
#default_docbase=banhap_qa1
default_docbase=banhap_dev1
docbase_override=true

velocity_properties_file=/bnhp_velocity.properties
velocity_template_name_regexp=^[a-zA-Z0-9_-]+$
velocity_template_prefix=/templates/
velocity_template_suffix=.txt


#magic field values, which are used in search services
category_scan_status=104
category_sign_status=106

# comma separated list of projects, that are relevant for the sync TBO
legacy_create_for_projects=1,2

# retrieve settings
retrieve_links_acs=false
retrieve_links_acs_unduplicate_retries=2
retrieve_links_acs_append_request_id=true

retrieve_links_acs_threshold=0

retrieve_links_acs_uri_regexp=^http:.*$

retrieve_links_acs_inband_fallback=false


retrieve_cyberark_allow=false

retrieve_cyberark_config=DOCUMNETO_T
retrieve_cyberark_concurrency_limit=3

# cyberarc configurations
cyberark[DOCUMNETO_T].substitutions=^	https://ttoapp02.restest.bank/SFE/WebServices/API.svc/
# ms
cyberark[DOCUMNETO_T].saf_timeout=5000

# file based upload

#local_file_upload_base_dir=S:/Async_Service_DEV7_TEMP/
#local_file_upload_base_dir=/mnt/network/popnasal09.bnhpgroup.com/SysProjectsUnix01/dctm_projects/Async_Service_DEV7_TEMP/,/mnt/network/popnasal09.bnhpgroup.com/SysProjectsUnix01/dctm_projects/NewUploadTest/Async_Service_DEV7_TEMP/
#server_file_upload_base_dir=/DocumentumAsync/Async_Service_DEV7_TEMP/,/DocumentumAsyncNew/Async_Service_DEV7_TEMP/

local_file_upload_base_dir@TSTDU31=/DocumentumAsync/Async_Service_DEV7_TEMP
local_file_upload_base_dir=/24400_2/
server_file_upload_base_dir@TSTDU31=/DocumentumAsync/Async_Service_DEV7_TEMP
server_file_upload_base_dir=/24400_2/

#allowed_upload_url_regexp=^file:///[\/A-Za-z0-9_]+\\.[0-9A-Za-z_]+$
allowed_upload_url_regexp=^file:///[\/A-Za-z0-9_\.-]+$

file_upload_enabled = true
server_file_upload_enabled= true

fallback_upload_enabled=false

#allow_update_log_deleted_docs@httpfaxuser=true
#local_file_upload_base_dir@uploadfaxuser=S:/Async_Service_DEV/
#server_file_upload_base_dir@uploadfaxuser=/DocumentumAsync/Async_Service_DEV/

# zero copy enable
zero_copy_upload_enabled=false

# Renditions
generate_renditions_sync=true

# content updates w/o versions
same_version_content_updates_no_metadata=true
same_version_content_updates_no_metadata@testfaxuser=false

same_version_content_updates_allowed_time_sec=86400


make_auto_event_on_same_version_content_updates=false
make_auto_event_on_same_version_content_updates@httptfspeula=true

dup_suppression_grace_period_sec  = 11

default_max_results_search_by_document_group_id_prop=100


content_share_enabled@testfaxuser=false
allowed_content_share_url_regexp=^dctm:///[A-Za-z0-9/?=&_@-]+$

# validations against permissions table
permtab_validation_required=false
permtab_validate_document_form_id=true
permtab_validate_user=false
permtab_validate_data_folder=false

offline_allow_default_data_files=true
offline_input_filename_ext_regexp=^.*\\.([A-Za-z0-9_]+)$

# application id
app_instance_id=1

expected_err_regex=.*(Permission denied|Input/output error).*

# warmup config
perform_warmup=true
perform_jms_warmup=false
warmup_types=bnhp_customer_doc,bnhp_doc_event,bnhp_doc_xml_form,bnhp_doc_folder,bnhp_tfs_peula_doc,bnhp_yoman_eruim_table,bnhp_yoman_sugim,bnhp_central_code_table,bnhp_categoriot_table
warmup_jms_factory=jms/WebServicesReplyQCF
warmup_jms_queue=jms/WsEcmQueueJms
warmup_jms_target=WebServicesJMSRouter 
warmup_jms_idval=app_instance_id=1
warmup_cyberark=false

# DFC instance registration (part of warmup currently)
instance_registration_action=PERFORM
instance_registration_required_roles=dm_superusers_dynamic


# format guess/normalization
format_normalization_enabled=true
format_guess_enabled=true
retrieve_format_normalization_enabled=true
format_ext_cache_query=SELECT f.name AS name, lower(f.dos_extension) AS dos_extension, f.i_vstamp as i_vstamp FROM dm_dbo.BNHP_FORMATS_V f WHERE dos_extension<>' ' ORDER BY weight
format_mimetype_cache_query=SELECT f.name AS name, lower(f.mime_type) AS mime_type, f.i_vstamp as i_vstamp FROM dm_dbo.BNHP_FORMATS_V f WHERE mime_type<>' ' ORDER BY weight

# zero copy upload settings
zero_copy_map[filestore_01]=/DocumentumAsync/Async_Service_DEV7_TEMP/
zero_copy_map[Tofes-Peula]=/DocumentumAsync/Async_Service_DEV7_TEMP/,/DocumentumAsyncNew/Async_Service_DEV7_TEMP/



# caches
cache_min_update_delay=600000
dpt_cache_version_id_query=select MAX(update_datetime) FROM DPT.DPT_BAKARA WHERE table_number in (2042,2040,2044,2043,484)

are_props_reloadable=true
props_time_to_live=10000

business_logger=BnhpDFSBusinessLogger



#
#datacheck@

# HOOKS
#COMMON_TEST_HOOK=(PROGN (LOG "INFO" "HELLO FROM COMMON_TEST_HOOK") (IF (BOUNDP (QUOTE please-fail)) (THROW please-fail) "HELLO FROM COMMON_TEST_HOOK"))
#USER_TEST_HOOK@someuser=(STR "HELLO FROM USER_TEST_HOOK")
#SYSUSER_TEST_HOOK@someuser@sysuser@JMS=(STR "HELLO FROM SYSUSER_TEST_HOOK")
#retrieve_validation_hook@testfaxuser@doccheck@JMS=(IF (docDataCheck-has-customers?) "OK: docDataCheck has customer data" (throw-validation-error "docDataCheck validation is required"))
#retrieve_prereturn_hook@testfaxuser@doccheck@JMS=(IF  (customers-check?) "OK: docDataCheck on customers" (THROW "DocDataCheck validation has FAILED"))
#update_pre_update_hook@httpfaxuser=(faxes-update-pre-update-hook)
#appreq_pre_xact_hook@${ENV}DU15=(minhali-appreq-pre-xact-hook)
#
#retrieve_validation_hook@dctm=(IF (docDataCheck-has-customers?) "OK: docDataCheck has customer data" (throw-validation-error "docDataCheck validation  is required"))
#retrieve_prereturn_hook@dctm=(IF  (customers-check?) "OK: docDataCheck on customers" (THROW "DocDataCheck validation has FAILED"))
#retrieve_prereturn_hook@TSTDU17=(PROGN (VALIDATE "file_md" docDataCheck ddfr))
#retrieve_prereturn_hook@tdtalyon=(PROGN (VALIDATE "file_md" docDataCheck ddfr))
##retrieve_prereturn_hook=(IF docDataCheck (IF (VALIDATE "file_md" docDataCheck ddfr) "Validate:OK" THROW "Validate:FAILED") "Validate:SKIPPED")
retrieve_prereturn_hook=(IF docDataCheck (IF (VALIDATE "file_md" docDataCheck ddfr) "Validate:OK" (THROW "Validate:FAILED")) "Validate:SKIPPED")
#retrieve_prereturn_hook=(IF docDataCheck (IF (VALIDATE "file_md" docDataCheck ddfr) "Validate:OK" "Validate:FAILED") "Validate:SKIPPED")
#retrieve_prereturn_hook=(IF docDataCheck (IF (VALIDATE "file_md" docDataCheck ddfr) "Validate:OK" "Validate:FAILED") "Validate:SKIPPED")
#retrieve_prereturn_hook@tdtalyon=(IF docDataCheck (VALIDATE "file_md" docDataCheck ddfr) "Validate:SKIPPED")

pdf_customer_id_custom_props=Validate_ID_1,Validate_ID_2,Validate_ID_3
pdf_account_id_custom_props=Validate_AccountNumber_1,Validate_AccountNumber_2,Validate_AccountNumber_3

#ExcutorDetailsProperties:
# Cases: PROVIDE, JWT, AUTO
#      PROVIDE - require as parameter inside the request.
#      JWT - build executorDetails basis of the jwt
#      AUTO - fill ED from properties bellow
executor_details@user=AUTO

# Settings for JWT option - Map from JWT properties to executor details props
executor_details@Jwt@executingEmpIdCode=http://wso2.org/claims/givenname,http://wso2.org/claims/lastname
executor_details@Jwt@fullName=http://wso2.org/claims/enduser

#Settings for AUTO options - fill ED props from bellow:
executor_details@Auto@executingEmpIdCode=1234567890
executor_details@Auto@fullName=someFullName
executor_details@Auto@ipAddress=1.2.3.4




file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources-dev\env_vars.yaml
-----------------------------------------------------
---
orapass: de34rfvc
orainstance: docdbd
orauser: dctm
docbase: banhap_dev1


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources-dev\ErrorInfo.properties
-----------------------------------------------------
# Creation error codes
legacy_id_not_unique = GENERAL_ERROR:600:business constraint violated. Non-unique value %1s in field legacyId of object %2s. The existing id is - %3s
mixed_creation_request = GENERAL_ERROR:601:saving existing and non existing documents in the same transaction is not supported. One of the existing legacyIds is - %1s
legacy_id_not_unique_different_customer_data = GENERAL_ERROR:602:non-unique value %1s in field legacyId but different customer data. The existing id is - %2s
legacy_id_not_unique_different_event_data = GENERAL_ERROR:603:non-unique value %1s in field legacyId but different event data. The existing id is - %2s
legacy_id_not_unique_different_extensions_data = GENERAL_ERROR:604:non-unique value %1s in field legacyId but different extensions data. The existing id is - %2s
legacy_id_not_unique_different_file_size = GENERAL_ERROR:605:non-unique value %1s in field legacyId but different file size. The existing id is - %2s
document_is_deleted = GENERAL_ERROR:606:Unexpectedly failed to retrieve existing document, probably it is logically deleted, legacy id is - %1s

# Query error codes
# FIXME: need to check if in all cases this one indicates validation error
not_single_query_result = VALIDATION_ERROR:700:single query result expected, but query %1s has returned %2s results
unexpected_type_returned = GENERAL_ERROR:701:returned document of unexpected type %1s

# System exception from underlying layers
generic_dfs_service_exception = AUTOTYPE_ERROR:750:DFS Service Exception: %1s 
generic_dfc_exception = AUTOTYPE_ERROR:751:Generic DFC Exception: %1s
generic_exception = AUTOTYPE_ERROR:752:Generic Exception: %1s

# Retrieve error codes
non_existing_object_to_retrieve = GENERAL_ERROR:800:the requested document with %1s=%2s does not exist or you do not have rights to retrieve it

# Validation technical error codes
security_context_not_complete = VALIDATION_ERROR:1100:securityContext is not complete
fetch_type_set_not_set = VALIDATION_ERROR:1101:fetchTypeSet must exist
max_docs_to_process_reached = VALIDATION_ERROR:1102:processing more than 10 documents is not supported
invalid_value_for_field = VALIDATION_ERROR:1105:invalid value %1s for field %2s - %3s
cannot_parse_value = VALIDATION_ERROR:1106:cannot parse value %1s as %2s - %3s
security_context_not_set = VALIDATION_ERROR:1107:securityContext must exist
property_name_invalid = VALIDATION_ERROR:1108:property name %1s is not valid
file_update_same_version_unsupported = VALIDATION_ERROR:1109:no file update with metadata is allowed without creating new version
update_new_version_no_file_unsupported = VALIDATION_ERROR:1110:update a version without a file is not allowed
version_label_not_set = VALIDATION_ERROR:1111:versionLabel must exist
prepared_query_not_set = VALIDATION_ERROR:1112:preparedQuery must exist
wrong_date_format = VALIDATION_ERROR:1113:the date is not in the format of XMLGregorianCalendar
between_null_dates = VALIDATION_ERROR:1114:the dates are null in BETWEEN DATES clause
only_one_of_legacy_and_dctm_id_must_be_provided = VALIDATION_ERROR:1115:only one of legacyDocumentId and dctmDocumentId must be provided, but got both
same_version_update_of_existing_file_is_not_supported =VALIDATION_ERROR:1116:update of existing main content is not allowed without creating new document version
same_version_update_not_allowed=VALIDATION_ERROR:1117:main content update without metadata is not allowed by server configuration
same_version_update_timeout=VALIDATION_ERROR:1118:main content update without metadata is not allowed: too late, maximum time of %s seconds is passed
extension_date_format_invalid==VALIDATION_ERROR:1119:date format in extension is invalid: %1s

# Validation business error codes
doc_data_not_set = VALIDATION_ERROR:1200:docData must exist
doc_customer_data_not_set = VALIDATION_ERROR:1201:docCustomerData must exist
doc_file_not_complete = VALIDATION_ERROR:1202:docFile is not complete
secondary_doc_file_not_complete = VALIDATION_ERROR:1206:secondaryDocFile is not complete
template_source_code_not_set = VALIDATION_ERROR:1207:templateSourceCode in secondaryDocFile must exist
auto_event_ind_not_set = VALIDATION_ERROR:1208:autoEventInd in docEventData must exist
event_category_code_not_set = VALIDATION_ERROR:1209:eventCategoryCode in docEventData must exist
event_category_type_code_not_set = VALIDATION_ERROR:1210:eventCategoryTypeCode in docEventData must exist
legacy_event_entry_dttm_not_set = VALIDATION_ERROR:1211:legacyEventEntryDttm in docEventData must exist
extension_name_invalid = VALIDATION_ERROR:1212:extensionName '%1s' in docPropertyExtensions is invalid
property_key_values_not_complete = VALIDATION_ERROR:1213:propertyKeyValues are not complete
doc_details_not_set = VALIDATION_ERROR:1214:docDetails must exist
business_process_id_not_set = VALIDATION_ERROR:1215:businessProcessId in docDetails must exist
document_form_id_not_set = VALIDATION_ERROR:1216:documentFormId in docDetails must exist
ongoing_or_history_code_not_set = VALIDATION_ERROR:1217:ongoingOrHistoryCode in docDetails must exist
legacy_document_entry_dttm_doc_details_not_set  = VALIDATION_ERROR:1218:legacyDocumentEntryDttm in docDetails must exist
project_id_not_set  = VALIDATION_ERROR:1219:projectId in docDetails must exist
business_sub_area_code_not_set  = VALIDATION_ERROR:1220:businessSubAreaCode in docDetails must exist
executor_details_not_set  = VALIDATION_ERROR:1221:executorDetails must exist
executing_emp_id_code_not_set  = VALIDATION_ERROR:1222:executingEmpIdCode in executorDetails must exist
ip_address_not_set  = VALIDATION_ERROR:1223:ipAddress in executorDetails must exist
pension_fund_not_set  = VALIDATION_ERROR:1224:pensionFund must exist
pension_fund_nbr_not_set  = VALIDATION_ERROR:1225:pensionFundNbr in pensionFund must exist
planholder_number_not_set  = VALIDATION_ERROR:1226:planholderNumber in pensionFund must exist
complete_customer_id_code_not_set  = VALIDATION_ERROR:1227:completeCustomerIdCode in customerKeys must exist
occasional_customer_ind_not_set  = VALIDATION_ERROR:1228:occasionalCustomerInd in customerKeys must exist
customer_id_doc_type_code_not_set  = VALIDATION_ERROR:1229:customerIdDocTypeCode in customerKeys must exist
customer_id_not_set  = VALIDATION_ERROR:1230:customerId in customerKeys must exist
bank_accounts_not_set  = VALIDATION_ERROR:1231:bankAccounts must exist
account_nbr_not_set  = VALIDATION_ERROR:1232:accountNbr in bankAccounts must exist
customer_keys_not_set  = VALIDATION_ERROR:1233:customerKeys must exist
branch_id_not_set  = VALIDATION_ERROR:1234:branchId in bankAccounts must exist
dctm_document_id_not_set  = VALIDATION_ERROR:1235:dctmDocumentId must exist
legacy_document_id_not_set= VALIDATION_ERROR:1236:legacyDocumentId must exist
query_name_not_set= VALIDATION_ERROR:1237:queryName must exist
document_group_id_not_set= VALIDATION_ERROR:1238:documentGroupId must exist
document_id_not_set= VALIDATION_ERROR:1239:documentId must exist
legacy_document_entry_dttm_event_not_set = VALIDATION_ERROR:1240:legacyDocumentEntryDttm in docEventData must exist
entity_validation_error = VALIDATION_ERROR:1241:entity validation error: %1s
doc_data_for_create_not_set = VALIDATION_ERROR:1242:docDataForCreate must nut be null
general_validation_error = VALIDATION_ERROR:1243:General validation error: %1s
validation_hook_retrieve_customer_document_compare_customer_and_account=VALIDATION_ERROR:1244:mismatch validation between given customer and account and archived customer and account
validation_hook_retrieve_customer_document_compare_cust=VALIDATION_ERROR:1245:mismatch validation between given customer and archived customer
validation_hook_retrieve_customer_document_compare_account=VALIDATION_ERROR:1246:mismatch validation between given account and archived account
need_one_of_gemel_customer_account = VALIDATION_ERROR:1247:Need at least one of three to be non-empty: PensionFund, CustomerKeys, BankAccounts


# Format validation and guessing
invalid_document_format_provided=VALIDATION_ERROR:1250:Document Format that was provided '%1s' is invalid 
format_not_provided_and_failed_to_guess=VALIDATION_ERROR:1251:Document Format was not provided and failed to guess using DOS extension or content

# Validation against permission table
permtabentry_not_exists=VALIDATION_ERROR:1280:Permission table entry not exists for given project id
permtabentry_wrong_document_form_id=VALIDATION_ERROR:1281:Wrong document form id %1s for project id %2s
permtabentry_wrong_content_upload_path=VALIDATION_ERROR:1282:Wrong content upload path '%1s' for project id %2s
permtabentry_wrong_username=VALIDATION_ERROR:1283:Wrong application user name '%1s' for project id %2s


# applicative request error codes
appx_required_parameter_missing = GENERAL_ERROR:1501:missing value for parameter %1s for stage %2s 
appx_api_call_required_parameter_missing = GENERAL_ERROR:1502:missing value for parameter %1s for api call %2s, stage %3s
appx_unsupported_value_for_parameter = GENERAL_ERROR:1503:invalid value '%1s' for parameter %2s, stage %3s
appx_api_call_failed = GENERAL_ERROR:1504:api call %1s method %2s failed, stage %3s: %4s
failed_to_parse_merged_query = GENERAL_ERROR:1505:failed to parse merged query

# content retrieve errors
# this one should not happen, if it happens we do not know if it temporary
uriprovider_failure=GENERAL_ERROR:1601:Error getting content URL: %1s
# this usually means that ACS is down, unavailable or not properly configured 
acs_uriprovider_failure=TEMPORARY_ERROR:1610:Error getting ACS Server content URL : %1s
# this usually means temporarry error while calling CyberArk
cyberark_uriprovider_failure=TEMPORARY_ERROR:1620:Error returning content via CyberArk service: %1s




file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources-prod\DctmRestApp.yml
-----------------------------------------------------
---
configEnvironment: PROD
extraClasspath: [ "resources-prod" ]
messageInputs: [  "asyncinput" , "definput", "asyncreply" ]

definput:
  implementation: bnhp.dctmrest.msginput.HttpInput
  port: 9033
  host: 0.0.0.0
  ssl: true
  # NOT_REQUESTED | REQUESTED | REQUIRED
  sslAuthMode: NOT_REQUESTED
  ksPath: resources-prod/server.keystore.jks
  tsPath: resources-prod/server.truststore.jks
  dumpRequests: false


handlerFactory:
  cancelObjectById: bnhp.dctmrest.handlers.CancelObjectById
  createDocumentById: bnhp.dctmrest.handlers.CreateDocumentById
  putDocumentById: bnhp.dctmrest.handlers.PutDocumentById
  retrieveObjectById: bnhp.dctmrest.handlers.RetrieveDocumentById
  appRequest: bnhp.dctmrest.handlers.AppRequest
  search: bnhp.dctmrest.handlers.Search
  getAsyncRequestStatus: bnhp.dctmrest.handlers.GetAsyncRequestStatus
  whoami: bnhp.dctmrest.handlers.Whoami


asyncreply:
  implementation: bnhp.dctmrest.msginput.AsyncInput
  threads: 1
  task:
    implementation: bnhp.dctmrest.msginput.AsyncReplyTask
    replySenders: [ nop, file]
    nop:
      implementation: bnhp.dctmrest.reply.NOPReplySender
    file:
      implementation: bnhp.dctmrest.reply.FileReplySender
      regex: "^file:///.*$"


asyncinput:
  implementation: bnhp.dctmrest.msginput.AsyncInput
  threads: 1
  task:
    implementation: bnhp.dctmrest.msginput.AsyncWorkerTask




file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources-prod\DctmRestSecrets.yml
-----------------------------------------------------
$ANSIBLE_VAULT;1.1;AES256
63623763336331323661386639333362303936316138396266623435363263633634643039336637
3662616432376663663837653130353433643164656536640a343861633434663538373832386637
61633831393863646463313530353434366464353461356437386366646430666230386637613462
3966313062656437350a633135353836383937333731396431626531323038623130343038373061
30633532356631646539316166313537656535623231303135316336313765666663343930363237
38633938346162626134366562653061346665346336346234393838303733333239386538646334
62363662343464623939356639663535333439313864613436353339303030366630396231646237
33653237316361333064623332383265396465333738613432653566373930633237613333653562
34666265636362323637336131316466653638353238366665383834636136633463303433336262
32303166646162326539626164366638393335646337643363393531343762613836353834366335
39643066636431666238396439646363393035616261636664323532306632353730653433336334
62656232653638613763336332623439353563623632386363343338643864313231636637326636
33623139643233373561653035396238393763636462613637383035663534353935643763353562
34356136623938333434313830623065636262353965323465343334353134366635626165643139
63633565303966636261336332306464386334663061373635343337636630356362653862333738
32383361646237643864323534386464366436663831613462376137393262643433623962313539
61376664653535666261376230613931633832343230353861383538393863353166326666373236
64626534663731663064363637323633323265646636633733386534653661643039353732613364
36343663343266393762386634636334656230363261643737316331616135313336356564643131
38666638323964323338656634336231383331383932363131623363613535313538313835393832
62663339666237363138383232356335336637333636303563366335386537663265


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources-prod\dfc.properties
-----------------------------------------------------
dfc.data.dir=/usr/PDC/duecmrest/dfc_config
dfc.data.user_dir=${dfc.data.dir}
dfc.checkout.dir=${dfc.data.user_dir}/checkout
dfc.export.dir=${dfc.data.user_dir}/export
dfc.tokenstorage.dir=${dfc.data.user_dir}/apptoken
dfc.security.keystore.file=${dfc.data.user_dir}/dfc.keystore

#include /usr/PDC/duecmrest/resources-prod/dfc_main.properties
#include /usr/PDC/duecmrest/resources-prod/dfc_extended.properties


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources-prod\dfc_main.properties
-----------------------------------------------------
dfc.docbroker.host[1]=pdcmcs01.resource.bank
dfc.docbroker.port[1]=27400
dfc.docbroker.host[2]=pdcmcs02.resource.bank
dfc.docbroker.port[2]=27400
dfc.docbroker.auto_request_forward=T
dfc.globalregistry.repository=banhap_prd
dfc.globalregistry.username=dm_bof_registry
dfc.globalregistry.password=AAAAEKw7B0IXFxhPNzIXJmMIFytVkvJ5WznHy/qSbKs76Xbf
dfc.session.max_collection_count = 300
dfc.session.max_count = 200
dfc.session.pool.enable = true
dfc.session.pool.expiration_interval = 5
dfc.session.reuse_limit = 4
dfc.session.pool.mode=level2
dfc.cache.object.size = 600

#dfc.cache.type.currency_check_interval=86400
#dfc.cache.ddinfo.size=10000
dfc.exception.include_id=false
dfc.exception.include_decoration=false
dfc.diagnostics.resources.enable = false
#dfc.tracing.enable = true
#dfc.tracing.include_rpcs = true
#dfc.tracing.print_exception_stack = true 
#dfc.logging.verbose = true
#dfc.tracing.max_stack_depth = 1
#dfc.tracing.mode=standard
#dfc.tracing.log.level = DEBUG
#dfc.tracing.config_type=dfc
#dfc.tracing.max_file_size = 50MB
#dfc.tracing.max_backup_index = 10
#dfc.tracing.dir=/usr/PDC/WebSphere7/Trace_log/dfstrace.txt
#dfc.tracing.file_prefix=MyTrace01



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources-prod\EnvProperty.properties
-----------------------------------------------------
are_props_reloadable=true
props_time_to_live=300000

#MF tables
kesher_type = DPT.DPT2042
makat_type = DPT.DPT2040
tchum_type = DPT.DPT2044
tat_type = DPT.DPT2043
matbea_type = DPT.DPT0484
central_code_table_doc_type=bnhp_central_code_table
# empty temporary entry until we have the table
kupot_gemel_type =
# dm_dbo.DPT200TMP
kupot_gemel_field_code=num
kupot_gemel_field_descr=descr

dfs_logger_id=BnhpDFSServices
wrapper_logger_id=BnhpDFSWrapper
err_logger_id=BnhpDFSWrapperErr
business_logger_id=BnhpDFSBusiness
operator_logger_id=BnhpDFSOperator

user_name = dctm
user_pass = AAAAEBCWopz3vvb7yrDsIFqG4HZzbbAlfsCh77DQMjt5c96k

perform_audit=false

default_docbase=banhap_prd
#default_docbase=banhap_qa1
docbase_override=true

# override entity for tofes peula, set (account or customer or pension)
fixed_entity_for_project[1]=7
fixed_entity_for_project[2]=7

velocity_properties_file=/bnhp_velocity.properties
velocity_template_name_regexp=^[a-zA-Z0-9_-]+$
velocity_template_prefix=/templates/
velocity_template_suffix=.txt


#magic field values, which are used in search services
category_scan_status=104
category_sign_status=106

# retrieve settings
retrieve_links_acs=false

retrieve_links_acs_unduplicate_retries=2
retrieve_links_acs_append_request_id=true


# retrieve settings
retrieve_links_acs=true

local_file_upload_base_dir=/DocumentumAsync/Async_Service_PROD/
server_file_upload_base_dir=/DocumentumAsync/Async_Service_PROD/
allowed_upload_url_regexp=^file:///[\/A-Za-z0-9_\.-]+$


file_upload_enabled = true
server_file_upload_enabled=true

# Renditions
generate_renditions_sync=true

# content updates w/o versions
same_version_content_updates_no_metadata=false
same_version_content_updates_no_metadata@PrdDctmMesila01=true
same_version_content_updates_allowed_time_sec=86400
make_auto_event_on_same_version_content_updates=true
dup_suppression_grace_period_sec  = 1000

# validations against permissions table
permtab_validation_required=false
permtab_validate_document_form_id=true
permtab_validate_user=false
permtab_validate_data_folder=false

# application id
app_instance_id=11

expected_err_regex=.*(Permission denied|Input/output error).*

# warmup config
perform_warmup=true
perform_jms_warmup=false
warmup_types=bnhp_customer_doc,bnhp_doc_event,bnhp_doc_xml_form,bnhp_doc_folder,bnhp_tfs_peula_doc,bnhp_yoman_eruim_table,bnhp_yoman_sugim,bnhp_central_code_table,bnhp_categoriot_table
warmup_jms_factory=jms/WebServicesReplyQCF
warmup_jms_queue=jms/WsEcmQueueJms
warmup_jms_target=DocumentumServicesJmsWrapper
# next macro will convert (or already has converted) hostname to Application number
warmup_jms_idval=app_instance_id=1

# DFC instance registration (part of warmup currently)
instance_registration_action=PERFORM
instance_registration_required_roles=dm_superusers_dynamic

# format guess/normalization
format_normalization_enabled=true
format_guess_enabled=true
retrieve_format_normalization_enabled=true
format_ext_cache_query=SELECT f.name AS name, lower(f.dos_extension) AS dos_extension, f.i_vstamp as i_vstamp FROM dm_dbo.BNHP_FORMATS_V f WHERE dos_extension<>' ' ORDER BY weight
format_mimetype_cache_query=SELECT f.name AS name, lower(f.mime_type) AS mime_type, f.i_vstamp as i_vstamp FROM dm_dbo.BNHP_FORMATS_V f WHERE mime_type<>' ' ORDER BY weight


# caches
cache_min_update_delay=600000
dpt_cache_version_id_query=select MAX(update_datetime) FROM DPT.DPT_BAKARA WHERE table_number in (2042,2040,2044,2043,484)

# LT SERVICE
lt_saf_version_spec=5.0

# HOOKS
# common doc data check for all
retrieve_prereturn_hook=(IF  docDataCheck (IF (OR (customers-check?) (accounts-check?)) "OK: docDataCheck PASSED" (THROW "DocDataCheck FAILED")) "docDataCheck SKIPPED")

#ExcutorDetailsProperties:
# Cases: PROVIDE, JWT, AUTO
#      PROVIDE - require as parameter inside the request.
#      JWT - build executorDetails basis of the jwt
#      AUTO - fill ED from properties bellow
executor_details@user=AUTO

# Settings for JWT option - Map from JWT properties to executor details props
executor_details@Jwt@executingEmpIdCode=http://wso2.org/claims/givenname,http://wso2.org/claims/lastname
executor_details@Jwt@fullName=http://wso2.org/claims/enduser

#Settings for AUTO options - fill ED props from bellow:
executor_details@Auto@executingEmpIdCode=1234567890
executor_details@Auto@fullName=FIXME
executor_details@Auto@ipAddress=1.2.3.4



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources-prod\env_vars.yaml
-----------------------------------------------------
---
orapass: xxxxxxx
orainstance: docdbp
orauser: dctm
docbase: banhap_prd


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources-prod\ErrorInfo.properties
-----------------------------------------------------
# Creation error codes
legacy_id_not_unique = GENERAL_ERROR:600:business constraint violated. Non-unique value %1s in field legacyId of object %2s. The existing id is - %3s
mixed_creation_request = GENERAL_ERROR:601:saving existing and non existing documents in the same transaction is not supported. One of the existing legacyIds is - %1s
legacy_id_not_unique_different_customer_data = GENERAL_ERROR:602:non-unique value %1s in field legacyId but different customer data. The existing id is - %2s
legacy_id_not_unique_different_event_data = GENERAL_ERROR:603:non-unique value %1s in field legacyId but different event data. The existing id is - %2s
legacy_id_not_unique_different_extensions_data = GENERAL_ERROR:604:non-unique value %1s in field legacyId but different extensions data. The existing id is - %2s
legacy_id_not_unique_different_file_size = GENERAL_ERROR:605:non-unique value %1s in field legacyId but different file size. The existing id is - %2s
document_is_deleted = GENERAL_ERROR:606:Unexpectedly failed to retrieve existing document, probably it is logically deleted, legacy id is - %1s

# Query error codes
# FIXME: need to check if in all cases this one indicates validation error
not_single_query_result = VALIDATION_ERROR:700:single query result expected, but query %1s has returned %2s results
unexpected_type_returned = GENERAL_ERROR:701:returned document of unexpected type %1s

# System exception from underlying layers
generic_dfs_service_exception = AUTOTYPE_ERROR:750:DFS Service Exception: %1s 
generic_dfc_exception = AUTOTYPE_ERROR:751:Generic DFC Exception: %1s
generic_exception = AUTOTYPE_ERROR:752:Generic Exception: %1s

# Retrieve error codes
non_existing_object_to_retrieve = GENERAL_ERROR:800:the requested document with %1s=%2s does not exist or you do not have rights to retrieve it

# Validation technical error codes
security_context_not_complete = VALIDATION_ERROR:1100:securityContext is not complete
fetch_type_set_not_set = VALIDATION_ERROR:1101:fetchTypeSet must exist
max_docs_to_process_reached = VALIDATION_ERROR:1102:processing more than 10 documents is not supported
invalid_value_for_field = VALIDATION_ERROR:1105:invalid value %1s for field %2s - %3s
cannot_parse_value = VALIDATION_ERROR:1106:cannot parse value %1s as %2s - %3s
security_context_not_set = VALIDATION_ERROR:1107:securityContext must exist
property_name_invalid = VALIDATION_ERROR:1108:property name %1s is not valid
file_update_same_version_unsupported = VALIDATION_ERROR:1109:no file update with metadata is allowed without creating new version
update_new_version_no_file_unsupported = VALIDATION_ERROR:1110:update a version without a file is not allowed
version_label_not_set = VALIDATION_ERROR:1111:versionLabel must exist
prepared_query_not_set = VALIDATION_ERROR:1112:preparedQuery must exist
wrong_date_format = VALIDATION_ERROR:1113:the date is not in the format of XMLGregorianCalendar
between_null_dates = VALIDATION_ERROR:1114:the dates are null in BETWEEN DATES clause
only_one_of_legacy_and_dctm_id_must_be_provided = VALIDATION_ERROR:1115:only one of legacyDocumentId and dctmDocumentId must be provided, but got both
same_version_update_of_existing_file_is_not_supported =VALIDATION_ERROR:1116:update of existing main content is not allowed without creating new document version
same_version_update_not_allowed=VALIDATION_ERROR:1117:main content update without metadata is not allowed by server configuration
same_version_update_timeout=VALIDATION_ERROR:1118:main content update without metadata is not allowed: too late, maximum time of %s seconds is passed
extension_date_format_invalid==VALIDATION_ERROR:1119:date format in extension is invalid: %1s

# Validation business error codes
doc_data_not_set = VALIDATION_ERROR:1200:docData must exist
doc_customer_data_not_set = VALIDATION_ERROR:1201:docCustomerData must exist
doc_file_not_complete = VALIDATION_ERROR:1202:docFile is not complete
secondary_doc_file_not_complete = VALIDATION_ERROR:1206:secondaryDocFile is not complete
template_source_code_not_set = VALIDATION_ERROR:1207:templateSourceCode in secondaryDocFile must exist
auto_event_ind_not_set = VALIDATION_ERROR:1208:autoEventInd in docEventData must exist
event_category_code_not_set = VALIDATION_ERROR:1209:eventCategoryCode in docEventData must exist
event_category_type_code_not_set = VALIDATION_ERROR:1210:eventCategoryTypeCode in docEventData must exist
legacy_event_entry_dttm_not_set = VALIDATION_ERROR:1211:legacyEventEntryDttm in docEventData must exist
extension_name_invalid = VALIDATION_ERROR:1212:extensionName '%1s' in docPropertyExtensions is invalid
property_key_values_not_complete = VALIDATION_ERROR:1213:propertyKeyValues are not complete
doc_details_not_set = VALIDATION_ERROR:1214:docDetails must exist
business_process_id_not_set = VALIDATION_ERROR:1215:businessProcessId in docDetails must exist
document_form_id_not_set = VALIDATION_ERROR:1216:documentFormId in docDetails must exist
ongoing_or_history_code_not_set = VALIDATION_ERROR:1217:ongoingOrHistoryCode in docDetails must exist
legacy_document_entry_dttm_doc_details_not_set  = VALIDATION_ERROR:1218:legacyDocumentEntryDttm in docDetails must exist
project_id_not_set  = VALIDATION_ERROR:1219:projectId in docDetails must exist
business_sub_area_code_not_set  = VALIDATION_ERROR:1220:businessSubAreaCode in docDetails must exist
executor_details_not_set  = VALIDATION_ERROR:1221:executorDetails must exist
executing_emp_id_code_not_set  = VALIDATION_ERROR:1222:executingEmpIdCode in executorDetails must exist
ip_address_not_set  = VALIDATION_ERROR:1223:ipAddress in executorDetails must exist
pension_fund_not_set  = VALIDATION_ERROR:1224:pensionFund must exist
pension_fund_nbr_not_set  = VALIDATION_ERROR:1225:pensionFundNbr in pensionFund must exist
planholder_number_not_set  = VALIDATION_ERROR:1226:planholderNumber in pensionFund must exist
complete_customer_id_code_not_set  = VALIDATION_ERROR:1227:completeCustomerIdCode in customerKeys must exist
occasional_customer_ind_not_set  = VALIDATION_ERROR:1228:occasionalCustomerInd in customerKeys must exist
customer_id_doc_type_code_not_set  = VALIDATION_ERROR:1229:customerIdDocTypeCode in customerKeys must exist
customer_id_not_set  = VALIDATION_ERROR:1230:customerId in customerKeys must exist
bank_accounts_not_set  = VALIDATION_ERROR:1231:bankAccounts must exist
account_nbr_not_set  = VALIDATION_ERROR:1232:accountNbr in bankAccounts must exist
customer_keys_not_set  = VALIDATION_ERROR:1233:customerKeys must exist
branch_id_not_set  = VALIDATION_ERROR:1234:branchId in bankAccounts must exist
dctm_document_id_not_set  = VALIDATION_ERROR:1235:dctmDocumentId must exist
legacy_document_id_not_set= VALIDATION_ERROR:1236:legacyDocumentId must exist
query_name_not_set= VALIDATION_ERROR:1237:queryName must exist
document_group_id_not_set= VALIDATION_ERROR:1238:documentGroupId must exist
document_id_not_set= VALIDATION_ERROR:1239:documentId must exist
legacy_document_entry_dttm_event_not_set = VALIDATION_ERROR:1240:legacyDocumentEntryDttm in docEventData must exist
entity_validation_error = VALIDATION_ERROR:1241:entity validation error: %1s
doc_data_for_create_not_set = VALIDATION_ERROR:1242:docDataForCreate must nut be null
general_validation_error = VALIDATION_ERROR:1243:General validation error: %1s
need_one_of_gemel_customer_account = VALIDATION_ERROR:1243:Need at least one of three to be non-empty: PensionFund, CustomerKeys, BankAccounts 
#validation_hook_retrieve_customer_document = VALIDATION_ERROR:1244:mismatch validation between doc customer Id(or account details) and input customer (or account details)
validation_hook_retrieve_customer_document_compare_customer_and_account=VALIDATION_ERROR:1244:mismatch validation between given customer and account and archived customer and account
validation_hook_retrieve_customer_document_compare_cust=VALIDATION_ERROR:1245:mismatch validation between given customer and archived customer
validation_hook_retrieve_customer_document_compare_account=VALIDATION_ERROR:1246:mismatch validation between given account and archived account
need_one_of_gemel_customer_account = VALIDATION_ERROR:1247:Need at least one of three to be non-empty: PensionFund, CustomerKeys, BankAccounts 

# Format validation and guessing
invalid_document_format_provided=VALIDATION_ERROR:1250:Document Format that was provided '%1s' is invalid 
format_not_provided_and_failed_to_guess=VALIDATION_ERROR:1251:Document Format was not provided and failed to guess using DOS extension or content

# Validation against permission table
permtabentry_not_exists=VALIDATION_ERROR:1280:Permission table entry not exists for given project id
permtabentry_wrong_document_form_id=VALIDATION_ERROR:1281:Wrong document form id %1s for project id %2s
permtabentry_wrong_content_upload_path=VALIDATION_ERROR:1282:Wrong content upload path '%1s' for project id %2s
permtabentry_wrong_username=VALIDATION_ERROR:1283:Wrong application user name '%1s' for project id %2s


# applicative request error codes
appx_required_parameter_missing = GENERAL_ERROR:1501:missing value for parameter %1s for stage %2s 
appx_api_call_required_parameter_missing = GENERAL_ERROR:1502:missing value for parameter %1s for api call %2s, stage %3s
appx_unsupported_value_for_parameter = GENERAL_ERROR:1503:invalid value '%1s' for parameter %2s, stage %3s
appx_api_call_failed = GENERAL_ERROR:1504:api call %1s method %2s failed, stage %3s: %4s
failed_to_parse_merged_query = GENERAL_ERROR:1505:failed to parse merged query

# content retrieve errors
# this one should not happen, if it happens we do not know if it temporary
uriprovider_failure=GENERAL_ERROR:1601:Error getting content URL: %1s
# this usually means that ACS is down, unavailable or not properly configured 
acs_uriprovider_failure=TEMPORARY_ERROR:1610:Error getting ACS Server content URL : %1s
# this usually means temporarry error while calling CyberArk
cyberark_uriprovider_failure=TEMPORARY_ERROR:1620:Error returning content via CyberArk service: %1s




file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources-test\bhEnvProperty.properties
-----------------------------------------------------
# vanilla
#repository_name=banhap_qa1
#folder_id=0b00000a801e5f84
#folder_id_4_reprints=0b00000a801e5f85
# preprod
#repository_name = banhap_preprd1
#folder_id = 0b000009800bb5a6
#folder_id_4_reprints=0b000009800bb5a5
# s
repository_name = banhap_qa1
folder_id = 0b00000a800927c7
folder_id_4_reprints=0b00000a800927c6


# DEV
#repository_name = banhap_dev1
#folder_id = 0b00000a8004e6d2
#folder_id_4_reprints=0b00000a8004e6d4

context_root = http://localhost:9080/services

module_name = core
doc_type = bnhp_tfs_peula_doc
doc_type_alias = doc
erua_type=bnhp_yoman_eruim_table
heara_type=bnhp_yoman_eruim_table
doc_type_pb = bnhp_tfs_peula_reprint
central_code_table_doc_type = bnhp_central_code_table
bnhp_yoman_eruim_table_doc_type = bnhp_yoman_eruim_table
reprint_relation_type = bnhp_tofes_reprint_relation
#MF tables
kesher_type = DPT.DPT2042
makat_type = DPT.DPT2040
tchum_type = DPT.DPT2044
tat_type = DPT.DPT2043
matbea_type = DPT.DPT0484

user_name = dctm
user_pass = AAAAEFJMk9QntvpBhsRyNsXgyDBZ//4n3Q7zJK/xjgjMxeio

#For create/update object service - properties not to be updated 
pakid_unupdatable_properties=
customer_unupdatable_properties=kodCheshbonMutzpan,misparHativa,misparBank,misparCheshbon,mprZihuyLakoach,mprSiduriLakoach,misparSnif,misparAmit,misparKupatGemel,sugMismachMezaheLak,sifrurLakoach,shemLakoach
tofes_unupdatable_properties=misparMahadura,misparTofes,docType,docSubType
appl_unupdatable_properties=docKey,appId,projectId,shotefOrHistory
scan_unupdatable_properties=pageCount

#For create/update object service - to validate their values before populate them, and throw exception in case of not valid
centralCodesProperties=projectId,docStatus,shotefOrHistory,incomplete,archive,physicalLocation,scanStatus
peulaMFCodesProperties=misparTofes,docType,docSubType
peulaMFCurrencyCodesProperties=shemIvri,shemLoazi

#Categories of BHPeulaDocDataContext fields
projectId=105
docStatus=106
shotefOrHistory=100
incomplete=101
archive=102
physicalLocation=103
scanStatus=104
mezahePak=108
mezaheLak=107
arutz=112

#Categories of BHPeulaYomanDataContext fields
kodSugErua=200
ofenTipulErua=201
ofenTipulErua4Heara=203
createTypeErua=202

#Categories of scan status and doc_status fields
scanStatusCategory=104
docStatusCategory=106

# For extended debug log
printInput2LogMode=true

# For Harigim Screen Initialization
defaultOfenTipulCodes=1,2

# For Search Screen Initialization
statusCategories=104,106

#For Search results
category_scan_status=104
category_sign_status=106

# ofen tipul for kod sug tofes
ofenTipulForKodSug_1=2,3,4,6
ofenTipulForKodSug_2=2,3,4,5,6
ofenTipulForKodSug_3=2,3,4,5,6
ofenTipulForKodSug_4=2,3,4,5,6

#
heara_4_cheshbon_mushhe= 
pakid_def_shem= 
pakid_def_mispar_tachana=0
pakid_def_mispar_bankol=0

#keystoreLocation = /usr/IBM/SSL/tdcmdfs.p12
storepass = tdcmdfs
keyalias = tdcmdfs
keypassword = XXXXXX

#performance hints
search_archive_by_customer_use_hints=true
search_archive_by_customer_index=HO_ BNHP_BASE_LAKOACH_DOC_S_I1

search_by_account_use_hints=true
search_by_account_index=HO_ BNHP_BASE_LAKOACH_DOC_S_I3

search_by_status_use_hints=false
search_by_status_index=HO_ BNHP_BASE_LAKOACH_DOC_S_I1

search_by_amit_use_hints=true
search_by_amit_index=HO_ BNHP_BASE_LAKOACH_DOC_S_I4

search_by_customer_use_hints=true
search_by_customer_index=HO_ BNHP_BASE_LAKOACH_DOC_S_I1

search_by_official_use_hints=false
search_by_official_index=

search_by_process_use_hints=false
search_by_process_index=




file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources-test\BnhpInfraDFSServicesTests.properties
-----------------------------------------------------
test_user=testfaxuser
test_password=1234
#test_docbase=banhap_dev1

http_test_user=httpfaxuser
http_test_password=AES128:U2FsdGVkX1/eQrJzL/nWNJBTQV70+Ak5oUTkz21P47Y=

#test_user=TSTBO14
#test_user=faxuser
#test_docbase=banhap_dev1
#test_docbase=banhapvan_kg
test_docbase=banhap_qa1
#test_docbase=banhap_preprd1

legacy_test_user=testtfspeula
legacy_test_password=AES128:U2FsdGVkX18vlnqRWqvypOXKpZ1lTcysRk2JA/QWk/0=

http_legacy_test_user=httptfspeula
http_legacy_test_password=AES128:U2FsdGVkX1+ZVMC03i/lclKdh1jsMMLAQBda4xYugIQ=

safe_test_user=safetfspeula
safe_test_password=AES128:U2FsdGVkX1/MsNNbfuQ9tTFHp/HsYT6jrolo6vxmsBo=


#legacy_test_user=tofespeulausrtst

pension_test_user=pensionfundtest
pension_test_password=AES128:U2FsdGVkX1/AVm7b1njgyKDYCAJBOqRFUx7khxK7oW0=

# users for file based upload testing
fileupload_test_user=httpfaxuser
fileupload_test_password=AES128:U2FsdGVkX18BiHSaO4f4tNQ/9WhlaN0HyMAF7leqqKo=

server_api_fileupload_test_user=apifaxuser
server_api_fileupload_test_password=AES128:U2FsdGVkX1/DVJ9yzPfflQd7iT8tOZwk/eJYxdGHLL4=

nofileupload_test_user=testfaxuser
nofileupload_test_password=AES128:U2FsdGVkX1/X7bqvheAVj4237Emvc5U12PG88n1JgwQ=

nocontentshare_test_user=testfaxuser
nocontentshare_test_password=AES128:U2FsdGVkX198dd+1pnnUlYq2qFnRPF/fPIuvv5x3uK8=

no_privs_user=no_privs_user
no_privs_password=AES128:U2FsdGVkX18MTe9YB3VlKlHoBzU/KpPfToyYxJKQD0Y=

# user that has R/O rights but member of susperusers_dynamic
view_only_user=testfaxview
view_only_password=AES128:U2FsdGVkX19TAXWra5wbSF2n37Xzl644imljpvu3/NI=




# a non-administrative user, which can perform server based upload
# (privilages are elevated for server based upload to be performed)
server_fileupload_test_user=uploadfaxuser
server_fileupload_test_password=AES128:U2FsdGVkX1/iltKtbUPbYnpqjgWNKvPd1gcHfdPI6Rc=

server_zc_fileupload_test_user=zcfaxuser
server_zc_fileupload_test_password=AES128:U2FsdGVkX19FI9PPDYGSLaVoS3XsEvwWFg0WL6ljShI=

server_upload_tfs_test_user=uploadtfspeula
server_upload_tfs_test_password=AES128:U2FsdGVkX19q0b9ET7OtnWQgaTTBex6YABTzXiNxtT8=

server_zc_upload_tfs_test_user=zctfspeula
server_zc_upload_tfs_test_password=AES128:U2FsdGVkX19lLUcXKdOKKR+jTSXhJgJUfEg4h50e6lY=

server_api_upload_tfs_test_user=apitfspeula
server_api_upload_tfs_test_password=AES128:U2FsdGVkX1+mzma4sUofimMUuh1QNsVc0hOBKb4KBiU=


server_fb_upload_tfs_test_user=fbtfspeula
server_fb_upload_tfs_test_password=AES128:U2FsdGVkX19UnVk6GNfO4spLr5p/tHLsYGneczPYeo0=


# an administrative user, which can perform server based upload
server_fileupload_admin_test_user=dctm
server_fileupload_admin_test_password=AES128:U2FsdGVkX19OotyyD4C7ibHKSRAs26wYcOyoebod/18=

# user, which can access bot legacy and non-legacy project
both_test_user=dctm
both_test_password=AES128:U2FsdGVkX1+eEb2JGCPnrETxzAABGTUaL4JBpMSL0zI=

local_offline_input_dir=S:/Offline_Service_DEV/Faxes
server_offline_input_dir=/DocumentumAsync/Offline_Service_DEV/Faxes

bnhp_customer_doc_mv_name=BNHP_CUSTOMER_DOC_MV

bad_makats=0000011460,0000019970,0000022542,0000022545,0000022546,0000062001,0000062011,0000062012,0000062013,0000062014,0000063126,0000083812,0000084024,0000084030,0000084031,0000089001,0000130766,4444400050,4444400052,4444404000,5000000100,5000000101,5000000102,5444448967,5444466124,6000000000,9999912385,9999917260,9999918652,9999919450


cyberark_auth_user=DocumentumUser
cyberarc_auth_password=AES128:U2FsdGVkX19MqMz7ucY6zPdwPnXPEqXB/VU+LImHyB8=
cyberarc_auth_url_prefix=https://ttoapp02.restest.bank/SFE/WebServices/auth/Cyberark/CyberArkAuthenticationService.svc

          


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources-test\cache\7.1.0000.0115\bof\banhap_qa1\content.xml
-----------------------------------------------------
<?xml version="1.0"?>
<CacheContent MasterVersionStamp="25633"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="CacheContent.xsd">
    <Entries>
        <Entry ObjectId="0b00000a8049100c" ObjectName="bnhp_customer_doc">
            <ImplClass>com.documentum.fc.client.customerdoc.tbo.CustomerDoc</ImplClass>
            <VersionStamp>198</VersionStamp>
            <BofVersion>1.0</BofVersion>
            <ObjectType>TBO</ObjectType>
            <Files>
                <File
                    FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-test\cache\7.1.0000.0115\bof\banhap_qa1\0900000a8049101c.jar"
                    IsArchive="true" IsSandboxed="false"/>
                <File
                    FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-test\cache\7.1.0000.0115\bof\banhap_qa1\0900000a80491016.jar"
                    IsArchive="true" IsSandboxed="false"/>
                <File
                    FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-test\cache\7.1.0000.0115\bof\banhap_qa1\0900000a812967fe.jar"
                    IsArchive="true" IsSandboxed="true"/>
                <File
                    FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-test\cache\7.1.0000.0115\bof\banhap_qa1\0900000a8070050a.jar"
                    IsArchive="true" IsSandboxed="false"/>
            </Files>
            <Interfaces>
                <Interface>com.documentum.fc.client.customerdoc.tbo.ICustomerDoc</Interface>
                <Interface>com.documentum.fc.client.IDfDocument</Interface>
                <Interface>com.documentum.fc.client.IDfSysObject</Interface>
                <Interface>com.documentum.fc.client.IDfPersistentObject</Interface>
                <Interface>com.documentum.fc.client.IDfTypedObject</Interface>
                <Interface>bnhp.infra.base.tbo.ISyncObject</Interface>
                <Interface>com.documentum.fc.client.impl.ISysObject</Interface>
                <Interface>com.documentum.fc.client.impl.IPersistentObject</Interface>
                <Interface>com.documentum.fc.client.impl.ITypedObject</Interface>
                <Interface>com.documentum.fc.client.internal.ITypedObjectInternal</Interface>
                <Interface>com.documentum.fc.tracing.IUserIdentifyingObject</Interface>
                <Interface>com.documentum.fc.client.internal.IPersistentObjectInternal</Interface>
                <Interface>com.documentum.fc.client.internal.ISysObjectInternal</Interface>
                <Interface>com.documentum.fc.client.impl.IAliasResolution</Interface>
                <Interface>com.documentum.fc.client.IDfSysObjectInternal</Interface>
                <Interface>com.documentum.fc.client.IDfPersistentObjectInternal</Interface>
                <Interface>com.documentum.fc.client.IDfSysObjectRetention</Interface>
                <Interface>com.documentum.fc.impl.util.reflection.proxy.IProxyTarget</Interface>
                <Interface>com.documentum.fc.client.relationship.IDfRelatable</Interface>
                <Interface>com.documentum.fc.client.aspect.IDfAspects</Interface>
                <Interface>java.lang.Cloneable</Interface>
                <Interface>com.documentum.fc.client.IDfTypedObjectInternal</Interface>
            </Interfaces>
            <Dependencies>
                <Dependency>bnhp.infra.base.sbo.IMigrationConfigService</Dependency>
            </Dependencies>
            <Privileged>false</Privileged>
            <PrivilegeRoles/>
            <MinDFCVersion/>
            <ClassLoadingFilters/>
        </Entry>
        <Entry ObjectId="0b00000a8024d7a0" ObjectName="general_doc_aspect">
            <ImplClass>bnhp.infra.base.aspect.GeneralDocAspect</ImplClass>
            <VersionStamp>252</VersionStamp>
            <BofVersion>1.0</BofVersion>
            <ObjectType>Aspect</ObjectType>
            <Files>
                <File
                    FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-test\cache\7.1.0000.0115\bof\banhap_qa1\0900000a814cbade.jar"
                    IsArchive="true" IsSandboxed="true"/>
                <File
                    FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-test\cache\7.1.0000.0115\bof\banhap_qa1\0900000a814cbae0.jar"
                    IsArchive="true" IsSandboxed="false"/>
            </Files>
            <Interfaces>
                <Interface>com.documentum.fc.client.IDfDocument</Interface>
                <Interface>com.documentum.fc.client.IDfSysObject</Interface>
                <Interface>com.documentum.fc.client.IDfPersistentObject</Interface>
                <Interface>com.documentum.fc.client.IDfTypedObject</Interface>
                <Interface>com.documentum.fc.client.impl.ISysObject</Interface>
                <Interface>com.documentum.fc.client.impl.IPersistentObject</Interface>
                <Interface>com.documentum.fc.client.impl.ITypedObject</Interface>
                <Interface>com.documentum.fc.client.internal.ITypedObjectInternal</Interface>
                <Interface>com.documentum.fc.tracing.IUserIdentifyingObject</Interface>
                <Interface>com.documentum.fc.client.internal.IPersistentObjectInternal</Interface>
                <Interface>com.documentum.fc.client.internal.ISysObjectInternal</Interface>
                <Interface>com.documentum.fc.client.impl.IAliasResolution</Interface>
                <Interface>com.documentum.fc.client.IDfSysObjectInternal</Interface>
                <Interface>com.documentum.fc.client.IDfPersistentObjectInternal</Interface>
                <Interface>com.documentum.fc.client.IDfSysObjectRetention</Interface>
                <Interface>com.documentum.fc.impl.util.reflection.proxy.IProxyTarget</Interface>
                <Interface>com.documentum.fc.client.relationship.IDfRelatable</Interface>
                <Interface>com.documentum.fc.client.aspect.IDfAspects</Interface>
                <Interface>java.lang.Cloneable</Interface>
                <Interface>com.documentum.fc.client.IDfTypedObjectInternal</Interface>
            </Interfaces>
            <Dependencies/>
            <Privileged>false</Privileged>
            <PrivilegeRoles/>
            <MinDFCVersion/>
            <ClassLoadingFilters/>
        </Entry>
        <Entry ObjectId="0b00000a80305a53" ObjectName="bnhp.infra.base.storage.iface.IBnhpStorageSelectionService">
            <ImplClass>bnhp.infra.base.storage.impl.BnhpStorageSelectionService</ImplClass>
            <VersionStamp>62</VersionStamp>
            <BofVersion>1.0</BofVersion>
            <ObjectType>SBO</ObjectType>
            <Files>
                <File
                    FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-test\cache\7.1.0000.0115\bof\banhap_qa1\0900000a80329078.jar"
                    IsArchive="true" IsSandboxed="true"/>
                <File
                    FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-test\cache\7.1.0000.0115\bof\banhap_qa1\0900000a8032907e.jar"
                    IsArchive="true" IsSandboxed="false"/>
            </Files>
            <Interfaces>
                <Interface>bnhp.infra.base.storage.iface.IBnhpStorageSelectionService</Interface>
                <Interface>com.documentum.fc.client.IDfService</Interface>
                <Interface>com.documentum.fc.client.IDfModule</Interface>
            </Interfaces>
            <Dependencies/>
            <Privileged>false</Privileged>
            <PrivilegeRoles/>
            <MinDFCVersion/>
            <ClassLoadingFilters/>
        </Entry>
        <Entry ObjectId="0b00000a8049100f" ObjectName="bnhp.infra.base.sbo.IMigrationConfigService">
            <ImplClass>bnhp.infra.base.sbo.MigrationConfigService</ImplClass>
            <VersionStamp>220</VersionStamp>
            <BofVersion>1.0</BofVersion>
            <ObjectType>SBO</ObjectType>
            <Files>
                <File
                    FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-test\cache\7.1.0000.0115\bof\banhap_qa1\0900000a81296806.jar"
                    IsArchive="true" IsSandboxed="true"/>
                <File
                    FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-test\cache\7.1.0000.0115\bof\banhap_qa1\0900000a8070050a.jar"
                    IsArchive="true" IsSandboxed="false"/>
            </Files>
            <Interfaces>
                <Interface>bnhp.infra.base.sbo.IMigrationConfigService</Interface>
                <Interface>com.documentum.fc.client.IDfService</Interface>
                <Interface>com.documentum.fc.client.IDfModule</Interface>
            </Interfaces>
            <Dependencies/>
            <Privileged>false</Privileged>
            <PrivilegeRoles/>
            <MinDFCVersion/>
            <ClassLoadingFilters/>
        </Entry>
        <Entry ObjectId="0b00000a804910b0" ObjectName="bnhp_tfs_peula_doc">
            <ImplClass>com.documentum.fc.client.tfspeula.tbo.TfsPeulaDoc</ImplClass>
            <VersionStamp>203</VersionStamp>
            <BofVersion>1.0</BofVersion>
            <ObjectType>TBO</ObjectType>
            <Files>
                <File
                    FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-test\cache\7.1.0000.0115\bof\banhap_qa1\0900000a8070050e.jar"
                    IsArchive="true" IsSandboxed="false"/>
                <File
                    FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-test\cache\7.1.0000.0115\bof\banhap_qa1\0900000a80700510.jar"
                    IsArchive="true" IsSandboxed="true"/>
                <File
                    FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-test\cache\7.1.0000.0115\bof\banhap_qa1\0900000a804910bb.jar"
                    IsArchive="true" IsSandboxed="false"/>
                <File
                    FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-test\cache\7.1.0000.0115\bof\banhap_qa1\0900000a8070050a.jar"
                    IsArchive="true" IsSandboxed="false"/>
            </Files>
            <Interfaces>
                <Interface>com.documentum.fc.client.tfspeula.tbo.ITfsPeulaDoc</Interface>
                <Interface>com.documentum.fc.client.IDfDocument</Interface>
                <Interface>com.documentum.fc.client.IDfSysObject</Interface>
                <Interface>com.documentum.fc.client.IDfPersistentObject</Interface>
                <Interface>com.documentum.fc.client.IDfTypedObject</Interface>
                <Interface>bnhp.infra.base.tbo.ISyncObject</Interface>
                <Interface>com.documentum.fc.client.impl.ISysObject</Interface>
                <Interface>com.documentum.fc.client.impl.IPersistentObject</Interface>
                <Interface>com.documentum.fc.client.impl.ITypedObject</Interface>
                <Interface>com.documentum.fc.client.internal.ITypedObjectInternal</Interface>
                <Interface>com.documentum.fc.tracing.IUserIdentifyingObject</Interface>
                <Interface>com.documentum.fc.client.internal.IPersistentObjectInternal</Interface>
                <Interface>com.documentum.fc.client.internal.ISysObjectInternal</Interface>
                <Interface>com.documentum.fc.client.impl.IAliasResolution</Interface>
                <Interface>com.documentum.fc.client.IDfSysObjectInternal</Interface>
                <Interface>com.documentum.fc.client.IDfPersistentObjectInternal</Interface>
                <Interface>com.documentum.fc.client.IDfSysObjectRetention</Interface>
                <Interface>com.documentum.fc.impl.util.reflection.proxy.IProxyTarget</Interface>
                <Interface>com.documentum.fc.client.relationship.IDfRelatable</Interface>
                <Interface>com.documentum.fc.client.aspect.IDfAspects</Interface>
                <Interface>java.lang.Cloneable</Interface>
                <Interface>com.documentum.fc.client.IDfTypedObjectInternal</Interface>
            </Interfaces>
            <Dependencies>
                <Dependency>bnhp.infra.base.sbo.IMigrationConfigService</Dependency>
            </Dependencies>
            <Privileged>false</Privileged>
            <PrivilegeRoles/>
            <MinDFCVersion/>
            <ClassLoadingFilters/>
        </Entry>
        <Entry ObjectId="0b00000a804910b2" ObjectName="bnhp_yoman_eruim_table">
            <ImplClass>com.documentum.fc.client.tfspeula.tbo.TfsPeulaErua</ImplClass>
            <VersionStamp>140</VersionStamp>
            <BofVersion>1.0</BofVersion>
            <ObjectType>TBO</ObjectType>
            <Files>
                <File
                    FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-test\cache\7.1.0000.0115\bof\banhap_qa1\0900000a80700508.jar"
                    IsArchive="true" IsSandboxed="true"/>
                <File
                    FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-test\cache\7.1.0000.0115\bof\banhap_qa1\0900000a804910bb.jar"
                    IsArchive="true" IsSandboxed="false"/>
                <File
                    FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-test\cache\7.1.0000.0115\bof\banhap_qa1\0900000a80700512.jar"
                    IsArchive="true" IsSandboxed="false"/>
                <File
                    FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-test\cache\7.1.0000.0115\bof\banhap_qa1\0900000a8070050a.jar"
                    IsArchive="true" IsSandboxed="false"/>
            </Files>
            <Interfaces>
                <Interface>com.documentum.fc.client.tfspeula.tbo.ITfsPeulaErua</Interface>
                <Interface>com.documentum.fc.client.IDfPersistentObject</Interface>
                <Interface>com.documentum.fc.client.IDfTypedObject</Interface>
                <Interface>bnhp.infra.base.tbo.ISyncObject</Interface>
                <Interface>com.documentum.fc.client.impl.IPersistentObject</Interface>
                <Interface>com.documentum.fc.client.impl.ITypedObject</Interface>
                <Interface>com.documentum.fc.client.internal.ITypedObjectInternal</Interface>
                <Interface>com.documentum.fc.tracing.IUserIdentifyingObject</Interface>
                <Interface>com.documentum.fc.client.internal.IPersistentObjectInternal</Interface>
                <Interface>com.documentum.fc.client.IDfPersistentObjectInternal</Interface>
                <Interface>com.documentum.fc.impl.util.reflection.proxy.IProxyTarget</Interface>
                <Interface>com.documentum.fc.client.relationship.IDfRelatable</Interface>
                <Interface>com.documentum.fc.client.aspect.IDfAspects</Interface>
                <Interface>java.lang.Cloneable</Interface>
                <Interface>com.documentum.fc.client.IDfTypedObjectInternal</Interface>
            </Interfaces>
            <Dependencies>
                <Dependency>bnhp.infra.base.sbo.IMigrationConfigService</Dependency>
            </Dependencies>
            <Privileged>false</Privileged>
            <PrivilegeRoles/>
            <MinDFCVersion/>
            <ClassLoadingFilters/>
        </Entry>
        <Entry ObjectId="0b00000a802db972" ObjectName="bnhp_paper_doc">
            <ImplClass>bnhp.infra.base.aspect.EmptyDocAspect</ImplClass>
            <VersionStamp>237</VersionStamp>
            <BofVersion>1.0</BofVersion>
            <ObjectType>Aspect</ObjectType>
            <Files>
                <File
                    FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-test\cache\7.1.0000.0115\bof\banhap_qa1\0900000a81296802.jar"
                    IsArchive="true" IsSandboxed="true"/>
            </Files>
            <Interfaces/>
            <Dependencies/>
            <Privileged>false</Privileged>
            <PrivilegeRoles/>
            <MinDFCVersion/>
            <ClassLoadingFilters/>
        </Entry>
    </Entries>
    <FilesInventory>
        <File
            FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-test\cache\7.1.0000.0115\bof\banhap_qa1\0900000a8049101c.jar" ObjectLastAccessed="1619623446329"/>
        <File
            FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-test\cache\7.1.0000.0115\bof\banhap_qa1\0900000a80491016.jar" ObjectLastAccessed="1619623446329"/>
        <File
            FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-test\cache\7.1.0000.0115\bof\banhap_qa1\0900000a812967fe.jar" ObjectLastAccessed="1619623446322"/>
        <File
            FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-test\cache\7.1.0000.0115\bof\banhap_qa1\0900000a8070050a.jar" ObjectLastAccessed="1619623446329"/>
        <File
            FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-test\cache\7.1.0000.0115\bof\banhap_qa1\0900000a814cbade.jar" ObjectLastAccessed="1619623446324"/>
        <File
            FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-test\cache\7.1.0000.0115\bof\banhap_qa1\0900000a814cbae0.jar" ObjectLastAccessed="1619623446329"/>
        <File
            FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-test\cache\7.1.0000.0115\bof\banhap_qa1\0900000a80329078.jar" ObjectLastAccessed="1619622479667"/>
        <File
            FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-test\cache\7.1.0000.0115\bof\banhap_qa1\0900000a8032907e.jar" ObjectLastAccessed="1619623446329"/>
        <File
            FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-test\cache\7.1.0000.0115\bof\banhap_qa1\0900000a81296806.jar" ObjectLastAccessed="1619622479873"/>
        <File
            FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-test\cache\7.1.0000.0115\bof\banhap_qa1\0900000a8070050e.jar" ObjectLastAccessed="1619623446329"/>
        <File
            FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-test\cache\7.1.0000.0115\bof\banhap_qa1\0900000a80700510.jar" ObjectLastAccessed="1619622480307"/>
        <File
            FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-test\cache\7.1.0000.0115\bof\banhap_qa1\0900000a804910bb.jar" ObjectLastAccessed="1619623446329"/>
        <File
            FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-test\cache\7.1.0000.0115\bof\banhap_qa1\0900000a80700508.jar" ObjectLastAccessed="1619622480534"/>
        <File
            FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-test\cache\7.1.0000.0115\bof\banhap_qa1\0900000a80700512.jar" ObjectLastAccessed="1619623446329"/>
        <File
            FilePath="C:\Users\AP068\git\documentum\dudctmrest\resources-test\cache\7.1.0000.0115\bof\banhap_qa1\0900000a81296802.jar" ObjectLastAccessed="1619623446322"/>
    </FilesInventory>
</CacheContent>


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources-test\DctmRestApp.yml
-----------------------------------------------------
---
configEnvironment: TEST
extraClasspath: [ "resources-test" ]
#messageInputs: [  "definput"]
messageInputs: [  "definput",  "asyncinput", "asyncreply" ]
  
definput:
  implementation: bnhp.dctmrest.msginput.HttpInput
  port: 9033
  host: 0.0.0.0
  ssl: false
  ksPath: resources-test/server.keystore.jks
  ksPass: secret
  ksCertPass: secret
  tsPath: resources-test/server.truststore.jks
  tsPass: secret
  dumpRequests: true

asyncreply:
  implementation: bnhp.dctmrest.msginput.AsyncInput
  threads: 1
  task:
    implementation: bnhp.dctmrest.msginput.AsyncReplyTask
    replySenders: [ nop, file, wso2 ]
    nop:
      implementation: bnhp.dctmrest.reply.NOPReplySender
    file:
      implementation: bnhp.dctmrest.reply.FileReplySender
      regex: "^file:///.*$"
    wso2:
      implementation: bnhp.dctmrest.reply.HttpReplySender
      regex: "^https://twsogw(vip|01|02).restest.bank:8243/.*$"
      authenticators: [ oauth2 ]
      oauth2:
        implementation: bnhp.dctmrest.reply.Oauth2Auth
        content: "grant_type=client_credentials"
        authURL: "https://twsogwvip.restest.bank:8243/token"
    

  
asyncinput:
  implementation: bnhp.dctmrest.msginput.AsyncInput
  threads: 1
  task:
    implementation: bnhp.dctmrest.msginput.AsyncWorkerTask
    


handlerFactory: 
  cancelObjectById: bnhp.dctmrest.handlers.CancelObjectById
  createDocumentById: bnhp.dctmrest.handlers.CreateDocumentById
  putDocumentById: bnhp.dctmrest.handlers.PutDocumentById
  retrieveObjectById: bnhp.dctmrest.handlers.RetrieveDocumentById
  appRequest: bnhp.dctmrest.handlers.AppRequest
  search: bnhp.dctmrest.handlers.Search
  getAsyncRequestStatus: bnhp.dctmrest.handlers.GetAsyncRequestStatus
  whoami: bnhp.dctmrest.handlers.Whoami


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources-test\DctmRestSecrets.yml
-----------------------------------------------------
---
asyncreply:
  task:
    wso2:
      oauth2:
        consumerKey: "w7YnXxK00gHHxVELouIrBjefDHca"
        consumerSecret: "hxwuDv1zFE9py4NDXPyhjIbKUJMa"
    




file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources-test\DctmRestSecretsDecrypted.yml
-----------------------------------------------------
---
asyncreply:
  task:
    wso2:
      oauth2:
        consumerKey: "w7YnXxK00gHHxVELouIrBjefDHca"
        consumerSecret: "hxwuDv1zFE9py4NDXPyhjIbKUJMa"
        content: "grant_type=client_credentials"
        authURL: "https://twsogwvip.restest.bank:8243/token"        




file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources-test\dfc.properties
-----------------------------------------------------
dfc.registry.mode=file

dfc.data.dir=C:/Users/AP068/git/documentum/dudctmrest/resources-test
#dfc.data.dir=/usr/SDC/duecmrest/documentum
#/usr/SDC/duecmrest/documentum

dfc.globalregistry.password=AAAAEKw7B0IXFxhPNzIXJmMIFytVkvJ5WznHy/qSbKs76Xbf
#dfc.globalregistry.repository=banhap_dev1
dfc.globalregistry.username=dm_bof_registry

#dfc.globalregistry.password=GrRNPhLJrkoTDAZE0RGJow\=\=
dfc.globalregistry.repository=banhap_qa1
#dfc.globalregistry.username=dm_bof_registry


dfc.name=dfcTest
dfc.privilege.enable=true
#dfc.security.keystore.file=C:/Documentum/config/dfc.keystore
dfc.tokenstorage.dir=C:\Users\AP068\git\documentum\dudctmrest\documentum/apptoken

#dfc.verify_registration=true


# dev 7.1
#dfc.docbroker.host[0]=tdcmcs01-7.restest.bank
#dfc.docbroker.port[0]=1489

dfc.docbroker.host[0]=sdcmcs01.restest.bank
dfc.docbroker.port[0]=1489
#dfc.session.max_count = 20

#dfc.search.max_results=500
#dfc.search.max_results_per_source=500
#dfc.session.max_collection_count = 200
#dfc.session.max_count = 200
#dfc.session.pool.enable = false
#dfc.compatibility.truncate_long_values=false
#dfc.exception.include_id=false
#dfc.exception.include_decoration=false

#dfc.resources.diagnostics.enabled = false
#dfc.search.docbase.broker_count=400

dfc.name=st_sdcmdfs01-7-duecmrest


dfc.tracing.enable = false


# Determines the trace file creation policy for tracing. By default, all tracing
# information is logged to a single file. Using this property, tracing can be
# configured so it creates a separate log file for each user, or for each thread
# valid values: standard,thread,user
#
dfc.tracing.file_creation_mode = standard


# Sets a specific file path to use for tracing output. Normally DFC
# automatically generates a trace file path based on the other settings
# (directory, prefix, mode, time, etc). When this preference has a non-null
# value then it is used as the explicit trace file path.
#
dfc.tracing.file_override =


# Specifies the prefix string to place in from of trace file names when in
# standard filecreation mode. In standard file creation mode, the tracing
# infrastructure names log files <file_prefix>.<timestamp>.log.
#
#dfc.tracing.file_prefix =


# When this property is set to true, each entry in the trace log will record the
# current RPC count for that connection. The RPC count is ascertainable only
# after a method is called on an object which has an associated session. Hence,
# many entries in the trace log will have the value N/A for the RPC count.
#
dfc.tracing.include_rpc_count = false


# Controls whether RPC information is included in the trace.
#
dfc.tracing.include_rpcs = false


# Controls whether session ID information is included in the trace. By default,
# all entries in the trace log will record the associated user (if that
# information is available from the call context). When this property is set to
# true, the external session ID (e.g.: s1, s2) and the identity hash code of the
# associated session manager is printed along with the user.
#
dfc.tracing.include_session_id = true


# For each additional logging category defined in dfc.tracing.log.category this
# specifies thelog4j additivity setting. Normally you do not need to set this
# preference. The default is normally the correct setting.
# prototype value: false
#
dfc.tracing.log.additivity = false


# Defines additional logging categories to be included in the trace output.
# default values: com,documentum,fc,client,impl,session,com,documentum,fc,client,impl,connection
#
dfc.tracing.log.category = {"com.documentum"}

#dfc.tracing.file_override = /tmp/dfctrace

#
dfc.tracing.log.level =TRACE  


# The number of backups that DFC will keep. Whenever the trace file rolls over,
# DFC will backup the old one. The oldest backup files get deleted first when
# the configured number of backups has been exceeded.
#
dfc.tracing.max_backup_index = 1


# Specifies the maximum size that the trace file can reach before it rolls over.
#
dfc.tracing.max_file_size = 100MB




file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources-test\dfc_extended.properties
-----------------------------------------------------
dfc.name=SDCMDFS01-7_duecmrest


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources-test\dfc_main.properties
-----------------------------------------------------
dfc.docbroker.host[0]=172.22.70.28
dfc.docbroker.port[0]=1489
dfc.globalregistry.repository=banhap_qa1
dfc.globalregistry.username=dm_bof_registry
dfc.globalregistry.password=AAAAEKw7B0IXFxhPNzIXJmMIFytVkvJ5WznHy/qSbKs76Xbf
dfc.search.max_results=500
dfc.search.max_results_per_source=500
dfc.session.max_collection_count = 200
dfc.session.max_count = 450
dfc.session.pool.enable = true
dfc.compatibility.truncate_long_values=false
dfc.exception.include_id=false
dfc.exception.include_decoration=false

dfc.resources.diagnostics.enabled = false
dfc.search.docbase.broker_count=400
dfc.tracing.enable = false
dfc.tracing.include_rpcs = true
dfc.tracing.include_session_id = true
dfc.tracing.print_exception_stack = true 
dfc.logging.verbose = true
dfc.tracing.max_stack_depth = 4
dfc.tracing.mode=standard
dfc.tracing.log.level = DEBUG
dfc.tracing.config_type=dfc
dfc.tracing.max_file_size = 50MB
dfc.tracing.max_backup_index = 10
dfc.tracing.dir=/usr/SDC/duecmrest/trace/dfstrace.txt
dfc.tracing.file_prefix=MyTrace01


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources-test\documentum.ini
-----------------------------------------------------
[documentum]
[documentum\Common]
[documentum\Common\ApplicationSupportDocuments]
[documentum\Common\HouseKeeping]
LastHouseKeeping=04282021
[documentum\Common\ViewFiles]


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources-test\EnvProperty.properties
-----------------------------------------------------
are_props_reloadable=true
props_time_to_live=300000

#MF tables
kesher_type = DPT.DPT2042
makat_type = DPT.DPT2040
tchum_type = DPT.DPT2044
tat_type = DPT.DPT2043
matbea_type = DPT.DPT0484
central_code_table_doc_type=bnhp_central_code_table
# empty temporary entry until we have the table
kupot_gemel_type =
# dm_dbo.DPT200TMP
kupot_gemel_field_code=num
kupot_gemel_field_descr=descr

dfs_logger_id=BnhpDFSServices
wrapper_logger_id=BnhpDFSWrapper
err_logger_id=BnhpDFSWrapperErr
business_logger_id=BnhpDFSBusiness
operator_logger_id=BnhpDFSOperator

user_name = dctm
user_pass=AAAAEJ2LNqcENRu4gLR6oKHYaHNrHTH8QddDFVsUiwXaN6Ns
#user_pass = AAAAEBh9aM0sx68SPNqjKSonXbqwGViZhQAtYDYEn1Vq+4NN

perform_audit=false

default_docbase=banhap_qa1
#default_docbase=banhap_qa1
docbase_override=true

# detailed faults
force_detailed_fault@pensiontst=true

# override entity for tofes peula, set (account or customer or pension)
fixed_entity_for_project[1]=7
fixed_entity_for_project[2]=7
fixed_entity_for_project[42]=7
fixed_entity_for_project[44]=7

# switch warn/failure on several validity checks
#fail_on_codes_error=true
#fail_on_currency_error=true
#fail_on_dpt_error=true

velocity_properties_file=/bnhp_velocity.properties
velocity_template_name_regexp=^[a-zA-Z0-9_-]+$
velocity_template_prefix=/templates/
velocity_template_suffix=.txt


#magic field values, which are used in search services
category_scan_status=104
category_sign_status=106

default_max_results_search_by_document_group_id_prop@PRDKM1=100
default_max_results_search_by_document_group_id_prop@tofespeulausrtst=50

# retrieve settings
retrieve_links_acs=false

retrieve_links_acs_unduplicate_retries=2
retrieve_links_acs_append_request_id=true


# acs links enabled for user httpfaxuser 
# acs links enabled for user httptfspeula
retrieve_links_acs@httpfaxuser=true
retrieve_links_acs@httptfspeula=true

retrieve_links_acs_threshold@httpfaxuser=540
retrieve_links_acs_threshold@httptfspeula=540

retrieve_links_acs_uri_regexp@httpfaxuser=^http:.*$
retrieve_links_acs_uri_regexp@httptfspeula=^https:.*$

retrieve_links_acs_inband_fallback@httpfaxuser=false
retrieve_links_acs_inband_fallback@httptfspeula=true

# retrieve settings
retrieve_links_acs=false


# acs links enabled for user httpfaxuser
# acs links enabled for user httptfspeula
retrieve_links_acs@httpfaxuser=true
retrieve_links_acs@httpsfaxuser=true
retrieve_links_acs@httptfspeula=true
retrieve_links_acs@uploadfaxuser=true
retrieve_links_acs@DWHTEMP=true
retrieve_links_acs@tstikulim=true
retrieve_links_acs@PRDKM1=true
retrieve_links_acs@tofespeulausrtst=true
retrieve_links_acs@tstvc01=false
retrieve_links_acs@safereadtest=false
retrieve_links_acs@TSTDUDIALOG02=false


retrieve_links_acs_threshold@httpfaxuser=540
retrieve_links_acs_threshold@httpsfaxuser=540
retrieve_links_acs_threshold@httptfspeula=540
retrieve_links_acs_threshold@uploadfaxuser=0
retrieve_links_acs_threshold@DWHTEMP=0
retrieve_links_acs_threshold@tstikulim=0
retrieve_links_acs_threshold@PRDKM1=0
retrieve_links_acs_threshold@tofespeulausrtst=0
retrieve_links_acs_threshold@tstvc01=0
retrieve_links_acs_threshold@safereadtest=0
retrieve_links_acs_threshold@TSTDUDIALOG02=0

retrieve_links_acs_uri_regexp@httpfaxuser=^http:.*$
retrieve_links_acs_uri_regexp@httptfspeula=^https:.*$
retrieve_links_acs_uri_regexp@httpsfaxuser=^https:.*$
retrieve_links_acs_uri_regexp@uploadfaxuser=^http:.*$
retrieve_links_acs_uri_regexp@DWHTEMP=^http:.*$
retrieve_links_acs_uri_regexp@tstikulim=^http:.*$
retrieve_links_acs_uri_regexp@PRDKM1=^http:.*$
retrieve_links_acs_uri_regexp@tofespeulausrtst=^http:.*$
retrieve_links_acs_uri_regexp@prdvc01=^http:.*$
retrieve_links_acs_uri_regexp@tstvc01=^http:.*$
retrieve_links_acs_uri_regexp@safereadtest=^http:.*$
retrieve_links_acs_uri_regexp@TSTDUDIALOG02=^http:.*$


retrieve_links_acs_inband_fallback@httpfaxuser=false
retrieve_links_acs_inband_fallback@httpsfaxuser=false
retrieve_links_acs_inband_fallback@httptfspeula=true
retrieve_links_acs_inband_fallback@uploadfaxuser=false
retrieve_links_acs_inband_fallback@DWHTEMP=false
retrieve_links_acs_inband_fallback@tstikulim=false
retrieve_links_acs_inband_fallback@PRDKM1=false
retrieve_links_acs_inband_fallback@tofespeulausrtst=false
retrieve_links_acs_inband_fallback@prdvc01=true
retrieve_links_acs_inband_fallback@tstvc01=true
retrieve_links_acs_inband_fallback@safereadtest=false
retrieve_links_acs_inband_fallback@TSTDUDIALOG02=false

#retrieve_cyberark@=true
retrieve_cyberark_allowed@prdvc01=true
retrieve_cyberark_allowed@tstvc01=true
retrieve_cyberark_allowed@safereadtest=true
retrieve_cyberark_allowed=false

retrieve_cyberark_config=DOCUMNETO_T
retrieve_cyberark_concurrency_limit=3

compat_string@tofespeulausrtst=forceBusinessProcessId
compat_string@prdvc01=forceBusinessProcessId
compat_string@tstvc01=forceBusinessProcessId

# cyberarc configurations
cyberark[DOCUMNETO_T].substitutions=^	https://ttoapp02.restest.bank/SFE/WebServices/API.svc/
# ms
cyberark[DOCUMNETO_T].saf_timeout=7000

# file based upload

#local_file_upload_base_dir=/DocumentumAsync/Async_Service_QA/
#server_file_upload_base_dir=/DocumentumAsync/Async_Service_QA/

local_file_upload_base_dir=/24400_2/
server_file_upload_base_dir=/24400_2/


allowed_upload_url_regexp=^file:///[\/A-Za-z0-9_\.-]+$

file_upload_enabled = true
server_file_upload_enabled=true


# update versions
allow_update_log_deleted_docs@PRDDUDIALOG02=true
allow_update_log_deleted_docs@TSTDUDIALOG02=true
allow_update_log_deleted_docs@tofespeulausrtst=true


# Renditions
generate_renditions_sync=true

# content updates w/o versions
same_version_content_updates_no_metadata=false
same_version_content_updates_no_metadata@tofespeulausrtst=true
same_version_content_updates_allowed_time_sec=86400
make_auto_event_on_same_version_content_updates=true
dup_suppression_grace_period_sec  = 300


# validations against permissions table
permtab_validation_required=false
permtab_validate_document_form_id=true
permtab_validate_user=false
permtab_validate_data_folder=false

# application id
app_instance_id=1

expected_err_regex=.*(Permission denied|Input/output error).*

# warmup config
perform_warmup=true
perform_jms_warmup=false
warmup_types=bnhp_customer_doc,bnhp_doc_event,bnhp_doc_xml_form,bnhp_doc_folder,bnhp_tfs_peula_doc,bnhp_yoman_eruim_table,bnhp_yoman_sugim,bnhp_central_code_table,bnhp_categoriot_table
warmup_jms_factory=jms/WebServicesReplyQCF
warmup_jms_queue=jms/WsEcmQueueJms
warmup_jms_target=DocumentumServicesJmsWrapper
# next macro will convert (or already has converted) hostname to Application number
warmup_jms_idval=app_instance_id=1

# DFC instance registration (part of warmup currently)
instance_registration_action=PERFORM
instance_registration_required_roles=dm_superusers_dynamic

# format guess/normalization
format_normalization_enabled=true
format_guess_enabled=true
retrieve_format_normalization_enabled=true
format_ext_cache_query=SELECT f.name AS name, lower(f.dos_extension) AS dos_extension, f.i_vstamp as i_vstamp FROM dm_dbo.BNHP_FORMATS_V f WHERE dos_extension<>' ' ORDER BY weight
format_mimetype_cache_query=SELECT f.name AS name, lower(f.mime_type) AS mime_type, f.i_vstamp as i_vstamp FROM dm_dbo.BNHP_FORMATS_V f WHERE mime_type<>' ' ORDER BY weight


# caches
cache_min_update_delay=600000
dpt_cache_version_id_query=select MAX(update_datetime) FROM DPT.DPT_BAKARA WHERE table_number in (2042,2040,2044,2043,484)

# LT SERVICE
lt_saf_version_spec=5.0



# not actual for REST
# # SMART ADVICE
# retrieve_validation_hook@TSTDU19=(IF (docDataCheck-has-customers?) "OK: docDataCheck has customer data" (throw-validation-error "docDataCheck validation is required"))
# retrieve_prereturn_hook@TSTDU19=(IF  (customers-check?) "OK: docDataCheck on customers" (THROW "DocDataCheck validation has FAILED"))

# # ashrai hogen
# retrieve_validation_hook@tstashraihogen=(IF (OR (docDataCheck-has-customers?) (docDataCheck-has-accounts?))  "OK: docDataCheck has customer data" (throw-validation-error "docDataCheck validation is required"))
# # project 26 excluded for ashrai hogen!
# retrieve_prereturn_hook@tstashraihogen=(IF  (OR (customers-check?) (accounts-check?)  (project-eq? 26)) "OK: docDataCheck validation passed" (THROW "DocDataCheck validation has FAILED"))

# # shuk hon
# retrieve_validation_hook@TSTDU21=(IF (docDataCheck-has-customers?) "OK: docDataCheck has customer data" (throw-validation-error "docDataCheck validation is required"))
# retrieve_prereturn_hook@TSTDU21=(IF  (customers-check?) "OK: docDataCheck on customers" (THROW "DocDataCheck validation has FAILED"))

update_pre_update_hook@TSTBO14=(faxes-update-pre-update-hook)
appreq_pre_xact_hook@${ENV}DU15=(minhali-appreq-pre-xact-hook)

# Default 'retrieve_prereturn_hook' hook - throw exception when validate fail:
#retrieve_prereturn_hook=(IF (PROGN (VALIDATE "file_md" docDataCheck ddfr)) "validate success" (THROW "DocDataCheck validation has FAILED for user"))
retrieve_prereturn_hook=(IF docDataCheck (IF (VALIDATE "file_md" docDataCheck ddfr) "Validate:OK" (THROW "Validate:FAILED")) "Validate:SKIPPED")
#retrieve_prereturn_hook@sdtalyon=(IF docDataCheck (IF (VALIDATE "file_md" docDataCheck ddfr) "Validate:OK" "Validate:FAILED") "Validate:SKIPPED")

# List of specific users that we want ignore the validate hook result and always receive the document:
#retrieve_prereturn_hook@TSTPUB=(PROGN (VALIDATE "file_md" docDataCheck ddfr))
#retrieve_prereturn_hook@httptfspeula=(PROGN (VALIDATE "file_md" docDataCheck ddfr))
#retrieve_prereturn_hook@tstashraihogen=(PROGN (VALIDATE "file_md" docDataCheck ddfr))
#retrieve_prereturn_hook@sdtalyon=(PROGN (VALIDATE "file_md" docDataCheck ddfr))
#retrieve_prereturn_hook@sdtalyon@PRDZZAP2@carbon.super#Talyon=(PROGN (VALIDATE "file_md" docDataCheck ddfr))

# List of customer\s and account\s properties names on pdf custom properties - use on Pdf-custom-props validate:
pdf_customer_id_custom_props=Validate_ID_1,Validate_ID_2,Validate_ID_3
pdf_account_id_custom_props=Validate_AccountNumber_1,Validate_AccountNumber_2,Validate_AccountNumber_3

#appreq_pre_xact_hook@${ENV}DU15=(minhali-appreq-pre-xact-hook)

#ExcutorDetailsProperties:
# Cases: PROVIDE, JWT, AUTO
#      PROVIDE - require as parameter inside the request.
#      JWT - build executorDetails basis of the jwt
#      AUTO - fill ED from properties bellow
executor_details@user=AUTO

# Settings for JWT option - Map from JWT properties to executor details props
executor_details@Jwt@executingEmpIdCode=http://wso2.org/claims/givenname,http://wso2.org/claims/lastname
executor_details@Jwt@fullName=http://wso2.org/claims/enduser

#Settings for AUTO options - fill ED props from bellow:
executor_details@Auto@executingEmpIdCode=1234567890
executor_details@Auto@fullName=someFullName
executor_details@Auto@ipAddress=1.2.3.4




file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources-test\env_vars.yaml
-----------------------------------------------------
---
orapass: de34rfvc
orainstance: docdbs
orauser: dctm
docbase: banhap_qa1


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\resources-test\ErrorInfo.properties
-----------------------------------------------------
# Creation error codes
legacy_id_not_unique = GENERAL_ERROR:600:business constraint violated. Non-unique value %1s in field legacyId of object %2s. The existing id is - %3s
mixed_creation_request = GENERAL_ERROR:601:saving existing and non existing documents in the same transaction is not supported. One of the existing legacyIds is - %1s
legacy_id_not_unique_different_customer_data = GENERAL_ERROR:602:non-unique value %1s in field legacyId but different customer data. The existing id is - %2s
legacy_id_not_unique_different_event_data = GENERAL_ERROR:603:non-unique value %1s in field legacyId but different event data. The existing id is - %2s
legacy_id_not_unique_different_extensions_data = GENERAL_ERROR:604:non-unique value %1s in field legacyId but different extensions data. The existing id is - %2s
legacy_id_not_unique_different_file_size = GENERAL_ERROR:605:non-unique value %1s in field legacyId but different file size. The existing id is - %2s
document_is_deleted = GENERAL_ERROR:606:Unexpectedly failed to retrieve existing document, probably it is logically deleted, legacy id is - %1s

# Query error codes
# FIXME: need to check if in all cases this one indicates validation error
not_single_query_result = VALIDATION_ERROR:700:single query result expected, but query %1s has returned %2s results
unexpected_type_returned = GENERAL_ERROR:701:returned document of unexpected type %1s

# System exception from underlying layers
generic_dfs_service_exception = AUTOTYPE_ERROR:750:DFS Service Exception: %1s 
generic_dfc_exception = AUTOTYPE_ERROR:751:Generic DFC Exception: %1s
generic_exception = AUTOTYPE_ERROR:752:Generic Exception: %1s

# Retrieve error codes
non_existing_object_to_retrieve = GENERAL_ERROR:800:the requested document with %1s=%2s does not exist or you do not have rights to retrieve it

# Validation technical error codes
security_context_not_complete = VALIDATION_ERROR:1100:securityContext is not complete
fetch_type_set_not_set = VALIDATION_ERROR:1101:fetchTypeSet must exist
max_docs_to_process_reached = VALIDATION_ERROR:1102:processing more than 10 documents is not supported
invalid_value_for_field = VALIDATION_ERROR:1105:invalid value %1s for field %2s - %3s
cannot_parse_value = VALIDATION_ERROR:1106:cannot parse value %1s as %2s - %3s
security_context_not_set = VALIDATION_ERROR:1107:securityContext must exist
property_name_invalid = VALIDATION_ERROR:1108:property name %1s is not valid
file_update_same_version_unsupported = VALIDATION_ERROR:1109:no file update with metadata is allowed without creating new version
update_new_version_no_file_unsupported = VALIDATION_ERROR:1110:update a version without a file is not allowed
version_label_not_set = VALIDATION_ERROR:1111:versionLabel must exist
prepared_query_not_set = VALIDATION_ERROR:1112:preparedQuery must exist
wrong_date_format = VALIDATION_ERROR:1113:the date is not in the format of XMLGregorianCalendar
between_null_dates = VALIDATION_ERROR:1114:the dates are null in BETWEEN DATES clause
only_one_of_legacy_and_dctm_id_must_be_provided = VALIDATION_ERROR:1115:only one of legacyDocumentId and dctmDocumentId must be provided, but got both
same_version_update_of_existing_file_is_not_supported =VALIDATION_ERROR:1116:update of existing main content is not allowed without creating new document version
same_version_update_not_allowed=VALIDATION_ERROR:1117:main content update without metadata is not allowed by server configuration
same_version_update_timeout=VALIDATION_ERROR:1118:main content update without metadata is not allowed: too late, maximum time of %s seconds is passed
extension_date_format_invalid==VALIDATION_ERROR:1119:date format in extension is invalid: %1s

# Validation business error codes
doc_data_not_set = VALIDATION_ERROR:1200:docData must exist
doc_customer_data_not_set = VALIDATION_ERROR:1201:docCustomerData must exist
doc_file_not_complete = VALIDATION_ERROR:1202:docFile is not complete
secondary_doc_file_not_complete = VALIDATION_ERROR:1206:secondaryDocFile is not complete
template_source_code_not_set = VALIDATION_ERROR:1207:templateSourceCode in secondaryDocFile must exist
auto_event_ind_not_set = VALIDATION_ERROR:1208:autoEventInd in docEventData must exist
event_category_code_not_set = VALIDATION_ERROR:1209:eventCategoryCode in docEventData must exist
event_category_type_code_not_set = VALIDATION_ERROR:1210:eventCategoryTypeCode in docEventData must exist
legacy_event_entry_dttm_not_set = VALIDATION_ERROR:1211:legacyEventEntryDttm in docEventData must exist
extension_name_invalid = VALIDATION_ERROR:1212:extensionName '%1s' in docPropertyExtensions is invalid
property_key_values_not_complete = VALIDATION_ERROR:1213:propertyKeyValues are not complete
doc_details_not_set = VALIDATION_ERROR:1214:docDetails must exist
business_process_id_not_set = VALIDATION_ERROR:1215:businessProcessId in docDetails must exist
document_form_id_not_set = VALIDATION_ERROR:1216:documentFormId in docDetails must exist
ongoing_or_history_code_not_set = VALIDATION_ERROR:1217:ongoingOrHistoryCode in docDetails must exist
legacy_document_entry_dttm_doc_details_not_set  = VALIDATION_ERROR:1218:legacyDocumentEntryDttm in docDetails must exist
project_id_not_set  = VALIDATION_ERROR:1219:projectId in docDetails must exist
business_sub_area_code_not_set  = VALIDATION_ERROR:1220:businessSubAreaCode in docDetails must exist
executor_details_not_set  = VALIDATION_ERROR:1221:executorDetails must exist
executing_emp_id_code_not_set  = VALIDATION_ERROR:1222:executingEmpIdCode in executorDetails must exist
ip_address_not_set  = VALIDATION_ERROR:1223:ipAddress in executorDetails must exist
pension_fund_not_set  = VALIDATION_ERROR:1224:pensionFund must exist
pension_fund_nbr_not_set  = VALIDATION_ERROR:1225:pensionFundNbr in pensionFund must exist
planholder_number_not_set  = VALIDATION_ERROR:1226:planholderNumber in pensionFund must exist
complete_customer_id_code_not_set  = VALIDATION_ERROR:1227:completeCustomerIdCode in customerKeys must exist
occasional_customer_ind_not_set  = VALIDATION_ERROR:1228:occasionalCustomerInd in customerKeys must exist
customer_id_doc_type_code_not_set  = VALIDATION_ERROR:1229:customerIdDocTypeCode in customerKeys must exist
customer_id_not_set  = VALIDATION_ERROR:1230:customerId in customerKeys must exist
bank_accounts_not_set  = VALIDATION_ERROR:1231:bankAccounts must exist
account_nbr_not_set  = VALIDATION_ERROR:1232:accountNbr in bankAccounts must exist
customer_keys_not_set  = VALIDATION_ERROR:1233:customerKeys must exist
branch_id_not_set  = VALIDATION_ERROR:1234:branchId in bankAccounts must exist
dctm_document_id_not_set  = VALIDATION_ERROR:1235:dctmDocumentId must exist
legacy_document_id_not_set= VALIDATION_ERROR:1236:legacyDocumentId must exist
query_name_not_set= VALIDATION_ERROR:1237:queryName must exist
document_group_id_not_set= VALIDATION_ERROR:1238:documentGroupId must exist
document_id_not_set= VALIDATION_ERROR:1239:documentId must exist
legacy_document_entry_dttm_event_not_set = VALIDATION_ERROR:1240:legacyDocumentEntryDttm in docEventData must exist
entity_validation_error = VALIDATION_ERROR:1241:entity validation error: %1s
doc_data_for_create_not_set = VALIDATION_ERROR:1242:docDataForCreate must nut be null
general_validation_error = VALIDATION_ERROR:1243:General validation error: %1s
validation_hook_retrieve_customer_document_compare_customer_and_account=VALIDATION_ERROR:1244:mismatch validation between given customer and account and archived customer and account
validation_hook_retrieve_customer_document_compare_cust=VALIDATION_ERROR:1245:mismatch validation between given customer and archived customer
validation_hook_retrieve_customer_document_compare_account=VALIDATION_ERROR:1246:mismatch validation between given account and archived account
need_one_of_gemel_customer_account = VALIDATION_ERROR:1247:Need at least one of three to be non-empty: PensionFund, CustomerKeys, BankAccounts 
#validation_hook_retrieve_customer_document=VALIDATION_ERROR:1244:mismatch validation between doc customer Id(or account details):%1s and input customer (or account details):%2s


# Format validation and guessing
invalid_document_format_provided=VALIDATION_ERROR:1250:Document Format that was provided '%1s' is invalid 
format_not_provided_and_failed_to_guess=VALIDATION_ERROR:1251:Document Format was not provided and failed to guess using DOS extension or content

# Validation against permission table
permtabentry_not_exists=VALIDATION_ERROR:1280:Permission table entry not exists for given project id
permtabentry_wrong_document_form_id=VALIDATION_ERROR:1281:Wrong document form id %1s for project id %2s
permtabentry_wrong_content_upload_path=VALIDATION_ERROR:1282:Wrong content upload path '%1s' for project id %2s
permtabentry_wrong_username=VALIDATION_ERROR:1283:Wrong application user name '%1s' for project id %2s


# applicative request error codes
appx_required_parameter_missing = GENERAL_ERROR:1501:missing value for parameter %1s for stage %2s 
appx_api_call_required_parameter_missing = GENERAL_ERROR:1502:missing value for parameter %1s for api call %2s, stage %3s
appx_unsupported_value_for_parameter = GENERAL_ERROR:1503:invalid value '%1s' for parameter %2s, stage %3s
appx_api_call_failed = GENERAL_ERROR:1504:api call %1s method %2s failed, stage %3s: %4s
failed_to_parse_merged_query = GENERAL_ERROR:1505:failed to parse merged query

# content retrieve errors
# this one should not happen, if it happens we do not know if it temporary
uriprovider_failure=GENERAL_ERROR:1601:Error getting content URL: %1s
# this usually means that ACS is down, unavailable or not properly configured 
acs_uriprovider_failure=TEMPORARY_ERROR:1610:Error getting ACS Server content URL : %1s
# this usually means temporarry error while calling CyberArk
cyberark_uriprovider_failure=TEMPORARY_ERROR:1620:Error returning content via CyberArk service: %1s




file Read:C:\Users\AP068\git\documentum\rest-cd-prod\runapp.sh
-----------------------------------------------------
#!/bin/sh
java -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=7777 -cp "/home/FW0/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.8.11.2/jackson-databind-2.8.11.2.jar:/home/FW0/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.8.11/jackson-core-2.8.11.jar:/home/FW0/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.8.10/jackson-datatype-jsr310-2.8.10.jar:/home/FW0/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.8.11/jackson-annotations-2.8.11.jar:/home/FW0/.m2/repository/io/undertow/undertow-core/1.4.25.Final/undertow-core-1.4.25.Final.jar:/home/FW0/.m2/repository/org/jboss/logging/jboss-logging/3.2.1.Final/jboss-logging-3.2.1.Final.jar:/home/FW0/.m2/repository/org/jboss/xnio/xnio-api/3.3.8.Final/xnio-api-3.3.8.Final.jar:/home/FW0/.m2/repository/org/jboss/xnio/xnio-nio/3.3.8.Final/xnio-nio-3.3.8.Final.jar:/home/FW0/.m2/repository/io/swagger/swagger-annotations/1.5.10/swagger-annotations-1.5.10.jar:/home/FW0/.m2/repository/org/cfg4j/cfg4j-core/4.4.0/cfg4j-core-4.4.0.jar:/home/FW0/.m2/repository/org/json/json/20160212/json-20160212.jar:/home/FW0/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.2/metrics-core-3.1.2.jar:/home/FW0/.m2/repository/com/github/drapostolos/type-parser/0.5.0/type-parser-0.5.0.jar:/home/FW0/.m2/repository/org/slf4j/slf4j-api/1.7.21/slf4j-api-1.7.21.jar:/home/FW0/.m2/repository/org/yaml/snakeyaml/1.17/snakeyaml-1.17.jar:/home/FW0/.m2/repository/junit/junit/4.12/junit-4.12.jar:/home/FW0/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/FW0/.m2/repository/org/python/jython-standalone/2.7.1/jython-standalone-2.7.1.jar:/home/FW0/.m2/repository/com/poalim/documentum/jwtutil/0.0.1/jwtutil-0.0.1-uber.jar:/home/FW0/.m2/repository/com/auth0/java-jwt/3.4.0/java-jwt-3.4.0.jar:/home/FW0/.m2/repository/com/poalim/documentum/BnhpInfraDFServices/1.0-SNAPSHOT/BnhpInfraDFServices-1.0-SNAPSHOT-basic.jar:/home/FW0/.m2/repository/com/ibm/org.apache.axis2/7.0.0/org.apache.axis2-7.0.0.jar:/home/FW0/.m2/repository/org/apache/velocity/velocity/1.7/velocity-1.7.jar:/home/FW0/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/home/FW0/.m2/repository/commons-lang/commons-lang/2.4/commons-lang-2.4.jar:/home/FW0/.m2/repository/emc/dfs/sdk/ucf/client/ucf-installer-config/7.1/ucf-installer-config-7.1.xml:/home/FW0/.m2/repository/org/dudinea/explang/explang/0.1-SNAPSHOT/explang-0.1-SNAPSHOT.jar:/home/FW0/.m2/repository/com/poalim/documentum/BnhpInfraDFServices/1.0-SNAPSHOT/BnhpInfraDFServices-1.0-SNAPSHOT-tests.jar:/home/FW0/.m2/repository/org/apache/logging/log4j/log4j-core/2.3/log4j-core-2.3.jar:/home/FW0/.m2/repository/org/apache/logging/log4j/log4j-api/2.3/log4j-api-2.3.jar:/home/FW0/.m2/repository/com/poalim/dependencies/documentum-71-deps/1.0-SNAPSHOT/documentum-71-deps-1.0-SNAPSHOT.pom:/home/FW0/.m2/repository/emc/dfs/sdk/activation/7.1/activation-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/aspectjrt/7.1/aspectjrt-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/bpmutil/7.1/bpmutil-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/bpm_infra/7.1/bpm_infra-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/castor-1.1-xml/7.1/castor-1.1-xml-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/certj/7.1/certj-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/ci/7.1/ci-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/ci_FOR_TEST/7.1/ci_FOR_TEST-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/collaboration/7.1/collaboration-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/commons-cli-1.0/7.1/commons-cli-1.0-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/commons-io-1.2/7.1/commons-io-1.2-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/commons-jxpath-1.2/7.1/commons-jxpath-1.2-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/commons-lang-2.4/7.1/commons-lang-2.4-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/configservice-api/7.1/configservice-api-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/configservice-impl/7.1/configservice-impl-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/cryptojce/7.1/cryptojce-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/cryptojcommon/7.1/cryptojcommon-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/dfc/7.1/dfc-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/dms-client-api/7.1/dms-client-api-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/EccpressoAll/7.1/EccpressoAll-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/elmjava3_1_0-jdk1.5.0_12/7.1/elmjava3_1_0-jdk1.5.0_12-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/emc-admin-services-remote/7.1/emc-admin-services-remote-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/emc-admin-services/7.1/emc-admin-services-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/emc-bpm-services-remote/7.1/emc-bpm-services-remote-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/emc-bpm-services/7.1/emc-bpm-services-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/emc-ci-services-remote/7.1/emc-ci-services-remote-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/emc-ci-services/7.1/emc-ci-services-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/emc-collaboration-services-remote/7.1/emc-collaboration-services-remote-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/emc-collaboration-services/7.1/emc-collaboration-services-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/emc-dfs-rt-remote/7.1/emc-dfs-rt-remote-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/emc-dfs-rt/7.1/emc-dfs-rt-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/emc-dfs-services-remote/7.1/emc-dfs-services-remote-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/emc-dfs-services/7.1/emc-dfs-services-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/emc-dfs-tools/7.1/emc-dfs-tools-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/emc-search-services-remote/7.1/emc-search-services-remote-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/emc-search-services/7.1/emc-search-services-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/extended-search-api/7.1/extended-search-api-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/FastInfoset/7.1/FastInfoset-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/flexlm/7.1/flexlm-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/http/7.1/http-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/javassist/7.1/javassist-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/jaxb-api/7.1/jaxb-api-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/jaxb-impl/7.1/jaxb-impl-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/jaxb-xjc/7.1/jaxb-xjc-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/jaxb1-impl/7.1/jaxb1-impl-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/jaxr-api/7.1/jaxr-api-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/jaxr-impl/7.1/jaxr-impl-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/jaxws-api/7.1/jaxws-api-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/jaxws-rt/7.1/jaxws-rt-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/jaxws-tools/7.1/jaxws-tools-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/jcifs-krb5-1.3.1/7.1/jcifs-krb5-1.3.1-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/jcmFIPS/7.1/jcmFIPS-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/jsr173_api/7.1/jsr173_api-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/jsr181-api/7.1/jsr181-api-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/jsr250-api/7.1/jsr250-api-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/krbutil/7.1/krbutil-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/log4j/7.1/log4j-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/mimepull/7.1/mimepull-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/questFixForJDK7/7.1/questFixForJDK7-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/resolver/7.1/resolver-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/saaj-api/7.1/saaj-api-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/saaj-impl/7.1/saaj-impl-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/servlet/7.1/servlet-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/stax-ex/7.1/stax-ex-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/streambuffer/7.1/streambuffer-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/tools/7.1/tools-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/vsj-license/7.1/vsj-license-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/vsj-standard-3.3/7.1/vsj-standard-3.3-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/woodstox/7.1/woodstox-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/workflow/7.1/workflow-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/xerces-impl/7.1/xerces-impl-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/xmlsec/7.1/xmlsec-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/xtrim-api/7.1/xtrim-api-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/xtrim-server/7.1/xtrim-server-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/xws-security/7.1/xws-security-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/ucf/client/ucf-ca-office-auto/7.1/ucf-ca-office-auto-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/ucf/client/ucf-client-api/7.1/ucf-client-api-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/ucf/client/ucf-client-impl/7.1/ucf-client-impl-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/ucf/client/ucf-connection/7.1/ucf-connection-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/ucf/client/ucf-installer/7.1/ucf-installer-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/ucf/server/ucf-server-api/7.1/ucf-server-api-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/ucf/server/ucf-server-impl/7.1/ucf-server-impl-7.1.jar:/home/FW0/.m2/repository/emc/dfs/sdk/emc-dfs-tasks/7.1/emc-dfs-tasks-7.1.xml:/home/FW0/.m2/repository/bnhp/infra/dfs/services/BHInputObjectContexts/1.0/BHInputObjectContexts-1.0.jar:/home/FW0/.m2/repository/bnhp/infra/dfs/services/BHSearchContexts/1.0/BHSearchContexts-1.0.jar:/home/FW0/.m2/repository/bnhp/infra/dfs/services/BHObjectContexts/1.0/BHObjectContexts-1.0.jar:/home/FW0/.m2/repository/bnhp/infra/dfs/services/BHAuthorization/1.0/BHAuthorization-1.0.jar:/home/FW0/.m2/repository/bnhp/infra/dfs/services/BHGeneralUtil/1.0/BHGeneralUtil-1.0.jar:/home/FW0/.m2/repository/bnhp/infra/dfs/services/BHPeulaException/1.0/BHPeulaException-1.0.jar:/home/FW0/.m2/repository/com/poalim/documentum/BnhpEcmGeneralDocServices/1.0-SNAPSHOT/BnhpEcmGeneralDocServices-1.0-SNAPSHOT.jar:/home/FW0/.m2/repository/com/poalim/documentum/BnhpStoragePolicy/1.0-SNAPSHOT/BnhpStoragePolicy-1.0-SNAPSHOT.jar:/home/FW0/.m2/repository/com/poalim/documentum/build-dar/1.0-SNAPSHOT/build-dar-1.0-SNAPSHOT.xml:/home/FW0/.m2/repository/com/poalim/documentum/BnhpInfraDFServices/1.0-SNAPSHOT/BnhpInfraDFServices-1.0-SNAPSHOT.jar:/home/FW0/.m2/repository/com/ibm/javax.j2ee.jms/7.0.0/javax.j2ee.jms-7.0.0.jar:/home/FW0/.m2/repository/com/ibm/websphere/jython/jython/8.5.5/jython-8.5.5.jar:/home/FW0/.m2/repository/com/ibm/websphere/jython/jython-lib/8.5.5/jython-lib-8.5.5.jar:/home/FW0/.m2/repository/was/jaxws_thinclient/8.0/jaxws_thinclient-8.0.jar:/home/FW0/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/FW0/.m2/repository/nopagingbranch-remote/nopagingbranch-remote/1.0/nopagingbranch-remote-1.0.jar:/home/FW0/.m2/repository/com/poalim/documentum/fundamentalDocsV2/1.0/fundamentalDocsV2-1.0.jar:/home/FW0/.m2/repository/com/poalim/saf/services/to-cyberark-transfer/1.47.0/to-cyberark-transfer-1.47.0.jar:/home/FW0/.m2/repository/com/poalim/saf/services/du-ecm-customer-temp/1.154.0/du-ecm-customer-temp-1.154.0.jar:/home/FW0/.m2/repository/com/poalim/ht/saf-core/1.28.0.5/saf-core-1.28.0.5.jar:/home/FW0/.m2/repository/xerces/xercesImpl/2.8.1/xercesImpl-2.8.1.jar:/home/FW0/.m2/repository/xml-apis/xml-apis/1.3.03/xml-apis-1.3.03.jar:/home/FW0/.m2/repository/com/poalim/saf/services/trst/3.0/trst-3.0.jar:/home/FW0/.m2/repository/com/ibm/com.ibm.mq/7.0.1.6/com.ibm.mq-7.0.1.6.jar:/home/FW0/.m2/repository/com/ibm/com.ibm.mq.commonservices/7.0.1.6/com.ibm.mq.commonservices-7.0.1.6.jar:/home/FW0/.m2/repository/com/ibm/com.ibm.mq.headers/7.0.1.6/com.ibm.mq.headers-7.0.1.6.jar:/home/FW0/.m2/repository/com/ibm/com.ibm.mq.jmqi/7.0.1.6/com.ibm.mq.jmqi-7.0.1.6.jar:/home/FW0/.m2/repository/com/ibm/com.ibm.mq.pcf/7.0.1.6/com.ibm.mq.pcf-7.0.1.6.jar:/home/FW0/.m2/repository/javax/resource/connector/7.0.1.6/connector-7.0.1.6.jar:/home/FW0/.m2/repository/com/ibm/icu/icu4j/51.1/icu4j-51.1.jar:/home/FW0/.m2/repository/joda-time/joda-time/2.1/joda-time-2.1.jar:./resources:./resources-dev:target/classes:../../duecmcustomerdfservices/target/classes/" bnhp.dctmrest.DctmRestApp "$@"



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\scripts\backup_logs.sh
-----------------------------------------------------
#!/bin/bash

set -e
cd $(dirname $0)
export curr_version=$(date +'%d%m%Y')
cp logs/output.log logs/output_${curr_version}.log
cp logs/BnhpDFSServices.log logs/BnhpDFSServices_${curr_version}.log
cp logs/BnhpDFSOperator.log logs/BnhpDFSOperator_${curr_version}.log



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\scripts\curl-dev\curl-search_by_legacyId-imut-not-works.sh
-----------------------------------------------------
#!/bin/bash

 set -e -x
 export host=$(hostname)
 export legacy_id="testWsssaxfgfd"
 export accountBankId="41"
 export accountBranchId="42111"
 export accountNbr="40"
 
 export jwt_id="eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsIng1dCI6ImI2TnozUDJwMHg1QWpfWENsUmhrVDFzNlNIQSJ9.eyJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9hcHBsaWNhdGlvbnRpZXIiOiJVbmxpbWl0ZWQiLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9rZXl0eXBlIjoiUFJPRFVDVElPTiIsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL3ZlcnNpb24iOiIwLjMuNSIsImlzcyI6IndzbzIub3JnXC9wcm9kdWN0c1wvYW0iLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9hcHBsaWNhdGlvbm5hbWUiOiJ3c28yRGV2VHJ5SXQiLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9lbmR1c2VyIjoiSTBHRkBjYXJib24uc3VwZXIiLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9lbmR1c2VyVGVuYW50SWQiOiItMTIzNCIsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL3N1YnNjcmliZXIiOiJJMEdGIiwiaHR0cDpcL1wvd3NvMi5vcmdcL2NsYWltc1wvdGllciI6IkdvbGQiLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9hcHBsaWNhdGlvbmlkIjoiMzA5OCIsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL3VzZXJ0eXBlIjoiQVBQTElDQVRJT04iLCJleHAiOjE2MTA2MzkwNDQsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL2FwaWNvbnRleHQiOiJcL2JuaHAtRG9jdW1lbnRNYW5hZ2VyXC8wLjMuNSJ9.lD3QA4MYpu7apY9kIANe7Z4cdWSU9hdK5NE0UHUL9W59ofXTo5UVds/HBW+yz/sEI1ibK8RjnQelsY+I1daaTAM7DBo+n/g6aB6SAeMWt0JOdboByw3lE+5QfeS1hdY32FsCrcP0lMPGX7wsiOBYpDzyLrSdManYY23ME8/gupCPmQbpEs+hRQZDEIrk05+6Rz878xhUzGZ/32pfUCpir7OJOX6Z2gSG4fpqVpvueA+k85PrYZJEeoy9WZwMrL1YfUIMPgUIJkCekzphQWE5+I8NRtNmXdOX09+gPo6LhfOiJaPjFoieXQxfSNUKk8rUjmT+oIE/isdpORlnRbeqkA=="


 curl -k --request GET "http://${host}:9033/0.3.6/objects/legacyDocumentId/${legacy_id}?BnhpCustomerDoc&retrieveProfile=stream&fetchType=meta&accountBankId=${accountBankId}&accountBranchId=${accountBranchId}&accountNbr=${accountNbr}" \
--header "X-JWT-Assertion: ${jwt_id}" \
--header 'Accept: */*'

 


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\scripts\curl-dev\curl-search_by_legacyId-imut-works.sh
-----------------------------------------------------
#!/bin/bash

 set -e -x
 export host=$(hostname)
 export legacy_id="testWsssaxfgfd"
 export accountBankId="41"
 export accountBranchId="42"
 export accountNbr="40"
 
 export jwt_id="eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsIng1dCI6ImI2TnozUDJwMHg1QWpfWENsUmhrVDFzNlNIQSJ9.eyJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9hcHBsaWNhdGlvbnRpZXIiOiJVbmxpbWl0ZWQiLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9rZXl0eXBlIjoiUFJPRFVDVElPTiIsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL3ZlcnNpb24iOiIwLjMuNSIsImlzcyI6IndzbzIub3JnXC9wcm9kdWN0c1wvYW0iLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9hcHBsaWNhdGlvbm5hbWUiOiJ3c28yRGV2VHJ5SXQiLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9lbmR1c2VyIjoiSTBHRkBjYXJib24uc3VwZXIiLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9lbmR1c2VyVGVuYW50SWQiOiItMTIzNCIsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL3N1YnNjcmliZXIiOiJJMEdGIiwiaHR0cDpcL1wvd3NvMi5vcmdcL2NsYWltc1wvdGllciI6IkdvbGQiLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9hcHBsaWNhdGlvbmlkIjoiMzA5OCIsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL3VzZXJ0eXBlIjoiQVBQTElDQVRJT04iLCJleHAiOjE2MTA2MzkwNDQsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL2FwaWNvbnRleHQiOiJcL2JuaHAtRG9jdW1lbnRNYW5hZ2VyXC8wLjMuNSJ9.lD3QA4MYpu7apY9kIANe7Z4cdWSU9hdK5NE0UHUL9W59ofXTo5UVds/HBW+yz/sEI1ibK8RjnQelsY+I1daaTAM7DBo+n/g6aB6SAeMWt0JOdboByw3lE+5QfeS1hdY32FsCrcP0lMPGX7wsiOBYpDzyLrSdManYY23ME8/gupCPmQbpEs+hRQZDEIrk05+6Rz878xhUzGZ/32pfUCpir7OJOX6Z2gSG4fpqVpvueA+k85PrYZJEeoy9WZwMrL1YfUIMPgUIJkCekzphQWE5+I8NRtNmXdOX09+gPo6LhfOiJaPjFoieXQxfSNUKk8rUjmT+oIE/isdpORlnRbeqkA=="


 curl -k --request GET "http://${host}:9033/0.3.6/objects/legacyDocumentId/${legacy_id}?BnhpCustomerDoc&retrieveProfile=stream&fetchType=meta&accountBankId=${accountBankId}&accountBranchId=${accountBranchId}&accountNbr=${accountNbr}" \
--header "X-JWT-Assertion: ${jwt_id}" \
--header 'Accept: */*'

 


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\scripts\curl-dev\curl-search_by_legacyId.sh
-----------------------------------------------------
#!/bin/bash

 set -e -x
 export host=$(hostname)
 export legacy_id="testWsssaxfgfd"
 export jwt_id="eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsIng1dCI6ImI2TnozUDJwMHg1QWpfWENsUmhrVDFzNlNIQSJ9.eyJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9hcHBsaWNhdGlvbnRpZXIiOiJVbmxpbWl0ZWQiLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9rZXl0eXBlIjoiUFJPRFVDVElPTiIsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL3ZlcnNpb24iOiIwLjMuNSIsImlzcyI6IndzbzIub3JnXC9wcm9kdWN0c1wvYW0iLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9hcHBsaWNhdGlvbm5hbWUiOiJ3c28yRGV2VHJ5SXQiLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9lbmR1c2VyIjoiSTBHRkBjYXJib24uc3VwZXIiLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9lbmR1c2VyVGVuYW50SWQiOiItMTIzNCIsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL3N1YnNjcmliZXIiOiJJMEdGIiwiaHR0cDpcL1wvd3NvMi5vcmdcL2NsYWltc1wvdGllciI6IkdvbGQiLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9hcHBsaWNhdGlvbmlkIjoiMzA5OCIsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL3VzZXJ0eXBlIjoiQVBQTElDQVRJT04iLCJleHAiOjE2MTA2MzkwNDQsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL2FwaWNvbnRleHQiOiJcL2JuaHAtRG9jdW1lbnRNYW5hZ2VyXC8wLjMuNSJ9.lD3QA4MYpu7apY9kIANe7Z4cdWSU9hdK5NE0UHUL9W59ofXTo5UVds/HBW+yz/sEI1ibK8RjnQelsY+I1daaTAM7DBo+n/g6aB6SAeMWt0JOdboByw3lE+5QfeS1hdY32FsCrcP0lMPGX7wsiOBYpDzyLrSdManYY23ME8/gupCPmQbpEs+hRQZDEIrk05+6Rz878xhUzGZ/32pfUCpir7OJOX6Z2gSG4fpqVpvueA+k85PrYZJEeoy9WZwMrL1YfUIMPgUIJkCekzphQWE5+I8NRtNmXdOX09+gPo6LhfOiJaPjFoieXQxfSNUKk8rUjmT+oIE/isdpORlnRbeqkA=="
 
 curl -k --request GET "http://${host}:9033/0.3.6/objects/legacyDocumentId/${legacy_id}?BnhpCustomerDoc&retrieveProfile=stream&fetchType=meta" \
--header "X-JWT-Assertion: ${jwt_id}" \
--header 'Accept: */*'
 


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\scripts\curl-prod\curl-search_by_legacyId-imut-not-works.sh
-----------------------------------------------------
#!/bin/bash

 export host=$(hostname)
 set -e -x
 curl -k --request GET "https://${host}:9033/0.3.6/objects/legacyDocumentId/3b8f778b-e5eb-4862-a24d-100e96f12b3c?objectTypes=BnhpCustomerDoc&retrieveProfile=stream&fetchType=meta&completeCustomerIdCode=2059458841" \
--header 'X-JWT-Assertion: eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsIng1dCI6IlJZNzlTMk1xZk9RT0xBUG9XeGVjNkFSUEIzQSJ9.eyJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9hcHBsaWNhdGlvbnRpZXIiOiJVbmxpbWl0ZWQiLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9rZXl0eXBlIjoiUFJPRFVDVElPTiIsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL3ZlcnNpb24iOiIwLjMuNSIsImlzcyI6IndzbzIub3JnXC9wcm9kdWN0c1wvYW0iLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9hcHBsaWNhdGlvbm5hbWUiOiJEaWdpdGFsTW9ydGdhZ2VBcHAiLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9lbmR1c2VyIjoiUFJEWlpMQU4wMUBjYXJib24uc3VwZXIiLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9lbmR1c2VyVGVuYW50SWQiOiItMTIzNCIsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL3N1YnNjcmliZXIiOiJwcmR6emxhbjAxIiwiaHR0cDpcL1wvd3NvMi5vcmdcL2NsYWltc1wvdGllciI6IkdvbGQiLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9hcHBsaWNhdGlvbmlkIjoiOTIiLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC91c2VydHlwZSI6IkFQUExJQ0FUSU9OIiwiZXhwIjoxNjE3NjI1MzE0LCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9hcGljb250ZXh0IjoiXC9ibmhwLURvY3VtZW50TWFuYWdlclwvMC4zLjUifQ==.YpdHkLJ+KXASXpzxnBImpC8919ajkRE9idWuaecswmK9rU54MuhFct0GoFUhOMc+SkVO2LmQv+jL9Emf/Ci2RYUqUQOFPc3+g/OdimBVDiQ+bfTc8OAlK2Rc2gmVHrnRsfqWIrVPJIrxNNm0M9uFq3k1VtGFCA5DzJqmlHHXkGym512kKH/xjEHhKUuJXYSE3gScdd7ybtW0s3AOQJWDXVOl/QrcRQMlBdWVVvFLcC4pb2syv+X499EDlHFp7lSWfpZXI+P2We7JmWMB3JPlgn4JVXS+MPc0gEINqVXIlMtczX4xFrlXHjXBMUmEKoTy2vvoCqJrXPY0u6n3v+20ng==' \
--header 'Accept: */*'


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\scripts\curl-prod\curl-search_by_legacyId-imut-works.sh
-----------------------------------------------------
#!/bin/bash

 export host=$(hostname)
 set -e -x
 curl -k --request GET "https://${host}:9033/0.3.6/objects/legacyDocumentId/3b8f778b-e5eb-4862-a24d-100e96f12b3c?objectTypes=BnhpCustomerDoc&retrieveProfile=stream&fetchType=meta&completeCustomerIdCode=205945884" \
--header 'X-JWT-Assertion: eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsIng1dCI6IlJZNzlTMk1xZk9RT0xBUG9XeGVjNkFSUEIzQSJ9.eyJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9hcHBsaWNhdGlvbnRpZXIiOiJVbmxpbWl0ZWQiLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9rZXl0eXBlIjoiUFJPRFVDVElPTiIsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL3ZlcnNpb24iOiIwLjMuNSIsImlzcyI6IndzbzIub3JnXC9wcm9kdWN0c1wvYW0iLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9hcHBsaWNhdGlvbm5hbWUiOiJEaWdpdGFsTW9ydGdhZ2VBcHAiLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9lbmR1c2VyIjoiUFJEWlpMQU4wMUBjYXJib24uc3VwZXIiLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9lbmR1c2VyVGVuYW50SWQiOiItMTIzNCIsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL3N1YnNjcmliZXIiOiJwcmR6emxhbjAxIiwiaHR0cDpcL1wvd3NvMi5vcmdcL2NsYWltc1wvdGllciI6IkdvbGQiLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9hcHBsaWNhdGlvbmlkIjoiOTIiLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC91c2VydHlwZSI6IkFQUExJQ0FUSU9OIiwiZXhwIjoxNjE3NjI1MzE0LCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9hcGljb250ZXh0IjoiXC9ibmhwLURvY3VtZW50TWFuYWdlclwvMC4zLjUifQ==.YpdHkLJ+KXASXpzxnBImpC8919ajkRE9idWuaecswmK9rU54MuhFct0GoFUhOMc+SkVO2LmQv+jL9Emf/Ci2RYUqUQOFPc3+g/OdimBVDiQ+bfTc8OAlK2Rc2gmVHrnRsfqWIrVPJIrxNNm0M9uFq3k1VtGFCA5DzJqmlHHXkGym512kKH/xjEHhKUuJXYSE3gScdd7ybtW0s3AOQJWDXVOl/QrcRQMlBdWVVvFLcC4pb2syv+X499EDlHFp7lSWfpZXI+P2We7JmWMB3JPlgn4JVXS+MPc0gEINqVXIlMtczX4xFrlXHjXBMUmEKoTy2vvoCqJrXPY0u6n3v+20ng==' \
--header 'Accept: */*'


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\scripts\curl-prod\curl-search_by_legacyId.sh
-----------------------------------------------------
#!/bin/bash

 export host=$(hostname)
 set -e -x
 curl -k --request GET "https://${host}:9033/0.3.6/objects/legacyDocumentId/3b8f778b-e5eb-4862-a24d-100e96f12b3c?objectTypes=BnhpCustomerDoc&retrieveProfile=stream&fetchType=meta" \
--header 'X-JWT-Assertion: eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsIng1dCI6IlJZNzlTMk1xZk9RT0xBUG9XeGVjNkFSUEIzQSJ9.eyJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9hcHBsaWNhdGlvbnRpZXIiOiJVbmxpbWl0ZWQiLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9rZXl0eXBlIjoiUFJPRFVDVElPTiIsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL3ZlcnNpb24iOiIwLjMuNSIsImlzcyI6IndzbzIub3JnXC9wcm9kdWN0c1wvYW0iLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9hcHBsaWNhdGlvbm5hbWUiOiJEaWdpdGFsTW9ydGdhZ2VBcHAiLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9lbmR1c2VyIjoiUFJEWlpMQU4wMUBjYXJib24uc3VwZXIiLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9lbmR1c2VyVGVuYW50SWQiOiItMTIzNCIsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL3N1YnNjcmliZXIiOiJwcmR6emxhbjAxIiwiaHR0cDpcL1wvd3NvMi5vcmdcL2NsYWltc1wvdGllciI6IkdvbGQiLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9hcHBsaWNhdGlvbmlkIjoiOTIiLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC91c2VydHlwZSI6IkFQUExJQ0FUSU9OIiwiZXhwIjoxNjE3NjI1MzE0LCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9hcGljb250ZXh0IjoiXC9ibmhwLURvY3VtZW50TWFuYWdlclwvMC4zLjUifQ==.YpdHkLJ+KXASXpzxnBImpC8919ajkRE9idWuaecswmK9rU54MuhFct0GoFUhOMc+SkVO2LmQv+jL9Emf/Ci2RYUqUQOFPc3+g/OdimBVDiQ+bfTc8OAlK2Rc2gmVHrnRsfqWIrVPJIrxNNm0M9uFq3k1VtGFCA5DzJqmlHHXkGym512kKH/xjEHhKUuJXYSE3gScdd7ybtW0s3AOQJWDXVOl/QrcRQMlBdWVVvFLcC4pb2syv+X499EDlHFp7lSWfpZXI+P2We7JmWMB3JPlgn4JVXS+MPc0gEINqVXIlMtczX4xFrlXHjXBMUmEKoTy2vvoCqJrXPY0u6n3v+20ng==' \
--header 'Accept: */*'


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\scripts\curl-st\curl-create-By-FilePath.sh
-----------------------------------------------------
#!/bin/bash

set -e -x
export host=$(hostname)
export datetime=$(date +"%Y%m%d-%H%M%S")
export legacy_id="shai-${datetime}"
echo "legacyId generated:${legacy_id}" 
export jwt_id="eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsIng1dCI6IjBPZ3Z0dzRlaVI4cWhnQVVjblJyUHo4eFhyWSJ9.eyJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9hcHBsaWNhdGlvbnRpZXIiOiJVbmxpbWl0ZWQiLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9rZXl0eXBlIjoiUFJPRFVDVElPTiIsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL3ZlcnNpb24iOiIwLjMuNiIsImlzcyI6IndzbzIub3JnXC9wcm9kdWN0c1wvYW0iLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9hcHBsaWNhdGlvbm5hbWUiOiJUYWx5b24iLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9lbmR1c2VyIjoiUFJEWlpBUDJAY2FyYm9uLnN1cGVyIiwiaHR0cDpcL1wvd3NvMi5vcmdcL2NsYWltc1wvZW5kdXNlclRlbmFudElkIjoiLTEyMzQiLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9zdWJzY3JpYmVyIjoiUFJEWlpBUDIiLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC90aWVyIjoiVW5saW1pdGVkIiwiaHR0cDpcL1wvd3NvMi5vcmdcL2NsYWltc1wvYXBwbGljYXRpb25pZCI6IjE2NiIsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL3VzZXJ0eXBlIjoiQVBQTElDQVRJT04iLCJleHAiOjE2MjQyNzAwNDQsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL2FwaWNvbnRleHQiOiJcL2JuaHAtRG9jdW1lbnRNYW5hZ2VyXC8wLjMuNiJ9.RtLkJTi4rALIpZehhZxrdw2s/nOhqmnxe2jCZs01kIm/v4qYDAN+qwi0jaR3/m9MLKiQVj5c/jAmhRUoXGBXdnfgc3ssdi+ouldcWK50ppzJNtovwoKNebGmeZGqB86ArwevFLbi9CmJAIzEkALwqfAIO8X4eOj4SHx8Jtv+z2VslWUrzZvgWQ8zsXf2soXZfr4z3UVdksjmZ/BNISJrEoIxq8h7od/tPtexlFsSXSFtbJJMSby6xdIdktkkiabYVHDWVP+43Y+4M1kxx+2e38m84rt7vLXvGu+NBrbm4ttnsZJQ3K7esmDqF5peQruJ5avgLirAPcsGC4sNuUchtA=="
curl -k --request POST "http://${host}:9033/0.3.6/objects/legacyDocumentId/${legacy_id}" \
--header "X-JWT-Assertion: ${jwt_id}" \
--header 'Accept: */*' \
--header 'Content-Type: application/json' \
--header 'Accept: */*' \
--data "{ 
    \"docCustomerData\": { 
        \"bankAccounts\": [ 
            { 
                \"accountBankId\": 12, 
                \"accountNbr\": 196, 
                \"branchId\": 166236, 
                \"divisionId\": 5, 
                \"specialHandlingCode\": false 
            } 
        ], 
        \"customers\": [ 
            { 
                \"completeCustomerIdCode\": \"09876543\", 
                \"customerFullName\": \"Lakoah Ploni\", 
                \"customerId\": 1234, 
                \"customerIdDocTypeCode\": \"1\", 
                \"customerSerialNbr\": \"1\", 
                \"occasionalCustomerInd\": false 
            } 
        ], 
        \"docDetails\": { 
            \"businessAreaCode\": 40, 
            \"businessSubAreaCode\": 10, 
            \"channelId\": 1, 
            \"docCompletenessCode\": 0, 
            \"documentFormId\": \"5555500001\", 
            \"documentGroupIds\": [ 
                \"XX_SOME_GROUP_ID\" 
            ], 
            \"legacyDocumentEntryDttm\": \"2019-02-13T09:22:15Z\", 
            \"legacyDocumentId\": \"XX_SOME_DOCUMENT_ID\", 
            \"ongoingOrHistoryCode\": 1, 
            \"projectId\": 1, 
            \"scanStatusCode\": 4, 
            \"signatureStatusCode\": 0, 
            \"systemCode\": 28008 
        }, 
        \"executorDetails\": { 
            \"empIdDocumentTypeCode\": 1, 
            \"executingBankId\": 12, 
            \"executingBranchId\": 777, 
            \"executingEmpFullName\": \"Pakid Ploni\", 
            \"executingEmpIdCode\": \"12345678\", 
            \"executingUserName\": \"XYZ\", 
            \"ipAddress\": \"1.2.3.4\" 
        } 
    }, 
    \"docFiles\": [ 
        { 
            \"docURL\": \"file:///talyon/printbossoutput/HA_03BEC6A7-A35F-4901-B66D-90F09EE1A4B9.pdf\", 
            \"mimeType\": \"application/pdf\" 
        } 
    ], 
    \"objectName\": \"SampleCustomerDocument.pdf\", 
    \"objectType\": \"BnhpCustomerDocData\", 
    \"versionLabels\": [ 
        \"SOME_USER_LABEL\" 
    ] 
}" 



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\scripts\curl-st\curl-search_by_legacyId-imut-not-works.sh
-----------------------------------------------------
#!/bin/bash

 set -e -x
 export host=$(hostname)
 export legacy_id="ERP_3120"
 export accountBankId="12"
 export accountBranchId="715122222"
 export accountNbr="351222"
 export jwt_id="eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsIng1dCI6IjBPZ3Z0dzRlaVI4cWhnQVVjblJyUHo4eFhyWSJ9.eyJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9hcHBsaWNhdGlvbnRpZXIiOiJVbmxpbWl0ZWQiLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9rZXl0eXBlIjoiUFJPRFVDVElPTiIsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL3ZlcnNpb24iOiIwLjMuNSIsImlzcyI6IndzbzIub3JnXC9wcm9kdWN0c1wvYW0iLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9hcHBsaWNhdGlvbm5hbWUiOiJQdWJBcHBibmhwLURvY3VtZW50TWFuYWdlciIsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL2VuZHVzZXIiOiJQUkRaWkFQMkBjYXJib24uc3VwZXIiLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9lbmR1c2VyVGVuYW50SWQiOiItMTIzNCIsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL3N1YnNjcmliZXIiOiJQUkRaWkFQMiIsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL3RpZXIiOiJHb2xkIiwiaHR0cDpcL1wvd3NvMi5vcmdcL2NsYWltc1wvYXBwbGljYXRpb25pZCI6IjkzMyIsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL3VzZXJ0eXBlIjoiQVBQTElDQVRJT04iLCJleHAiOjE2MjM4NTI5NDEsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL2FwaWNvbnRleHQiOiJcL2JuaHAtRG9jdW1lbnRNYW5hZ2VyXC8wLjMuNSJ9.VWMeCTDgPj2Ss0BMw7ieP4Lqn2qHxYbFgltVuqf53/bh8zVm6X5yM3S+wb6gqWB6PzjRiYPongcenD8vWRczmyo6dlMhEdS69Zkc/y3XxiLC1T4JY4oqj8aNrRK14VuXt3qwFN9OCCkf3kFQ8eAFaAKGCmZTnB6zXOkN1CXTFoHAxHpoQxYrqqUuZsFHrE04oxLh3fP9V/5q8PhxqdjvE4nc7BCAwHykEJ2ADZ9FSODFtcX9+v2dmOErq7mgDGvN7Beda+xkaAm/oed5MQ1MXmRC+8m/71a1OxN00sYsgUitlbxO2dDZHUoyPCXRNzmmCsv4fcilVpRk86ay7BtQKg=="

 curl -k --request GET "http://${host}:9033/0.3.6/objects/legacyDocumentId/${legacy_id}?BnhpCustomerDoc&retrieveProfile=stream&fetchType=meta&accountBankId=${accountBankId}&accountBranchId=${accountBranchId}&accountNbr=${accountNbr}" \
--header "X-JWT-Assertion: ${jwt_id}" \
--header 'Accept: */*'

 


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\scripts\curl-st\curl-search_by_legacyId-imut-works.sh
-----------------------------------------------------
#!/bin/bash

 set -e -x
 export host=$(hostname)
 export legacy_id="ERP_3120"
 export accountBankId="12"
 export accountBranchId="715"
 export accountNbr="351222"
 export jwt_id="eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsIng1dCI6IjBPZ3Z0dzRlaVI4cWhnQVVjblJyUHo4eFhyWSJ9.eyJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9hcHBsaWNhdGlvbnRpZXIiOiJVbmxpbWl0ZWQiLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9rZXl0eXBlIjoiUFJPRFVDVElPTiIsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL3ZlcnNpb24iOiIwLjMuNSIsImlzcyI6IndzbzIub3JnXC9wcm9kdWN0c1wvYW0iLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9hcHBsaWNhdGlvbm5hbWUiOiJQdWJBcHBibmhwLURvY3VtZW50TWFuYWdlciIsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL2VuZHVzZXIiOiJQUkRaWkFQMkBjYXJib24uc3VwZXIiLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9lbmR1c2VyVGVuYW50SWQiOiItMTIzNCIsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL3N1YnNjcmliZXIiOiJQUkRaWkFQMiIsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL3RpZXIiOiJHb2xkIiwiaHR0cDpcL1wvd3NvMi5vcmdcL2NsYWltc1wvYXBwbGljYXRpb25pZCI6IjkzMyIsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL3VzZXJ0eXBlIjoiQVBQTElDQVRJT04iLCJleHAiOjE2MjM4NTI5NDEsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL2FwaWNvbnRleHQiOiJcL2JuaHAtRG9jdW1lbnRNYW5hZ2VyXC8wLjMuNSJ9.VWMeCTDgPj2Ss0BMw7ieP4Lqn2qHxYbFgltVuqf53/bh8zVm6X5yM3S+wb6gqWB6PzjRiYPongcenD8vWRczmyo6dlMhEdS69Zkc/y3XxiLC1T4JY4oqj8aNrRK14VuXt3qwFN9OCCkf3kFQ8eAFaAKGCmZTnB6zXOkN1CXTFoHAxHpoQxYrqqUuZsFHrE04oxLh3fP9V/5q8PhxqdjvE4nc7BCAwHykEJ2ADZ9FSODFtcX9+v2dmOErq7mgDGvN7Beda+xkaAm/oed5MQ1MXmRC+8m/71a1OxN00sYsgUitlbxO2dDZHUoyPCXRNzmmCsv4fcilVpRk86ay7BtQKg=="

 curl -k --request GET "http://${host}:9033/0.3.6/objects/legacyDocumentId/${legacy_id}?BnhpCustomerDoc&retrieveProfile=stream&fetchType=meta&accountBankId=${accountBankId}&accountBranchId=${accountBranchId}&accountNbr=${accountNbr}" \
--header "X-JWT-Assertion: ${jwt_id}" \
--header 'Accept: */*'

 


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\scripts\curl-st\curl-search_by_legacyId.sh
-----------------------------------------------------
#!/bin/bash

 set -e -x
 export host=$(hostname)
 export legacy_id="ERP_3120"
 export jwt_id="eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsIng1dCI6IjBPZ3Z0dzRlaVI4cWhnQVVjblJyUHo4eFhyWSJ9.eyJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9hcHBsaWNhdGlvbnRpZXIiOiJVbmxpbWl0ZWQiLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9rZXl0eXBlIjoiUFJPRFVDVElPTiIsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL3ZlcnNpb24iOiIwLjMuNSIsImlzcyI6IndzbzIub3JnXC9wcm9kdWN0c1wvYW0iLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9hcHBsaWNhdGlvbm5hbWUiOiJQdWJBcHBibmhwLURvY3VtZW50TWFuYWdlciIsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL2VuZHVzZXIiOiJQUkRaWkFQMkBjYXJib24uc3VwZXIiLCJodHRwOlwvXC93c28yLm9yZ1wvY2xhaW1zXC9lbmR1c2VyVGVuYW50SWQiOiItMTIzNCIsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL3N1YnNjcmliZXIiOiJQUkRaWkFQMiIsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL3RpZXIiOiJHb2xkIiwiaHR0cDpcL1wvd3NvMi5vcmdcL2NsYWltc1wvYXBwbGljYXRpb25pZCI6IjkzMyIsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL3VzZXJ0eXBlIjoiQVBQTElDQVRJT04iLCJleHAiOjE2MjM4NTI5NDEsImh0dHA6XC9cL3dzbzIub3JnXC9jbGFpbXNcL2FwaWNvbnRleHQiOiJcL2JuaHAtRG9jdW1lbnRNYW5hZ2VyXC8wLjMuNSJ9.VWMeCTDgPj2Ss0BMw7ieP4Lqn2qHxYbFgltVuqf53/bh8zVm6X5yM3S+wb6gqWB6PzjRiYPongcenD8vWRczmyo6dlMhEdS69Zkc/y3XxiLC1T4JY4oqj8aNrRK14VuXt3qwFN9OCCkf3kFQ8eAFaAKGCmZTnB6zXOkN1CXTFoHAxHpoQxYrqqUuZsFHrE04oxLh3fP9V/5q8PhxqdjvE4nc7BCAwHykEJ2ADZ9FSODFtcX9+v2dmOErq7mgDGvN7Beda+xkaAm/oed5MQ1MXmRC+8m/71a1OxN00sYsgUitlbxO2dDZHUoyPCXRNzmmCsv4fcilVpRk86ay7BtQKg=="
 
 curl -k --request GET "http://${host}:9033/0.3.6/objects/legacyDocumentId/${legacy_id}?BnhpCustomerDoc&retrieveProfile=stream&fetchType=meta" \
--header "X-JWT-Assertion: ${jwt_id}" \
--header 'Accept: */*'
 


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\scripts\default.template.sh
-----------------------------------------------------
# defaults for "{{service_name}}"
#



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\scripts\duecmrest.template.init.sh
-----------------------------------------------------
#!/bin/bash
#
# duecmrest		This shell script takes care of starting and stopping
#
# chkconfig: - 97 02
# description: duecmrest is an authentication proxy for sharepoint and documentum

### BEGIN INIT INFO
# Provides: duecmrest
# Required-Start: $network $local_fs $remote_fs
# Required-Stop: $network $local_fs $remote_fs
# Should-Start: $syslog $named duecmrestate
# Should-Stop: $syslog $named
# Short-Description: start and stop duecmrest
# Description: auth_prox is an authentication proxy for sharepoint and documentum
### END INIT INFO

# Source function library.
. /etc/init.d/functions

# Source networking configuration.
. /etc/sysconfig/network



dir="{{appdir}}"

PATH="$PATH:$dir"

prog="duecmrest"

defaultfile="/etc/default/${prog}"

if ! [ -r  "$defaultfile" ]; then
	exit 0
fi

. "$defaultfile"

if ! [ -n "ENVARG" ]; then
	exit 0
fi


lockfile=/var/lock/subsys/$prog
pidfile=/var/run/$prog

start() {
	[ "$EUID" != "0" ] && exit 4
	[ "$NETWORKING" = "no" ] && exit 1
	[ -x "$dir/$prog" ] || exit 5

        # Start daemons.
        echo -n $"Starting $prog: "
        #daemonize  -c "$dir" -E "$ENVARG" -p $pidfile -l $lockfile -u "{{app_user}}" "$dir/$prog"  && echo_success
		daemonize  -c "$dir" -p $pidfile -l $lockfile -u "{{app_user}}" "$dir/$prog"  && echo_success
	RETVAL=$?
        echo
	[ $RETVAL -eq 0 ] && touch $lockfile
	return $RETVAL
}

stop() {
	[ "$EUID" != "0" ] && exit 4
        echo -n $"Shutting down $prog: "
	killproc -p "$pidfile" $prog
	RETVAL=$?
        echo
	[ $RETVAL -eq 0 ] && rm -f $lockfile
	return $RETVAL
}

# See how we were called.
case "$1" in
  start)
	start
	;;
  stop)
	stop
	;;
  status)
	status $prog
	;;
  restart|force-reload)
	stop
	start
	;;
  try-restart|condrestart)
	if status $prog > /dev/null; then
	    stop
	    start
	fi
	;;
  reload)
	exit 3
	;;
  *)
	echo $"Usage: $0 {start|stop|status|restart|try-restart|force-reload}"
	exit 2
esac


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\scripts\duecmrest.template.sh
-----------------------------------------------------
#!/bin/bash
set -e

cd "{{appdir}}"
exec >logs/output.log 2>&1

JAVA_HOME="{{java_home}}"

exec "${JAVA_HOME}/bin/java" \
	 "-Djavax.net.ssl.trustStore={{appdir}}/resources/jssecacerts" \
	 "-Djavax.net.ssl.trustStorePassword=changeit" \
	 -cp "resources-{{env}}/" \
	 -jar "BnhpInfraDctmRest-{{appversion}}.jar" \
	 "resources-{{env}}/DctmRestApp.yml" \
	 "resources-{{env}}/DctmRestSecrets.yml" 
#	 \
#	 "resources-{{env}}/DctmRestAppExtra.yml"


#	  "-agentlib:jdwp=transport=dt_socket,server=y,address=4444,suspend=n"
# 	 "-Djavax.net.ssl.trustStore={{appdir}}/resources/jssecacerts" 
#	  "-Djavax.net.ssl.trustStorePassword="
#	-Ddebug
#	-Djavax.net.debug=ssl



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\settings.xml
-----------------------------------------------------
<?xml version="1.0" encoding="UTF-8"?>
<settings xsi:schemaLocation="http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd" xmlns="http://maven.apache.org/SETTINGS/1.0.0"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">
  <servers>
    <server>
      <username>${env.ARTIFACTORY_USER}</username>
      <password>${env.ARTIFACTORY_PASSWORD}</password>
      <id>central</id>
      <configuration>
	<httpConfiguration>
		<get>
			<usePreemptive>true</usePreemptive>
		</get>
	</httpConfiguration>
      </configuration>
    </server>
    <server>
      <username>${env.ARTIFACTORY_USER}</username>
      <password>${env.ARTIFACTORY_PASSWORD}</password>
      <id>snapshots</id>
      <configuration>
	<httpConfiguration>
		<get>
			<usePreemptive>true</usePreemptive>
		</get>
	</httpConfiguration>
      </configuration>
    </server>
    <server>
      <username>${env.ARTIFACTORY_USER}</username>
      <password>${env.ARTIFACTORY_PASSWORD}</password>
      <id>artifactory</id>
      <configuration>
	<httpConfiguration>
		<get>
			<usePreemptive>true</usePreemptive>
		</get>
	</httpConfiguration>
      </configuration>
    </server>
    <server>
      <username>${env.ARTIFACTORY_USER}</username>
      <password>${env.ARTIFACTORY_PASSWORD}</password>
      <id>poalim-core</id>
      <configuration>
	<httpConfiguration>
		<get>
			<usePreemptive>true</usePreemptive>
		</get>
	</httpConfiguration>
      </configuration>
    </server>
  </servers>
  <profiles>
    <profile>
      <repositories>
        <repository>
          <snapshots>
            <enabled>true</enabled>
			<updatePolicy>always</updatePolicy>
          </snapshots>
          <id>central</id>
          <name>libs-release</name>
          <url>https://repo.devops.poalim.bank/artifactory/s-28008-repo</url>
        </repository>
        <repository>
          <snapshots />
          <id>snapshots</id>
          <name>libs-snapshot</name>
          <url>https://repo.devops.poalim.bank/artifactory/s-28008-repo</url>
        </repository>
        <repository>
          <snapshots />
          <id>poalim_core</id>
          <name>poalim-core</name>
          <url>https://repo.devops.poalim.bank/artifactory/poalim-core</url>
        </repository>
      </repositories>
      <pluginRepositories>
        <pluginRepository>
          <snapshots>
            <enabled>false</enabled>
          </snapshots>
          <id>central</id>
          <name>plugins-release</name>
          <url>https://repo.devops.poalim.bank/artifactory/s-28008-repo</url>
        </pluginRepository>
        <pluginRepository>
          <snapshots />
          <id>snapshots</id>
          <name>plugins-snapshot</name>
          <url>https://repo.devops.poalim.bank/artifactory/s-28008-repo</url>
        </pluginRepository>
      </pluginRepositories>
      <id>artifactory</id>
      <properties>
        <headlesscomposer.location>/home/FW0/java/HeadlessComposer/</headlesscomposer.location>
        <java.home.for.dfs.build>/home/FW0/java/jdk-1.6.0_27</java.home.for.dfs.build>
        <downloadSources>true</downloadSources>
        <downloadJavadocs>true</downloadJavadocs>
      </properties>

    </profile>

  </profiles>
  <activeProfiles>
    <activeProfile>artifactory</activeProfile>
  </activeProfiles>

</settings>




file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\AsyncRequestStatus.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import com.fasterxml.jackson.annotation.JsonValue;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;
import java.util.Date;





@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class AsyncRequestStatus   {
  
  private String errorDetails;
  private Date finished;
  private byte[] output;
  private String outputType;
  private Date received;
  private Date replied;
  private String requestId;


  public enum RequestStatusEnum {
    WAITING("waiting"),
    STARTED("started"),
    SUCCESS("success"),
    FAILURE("failure");

    private String value;

    RequestStatusEnum(String value) {
      this.value = value;
    }

    @Override
    @JsonValue
    public String toString() {
      return value;
    }
  }

  private RequestStatusEnum requestStatus;
  private Date started;
  private Integer statusCode;
  private String statusMessage;

  /**
   * Detailed error message from the service
   **/
  public AsyncRequestStatus errorDetails(String errorDetails) {
    this.errorDetails = errorDetails;
    return this;
  }

  
  @ApiModelProperty(value = "Detailed error message from the service")
  @JsonProperty("errorDetails")
  public String getErrorDetails() {
    return errorDetails;
  }
  public void setErrorDetails(String errorDetails) {
    this.errorDetails = errorDetails;
  }

  /**
   * When processing has finished
   **/
  public AsyncRequestStatus finished(Date finished) {
    this.finished = finished;
    return this;
  }

  
  @ApiModelProperty(value = "When processing has finished")
  @JsonProperty("finished")
  public Date getFinished() {
    return finished;
  }
  public void setFinished(Date finished) {
    this.finished = finished;
  }

  /**
   * request output
   **/
  public AsyncRequestStatus output(byte[] output) {
    this.output = output;
    return this;
  }

  
  @ApiModelProperty(value = "request output")
  @JsonProperty("output")
  public byte[] getOutput() {
    return output;
  }
  public void setOutput(byte[] output) {
    this.output = output;
  }

  /**
   * request output MIME type
   **/
  public AsyncRequestStatus outputType(String outputType) {
    this.outputType = outputType;
    return this;
  }

  
  @ApiModelProperty(value = "request output MIME type")
  @JsonProperty("outputType")
  public String getOutputType() {
    return outputType;
  }
  public void setOutputType(String outputType) {
    this.outputType = outputType;
  }

  /**
   * When request has been received.
   **/
  public AsyncRequestStatus received(Date received) {
    this.received = received;
    return this;
  }

  
  @ApiModelProperty(value = "When request has been received.")
  @JsonProperty("received")
  public Date getReceived() {
    return received;
  }
  public void setReceived(Date received) {
    this.received = received;
  }

  /**
   * When asynchronous reply has been sent
   **/
  public AsyncRequestStatus replied(Date replied) {
    this.replied = replied;
    return this;
  }

  
  @ApiModelProperty(value = "When asynchronous reply has been sent")
  @JsonProperty("replied")
  public Date getReplied() {
    return replied;
  }
  public void setReplied(Date replied) {
    this.replied = replied;
  }

  /**
   * Asynchronous request id
   **/
  public AsyncRequestStatus requestId(String requestId) {
    this.requestId = requestId;
    return this;
  }

  
  @ApiModelProperty(value = "Asynchronous request id")
  @JsonProperty("requestId")
  public String getRequestId() {
    return requestId;
  }
  public void setRequestId(String requestId) {
    this.requestId = requestId;
  }

  /**
   * Current request status
   **/
  public AsyncRequestStatus requestStatus(RequestStatusEnum requestStatus) {
    this.requestStatus = requestStatus;
    return this;
  }

  
  @ApiModelProperty(value = "Current request status")
  @JsonProperty("requestStatus")
  public RequestStatusEnum getRequestStatus() {
    return requestStatus;
  }
  public void setRequestStatus(RequestStatusEnum requestStatus) {
    this.requestStatus = requestStatus;
  }

  /**
   * When processing started
   **/
  public AsyncRequestStatus started(Date started) {
    this.started = started;
    return this;
  }

  
  @ApiModelProperty(value = "When processing started")
  @JsonProperty("started")
  public Date getStarted() {
    return started;
  }
  public void setStarted(Date started) {
    this.started = started;
  }

  /**
   * Request HTTP status code
   **/
  public AsyncRequestStatus statusCode(Integer statusCode) {
    this.statusCode = statusCode;
    return this;
  }

  
  @ApiModelProperty(value = "Request HTTP status code")
  @JsonProperty("statusCode")
  public Integer getStatusCode() {
    return statusCode;
  }
  public void setStatusCode(Integer statusCode) {
    this.statusCode = statusCode;
  }

  /**
   * Request HTTP status message
   **/
  public AsyncRequestStatus statusMessage(String statusMessage) {
    this.statusMessage = statusMessage;
    return this;
  }

  
  @ApiModelProperty(value = "Request HTTP status message")
  @JsonProperty("statusMessage")
  public String getStatusMessage() {
    return statusMessage;
  }
  public void setStatusMessage(String statusMessage) {
    this.statusMessage = statusMessage;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    AsyncRequestStatus asyncRequestStatus = (AsyncRequestStatus) o;
    return Objects.equals(errorDetails, asyncRequestStatus.errorDetails) &&
        Objects.equals(finished, asyncRequestStatus.finished) &&
        Objects.equals(output, asyncRequestStatus.output) &&
        Objects.equals(outputType, asyncRequestStatus.outputType) &&
        Objects.equals(received, asyncRequestStatus.received) &&
        Objects.equals(replied, asyncRequestStatus.replied) &&
        Objects.equals(requestId, asyncRequestStatus.requestId) &&
        Objects.equals(requestStatus, asyncRequestStatus.requestStatus) &&
        Objects.equals(started, asyncRequestStatus.started) &&
        Objects.equals(statusCode, asyncRequestStatus.statusCode) &&
        Objects.equals(statusMessage, asyncRequestStatus.statusMessage);
  }

  @Override
  public int hashCode() {
    return Objects.hash(errorDetails, finished, output, outputType, received, replied, requestId, requestStatus, started, statusCode, statusMessage);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class AsyncRequestStatus {\n");
    
    sb.append("    errorDetails: ").append(toIndentedString(errorDetails)).append("\n");
    sb.append("    finished: ").append(toIndentedString(finished)).append("\n");
    sb.append("    output: ").append(toIndentedString(output)).append("\n");
    sb.append("    outputType: ").append(toIndentedString(outputType)).append("\n");
    sb.append("    received: ").append(toIndentedString(received)).append("\n");
    sb.append("    replied: ").append(toIndentedString(replied)).append("\n");
    sb.append("    requestId: ").append(toIndentedString(requestId)).append("\n");
    sb.append("    requestStatus: ").append(toIndentedString(requestStatus)).append("\n");
    sb.append("    started: ").append(toIndentedString(started)).append("\n");
    sb.append("    statusCode: ").append(toIndentedString(statusCode)).append("\n");
    sb.append("    statusMessage: ").append(toIndentedString(statusMessage)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\BankAccount.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;





@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class BankAccount   {
  
  private Integer accountBankId;
  private Integer accountNbr;
  private Integer accountType;
  private Integer branchId;
  private Integer divisionId;
  private Boolean specialHandlingCode;

  /**
   **/
  public BankAccount accountBankId(Integer accountBankId) {
    this.accountBankId = accountBankId;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("accountBankId")
  public Integer getAccountBankId() {
    return accountBankId;
  }
  public void setAccountBankId(Integer accountBankId) {
    this.accountBankId = accountBankId;
  }

  /**
   **/
  public BankAccount accountNbr(Integer accountNbr) {
    this.accountNbr = accountNbr;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("accountNbr")
  public Integer getAccountNbr() {
    return accountNbr;
  }
  public void setAccountNbr(Integer accountNbr) {
    this.accountNbr = accountNbr;
  }

  /**
   **/
  public BankAccount accountType(Integer accountType) {
    this.accountType = accountType;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("accountType")
  public Integer getAccountType() {
    return accountType;
  }
  public void setAccountType(Integer accountType) {
    this.accountType = accountType;
  }

  /**
   **/
  public BankAccount branchId(Integer branchId) {
    this.branchId = branchId;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("branchId")
  public Integer getBranchId() {
    return branchId;
  }
  public void setBranchId(Integer branchId) {
    this.branchId = branchId;
  }

  /**
   **/
  public BankAccount divisionId(Integer divisionId) {
    this.divisionId = divisionId;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("divisionId")
  public Integer getDivisionId() {
    return divisionId;
  }
  public void setDivisionId(Integer divisionId) {
    this.divisionId = divisionId;
  }

  /**
   **/
  public BankAccount specialHandlingCode(Boolean specialHandlingCode) {
    this.specialHandlingCode = specialHandlingCode;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("specialHandlingCode")
  public Boolean getSpecialHandlingCode() {
    return specialHandlingCode;
  }
  public void setSpecialHandlingCode(Boolean specialHandlingCode) {
    this.specialHandlingCode = specialHandlingCode;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    BankAccount bankAccount = (BankAccount) o;
    return Objects.equals(accountBankId, bankAccount.accountBankId) &&
        Objects.equals(accountNbr, bankAccount.accountNbr) &&
        Objects.equals(accountType, bankAccount.accountType) &&
        Objects.equals(branchId, bankAccount.branchId) &&
        Objects.equals(divisionId, bankAccount.divisionId) &&
        Objects.equals(specialHandlingCode, bankAccount.specialHandlingCode);
  }

  @Override
  public int hashCode() {
    return Objects.hash(accountBankId, accountNbr, accountType, branchId, divisionId, specialHandlingCode);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class BankAccount {\n");
    
    sb.append("    accountBankId: ").append(toIndentedString(accountBankId)).append("\n");
    sb.append("    accountNbr: ").append(toIndentedString(accountNbr)).append("\n");
    sb.append("    accountType: ").append(toIndentedString(accountType)).append("\n");
    sb.append("    branchId: ").append(toIndentedString(branchId)).append("\n");
    sb.append("    divisionId: ").append(toIndentedString(divisionId)).append("\n");
    sb.append("    specialHandlingCode: ").append(toIndentedString(specialHandlingCode)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\BnhpCorporateDoc.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import bnhp.dctmrest.model.BnhpCorporateDocAllOf;
import bnhp.dctmrest.model.BnhpCorporateDocAllOfProperties;
import bnhp.dctmrest.model.DocPropertyExtension;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;





@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class BnhpCorporateDoc extends DocPropertyExtension  {
  
  private BnhpCorporateDocAllOfProperties properties = null;

  /**
   **/
  public BnhpCorporateDoc properties(BnhpCorporateDocAllOfProperties properties) {
    this.properties = properties;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("properties")
  public BnhpCorporateDocAllOfProperties getProperties() {
    return properties;
  }
  public void setProperties(BnhpCorporateDocAllOfProperties properties) {
    this.properties = properties;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    BnhpCorporateDoc bnhpCorporateDoc = (BnhpCorporateDoc) o;
    return Objects.equals(properties, bnhpCorporateDoc.properties);
  }

  @Override
  public int hashCode() {
    return Objects.hash(properties);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class BnhpCorporateDoc {\n");
    sb.append("    ").append(toIndentedString(super.toString())).append("\n");
    sb.append("    properties: ").append(toIndentedString(properties)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\BnhpCorporateDocAllOf.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import bnhp.dctmrest.model.BnhpCorporateDocAllOfProperties;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;



/**
 * extension for corporate documents specific attributes
 **/

@ApiModel(description = "extension for corporate documents specific attributes")
@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class BnhpCorporateDocAllOf   {
  
  private BnhpCorporateDocAllOfProperties properties = null;

  /**
   **/
  public BnhpCorporateDocAllOf properties(BnhpCorporateDocAllOfProperties properties) {
    this.properties = properties;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("properties")
  public BnhpCorporateDocAllOfProperties getProperties() {
    return properties;
  }
  public void setProperties(BnhpCorporateDocAllOfProperties properties) {
    this.properties = properties;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    BnhpCorporateDocAllOf bnhpCorporateDocAllOf = (BnhpCorporateDocAllOf) o;
    return Objects.equals(properties, bnhpCorporateDocAllOf.properties);
  }

  @Override
  public int hashCode() {
    return Objects.hash(properties);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class BnhpCorporateDocAllOf {\n");
    
    sb.append("    properties: ").append(toIndentedString(properties)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\BnhpCorporateDocAllOfProperties.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;





@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class BnhpCorporateDocAllOfProperties   {
  
  private Boolean isPrivate;
  private String ownerName;

  /**
   **/
  public BnhpCorporateDocAllOfProperties isPrivate(Boolean isPrivate) {
    this.isPrivate = isPrivate;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("isPrivate")
  public Boolean getIsPrivate() {
    return isPrivate;
  }
  public void setIsPrivate(Boolean isPrivate) {
    this.isPrivate = isPrivate;
  }

  /**
   **/
  public BnhpCorporateDocAllOfProperties ownerName(String ownerName) {
    this.ownerName = ownerName;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("ownerName")
  public String getOwnerName() {
    return ownerName;
  }
  public void setOwnerName(String ownerName) {
    this.ownerName = ownerName;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    BnhpCorporateDocAllOfProperties bnhpCorporateDocAllOfProperties = (BnhpCorporateDocAllOfProperties) o;
    return Objects.equals(isPrivate, bnhpCorporateDocAllOfProperties.isPrivate) &&
        Objects.equals(ownerName, bnhpCorporateDocAllOfProperties.ownerName);
  }

  @Override
  public int hashCode() {
    return Objects.hash(isPrivate, ownerName);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class BnhpCorporateDocAllOfProperties {\n");
    
    sb.append("    isPrivate: ").append(toIndentedString(isPrivate)).append("\n");
    sb.append("    ownerName: ").append(toIndentedString(ownerName)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\BnhpCustomerDocData.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import bnhp.dctmrest.model.BnhpCustomerDocDataAllOf;
import bnhp.dctmrest.model.DocCustomerData;
import bnhp.dctmrest.model.DocFile;
import bnhp.dctmrest.model.OneOfbnhpPaperDocbnhpCorporateDocbnhpDivisionBusiness;
import bnhp.dctmrest.model.SysObjectData;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;
import java.util.ArrayList;
import java.util.Date;
import java.util.List;





@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class BnhpCustomerDocData extends SysObjectData  {
  
  private DocCustomerData docCustomerData = null;
  private List<DocFile> docFiles = new ArrayList<>();
  private List<OneOfbnhpPaperDocbnhpCorporateDocbnhpDivisionBusiness> extensions = new ArrayList<>();

  /**
   **/
  public BnhpCustomerDocData docCustomerData(DocCustomerData docCustomerData) {
    this.docCustomerData = docCustomerData;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("docCustomerData")
  public DocCustomerData getDocCustomerData() {
    return docCustomerData;
  }
  public void setDocCustomerData(DocCustomerData docCustomerData) {
    this.docCustomerData = docCustomerData;
  }

  /**
   **/
  public BnhpCustomerDocData docFiles(List<DocFile> docFiles) {
    this.docFiles = docFiles;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("docFiles")
  public List<DocFile> getDocFiles() {
    return docFiles;
  }
  public void setDocFiles(List<DocFile> docFiles) {
    this.docFiles = docFiles;
  }

  /**
   **/
  public BnhpCustomerDocData extensions(List<OneOfbnhpPaperDocbnhpCorporateDocbnhpDivisionBusiness> extensions) {
    this.extensions = extensions;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("extensions")
  public List<OneOfbnhpPaperDocbnhpCorporateDocbnhpDivisionBusiness> getExtensions() {
    return extensions;
  }
  public void setExtensions(List<OneOfbnhpPaperDocbnhpCorporateDocbnhpDivisionBusiness> extensions) {
    this.extensions = extensions;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    BnhpCustomerDocData bnhpCustomerDocData = (BnhpCustomerDocData) o;
    return Objects.equals(docCustomerData, bnhpCustomerDocData.docCustomerData) &&
        Objects.equals(docFiles, bnhpCustomerDocData.docFiles) &&
        Objects.equals(extensions, bnhpCustomerDocData.extensions);
  }

  @Override
  public int hashCode() {
    return Objects.hash(docCustomerData, docFiles, extensions);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class BnhpCustomerDocData {\n");
    sb.append("    ").append(toIndentedString(super.toString())).append("\n");
    sb.append("    docCustomerData: ").append(toIndentedString(docCustomerData)).append("\n");
    sb.append("    docFiles: ").append(toIndentedString(docFiles)).append("\n");
    sb.append("    extensions: ").append(toIndentedString(extensions)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\BnhpCustomerDocDataAllOf.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import bnhp.dctmrest.model.DocCustomerData;
import bnhp.dctmrest.model.DocFile;
import bnhp.dctmrest.model.OneOfbnhpPaperDocbnhpCorporateDocbnhpDivisionBusiness;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;
import java.util.ArrayList;
import java.util.List;





@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class BnhpCustomerDocDataAllOf   {
  
  private DocCustomerData docCustomerData = null;
  private List<DocFile> docFiles = new ArrayList<>();
  private List<OneOfbnhpPaperDocbnhpCorporateDocbnhpDivisionBusiness> extensions = new ArrayList<>();

  /**
   **/
  public BnhpCustomerDocDataAllOf docCustomerData(DocCustomerData docCustomerData) {
    this.docCustomerData = docCustomerData;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("docCustomerData")
  public DocCustomerData getDocCustomerData() {
    return docCustomerData;
  }
  public void setDocCustomerData(DocCustomerData docCustomerData) {
    this.docCustomerData = docCustomerData;
  }

  /**
   **/
  public BnhpCustomerDocDataAllOf docFiles(List<DocFile> docFiles) {
    this.docFiles = docFiles;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("docFiles")
  public List<DocFile> getDocFiles() {
    return docFiles;
  }
  public void setDocFiles(List<DocFile> docFiles) {
    this.docFiles = docFiles;
  }

  /**
   **/
  public BnhpCustomerDocDataAllOf extensions(List<OneOfbnhpPaperDocbnhpCorporateDocbnhpDivisionBusiness> extensions) {
    this.extensions = extensions;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("extensions")
  public List<OneOfbnhpPaperDocbnhpCorporateDocbnhpDivisionBusiness> getExtensions() {
    return extensions;
  }
  public void setExtensions(List<OneOfbnhpPaperDocbnhpCorporateDocbnhpDivisionBusiness> extensions) {
    this.extensions = extensions;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    BnhpCustomerDocDataAllOf bnhpCustomerDocDataAllOf = (BnhpCustomerDocDataAllOf) o;
    return Objects.equals(docCustomerData, bnhpCustomerDocDataAllOf.docCustomerData) &&
        Objects.equals(docFiles, bnhpCustomerDocDataAllOf.docFiles) &&
        Objects.equals(extensions, bnhpCustomerDocDataAllOf.extensions);
  }

  @Override
  public int hashCode() {
    return Objects.hash(docCustomerData, docFiles, extensions);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class BnhpCustomerDocDataAllOf {\n");
    
    sb.append("    docCustomerData: ").append(toIndentedString(docCustomerData)).append("\n");
    sb.append("    docFiles: ").append(toIndentedString(docFiles)).append("\n");
    sb.append("    extensions: ").append(toIndentedString(extensions)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\BnhpDivisionBusiness.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import bnhp.dctmrest.model.BnhpDivisionBusinessAllOf;
import bnhp.dctmrest.model.BnhpDivisionBusinessAllOfProperties;
import bnhp.dctmrest.model.DocPropertyExtension;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;





@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class BnhpDivisionBusiness extends DocPropertyExtension  {
  
  private BnhpDivisionBusinessAllOfProperties properties = null;

  /**
   **/
  public BnhpDivisionBusiness properties(BnhpDivisionBusinessAllOfProperties properties) {
    this.properties = properties;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("properties")
  public BnhpDivisionBusinessAllOfProperties getProperties() {
    return properties;
  }
  public void setProperties(BnhpDivisionBusinessAllOfProperties properties) {
    this.properties = properties;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    BnhpDivisionBusiness bnhpDivisionBusiness = (BnhpDivisionBusiness) o;
    return Objects.equals(properties, bnhpDivisionBusiness.properties);
  }

  @Override
  public int hashCode() {
    return Objects.hash(properties);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class BnhpDivisionBusiness {\n");
    sb.append("    ").append(toIndentedString(super.toString())).append("\n");
    sb.append("    properties: ").append(toIndentedString(properties)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\BnhpDivisionBusinessAllOf.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import bnhp.dctmrest.model.BnhpDivisionBusinessAllOfProperties;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;



/**
 * extension for business division documents
 **/

@ApiModel(description = "extension for business division documents")
@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class BnhpDivisionBusinessAllOf   {
  
  private BnhpDivisionBusinessAllOfProperties properties = null;

  /**
   **/
  public BnhpDivisionBusinessAllOf properties(BnhpDivisionBusinessAllOfProperties properties) {
    this.properties = properties;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("properties")
  public BnhpDivisionBusinessAllOfProperties getProperties() {
    return properties;
  }
  public void setProperties(BnhpDivisionBusinessAllOfProperties properties) {
    this.properties = properties;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    BnhpDivisionBusinessAllOf bnhpDivisionBusinessAllOf = (BnhpDivisionBusinessAllOf) o;
    return Objects.equals(properties, bnhpDivisionBusinessAllOf.properties);
  }

  @Override
  public int hashCode() {
    return Objects.hash(properties);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class BnhpDivisionBusinessAllOf {\n");
    
    sb.append("    properties: ").append(toIndentedString(properties)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\BnhpDivisionBusinessAllOfProperties.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;
import java.util.ArrayList;
import java.util.Date;
import java.util.List;





@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class BnhpDivisionBusinessAllOfProperties   {
  
  private List<Integer> carNumber = new ArrayList<>();
  private Integer creditType;
  private List<Long> depositNumber = new ArrayList<>();
  private Date expirationDate;
  private Integer gushNumber;
  private Long helkaNumber;
  private Integer numberBranchConfidence;
  private Integer numberConfidence;
  private Integer numberDeal;
  private Integer originalDocument;
  private Integer propertyType;
  private Integer serialNbrLoanGuarantee;
  private Integer tathelkaNumber;

  /**
   **/
  public BnhpDivisionBusinessAllOfProperties carNumber(List<Integer> carNumber) {
    this.carNumber = carNumber;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("car_number")
  public List<Integer> getCarNumber() {
    return carNumber;
  }
  public void setCarNumber(List<Integer> carNumber) {
    this.carNumber = carNumber;
  }

  /**
   **/
  public BnhpDivisionBusinessAllOfProperties creditType(Integer creditType) {
    this.creditType = creditType;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("credit_type")
  public Integer getCreditType() {
    return creditType;
  }
  public void setCreditType(Integer creditType) {
    this.creditType = creditType;
  }

  /**
   **/
  public BnhpDivisionBusinessAllOfProperties depositNumber(List<Long> depositNumber) {
    this.depositNumber = depositNumber;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("deposit_number")
  public List<Long> getDepositNumber() {
    return depositNumber;
  }
  public void setDepositNumber(List<Long> depositNumber) {
    this.depositNumber = depositNumber;
  }

  /**
   **/
  public BnhpDivisionBusinessAllOfProperties expirationDate(Date expirationDate) {
    this.expirationDate = expirationDate;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("expiration_date")
  public Date getExpirationDate() {
    return expirationDate;
  }
  public void setExpirationDate(Date expirationDate) {
    this.expirationDate = expirationDate;
  }

  /**
   **/
  public BnhpDivisionBusinessAllOfProperties gushNumber(Integer gushNumber) {
    this.gushNumber = gushNumber;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("gush_number")
  public Integer getGushNumber() {
    return gushNumber;
  }
  public void setGushNumber(Integer gushNumber) {
    this.gushNumber = gushNumber;
  }

  /**
   **/
  public BnhpDivisionBusinessAllOfProperties helkaNumber(Long helkaNumber) {
    this.helkaNumber = helkaNumber;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("helka_number")
  public Long getHelkaNumber() {
    return helkaNumber;
  }
  public void setHelkaNumber(Long helkaNumber) {
    this.helkaNumber = helkaNumber;
  }

  /**
   **/
  public BnhpDivisionBusinessAllOfProperties numberBranchConfidence(Integer numberBranchConfidence) {
    this.numberBranchConfidence = numberBranchConfidence;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("number_branch_confidence")
  public Integer getNumberBranchConfidence() {
    return numberBranchConfidence;
  }
  public void setNumberBranchConfidence(Integer numberBranchConfidence) {
    this.numberBranchConfidence = numberBranchConfidence;
  }

  /**
   **/
  public BnhpDivisionBusinessAllOfProperties numberConfidence(Integer numberConfidence) {
    this.numberConfidence = numberConfidence;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("number_confidence")
  public Integer getNumberConfidence() {
    return numberConfidence;
  }
  public void setNumberConfidence(Integer numberConfidence) {
    this.numberConfidence = numberConfidence;
  }

  /**
   **/
  public BnhpDivisionBusinessAllOfProperties numberDeal(Integer numberDeal) {
    this.numberDeal = numberDeal;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("number_deal")
  public Integer getNumberDeal() {
    return numberDeal;
  }
  public void setNumberDeal(Integer numberDeal) {
    this.numberDeal = numberDeal;
  }

  /**
   **/
  public BnhpDivisionBusinessAllOfProperties originalDocument(Integer originalDocument) {
    this.originalDocument = originalDocument;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("original_document")
  public Integer getOriginalDocument() {
    return originalDocument;
  }
  public void setOriginalDocument(Integer originalDocument) {
    this.originalDocument = originalDocument;
  }

  /**
   **/
  public BnhpDivisionBusinessAllOfProperties propertyType(Integer propertyType) {
    this.propertyType = propertyType;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("property_type")
  public Integer getPropertyType() {
    return propertyType;
  }
  public void setPropertyType(Integer propertyType) {
    this.propertyType = propertyType;
  }

  /**
   **/
  public BnhpDivisionBusinessAllOfProperties serialNbrLoanGuarantee(Integer serialNbrLoanGuarantee) {
    this.serialNbrLoanGuarantee = serialNbrLoanGuarantee;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("serial_nbr_loan_guarantee")
  public Integer getSerialNbrLoanGuarantee() {
    return serialNbrLoanGuarantee;
  }
  public void setSerialNbrLoanGuarantee(Integer serialNbrLoanGuarantee) {
    this.serialNbrLoanGuarantee = serialNbrLoanGuarantee;
  }

  /**
   **/
  public BnhpDivisionBusinessAllOfProperties tathelkaNumber(Integer tathelkaNumber) {
    this.tathelkaNumber = tathelkaNumber;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("tathelka_number")
  public Integer getTathelkaNumber() {
    return tathelkaNumber;
  }
  public void setTathelkaNumber(Integer tathelkaNumber) {
    this.tathelkaNumber = tathelkaNumber;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    BnhpDivisionBusinessAllOfProperties bnhpDivisionBusinessAllOfProperties = (BnhpDivisionBusinessAllOfProperties) o;
    return Objects.equals(carNumber, bnhpDivisionBusinessAllOfProperties.carNumber) &&
        Objects.equals(creditType, bnhpDivisionBusinessAllOfProperties.creditType) &&
        Objects.equals(depositNumber, bnhpDivisionBusinessAllOfProperties.depositNumber) &&
        Objects.equals(expirationDate, bnhpDivisionBusinessAllOfProperties.expirationDate) &&
        Objects.equals(gushNumber, bnhpDivisionBusinessAllOfProperties.gushNumber) &&
        Objects.equals(helkaNumber, bnhpDivisionBusinessAllOfProperties.helkaNumber) &&
        Objects.equals(numberBranchConfidence, bnhpDivisionBusinessAllOfProperties.numberBranchConfidence) &&
        Objects.equals(numberConfidence, bnhpDivisionBusinessAllOfProperties.numberConfidence) &&
        Objects.equals(numberDeal, bnhpDivisionBusinessAllOfProperties.numberDeal) &&
        Objects.equals(originalDocument, bnhpDivisionBusinessAllOfProperties.originalDocument) &&
        Objects.equals(propertyType, bnhpDivisionBusinessAllOfProperties.propertyType) &&
        Objects.equals(serialNbrLoanGuarantee, bnhpDivisionBusinessAllOfProperties.serialNbrLoanGuarantee) &&
        Objects.equals(tathelkaNumber, bnhpDivisionBusinessAllOfProperties.tathelkaNumber);
  }

  @Override
  public int hashCode() {
    return Objects.hash(carNumber, creditType, depositNumber, expirationDate, gushNumber, helkaNumber, numberBranchConfidence, numberConfidence, numberDeal, originalDocument, propertyType, serialNbrLoanGuarantee, tathelkaNumber);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class BnhpDivisionBusinessAllOfProperties {\n");
    
    sb.append("    carNumber: ").append(toIndentedString(carNumber)).append("\n");
    sb.append("    creditType: ").append(toIndentedString(creditType)).append("\n");
    sb.append("    depositNumber: ").append(toIndentedString(depositNumber)).append("\n");
    sb.append("    expirationDate: ").append(toIndentedString(expirationDate)).append("\n");
    sb.append("    gushNumber: ").append(toIndentedString(gushNumber)).append("\n");
    sb.append("    helkaNumber: ").append(toIndentedString(helkaNumber)).append("\n");
    sb.append("    numberBranchConfidence: ").append(toIndentedString(numberBranchConfidence)).append("\n");
    sb.append("    numberConfidence: ").append(toIndentedString(numberConfidence)).append("\n");
    sb.append("    numberDeal: ").append(toIndentedString(numberDeal)).append("\n");
    sb.append("    originalDocument: ").append(toIndentedString(originalDocument)).append("\n");
    sb.append("    propertyType: ").append(toIndentedString(propertyType)).append("\n");
    sb.append("    serialNbrLoanGuarantee: ").append(toIndentedString(serialNbrLoanGuarantee)).append("\n");
    sb.append("    tathelkaNumber: ").append(toIndentedString(tathelkaNumber)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\BnhpDocFolderData.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import bnhp.dctmrest.model.BnhpDocFolderDataAllOf;
import bnhp.dctmrest.model.Customer;
import bnhp.dctmrest.model.DocumentData;
import bnhp.dctmrest.model.SysObjectData;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;
import java.util.ArrayList;
import java.util.Date;
import java.util.List;





@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class BnhpDocFolderData extends SysObjectData  {
  
  private List<Customer> customers = new ArrayList<>();
  private List<DocumentData> folderContent = new ArrayList<>();
  private Boolean isEmpty;

  /**
   **/
  public BnhpDocFolderData customers(List<Customer> customers) {
    this.customers = customers;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("customers")
  public List<Customer> getCustomers() {
    return customers;
  }
  public void setCustomers(List<Customer> customers) {
    this.customers = customers;
  }

  /**
   **/
  public BnhpDocFolderData folderContent(List<DocumentData> folderContent) {
    this.folderContent = folderContent;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("folderContent")
  public List<DocumentData> getFolderContent() {
    return folderContent;
  }
  public void setFolderContent(List<DocumentData> folderContent) {
    this.folderContent = folderContent;
  }

  /**
   **/
  public BnhpDocFolderData isEmpty(Boolean isEmpty) {
    this.isEmpty = isEmpty;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("isEmpty")
  public Boolean getIsEmpty() {
    return isEmpty;
  }
  public void setIsEmpty(Boolean isEmpty) {
    this.isEmpty = isEmpty;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    BnhpDocFolderData bnhpDocFolderData = (BnhpDocFolderData) o;
    return Objects.equals(customers, bnhpDocFolderData.customers) &&
        Objects.equals(folderContent, bnhpDocFolderData.folderContent) &&
        Objects.equals(isEmpty, bnhpDocFolderData.isEmpty);
  }

  @Override
  public int hashCode() {
    return Objects.hash(customers, folderContent, isEmpty);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class BnhpDocFolderData {\n");
    sb.append("    ").append(toIndentedString(super.toString())).append("\n");
    sb.append("    customers: ").append(toIndentedString(customers)).append("\n");
    sb.append("    folderContent: ").append(toIndentedString(folderContent)).append("\n");
    sb.append("    isEmpty: ").append(toIndentedString(isEmpty)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\BnhpDocFolderDataAllOf.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import bnhp.dctmrest.model.Customer;
import bnhp.dctmrest.model.DocumentData;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;
import java.util.ArrayList;
import java.util.List;





@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class BnhpDocFolderDataAllOf   {
  
  private List<Customer> customers = new ArrayList<>();
  private List<DocumentData> folderContent = new ArrayList<>();
  private Boolean isEmpty;

  /**
   **/
  public BnhpDocFolderDataAllOf customers(List<Customer> customers) {
    this.customers = customers;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("customers")
  public List<Customer> getCustomers() {
    return customers;
  }
  public void setCustomers(List<Customer> customers) {
    this.customers = customers;
  }

  /**
   **/
  public BnhpDocFolderDataAllOf folderContent(List<DocumentData> folderContent) {
    this.folderContent = folderContent;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("folderContent")
  public List<DocumentData> getFolderContent() {
    return folderContent;
  }
  public void setFolderContent(List<DocumentData> folderContent) {
    this.folderContent = folderContent;
  }

  /**
   **/
  public BnhpDocFolderDataAllOf isEmpty(Boolean isEmpty) {
    this.isEmpty = isEmpty;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("isEmpty")
  public Boolean getIsEmpty() {
    return isEmpty;
  }
  public void setIsEmpty(Boolean isEmpty) {
    this.isEmpty = isEmpty;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    BnhpDocFolderDataAllOf bnhpDocFolderDataAllOf = (BnhpDocFolderDataAllOf) o;
    return Objects.equals(customers, bnhpDocFolderDataAllOf.customers) &&
        Objects.equals(folderContent, bnhpDocFolderDataAllOf.folderContent) &&
        Objects.equals(isEmpty, bnhpDocFolderDataAllOf.isEmpty);
  }

  @Override
  public int hashCode() {
    return Objects.hash(customers, folderContent, isEmpty);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class BnhpDocFolderDataAllOf {\n");
    
    sb.append("    customers: ").append(toIndentedString(customers)).append("\n");
    sb.append("    folderContent: ").append(toIndentedString(folderContent)).append("\n");
    sb.append("    isEmpty: ").append(toIndentedString(isEmpty)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\BnhpGeneralDocData.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import bnhp.dctmrest.model.BnhpGeneralDocDataAllOf;
import bnhp.dctmrest.model.DocFile;
import bnhp.dctmrest.model.SysObjectData;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;
import java.util.ArrayList;
import java.util.Date;
import java.util.List;





@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class BnhpGeneralDocData extends SysObjectData  {
  
  private List<DocFile> docFiles = new ArrayList<>();
  private Date legacyDocumentEntryDttm;
  private String legacyDocumentId;
  private String owner;

  /**
   **/
  public BnhpGeneralDocData docFiles(List<DocFile> docFiles) {
    this.docFiles = docFiles;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("docFiles")
  public List<DocFile> getDocFiles() {
    return docFiles;
  }
  public void setDocFiles(List<DocFile> docFiles) {
    this.docFiles = docFiles;
  }

  /**
   **/
  public BnhpGeneralDocData legacyDocumentEntryDttm(Date legacyDocumentEntryDttm) {
    this.legacyDocumentEntryDttm = legacyDocumentEntryDttm;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("legacyDocumentEntryDttm")
  public Date getLegacyDocumentEntryDttm() {
    return legacyDocumentEntryDttm;
  }
  public void setLegacyDocumentEntryDttm(Date legacyDocumentEntryDttm) {
    this.legacyDocumentEntryDttm = legacyDocumentEntryDttm;
  }

  /**
   **/
  public BnhpGeneralDocData legacyDocumentId(String legacyDocumentId) {
    this.legacyDocumentId = legacyDocumentId;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("legacyDocumentId")
  public String getLegacyDocumentId() {
    return legacyDocumentId;
  }
  public void setLegacyDocumentId(String legacyDocumentId) {
    this.legacyDocumentId = legacyDocumentId;
  }

  /**
   **/
  public BnhpGeneralDocData owner(String owner) {
    this.owner = owner;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("owner")
  public String getOwner() {
    return owner;
  }
  public void setOwner(String owner) {
    this.owner = owner;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    BnhpGeneralDocData bnhpGeneralDocData = (BnhpGeneralDocData) o;
    return Objects.equals(docFiles, bnhpGeneralDocData.docFiles) &&
        Objects.equals(legacyDocumentEntryDttm, bnhpGeneralDocData.legacyDocumentEntryDttm) &&
        Objects.equals(legacyDocumentId, bnhpGeneralDocData.legacyDocumentId) &&
        Objects.equals(owner, bnhpGeneralDocData.owner);
  }

  @Override
  public int hashCode() {
    return Objects.hash(docFiles, legacyDocumentEntryDttm, legacyDocumentId, owner);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class BnhpGeneralDocData {\n");
    sb.append("    ").append(toIndentedString(super.toString())).append("\n");
    sb.append("    docFiles: ").append(toIndentedString(docFiles)).append("\n");
    sb.append("    legacyDocumentEntryDttm: ").append(toIndentedString(legacyDocumentEntryDttm)).append("\n");
    sb.append("    legacyDocumentId: ").append(toIndentedString(legacyDocumentId)).append("\n");
    sb.append("    owner: ").append(toIndentedString(owner)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\BnhpGeneralDocDataAllOf.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import bnhp.dctmrest.model.DocFile;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;
import java.util.ArrayList;
import java.util.Date;
import java.util.List;





@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class BnhpGeneralDocDataAllOf   {
  
  private List<DocFile> docFiles = new ArrayList<>();
  private Date legacyDocumentEntryDttm;
  private String legacyDocumentId;
  private String owner;

  /**
   **/
  public BnhpGeneralDocDataAllOf docFiles(List<DocFile> docFiles) {
    this.docFiles = docFiles;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("docFiles")
  public List<DocFile> getDocFiles() {
    return docFiles;
  }
  public void setDocFiles(List<DocFile> docFiles) {
    this.docFiles = docFiles;
  }

  /**
   **/
  public BnhpGeneralDocDataAllOf legacyDocumentEntryDttm(Date legacyDocumentEntryDttm) {
    this.legacyDocumentEntryDttm = legacyDocumentEntryDttm;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("legacyDocumentEntryDttm")
  public Date getLegacyDocumentEntryDttm() {
    return legacyDocumentEntryDttm;
  }
  public void setLegacyDocumentEntryDttm(Date legacyDocumentEntryDttm) {
    this.legacyDocumentEntryDttm = legacyDocumentEntryDttm;
  }

  /**
   **/
  public BnhpGeneralDocDataAllOf legacyDocumentId(String legacyDocumentId) {
    this.legacyDocumentId = legacyDocumentId;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("legacyDocumentId")
  public String getLegacyDocumentId() {
    return legacyDocumentId;
  }
  public void setLegacyDocumentId(String legacyDocumentId) {
    this.legacyDocumentId = legacyDocumentId;
  }

  /**
   **/
  public BnhpGeneralDocDataAllOf owner(String owner) {
    this.owner = owner;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("owner")
  public String getOwner() {
    return owner;
  }
  public void setOwner(String owner) {
    this.owner = owner;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    BnhpGeneralDocDataAllOf bnhpGeneralDocDataAllOf = (BnhpGeneralDocDataAllOf) o;
    return Objects.equals(docFiles, bnhpGeneralDocDataAllOf.docFiles) &&
        Objects.equals(legacyDocumentEntryDttm, bnhpGeneralDocDataAllOf.legacyDocumentEntryDttm) &&
        Objects.equals(legacyDocumentId, bnhpGeneralDocDataAllOf.legacyDocumentId) &&
        Objects.equals(owner, bnhpGeneralDocDataAllOf.owner);
  }

  @Override
  public int hashCode() {
    return Objects.hash(docFiles, legacyDocumentEntryDttm, legacyDocumentId, owner);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class BnhpGeneralDocDataAllOf {\n");
    
    sb.append("    docFiles: ").append(toIndentedString(docFiles)).append("\n");
    sb.append("    legacyDocumentEntryDttm: ").append(toIndentedString(legacyDocumentEntryDttm)).append("\n");
    sb.append("    legacyDocumentId: ").append(toIndentedString(legacyDocumentId)).append("\n");
    sb.append("    owner: ").append(toIndentedString(owner)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\BnhpPaperDoc.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import bnhp.dctmrest.model.BnhpPaperDocAllOf;
import bnhp.dctmrest.model.BnhpPaperDocAllOfProperties;
import bnhp.dctmrest.model.DocPropertyExtension;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;





@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class BnhpPaperDoc extends DocPropertyExtension  {
  
  private BnhpPaperDocAllOfProperties properties = null;

  /**
   **/
  public BnhpPaperDoc properties(BnhpPaperDocAllOfProperties properties) {
    this.properties = properties;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("properties")
  public BnhpPaperDocAllOfProperties getProperties() {
    return properties;
  }
  public void setProperties(BnhpPaperDocAllOfProperties properties) {
    this.properties = properties;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    BnhpPaperDoc bnhpPaperDoc = (BnhpPaperDoc) o;
    return Objects.equals(properties, bnhpPaperDoc.properties);
  }

  @Override
  public int hashCode() {
    return Objects.hash(properties);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class BnhpPaperDoc {\n");
    sb.append("    ").append(toIndentedString(super.toString())).append("\n");
    sb.append("    properties: ").append(toIndentedString(properties)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\BnhpPaperDocAllOf.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import bnhp.dctmrest.model.BnhpPaperDocAllOfProperties;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;



/**
 * extension for scanned documents
 **/

@ApiModel(description = "extension for scanned documents")
@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class BnhpPaperDocAllOf   {
  
  private BnhpPaperDocAllOfProperties properties = null;

  /**
   **/
  public BnhpPaperDocAllOf properties(BnhpPaperDocAllOfProperties properties) {
    this.properties = properties;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("properties")
  public BnhpPaperDocAllOfProperties getProperties() {
    return properties;
  }
  public void setProperties(BnhpPaperDocAllOfProperties properties) {
    this.properties = properties;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    BnhpPaperDocAllOf bnhpPaperDocAllOf = (BnhpPaperDocAllOf) o;
    return Objects.equals(properties, bnhpPaperDocAllOf.properties);
  }

  @Override
  public int hashCode() {
    return Objects.hash(properties);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class BnhpPaperDocAllOf {\n");
    
    sb.append("    properties: ").append(toIndentedString(properties)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\BnhpPaperDocAllOfProperties.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;
import java.util.Date;





@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class BnhpPaperDocAllOfProperties   {
  
  private Integer archiveBoxNbr;
  private Date archiveDate;
  private Integer archiveFilmNbr;
  private Integer bankArchiveId;
  private String barCode;
  private Integer boxBatchNbr;
  private Integer boxDocSerialNbr;
  private Integer docLocationCode;
  private Integer documentPageCnt;
  private Integer filmFrameNbr;
  private Date paperDestruction;

  /**
   **/
  public BnhpPaperDocAllOfProperties archiveBoxNbr(Integer archiveBoxNbr) {
    this.archiveBoxNbr = archiveBoxNbr;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("archive_box_nbr")
  public Integer getArchiveBoxNbr() {
    return archiveBoxNbr;
  }
  public void setArchiveBoxNbr(Integer archiveBoxNbr) {
    this.archiveBoxNbr = archiveBoxNbr;
  }

  /**
   **/
  public BnhpPaperDocAllOfProperties archiveDate(Date archiveDate) {
    this.archiveDate = archiveDate;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("archive_date")
  public Date getArchiveDate() {
    return archiveDate;
  }
  public void setArchiveDate(Date archiveDate) {
    this.archiveDate = archiveDate;
  }

  /**
   **/
  public BnhpPaperDocAllOfProperties archiveFilmNbr(Integer archiveFilmNbr) {
    this.archiveFilmNbr = archiveFilmNbr;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("archive_film_nbr")
  public Integer getArchiveFilmNbr() {
    return archiveFilmNbr;
  }
  public void setArchiveFilmNbr(Integer archiveFilmNbr) {
    this.archiveFilmNbr = archiveFilmNbr;
  }

  /**
   **/
  public BnhpPaperDocAllOfProperties bankArchiveId(Integer bankArchiveId) {
    this.bankArchiveId = bankArchiveId;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("bank_archive_id")
  public Integer getBankArchiveId() {
    return bankArchiveId;
  }
  public void setBankArchiveId(Integer bankArchiveId) {
    this.bankArchiveId = bankArchiveId;
  }

  /**
   **/
  public BnhpPaperDocAllOfProperties barCode(String barCode) {
    this.barCode = barCode;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("bar_code")
  public String getBarCode() {
    return barCode;
  }
  public void setBarCode(String barCode) {
    this.barCode = barCode;
  }

  /**
   **/
  public BnhpPaperDocAllOfProperties boxBatchNbr(Integer boxBatchNbr) {
    this.boxBatchNbr = boxBatchNbr;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("box_batch_nbr")
  public Integer getBoxBatchNbr() {
    return boxBatchNbr;
  }
  public void setBoxBatchNbr(Integer boxBatchNbr) {
    this.boxBatchNbr = boxBatchNbr;
  }

  /**
   **/
  public BnhpPaperDocAllOfProperties boxDocSerialNbr(Integer boxDocSerialNbr) {
    this.boxDocSerialNbr = boxDocSerialNbr;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("box_doc_serial_nbr")
  public Integer getBoxDocSerialNbr() {
    return boxDocSerialNbr;
  }
  public void setBoxDocSerialNbr(Integer boxDocSerialNbr) {
    this.boxDocSerialNbr = boxDocSerialNbr;
  }

  /**
   **/
  public BnhpPaperDocAllOfProperties docLocationCode(Integer docLocationCode) {
    this.docLocationCode = docLocationCode;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("doc_location_code")
  public Integer getDocLocationCode() {
    return docLocationCode;
  }
  public void setDocLocationCode(Integer docLocationCode) {
    this.docLocationCode = docLocationCode;
  }

  /**
   **/
  public BnhpPaperDocAllOfProperties documentPageCnt(Integer documentPageCnt) {
    this.documentPageCnt = documentPageCnt;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("document_page_cnt")
  public Integer getDocumentPageCnt() {
    return documentPageCnt;
  }
  public void setDocumentPageCnt(Integer documentPageCnt) {
    this.documentPageCnt = documentPageCnt;
  }

  /**
   **/
  public BnhpPaperDocAllOfProperties filmFrameNbr(Integer filmFrameNbr) {
    this.filmFrameNbr = filmFrameNbr;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("film_frame_nbr")
  public Integer getFilmFrameNbr() {
    return filmFrameNbr;
  }
  public void setFilmFrameNbr(Integer filmFrameNbr) {
    this.filmFrameNbr = filmFrameNbr;
  }

  /**
   **/
  public BnhpPaperDocAllOfProperties paperDestruction(Date paperDestruction) {
    this.paperDestruction = paperDestruction;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("paper_destruction")
  public Date getPaperDestruction() {
    return paperDestruction;
  }
  public void setPaperDestruction(Date paperDestruction) {
    this.paperDestruction = paperDestruction;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    BnhpPaperDocAllOfProperties bnhpPaperDocAllOfProperties = (BnhpPaperDocAllOfProperties) o;
    return Objects.equals(archiveBoxNbr, bnhpPaperDocAllOfProperties.archiveBoxNbr) &&
        Objects.equals(archiveDate, bnhpPaperDocAllOfProperties.archiveDate) &&
        Objects.equals(archiveFilmNbr, bnhpPaperDocAllOfProperties.archiveFilmNbr) &&
        Objects.equals(bankArchiveId, bnhpPaperDocAllOfProperties.bankArchiveId) &&
        Objects.equals(barCode, bnhpPaperDocAllOfProperties.barCode) &&
        Objects.equals(boxBatchNbr, bnhpPaperDocAllOfProperties.boxBatchNbr) &&
        Objects.equals(boxDocSerialNbr, bnhpPaperDocAllOfProperties.boxDocSerialNbr) &&
        Objects.equals(docLocationCode, bnhpPaperDocAllOfProperties.docLocationCode) &&
        Objects.equals(documentPageCnt, bnhpPaperDocAllOfProperties.documentPageCnt) &&
        Objects.equals(filmFrameNbr, bnhpPaperDocAllOfProperties.filmFrameNbr) &&
        Objects.equals(paperDestruction, bnhpPaperDocAllOfProperties.paperDestruction);
  }

  @Override
  public int hashCode() {
    return Objects.hash(archiveBoxNbr, archiveDate, archiveFilmNbr, bankArchiveId, barCode, boxBatchNbr, boxDocSerialNbr, docLocationCode, documentPageCnt, filmFrameNbr, paperDestruction);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class BnhpPaperDocAllOfProperties {\n");
    
    sb.append("    archiveBoxNbr: ").append(toIndentedString(archiveBoxNbr)).append("\n");
    sb.append("    archiveDate: ").append(toIndentedString(archiveDate)).append("\n");
    sb.append("    archiveFilmNbr: ").append(toIndentedString(archiveFilmNbr)).append("\n");
    sb.append("    bankArchiveId: ").append(toIndentedString(bankArchiveId)).append("\n");
    sb.append("    barCode: ").append(toIndentedString(barCode)).append("\n");
    sb.append("    boxBatchNbr: ").append(toIndentedString(boxBatchNbr)).append("\n");
    sb.append("    boxDocSerialNbr: ").append(toIndentedString(boxDocSerialNbr)).append("\n");
    sb.append("    docLocationCode: ").append(toIndentedString(docLocationCode)).append("\n");
    sb.append("    documentPageCnt: ").append(toIndentedString(documentPageCnt)).append("\n");
    sb.append("    filmFrameNbr: ").append(toIndentedString(filmFrameNbr)).append("\n");
    sb.append("    paperDestruction: ").append(toIndentedString(paperDestruction)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\Customer.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;





@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class Customer   {
  
  private String completeCustomerIdCode;
  private String customerFullName;
  private Long customerId;
  private Integer customerIdDocTypeCode;
  private Integer customerSerialNbr;
  private Boolean occasionalCustomerInd;

  /**
   **/
  public Customer completeCustomerIdCode(String completeCustomerIdCode) {
    this.completeCustomerIdCode = completeCustomerIdCode;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("completeCustomerIdCode")
  public String getCompleteCustomerIdCode() {
    return completeCustomerIdCode;
  }
  public void setCompleteCustomerIdCode(String completeCustomerIdCode) {
    this.completeCustomerIdCode = completeCustomerIdCode;
  }

  /**
   **/
  public Customer customerFullName(String customerFullName) {
    this.customerFullName = customerFullName;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("customerFullName")
  public String getCustomerFullName() {
    return customerFullName;
  }
  public void setCustomerFullName(String customerFullName) {
    this.customerFullName = customerFullName;
  }

  /**
   **/
  public Customer customerId(Long customerId) {
    this.customerId = customerId;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("customerId")
  public Long getCustomerId() {
    return customerId;
  }
  public void setCustomerId(Long customerId) {
    this.customerId = customerId;
  }

  /**
   * Type of customer:   1 -     4 -     5 -     6 -      7 -      8 -  
   **/
  public Customer customerIdDocTypeCode(Integer customerIdDocTypeCode) {
    this.customerIdDocTypeCode = customerIdDocTypeCode;
    return this;
  }

  
  @ApiModelProperty(value = "Type of customer:   1 -     4 -     5 -     6 -      7 -      8 -  ")
  @JsonProperty("customerIdDocTypeCode")
  public Integer getCustomerIdDocTypeCode() {
    return customerIdDocTypeCode;
  }
  public void setCustomerIdDocTypeCode(Integer customerIdDocTypeCode) {
    this.customerIdDocTypeCode = customerIdDocTypeCode;
  }

  /**
   **/
  public Customer customerSerialNbr(Integer customerSerialNbr) {
    this.customerSerialNbr = customerSerialNbr;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("customerSerialNbr")
  public Integer getCustomerSerialNbr() {
    return customerSerialNbr;
  }
  public void setCustomerSerialNbr(Integer customerSerialNbr) {
    this.customerSerialNbr = customerSerialNbr;
  }

  /**
   **/
  public Customer occasionalCustomerInd(Boolean occasionalCustomerInd) {
    this.occasionalCustomerInd = occasionalCustomerInd;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("occasionalCustomerInd")
  public Boolean getOccasionalCustomerInd() {
    return occasionalCustomerInd;
  }
  public void setOccasionalCustomerInd(Boolean occasionalCustomerInd) {
    this.occasionalCustomerInd = occasionalCustomerInd;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    Customer customer = (Customer) o;
    return Objects.equals(completeCustomerIdCode, customer.completeCustomerIdCode) &&
        Objects.equals(customerFullName, customer.customerFullName) &&
        Objects.equals(customerId, customer.customerId) &&
        Objects.equals(customerIdDocTypeCode, customer.customerIdDocTypeCode) &&
        Objects.equals(customerSerialNbr, customer.customerSerialNbr) &&
        Objects.equals(occasionalCustomerInd, customer.occasionalCustomerInd);
  }

  @Override
  public int hashCode() {
    return Objects.hash(completeCustomerIdCode, customerFullName, customerId, customerIdDocTypeCode, customerSerialNbr, occasionalCustomerInd);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class Customer {\n");
    
    sb.append("    completeCustomerIdCode: ").append(toIndentedString(completeCustomerIdCode)).append("\n");
    sb.append("    customerFullName: ").append(toIndentedString(customerFullName)).append("\n");
    sb.append("    customerId: ").append(toIndentedString(customerId)).append("\n");
    sb.append("    customerIdDocTypeCode: ").append(toIndentedString(customerIdDocTypeCode)).append("\n");
    sb.append("    customerSerialNbr: ").append(toIndentedString(customerSerialNbr)).append("\n");
    sb.append("    occasionalCustomerInd: ").append(toIndentedString(occasionalCustomerInd)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\DocCustomerData.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import bnhp.dctmrest.model.BankAccount;
import bnhp.dctmrest.model.Customer;
import bnhp.dctmrest.model.DocDetails;
import bnhp.dctmrest.model.ExecutorDetails;
import bnhp.dctmrest.model.PensionFund;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;
import java.util.ArrayList;
import java.util.List;





@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class DocCustomerData   {
  
  private List<BankAccount> bankAccounts = new ArrayList<>();
  private List<Customer> customers = new ArrayList<>();
  private DocDetails docDetails = null;
  private ExecutorDetails executorDetails = null;
  private PensionFund pensionFund = null;

  /**
   **/
  public DocCustomerData bankAccounts(List<BankAccount> bankAccounts) {
    this.bankAccounts = bankAccounts;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("bankAccounts")
  public List<BankAccount> getBankAccounts() {
    return bankAccounts;
  }
  public void setBankAccounts(List<BankAccount> bankAccounts) {
    this.bankAccounts = bankAccounts;
  }

  /**
   **/
  public DocCustomerData customers(List<Customer> customers) {
    this.customers = customers;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("customers")
  public List<Customer> getCustomers() {
    return customers;
  }
  public void setCustomers(List<Customer> customers) {
    this.customers = customers;
  }

  /**
   **/
  public DocCustomerData docDetails(DocDetails docDetails) {
    this.docDetails = docDetails;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("docDetails")
  public DocDetails getDocDetails() {
    return docDetails;
  }
  public void setDocDetails(DocDetails docDetails) {
    this.docDetails = docDetails;
  }

  /**
   **/
  public DocCustomerData executorDetails(ExecutorDetails executorDetails) {
    this.executorDetails = executorDetails;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("executorDetails")
  public ExecutorDetails getExecutorDetails() {
    return executorDetails;
  }
  public void setExecutorDetails(ExecutorDetails executorDetails) {
    this.executorDetails = executorDetails;
  }

  /**
   **/
  public DocCustomerData pensionFund(PensionFund pensionFund) {
    this.pensionFund = pensionFund;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("pensionFund")
  public PensionFund getPensionFund() {
    return pensionFund;
  }
  public void setPensionFund(PensionFund pensionFund) {
    this.pensionFund = pensionFund;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    DocCustomerData docCustomerData = (DocCustomerData) o;
    return Objects.equals(bankAccounts, docCustomerData.bankAccounts) &&
        Objects.equals(customers, docCustomerData.customers) &&
        Objects.equals(docDetails, docCustomerData.docDetails) &&
        Objects.equals(executorDetails, docCustomerData.executorDetails) &&
        Objects.equals(pensionFund, docCustomerData.pensionFund);
  }

  @Override
  public int hashCode() {
    return Objects.hash(bankAccounts, customers, docDetails, executorDetails, pensionFund);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class DocCustomerData {\n");
    
    sb.append("    bankAccounts: ").append(toIndentedString(bankAccounts)).append("\n");
    sb.append("    customers: ").append(toIndentedString(customers)).append("\n");
    sb.append("    docDetails: ").append(toIndentedString(docDetails)).append("\n");
    sb.append("    executorDetails: ").append(toIndentedString(executorDetails)).append("\n");
    sb.append("    pensionFund: ").append(toIndentedString(pensionFund)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\DocDetails.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;
import java.util.ArrayList;
import java.util.Date;
import java.util.List;





@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class DocDetails   {
  
  private Integer businessAreaCode;
  private Integer businessProcessId;
  private Integer businessSubAreaCode;
  private Integer channelId;
  private List<String> concatenatedEventIds = new ArrayList<>();
  private Integer currencyCode;
  private String dctmDocumentId;
  private Integer docCompletenessCode;
  private Integer docDeliveryNum;
  private Integer documentEditionNbr;
  private String documentFormId;
  private List<String> documentGroupIds = new ArrayList<>();
  private Date legacyDocumentEntryDttm;
  private String legacyDocumentId;
  private Integer ongoingOrHistoryCode;
  private Integer projectId;
  private Integer scanStatusCode;
  private Integer signatureStatusCode;
  private Integer systemCode;
  private Boolean templateDataExistsInd;
  private Double transactionAmt;

  /**
   **/
  public DocDetails businessAreaCode(Integer businessAreaCode) {
    this.businessAreaCode = businessAreaCode;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("businessAreaCode")
  public Integer getBusinessAreaCode() {
    return businessAreaCode;
  }
  public void setBusinessAreaCode(Integer businessAreaCode) {
    this.businessAreaCode = businessAreaCode;
  }

  /**
   **/
  public DocDetails businessProcessId(Integer businessProcessId) {
    this.businessProcessId = businessProcessId;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("businessProcessId")
  public Integer getBusinessProcessId() {
    return businessProcessId;
  }
  public void setBusinessProcessId(Integer businessProcessId) {
    this.businessProcessId = businessProcessId;
  }

  /**
   **/
  public DocDetails businessSubAreaCode(Integer businessSubAreaCode) {
    this.businessSubAreaCode = businessSubAreaCode;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("businessSubAreaCode")
  public Integer getBusinessSubAreaCode() {
    return businessSubAreaCode;
  }
  public void setBusinessSubAreaCode(Integer businessSubAreaCode) {
    this.businessSubAreaCode = businessSubAreaCode;
  }

  /**
   **/
  public DocDetails channelId(Integer channelId) {
    this.channelId = channelId;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("channelId")
  public Integer getChannelId() {
    return channelId;
  }
  public void setChannelId(Integer channelId) {
    this.channelId = channelId;
  }

  /**
   **/
  public DocDetails concatenatedEventIds(List<String> concatenatedEventIds) {
    this.concatenatedEventIds = concatenatedEventIds;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("concatenatedEventIds")
  public List<String> getConcatenatedEventIds() {
    return concatenatedEventIds;
  }
  public void setConcatenatedEventIds(List<String> concatenatedEventIds) {
    this.concatenatedEventIds = concatenatedEventIds;
  }

  /**
   **/
  public DocDetails currencyCode(Integer currencyCode) {
    this.currencyCode = currencyCode;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("currencyCode")
  public Integer getCurrencyCode() {
    return currencyCode;
  }
  public void setCurrencyCode(Integer currencyCode) {
    this.currencyCode = currencyCode;
  }

  /**
   **/
  public DocDetails dctmDocumentId(String dctmDocumentId) {
    this.dctmDocumentId = dctmDocumentId;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("dctmDocumentId")
  public String getDctmDocumentId() {
    return dctmDocumentId;
  }
  public void setDctmDocumentId(String dctmDocumentId) {
    this.dctmDocumentId = dctmDocumentId;
  }

  /**
   **/
  public DocDetails docCompletenessCode(Integer docCompletenessCode) {
    this.docCompletenessCode = docCompletenessCode;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("docCompletenessCode")
  public Integer getDocCompletenessCode() {
    return docCompletenessCode;
  }
  public void setDocCompletenessCode(Integer docCompletenessCode) {
    this.docCompletenessCode = docCompletenessCode;
  }

  /**
   **/
  public DocDetails docDeliveryNum(Integer docDeliveryNum) {
    this.docDeliveryNum = docDeliveryNum;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("docDeliveryNum")
  public Integer getDocDeliveryNum() {
    return docDeliveryNum;
  }
  public void setDocDeliveryNum(Integer docDeliveryNum) {
    this.docDeliveryNum = docDeliveryNum;
  }

  /**
   **/
  public DocDetails documentEditionNbr(Integer documentEditionNbr) {
    this.documentEditionNbr = documentEditionNbr;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("documentEditionNbr")
  public Integer getDocumentEditionNbr() {
    return documentEditionNbr;
  }
  public void setDocumentEditionNbr(Integer documentEditionNbr) {
    this.documentEditionNbr = documentEditionNbr;
  }

  /**
   **/
  public DocDetails documentFormId(String documentFormId) {
    this.documentFormId = documentFormId;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("documentFormId")
  public String getDocumentFormId() {
    return documentFormId;
  }
  public void setDocumentFormId(String documentFormId) {
    this.documentFormId = documentFormId;
  }

  /**
   **/
  public DocDetails documentGroupIds(List<String> documentGroupIds) {
    this.documentGroupIds = documentGroupIds;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("documentGroupIds")
  public List<String> getDocumentGroupIds() {
    return documentGroupIds;
  }
  public void setDocumentGroupIds(List<String> documentGroupIds) {
    this.documentGroupIds = documentGroupIds;
  }

  /**
   **/
  public DocDetails legacyDocumentEntryDttm(Date legacyDocumentEntryDttm) {
    this.legacyDocumentEntryDttm = legacyDocumentEntryDttm;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("legacyDocumentEntryDttm")
  public Date getLegacyDocumentEntryDttm() {
    return legacyDocumentEntryDttm;
  }
  public void setLegacyDocumentEntryDttm(Date legacyDocumentEntryDttm) {
    this.legacyDocumentEntryDttm = legacyDocumentEntryDttm;
  }

  /**
   **/
  public DocDetails legacyDocumentId(String legacyDocumentId) {
    this.legacyDocumentId = legacyDocumentId;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("legacyDocumentId")
  public String getLegacyDocumentId() {
    return legacyDocumentId;
  }
  public void setLegacyDocumentId(String legacyDocumentId) {
    this.legacyDocumentId = legacyDocumentId;
  }

  /**
   **/
  public DocDetails ongoingOrHistoryCode(Integer ongoingOrHistoryCode) {
    this.ongoingOrHistoryCode = ongoingOrHistoryCode;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("ongoingOrHistoryCode")
  public Integer getOngoingOrHistoryCode() {
    return ongoingOrHistoryCode;
  }
  public void setOngoingOrHistoryCode(Integer ongoingOrHistoryCode) {
    this.ongoingOrHistoryCode = ongoingOrHistoryCode;
  }

  /**
   **/
  public DocDetails projectId(Integer projectId) {
    this.projectId = projectId;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("projectId")
  public Integer getProjectId() {
    return projectId;
  }
  public void setProjectId(Integer projectId) {
    this.projectId = projectId;
  }

  /**
   **/
  public DocDetails scanStatusCode(Integer scanStatusCode) {
    this.scanStatusCode = scanStatusCode;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("scanStatusCode")
  public Integer getScanStatusCode() {
    return scanStatusCode;
  }
  public void setScanStatusCode(Integer scanStatusCode) {
    this.scanStatusCode = scanStatusCode;
  }

  /**
   **/
  public DocDetails signatureStatusCode(Integer signatureStatusCode) {
    this.signatureStatusCode = signatureStatusCode;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("signatureStatusCode")
  public Integer getSignatureStatusCode() {
    return signatureStatusCode;
  }
  public void setSignatureStatusCode(Integer signatureStatusCode) {
    this.signatureStatusCode = signatureStatusCode;
  }

  /**
   **/
  public DocDetails systemCode(Integer systemCode) {
    this.systemCode = systemCode;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("systemCode")
  public Integer getSystemCode() {
    return systemCode;
  }
  public void setSystemCode(Integer systemCode) {
    this.systemCode = systemCode;
  }

  /**
   **/
  public DocDetails templateDataExistsInd(Boolean templateDataExistsInd) {
    this.templateDataExistsInd = templateDataExistsInd;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("templateDataExistsInd")
  public Boolean getTemplateDataExistsInd() {
    return templateDataExistsInd;
  }
  public void setTemplateDataExistsInd(Boolean templateDataExistsInd) {
    this.templateDataExistsInd = templateDataExistsInd;
  }

  /**
   **/
  public DocDetails transactionAmt(Double transactionAmt) {
    this.transactionAmt = transactionAmt;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("transactionAmt")
  public Double getTransactionAmt() {
    return transactionAmt;
  }
  public void setTransactionAmt(Double transactionAmt) {
    this.transactionAmt = transactionAmt;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    DocDetails docDetails = (DocDetails) o;
    return Objects.equals(businessAreaCode, docDetails.businessAreaCode) &&
        Objects.equals(businessProcessId, docDetails.businessProcessId) &&
        Objects.equals(businessSubAreaCode, docDetails.businessSubAreaCode) &&
        Objects.equals(channelId, docDetails.channelId) &&
        Objects.equals(concatenatedEventIds, docDetails.concatenatedEventIds) &&
        Objects.equals(currencyCode, docDetails.currencyCode) &&
        Objects.equals(dctmDocumentId, docDetails.dctmDocumentId) &&
        Objects.equals(docCompletenessCode, docDetails.docCompletenessCode) &&
        Objects.equals(docDeliveryNum, docDetails.docDeliveryNum) &&
        Objects.equals(documentEditionNbr, docDetails.documentEditionNbr) &&
        Objects.equals(documentFormId, docDetails.documentFormId) &&
        Objects.equals(documentGroupIds, docDetails.documentGroupIds) &&
        Objects.equals(legacyDocumentEntryDttm, docDetails.legacyDocumentEntryDttm) &&
        Objects.equals(legacyDocumentId, docDetails.legacyDocumentId) &&
        Objects.equals(ongoingOrHistoryCode, docDetails.ongoingOrHistoryCode) &&
        Objects.equals(projectId, docDetails.projectId) &&
        Objects.equals(scanStatusCode, docDetails.scanStatusCode) &&
        Objects.equals(signatureStatusCode, docDetails.signatureStatusCode) &&
        Objects.equals(systemCode, docDetails.systemCode) &&
        Objects.equals(templateDataExistsInd, docDetails.templateDataExistsInd) &&
        Objects.equals(transactionAmt, docDetails.transactionAmt);
  }

  @Override
  public int hashCode() {
    return Objects.hash(businessAreaCode, businessProcessId, businessSubAreaCode, channelId, concatenatedEventIds, currencyCode, dctmDocumentId, docCompletenessCode, docDeliveryNum, documentEditionNbr, documentFormId, documentGroupIds, legacyDocumentEntryDttm, legacyDocumentId, ongoingOrHistoryCode, projectId, scanStatusCode, signatureStatusCode, systemCode, templateDataExistsInd, transactionAmt);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class DocDetails {\n");
    
    sb.append("    businessAreaCode: ").append(toIndentedString(businessAreaCode)).append("\n");
    sb.append("    businessProcessId: ").append(toIndentedString(businessProcessId)).append("\n");
    sb.append("    businessSubAreaCode: ").append(toIndentedString(businessSubAreaCode)).append("\n");
    sb.append("    channelId: ").append(toIndentedString(channelId)).append("\n");
    sb.append("    concatenatedEventIds: ").append(toIndentedString(concatenatedEventIds)).append("\n");
    sb.append("    currencyCode: ").append(toIndentedString(currencyCode)).append("\n");
    sb.append("    dctmDocumentId: ").append(toIndentedString(dctmDocumentId)).append("\n");
    sb.append("    docCompletenessCode: ").append(toIndentedString(docCompletenessCode)).append("\n");
    sb.append("    docDeliveryNum: ").append(toIndentedString(docDeliveryNum)).append("\n");
    sb.append("    documentEditionNbr: ").append(toIndentedString(documentEditionNbr)).append("\n");
    sb.append("    documentFormId: ").append(toIndentedString(documentFormId)).append("\n");
    sb.append("    documentGroupIds: ").append(toIndentedString(documentGroupIds)).append("\n");
    sb.append("    legacyDocumentEntryDttm: ").append(toIndentedString(legacyDocumentEntryDttm)).append("\n");
    sb.append("    legacyDocumentId: ").append(toIndentedString(legacyDocumentId)).append("\n");
    sb.append("    ongoingOrHistoryCode: ").append(toIndentedString(ongoingOrHistoryCode)).append("\n");
    sb.append("    projectId: ").append(toIndentedString(projectId)).append("\n");
    sb.append("    scanStatusCode: ").append(toIndentedString(scanStatusCode)).append("\n");
    sb.append("    signatureStatusCode: ").append(toIndentedString(signatureStatusCode)).append("\n");
    sb.append("    systemCode: ").append(toIndentedString(systemCode)).append("\n");
    sb.append("    templateDataExistsInd: ").append(toIndentedString(templateDataExistsInd)).append("\n");
    sb.append("    transactionAmt: ").append(toIndentedString(transactionAmt)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\DocFile.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;
import java.util.HashMap;
import java.util.List;
import java.util.Map;





@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class DocFile   {
  
  private Map<String, Object> attributes = new HashMap<>();
  private String checkSum;
  private String classifier;
  private String docFormat;
  private Long docSize;
  private byte[] docStream;
  private String docURL;
  private String dosExtension;
  private String mimeType;

  /**
   **/
  public DocFile attributes(Map<String, Object> attributes) {
    this.attributes = attributes;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("attributes")
  public Map<String, Object> getAttributes() {
    return attributes;
  }
  public void setAttributes(Map<String, Object> attributes) {
    this.attributes = attributes;
  }

  /**
   **/
  public DocFile checkSum(String checkSum) {
    this.checkSum = checkSum;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("checkSum")
  public String getCheckSum() {
    return checkSum;
  }
  public void setCheckSum(String checkSum) {
    this.checkSum = checkSum;
  }

  /**
   * Content file classifier. Currently primary content has no classifier, secondary content (printboss job) has classifier \\\"secondary\\\". In the future other classifiers may be used.
   **/
  public DocFile classifier(String classifier) {
    this.classifier = classifier;
    return this;
  }

  
  @ApiModelProperty(value = "Content file classifier. Currently primary content has no classifier, secondary content (printboss job) has classifier \\\"secondary\\\". In the future other classifiers may be used.")
  @JsonProperty("classifier")
  public String getClassifier() {
    return classifier;
  }
  public void setClassifier(String classifier) {
    this.classifier = classifier;
  }

  /**
   **/
  public DocFile docFormat(String docFormat) {
    this.docFormat = docFormat;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("docFormat")
  public String getDocFormat() {
    return docFormat;
  }
  public void setDocFormat(String docFormat) {
    this.docFormat = docFormat;
  }

  /**
   **/
  public DocFile docSize(Long docSize) {
    this.docSize = docSize;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("docSize")
  public Long getDocSize() {
    return docSize;
  }
  public void setDocSize(Long docSize) {
    this.docSize = docSize;
  }

  /**
   **/
  public DocFile docStream(byte[] docStream) {
    this.docStream = docStream;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("docStream")
  public byte[] getDocStream() {
    return docStream;
  }
  public void setDocStream(byte[] docStream) {
    this.docStream = docStream;
  }

  /**
   **/
  public DocFile docURL(String docURL) {
    this.docURL = docURL;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("docURL")
  public String getDocURL() {
    return docURL;
  }
  public void setDocURL(String docURL) {
    this.docURL = docURL;
  }

  /**
   **/
  public DocFile dosExtension(String dosExtension) {
    this.dosExtension = dosExtension;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("dosExtension")
  public String getDosExtension() {
    return dosExtension;
  }
  public void setDosExtension(String dosExtension) {
    this.dosExtension = dosExtension;
  }

  /**
   **/
  public DocFile mimeType(String mimeType) {
    this.mimeType = mimeType;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("mimeType")
  public String getMimeType() {
    return mimeType;
  }
  public void setMimeType(String mimeType) {
    this.mimeType = mimeType;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    DocFile docFile = (DocFile) o;
    return Objects.equals(attributes, docFile.attributes) &&
        Objects.equals(checkSum, docFile.checkSum) &&
        Objects.equals(classifier, docFile.classifier) &&
        Objects.equals(docFormat, docFile.docFormat) &&
        Objects.equals(docSize, docFile.docSize) &&
        Objects.equals(docStream, docFile.docStream) &&
        Objects.equals(docURL, docFile.docURL) &&
        Objects.equals(dosExtension, docFile.dosExtension) &&
        Objects.equals(mimeType, docFile.mimeType);
  }

  @Override
  public int hashCode() {
    return Objects.hash(attributes, checkSum, classifier, docFormat, docSize, docStream, docURL, dosExtension, mimeType);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class DocFile {\n");
    
    sb.append("    attributes: ").append(toIndentedString(attributes)).append("\n");
    sb.append("    checkSum: ").append(toIndentedString(checkSum)).append("\n");
    sb.append("    classifier: ").append(toIndentedString(classifier)).append("\n");
    sb.append("    docFormat: ").append(toIndentedString(docFormat)).append("\n");
    sb.append("    docSize: ").append(toIndentedString(docSize)).append("\n");
    sb.append("    docStream: ").append(toIndentedString(docStream)).append("\n");
    sb.append("    docURL: ").append(toIndentedString(docURL)).append("\n");
    sb.append("    dosExtension: ").append(toIndentedString(dosExtension)).append("\n");
    sb.append("    mimeType: ").append(toIndentedString(mimeType)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\DocIdData.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;
import java.util.ArrayList;
import java.util.List;





@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class DocIdData   {
  
  private String dctmDocumentId;
  private List<String> versionLabels = new ArrayList<>();
  private String versionNumber;

  /**
   **/
  public DocIdData dctmDocumentId(String dctmDocumentId) {
    this.dctmDocumentId = dctmDocumentId;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("dctmDocumentId")
  public String getDctmDocumentId() {
    return dctmDocumentId;
  }
  public void setDctmDocumentId(String dctmDocumentId) {
    this.dctmDocumentId = dctmDocumentId;
  }

  /**
   **/
  public DocIdData versionLabels(List<String> versionLabels) {
    this.versionLabels = versionLabels;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("versionLabels")
  public List<String> getVersionLabels() {
    return versionLabels;
  }
  public void setVersionLabels(List<String> versionLabels) {
    this.versionLabels = versionLabels;
  }

  /**
   **/
  public DocIdData versionNumber(String versionNumber) {
    this.versionNumber = versionNumber;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("versionNumber")
  public String getVersionNumber() {
    return versionNumber;
  }
  public void setVersionNumber(String versionNumber) {
    this.versionNumber = versionNumber;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    DocIdData docIdData = (DocIdData) o;
    return Objects.equals(dctmDocumentId, docIdData.dctmDocumentId) &&
        Objects.equals(versionLabels, docIdData.versionLabels) &&
        Objects.equals(versionNumber, docIdData.versionNumber);
  }

  @Override
  public int hashCode() {
    return Objects.hash(dctmDocumentId, versionLabels, versionNumber);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class DocIdData {\n");
    
    sb.append("    dctmDocumentId: ").append(toIndentedString(dctmDocumentId)).append("\n");
    sb.append("    versionLabels: ").append(toIndentedString(versionLabels)).append("\n");
    sb.append("    versionNumber: ").append(toIndentedString(versionNumber)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\DocPropertyExtension.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;





@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class DocPropertyExtension   {
  
  private String name;

  /**
   **/
  public DocPropertyExtension name(String name) {
    this.name = name;
    return this;
  }

  
  @ApiModelProperty(required = true, value = "")
  @JsonProperty("name")
  public String getName() {
    return name;
  }
  public void setName(String name) {
    this.name = name;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    DocPropertyExtension docPropertyExtension = (DocPropertyExtension) o;
    return Objects.equals(name, docPropertyExtension.name);
  }

  @Override
  public int hashCode() {
    return Objects.hash(name);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class DocPropertyExtension {\n");
    
    sb.append("    name: ").append(toIndentedString(name)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\DocumentData.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import bnhp.dctmrest.model.BnhpCustomerDocData;
import bnhp.dctmrest.model.BnhpDocFolderData;
import bnhp.dctmrest.model.BnhpGeneralDocData;
import bnhp.dctmrest.model.Customer;
import bnhp.dctmrest.model.DocCustomerData;
import bnhp.dctmrest.model.DocFile;
import bnhp.dctmrest.model.DocumentData;
import bnhp.dctmrest.model.OneOfbnhpPaperDocbnhpCorporateDocbnhpDivisionBusiness;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;
import java.util.ArrayList;
import java.util.Date;
import java.util.List;





@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class DocumentData   {
  
  private Date creationTime;
  private Date lastUpdateTime;
  private String objectName;
  private String objectType;
  private List<String> paths = new ArrayList<>();
  private List<String> versionLabels = new ArrayList<>();
  private DocCustomerData docCustomerData = null;
  private List<DocFile> docFiles = new ArrayList<>();
  private List<OneOfbnhpPaperDocbnhpCorporateDocbnhpDivisionBusiness> extensions = new ArrayList<>();
  private Date legacyDocumentEntryDttm;
  private String legacyDocumentId;
  private String owner;
  private List<Customer> customers = new ArrayList<>();
  private List<DocumentData> folderContent = new ArrayList<>();
  private Boolean isEmpty;

  /**
   **/
  public DocumentData creationTime(Date creationTime) {
    this.creationTime = creationTime;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("creationTime")
  public Date getCreationTime() {
    return creationTime;
  }
  public void setCreationTime(Date creationTime) {
    this.creationTime = creationTime;
  }

  /**
   **/
  public DocumentData lastUpdateTime(Date lastUpdateTime) {
    this.lastUpdateTime = lastUpdateTime;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("lastUpdateTime")
  public Date getLastUpdateTime() {
    return lastUpdateTime;
  }
  public void setLastUpdateTime(Date lastUpdateTime) {
    this.lastUpdateTime = lastUpdateTime;
  }

  /**
   * Object name.
   **/
  public DocumentData objectName(String objectName) {
    this.objectName = objectName;
    return this;
  }

  
  @ApiModelProperty(value = "Object name.")
  @JsonProperty("objectName")
  public String getObjectName() {
    return objectName;
  }
  public void setObjectName(String objectName) {
    this.objectName = objectName;
  }

  /**
   **/
  public DocumentData objectType(String objectType) {
    this.objectType = objectType;
    return this;
  }

  
  @ApiModelProperty(required = true, value = "")
  @JsonProperty("objectType")
  public String getObjectType() {
    return objectType;
  }
  public void setObjectType(String objectType) {
    this.objectType = objectType;
  }

  /**
   * List of absolute paths of folders the object is linked to
   **/
  public DocumentData paths(List<String> paths) {
    this.paths = paths;
    return this;
  }

  
  @ApiModelProperty(value = "List of absolute paths of folders the object is linked to")
  @JsonProperty("paths")
  public List<String> getPaths() {
    return paths;
  }
  public void setPaths(List<String> paths) {
    this.paths = paths;
  }

  /**
   **/
  public DocumentData versionLabels(List<String> versionLabels) {
    this.versionLabels = versionLabels;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("versionLabels")
  public List<String> getVersionLabels() {
    return versionLabels;
  }
  public void setVersionLabels(List<String> versionLabels) {
    this.versionLabels = versionLabels;
  }

  /**
   **/
  public DocumentData docCustomerData(DocCustomerData docCustomerData) {
    this.docCustomerData = docCustomerData;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("docCustomerData")
  public DocCustomerData getDocCustomerData() {
    return docCustomerData;
  }
  public void setDocCustomerData(DocCustomerData docCustomerData) {
    this.docCustomerData = docCustomerData;
  }

  /**
   **/
  public DocumentData docFiles(List<DocFile> docFiles) {
    this.docFiles = docFiles;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("docFiles")
  public List<DocFile> getDocFiles() {
    return docFiles;
  }
  public void setDocFiles(List<DocFile> docFiles) {
    this.docFiles = docFiles;
  }

  /**
   **/
  public DocumentData extensions(List<OneOfbnhpPaperDocbnhpCorporateDocbnhpDivisionBusiness> extensions) {
    this.extensions = extensions;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("extensions")
  public List<OneOfbnhpPaperDocbnhpCorporateDocbnhpDivisionBusiness> getExtensions() {
    return extensions;
  }
  public void setExtensions(List<OneOfbnhpPaperDocbnhpCorporateDocbnhpDivisionBusiness> extensions) {
    this.extensions = extensions;
  }

  /**
   **/
  public DocumentData legacyDocumentEntryDttm(Date legacyDocumentEntryDttm) {
    this.legacyDocumentEntryDttm = legacyDocumentEntryDttm;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("legacyDocumentEntryDttm")
  public Date getLegacyDocumentEntryDttm() {
    return legacyDocumentEntryDttm;
  }
  public void setLegacyDocumentEntryDttm(Date legacyDocumentEntryDttm) {
    this.legacyDocumentEntryDttm = legacyDocumentEntryDttm;
  }

  /**
   **/
  public DocumentData legacyDocumentId(String legacyDocumentId) {
    this.legacyDocumentId = legacyDocumentId;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("legacyDocumentId")
  public String getLegacyDocumentId() {
    return legacyDocumentId;
  }
  public void setLegacyDocumentId(String legacyDocumentId) {
    this.legacyDocumentId = legacyDocumentId;
  }

  /**
   **/
  public DocumentData owner(String owner) {
    this.owner = owner;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("owner")
  public String getOwner() {
    return owner;
  }
  public void setOwner(String owner) {
    this.owner = owner;
  }

  /**
   **/
  public DocumentData customers(List<Customer> customers) {
    this.customers = customers;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("customers")
  public List<Customer> getCustomers() {
    return customers;
  }
  public void setCustomers(List<Customer> customers) {
    this.customers = customers;
  }

  /**
   **/
  public DocumentData folderContent(List<DocumentData> folderContent) {
    this.folderContent = folderContent;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("folderContent")
  public List<DocumentData> getFolderContent() {
    return folderContent;
  }
  public void setFolderContent(List<DocumentData> folderContent) {
    this.folderContent = folderContent;
  }

  /**
   **/
  public DocumentData isEmpty(Boolean isEmpty) {
    this.isEmpty = isEmpty;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("isEmpty")
  public Boolean getIsEmpty() {
    return isEmpty;
  }
  public void setIsEmpty(Boolean isEmpty) {
    this.isEmpty = isEmpty;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    DocumentData documentData = (DocumentData) o;
    return Objects.equals(creationTime, documentData.creationTime) &&
        Objects.equals(lastUpdateTime, documentData.lastUpdateTime) &&
        Objects.equals(objectName, documentData.objectName) &&
        Objects.equals(objectType, documentData.objectType) &&
        Objects.equals(paths, documentData.paths) &&
        Objects.equals(versionLabels, documentData.versionLabels) &&
        Objects.equals(docCustomerData, documentData.docCustomerData) &&
        Objects.equals(docFiles, documentData.docFiles) &&
        Objects.equals(extensions, documentData.extensions) &&
        Objects.equals(legacyDocumentEntryDttm, documentData.legacyDocumentEntryDttm) &&
        Objects.equals(legacyDocumentId, documentData.legacyDocumentId) &&
        Objects.equals(owner, documentData.owner) &&
        Objects.equals(customers, documentData.customers) &&
        Objects.equals(folderContent, documentData.folderContent) &&
        Objects.equals(isEmpty, documentData.isEmpty);
  }

  @Override
  public int hashCode() {
    return Objects.hash(creationTime, lastUpdateTime, objectName, objectType, paths, versionLabels, docCustomerData, docFiles, extensions, legacyDocumentEntryDttm, legacyDocumentId, owner, customers, folderContent, isEmpty);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class DocumentData {\n");
    
    sb.append("    creationTime: ").append(toIndentedString(creationTime)).append("\n");
    sb.append("    lastUpdateTime: ").append(toIndentedString(lastUpdateTime)).append("\n");
    sb.append("    objectName: ").append(toIndentedString(objectName)).append("\n");
    sb.append("    objectType: ").append(toIndentedString(objectType)).append("\n");
    sb.append("    paths: ").append(toIndentedString(paths)).append("\n");
    sb.append("    versionLabels: ").append(toIndentedString(versionLabels)).append("\n");
    sb.append("    docCustomerData: ").append(toIndentedString(docCustomerData)).append("\n");
    sb.append("    docFiles: ").append(toIndentedString(docFiles)).append("\n");
    sb.append("    extensions: ").append(toIndentedString(extensions)).append("\n");
    sb.append("    legacyDocumentEntryDttm: ").append(toIndentedString(legacyDocumentEntryDttm)).append("\n");
    sb.append("    legacyDocumentId: ").append(toIndentedString(legacyDocumentId)).append("\n");
    sb.append("    owner: ").append(toIndentedString(owner)).append("\n");
    sb.append("    customers: ").append(toIndentedString(customers)).append("\n");
    sb.append("    folderContent: ").append(toIndentedString(folderContent)).append("\n");
    sb.append("    isEmpty: ").append(toIndentedString(isEmpty)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\DocumentFormData.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import bnhp.dctmrest.model.DocumentData;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;





@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class DocumentFormData   {
  
  private DocumentData documentData = null;

  /**
   **/
  public DocumentFormData documentData(DocumentData documentData) {
    this.documentData = documentData;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("documentData")
  public DocumentData getDocumentData() {
    return documentData;
  }
  public void setDocumentData(DocumentData documentData) {
    this.documentData = documentData;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    DocumentFormData documentFormData = (DocumentFormData) o;
    return Objects.equals(documentData, documentFormData.documentData);
  }

  @Override
  public int hashCode() {
    return Objects.hash(documentData);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class DocumentFormData {\n");
    
    sb.append("    documentData: ").append(toIndentedString(documentData)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\ErrorDetails.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import com.fasterxml.jackson.annotation.JsonValue;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;





@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class ErrorDetails   {
  
  private Integer errorCode;
  private String errorDetails;


  public enum ErrorTypeEnum {
    TEMPORARY("temporary"),
    VALIDATION("validation"),
    GENERAL("general");

    private String value;

    ErrorTypeEnum(String value) {
      this.value = value;
    }

    @Override
    @JsonValue
    public String toString() {
      return value;
    }
  }

  private ErrorTypeEnum errorType;

  /**
   **/
  public ErrorDetails errorCode(Integer errorCode) {
    this.errorCode = errorCode;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("errorCode")
  public Integer getErrorCode() {
    return errorCode;
  }
  public void setErrorCode(Integer errorCode) {
    this.errorCode = errorCode;
  }

  /**
   **/
  public ErrorDetails errorDetails(String errorDetails) {
    this.errorDetails = errorDetails;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("errorDetails")
  public String getErrorDetails() {
    return errorDetails;
  }
  public void setErrorDetails(String errorDetails) {
    this.errorDetails = errorDetails;
  }

  /**
   **/
  public ErrorDetails errorType(ErrorTypeEnum errorType) {
    this.errorType = errorType;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("errorType")
  public ErrorTypeEnum getErrorType() {
    return errorType;
  }
  public void setErrorType(ErrorTypeEnum errorType) {
    this.errorType = errorType;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    ErrorDetails errorDetails = (ErrorDetails) o;
    return Objects.equals(errorCode, errorDetails.errorCode) &&
        Objects.equals(errorDetails, errorDetails.errorDetails) &&
        Objects.equals(errorType, errorDetails.errorType);
  }

  @Override
  public int hashCode() {
    return Objects.hash(errorCode, errorDetails, errorType);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class ErrorDetails {\n");
    
    sb.append("    errorCode: ").append(toIndentedString(errorCode)).append("\n");
    sb.append("    errorDetails: ").append(toIndentedString(errorDetails)).append("\n");
    sb.append("    errorType: ").append(toIndentedString(errorType)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\ExecutorDetails.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;





@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class ExecutorDetails   {
  
  private Integer bankolId;
  private Integer empIdDocumentTypeCode;
  private Integer executingBankId;
  private Integer executingBranchId;
  private String executingEmpFullName;
  private String executingEmpIdCode;
  private String executingUserName;
  private Integer instructionReceiveTypeCode;
  private String ipAddress;
  private Integer terminalChannelId;

  /**
   **/
  public ExecutorDetails bankolId(Integer bankolId) {
    this.bankolId = bankolId;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("bankolId")
  public Integer getBankolId() {
    return bankolId;
  }
  public void setBankolId(Integer bankolId) {
    this.bankolId = bankolId;
  }

  /**
   * Type of customer:   1 -     4 -     5 -     6 -      7 -      8 -  
   **/
  public ExecutorDetails empIdDocumentTypeCode(Integer empIdDocumentTypeCode) {
    this.empIdDocumentTypeCode = empIdDocumentTypeCode;
    return this;
  }

  
  @ApiModelProperty(value = "Type of customer:   1 -     4 -     5 -     6 -      7 -      8 -  ")
  @JsonProperty("empIdDocumentTypeCode")
  public Integer getEmpIdDocumentTypeCode() {
    return empIdDocumentTypeCode;
  }
  public void setEmpIdDocumentTypeCode(Integer empIdDocumentTypeCode) {
    this.empIdDocumentTypeCode = empIdDocumentTypeCode;
  }

  /**
   **/
  public ExecutorDetails executingBankId(Integer executingBankId) {
    this.executingBankId = executingBankId;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("executingBankId")
  public Integer getExecutingBankId() {
    return executingBankId;
  }
  public void setExecutingBankId(Integer executingBankId) {
    this.executingBankId = executingBankId;
  }

  /**
   **/
  public ExecutorDetails executingBranchId(Integer executingBranchId) {
    this.executingBranchId = executingBranchId;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("executingBranchId")
  public Integer getExecutingBranchId() {
    return executingBranchId;
  }
  public void setExecutingBranchId(Integer executingBranchId) {
    this.executingBranchId = executingBranchId;
  }

  /**
   **/
  public ExecutorDetails executingEmpFullName(String executingEmpFullName) {
    this.executingEmpFullName = executingEmpFullName;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("executingEmpFullName")
  public String getExecutingEmpFullName() {
    return executingEmpFullName;
  }
  public void setExecutingEmpFullName(String executingEmpFullName) {
    this.executingEmpFullName = executingEmpFullName;
  }

  /**
   **/
  public ExecutorDetails executingEmpIdCode(String executingEmpIdCode) {
    this.executingEmpIdCode = executingEmpIdCode;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("executingEmpIdCode")
  public String getExecutingEmpIdCode() {
    return executingEmpIdCode;
  }
  public void setExecutingEmpIdCode(String executingEmpIdCode) {
    this.executingEmpIdCode = executingEmpIdCode;
  }

  /**
   **/
  public ExecutorDetails executingUserName(String executingUserName) {
    this.executingUserName = executingUserName;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("executingUserName")
  public String getExecutingUserName() {
    return executingUserName;
  }
  public void setExecutingUserName(String executingUserName) {
    this.executingUserName = executingUserName;
  }

  /**
   **/
  public ExecutorDetails instructionReceiveTypeCode(Integer instructionReceiveTypeCode) {
    this.instructionReceiveTypeCode = instructionReceiveTypeCode;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("instructionReceiveTypeCode")
  public Integer getInstructionReceiveTypeCode() {
    return instructionReceiveTypeCode;
  }
  public void setInstructionReceiveTypeCode(Integer instructionReceiveTypeCode) {
    this.instructionReceiveTypeCode = instructionReceiveTypeCode;
  }

  /**
   **/
  public ExecutorDetails ipAddress(String ipAddress) {
    this.ipAddress = ipAddress;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("ipAddress")
  public String getIpAddress() {
    return ipAddress;
  }
  public void setIpAddress(String ipAddress) {
    this.ipAddress = ipAddress;
  }

  /**
   **/
  public ExecutorDetails terminalChannelId(Integer terminalChannelId) {
    this.terminalChannelId = terminalChannelId;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("terminalChannelId")
  public Integer getTerminalChannelId() {
    return terminalChannelId;
  }
  public void setTerminalChannelId(Integer terminalChannelId) {
    this.terminalChannelId = terminalChannelId;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    ExecutorDetails executorDetails = (ExecutorDetails) o;
    return Objects.equals(bankolId, executorDetails.bankolId) &&
        Objects.equals(empIdDocumentTypeCode, executorDetails.empIdDocumentTypeCode) &&
        Objects.equals(executingBankId, executorDetails.executingBankId) &&
        Objects.equals(executingBranchId, executorDetails.executingBranchId) &&
        Objects.equals(executingEmpFullName, executorDetails.executingEmpFullName) &&
        Objects.equals(executingEmpIdCode, executorDetails.executingEmpIdCode) &&
        Objects.equals(executingUserName, executorDetails.executingUserName) &&
        Objects.equals(instructionReceiveTypeCode, executorDetails.instructionReceiveTypeCode) &&
        Objects.equals(ipAddress, executorDetails.ipAddress) &&
        Objects.equals(terminalChannelId, executorDetails.terminalChannelId);
  }

  @Override
  public int hashCode() {
    return Objects.hash(bankolId, empIdDocumentTypeCode, executingBankId, executingBranchId, executingEmpFullName, executingEmpIdCode, executingUserName, instructionReceiveTypeCode, ipAddress, terminalChannelId);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class ExecutorDetails {\n");
    
    sb.append("    bankolId: ").append(toIndentedString(bankolId)).append("\n");
    sb.append("    empIdDocumentTypeCode: ").append(toIndentedString(empIdDocumentTypeCode)).append("\n");
    sb.append("    executingBankId: ").append(toIndentedString(executingBankId)).append("\n");
    sb.append("    executingBranchId: ").append(toIndentedString(executingBranchId)).append("\n");
    sb.append("    executingEmpFullName: ").append(toIndentedString(executingEmpFullName)).append("\n");
    sb.append("    executingEmpIdCode: ").append(toIndentedString(executingEmpIdCode)).append("\n");
    sb.append("    executingUserName: ").append(toIndentedString(executingUserName)).append("\n");
    sb.append("    instructionReceiveTypeCode: ").append(toIndentedString(instructionReceiveTypeCode)).append("\n");
    sb.append("    ipAddress: ").append(toIndentedString(ipAddress)).append("\n");
    sb.append("    terminalChannelId: ").append(toIndentedString(terminalChannelId)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\FetchType.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import io.swagger.annotations.ApiModel;
import com.fasterxml.jackson.annotation.JsonValue;
import com.fasterxml.jackson.annotation.JsonCreator;



/**
 * Kind of data to be retrieved. If not set and Accept header is received then the standard HTTP content negotiation mechanism will be used. The default is to retrieve object content.   * content - binary content for documents, list of entries for folders   * meta - object metadata (attributes)   * full  - both content and attributes
 **/

/**
* Kind of data to be retrieved. If not set and Accept header is received then the standard HTTP content negotiation mechanism will be used. The default is to retrieve object content.   * content - binary content for documents, list of entries for folders   * meta - object metadata (attributes)   * full  - both content and attributes
*/
public enum FetchType {
    
        FULL("full"),
        
        CONTENT("content"),
        
        META("meta");

private String value;

FetchType(String value) {
this.value = value;
}

@Override
@JsonValue
public String toString() {
return String.valueOf(value);
}

@JsonCreator
public static FetchType fromValue(String text) {
for (FetchType b : FetchType.values()) {
if (String.valueOf(b.value).equals(text)) {
return b;
}
}
throw new IllegalArgumentException("Unexpected value '" + text + "'");
}
}




file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\IdType.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import io.swagger.annotations.ApiModel;
import com.fasterxml.jackson.annotation.JsonValue;
import com.fasterxml.jackson.annotation.JsonCreator;



/**
 * type of unique object id:   * legacyDocumentId - external, created by service user   * dctmDocumentId - internal, created automatically by service
 **/

/**
* type of unique object id:   * legacyDocumentId - external, created by service user   * dctmDocumentId - internal, created automatically by service
*/
public enum IdType {
    
        LEGACYDOCUMENTID("legacyDocumentId"),
        
        DCTMDOCUMENTID("dctmDocumentId");

private String value;

IdType(String value) {
this.value = value;
}

@Override
@JsonValue
public String toString() {
return String.valueOf(value);
}

@JsonCreator
public static IdType fromValue(String text) {
for (IdType b : IdType.values()) {
if (String.valueOf(b.value).equals(text)) {
return b;
}
}
throw new IllegalArgumentException("Unexpected value '" + text + "'");
}
}




file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\InlineObject4.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import bnhp.dctmrest.model.ExecutorDetails;
import bnhp.dctmrest.model.FetchType;
import bnhp.dctmrest.model.PagingDefinition;
import bnhp.dctmrest.model.SearchSearchCustomerDocumentsAccounts;
import bnhp.dctmrest.model.SearchSearchCustomerDocumentsCustomers;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;
import java.util.ArrayList;
import java.util.Date;
import java.util.List;





@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class InlineObject4   {
  
  private List<SearchSearchCustomerDocumentsAccounts> accounts = new ArrayList<>();
  private List<SearchSearchCustomerDocumentsCustomers> customers = new ArrayList<>();
  private String dosExtension;
  private Date endDate;
  private ExecutorDetails executorDetails = null;
  private FetchType fetchType = FetchType.CONTENT;
  private String fulltext;
  private PagingDefinition pagingDefinitions = null;
  private List<Object> sortByFields = new ArrayList<>();
  private Date startDate;

  /**
   **/
  public InlineObject4 accounts(List<SearchSearchCustomerDocumentsAccounts> accounts) {
    this.accounts = accounts;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("accounts")
  public List<SearchSearchCustomerDocumentsAccounts> getAccounts() {
    return accounts;
  }
  public void setAccounts(List<SearchSearchCustomerDocumentsAccounts> accounts) {
    this.accounts = accounts;
  }

  /**
   **/
  public InlineObject4 customers(List<SearchSearchCustomerDocumentsCustomers> customers) {
    this.customers = customers;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("customers")
  public List<SearchSearchCustomerDocumentsCustomers> getCustomers() {
    return customers;
  }
  public void setCustomers(List<SearchSearchCustomerDocumentsCustomers> customers) {
    this.customers = customers;
  }

  /**
   **/
  public InlineObject4 dosExtension(String dosExtension) {
    this.dosExtension = dosExtension;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("dosExtension")
  public String getDosExtension() {
    return dosExtension;
  }
  public void setDosExtension(String dosExtension) {
    this.dosExtension = dosExtension;
  }

  /**
   **/
  public InlineObject4 endDate(Date endDate) {
    this.endDate = endDate;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("endDate")
  public Date getEndDate() {
    return endDate;
  }
  public void setEndDate(Date endDate) {
    this.endDate = endDate;
  }

  /**
   **/
  public InlineObject4 executorDetails(ExecutorDetails executorDetails) {
    this.executorDetails = executorDetails;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("executorDetails")
  public ExecutorDetails getExecutorDetails() {
    return executorDetails;
  }
  public void setExecutorDetails(ExecutorDetails executorDetails) {
    this.executorDetails = executorDetails;
  }

  /**
   **/
  public InlineObject4 fetchType(FetchType fetchType) {
    this.fetchType = fetchType;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("fetchType")
  public FetchType getFetchType() {
    return fetchType;
  }
  public void setFetchType(FetchType fetchType) {
    this.fetchType = fetchType;
  }

  /**
   **/
  public InlineObject4 fulltext(String fulltext) {
    this.fulltext = fulltext;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("fulltext")
  public String getFulltext() {
    return fulltext;
  }
  public void setFulltext(String fulltext) {
    this.fulltext = fulltext;
  }

  /**
   **/
  public InlineObject4 pagingDefinitions(PagingDefinition pagingDefinitions) {
    this.pagingDefinitions = pagingDefinitions;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("pagingDefinitions")
  public PagingDefinition getPagingDefinitions() {
    return pagingDefinitions;
  }
  public void setPagingDefinitions(PagingDefinition pagingDefinitions) {
    this.pagingDefinitions = pagingDefinitions;
  }

  /**
   * list of fields to sort by them
   **/
  public InlineObject4 sortByFields(List<Object> sortByFields) {
    this.sortByFields = sortByFields;
    return this;
  }

  
  @ApiModelProperty(value = "list of fields to sort by them")
  @JsonProperty("sortByFields")
  public List<Object> getSortByFields() {
    return sortByFields;
  }
  public void setSortByFields(List<Object> sortByFields) {
    this.sortByFields = sortByFields;
  }

  /**
   **/
  public InlineObject4 startDate(Date startDate) {
    this.startDate = startDate;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("startDate")
  public Date getStartDate() {
    return startDate;
  }
  public void setStartDate(Date startDate) {
    this.startDate = startDate;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    InlineObject4 inlineObject4 = (InlineObject4) o;
    return Objects.equals(accounts, inlineObject4.accounts) &&
        Objects.equals(customers, inlineObject4.customers) &&
        Objects.equals(dosExtension, inlineObject4.dosExtension) &&
        Objects.equals(endDate, inlineObject4.endDate) &&
        Objects.equals(executorDetails, inlineObject4.executorDetails) &&
        Objects.equals(fetchType, inlineObject4.fetchType) &&
        Objects.equals(fulltext, inlineObject4.fulltext) &&
        Objects.equals(pagingDefinitions, inlineObject4.pagingDefinitions) &&
        Objects.equals(sortByFields, inlineObject4.sortByFields) &&
        Objects.equals(startDate, inlineObject4.startDate);
  }

  @Override
  public int hashCode() {
    return Objects.hash(accounts, customers, dosExtension, endDate, executorDetails, fetchType, fulltext, pagingDefinitions, sortByFields, startDate);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class InlineObject4 {\n");
    
    sb.append("    accounts: ").append(toIndentedString(accounts)).append("\n");
    sb.append("    customers: ").append(toIndentedString(customers)).append("\n");
    sb.append("    dosExtension: ").append(toIndentedString(dosExtension)).append("\n");
    sb.append("    endDate: ").append(toIndentedString(endDate)).append("\n");
    sb.append("    executorDetails: ").append(toIndentedString(executorDetails)).append("\n");
    sb.append("    fetchType: ").append(toIndentedString(fetchType)).append("\n");
    sb.append("    fulltext: ").append(toIndentedString(fulltext)).append("\n");
    sb.append("    pagingDefinitions: ").append(toIndentedString(pagingDefinitions)).append("\n");
    sb.append("    sortByFields: ").append(toIndentedString(sortByFields)).append("\n");
    sb.append("    startDate: ").append(toIndentedString(startDate)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\InlineResponse200.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import bnhp.dctmrest.model.DocumentData;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;
import java.util.ArrayList;
import java.util.List;





@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class InlineResponse200   {
  
  private Long estimatedTotal;
  private List<DocumentData> objects = new ArrayList<>();
  private Long startIndex;

  /**
   **/
  public InlineResponse200 estimatedTotal(Long estimatedTotal) {
    this.estimatedTotal = estimatedTotal;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("estimatedTotal")
  public Long getEstimatedTotal() {
    return estimatedTotal;
  }
  public void setEstimatedTotal(Long estimatedTotal) {
    this.estimatedTotal = estimatedTotal;
  }

  /**
   **/
  public InlineResponse200 objects(List<DocumentData> objects) {
    this.objects = objects;
    return this;
  }

  
  @ApiModelProperty(required = true, value = "")
  @JsonProperty("objects")
  public List<DocumentData> getObjects() {
    return objects;
  }
  public void setObjects(List<DocumentData> objects) {
    this.objects = objects;
  }

  /**
   **/
  public InlineResponse200 startIndex(Long startIndex) {
    this.startIndex = startIndex;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("startIndex")
  public Long getStartIndex() {
    return startIndex;
  }
  public void setStartIndex(Long startIndex) {
    this.startIndex = startIndex;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    InlineResponse200 inlineResponse200 = (InlineResponse200) o;
    return Objects.equals(estimatedTotal, inlineResponse200.estimatedTotal) &&
        Objects.equals(objects, inlineResponse200.objects) &&
        Objects.equals(startIndex, inlineResponse200.startIndex);
  }

  @Override
  public int hashCode() {
    return Objects.hash(estimatedTotal, objects, startIndex);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class InlineResponse200 {\n");
    
    sb.append("    estimatedTotal: ").append(toIndentedString(estimatedTotal)).append("\n");
    sb.append("    objects: ").append(toIndentedString(objects)).append("\n");
    sb.append("    startIndex: ").append(toIndentedString(startIndex)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\InlineResponse202.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;





@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class InlineResponse202   {
  
  private String correlationId;

  /**
   **/
  public InlineResponse202 correlationId(String correlationId) {
    this.correlationId = correlationId;
    return this;
  }

  
  @ApiModelProperty(required = true, value = "")
  @JsonProperty("correlationId")
  public String getCorrelationId() {
    return correlationId;
  }
  public void setCorrelationId(String correlationId) {
    this.correlationId = correlationId;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    InlineResponse202 inlineResponse202 = (InlineResponse202) o;
    return Objects.equals(correlationId, inlineResponse202.correlationId);
  }

  @Override
  public int hashCode() {
    return Objects.hash(correlationId);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class InlineResponse202 {\n");
    
    sb.append("    correlationId: ").append(toIndentedString(correlationId)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\PagingDefinition.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;





@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class PagingDefinition   {
  
  private Integer maxResultCount = 25;
  private Boolean shouldReturnTotalResults = false;
  private Long startIndex = 0l;

  /**
   **/
  public PagingDefinition maxResultCount(Integer maxResultCount) {
    this.maxResultCount = maxResultCount;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("maxResultCount")
  public Integer getMaxResultCount() {
    return maxResultCount;
  }
  public void setMaxResultCount(Integer maxResultCount) {
    this.maxResultCount = maxResultCount;
  }

  /**
   **/
  public PagingDefinition shouldReturnTotalResults(Boolean shouldReturnTotalResults) {
    this.shouldReturnTotalResults = shouldReturnTotalResults;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("shouldReturnTotalResults")
  public Boolean getShouldReturnTotalResults() {
    return shouldReturnTotalResults;
  }
  public void setShouldReturnTotalResults(Boolean shouldReturnTotalResults) {
    this.shouldReturnTotalResults = shouldReturnTotalResults;
  }

  /**
   **/
  public PagingDefinition startIndex(Long startIndex) {
    this.startIndex = startIndex;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("startIndex")
  public Long getStartIndex() {
    return startIndex;
  }
  public void setStartIndex(Long startIndex) {
    this.startIndex = startIndex;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    PagingDefinition pagingDefinition = (PagingDefinition) o;
    return Objects.equals(maxResultCount, pagingDefinition.maxResultCount) &&
        Objects.equals(shouldReturnTotalResults, pagingDefinition.shouldReturnTotalResults) &&
        Objects.equals(startIndex, pagingDefinition.startIndex);
  }

  @Override
  public int hashCode() {
    return Objects.hash(maxResultCount, shouldReturnTotalResults, startIndex);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class PagingDefinition {\n");
    
    sb.append("    maxResultCount: ").append(toIndentedString(maxResultCount)).append("\n");
    sb.append("    shouldReturnTotalResults: ").append(toIndentedString(shouldReturnTotalResults)).append("\n");
    sb.append("    startIndex: ").append(toIndentedString(startIndex)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\PensionFund.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;





@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class PensionFund   {
  
  private Integer pensionFundNbr;
  private Integer planholderNumber;

  /**
   **/
  public PensionFund pensionFundNbr(Integer pensionFundNbr) {
    this.pensionFundNbr = pensionFundNbr;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("pensionFundNbr")
  public Integer getPensionFundNbr() {
    return pensionFundNbr;
  }
  public void setPensionFundNbr(Integer pensionFundNbr) {
    this.pensionFundNbr = pensionFundNbr;
  }

  /**
   **/
  public PensionFund planholderNumber(Integer planholderNumber) {
    this.planholderNumber = planholderNumber;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("planholderNumber")
  public Integer getPlanholderNumber() {
    return planholderNumber;
  }
  public void setPlanholderNumber(Integer planholderNumber) {
    this.planholderNumber = planholderNumber;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    PensionFund pensionFund = (PensionFund) o;
    return Objects.equals(pensionFundNbr, pensionFund.pensionFundNbr) &&
        Objects.equals(planholderNumber, pensionFund.planholderNumber);
  }

  @Override
  public int hashCode() {
    return Objects.hash(pensionFundNbr, planholderNumber);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class PensionFund {\n");
    
    sb.append("    pensionFundNbr: ").append(toIndentedString(pensionFundNbr)).append("\n");
    sb.append("    planholderNumber: ").append(toIndentedString(planholderNumber)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\RequestCountDocumentPagesRequestParameters.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import bnhp.dctmrest.model.OneOfstringarray;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;





@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class RequestCountDocumentPagesRequestParameters   {
  
  private OneOfstringarray documents = null;
  private String dosExtension;
  private String targetURL;

  /**
   **/
  public RequestCountDocumentPagesRequestParameters documents(OneOfstringarray documents) {
    this.documents = documents;
    return this;
  }

  
  @ApiModelProperty(required = true, value = "")
  @JsonProperty("documents")
  public OneOfstringarray getDocuments() {
    return documents;
  }
  public void setDocuments(OneOfstringarray documents) {
    this.documents = documents;
  }

  /**
   * Extension of content format to be used. If not set pdf will be used.
   **/
  public RequestCountDocumentPagesRequestParameters dosExtension(String dosExtension) {
    this.dosExtension = dosExtension;
    return this;
  }

  
  @ApiModelProperty(value = "Extension of content format to be used. If not set pdf will be used.")
  @JsonProperty("dosExtension")
  public String getDosExtension() {
    return dosExtension;
  }
  public void setDosExtension(String dosExtension) {
    this.dosExtension = dosExtension;
  }

  /**
   * URL of output file. If not set the service will attempt to return data array in response
   **/
  public RequestCountDocumentPagesRequestParameters targetURL(String targetURL) {
    this.targetURL = targetURL;
    return this;
  }

  
  @ApiModelProperty(value = "URL of output file. If not set the service will attempt to return data array in response")
  @JsonProperty("targetURL")
  public String getTargetURL() {
    return targetURL;
  }
  public void setTargetURL(String targetURL) {
    this.targetURL = targetURL;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    RequestCountDocumentPagesRequestParameters requestCountDocumentPagesRequestParameters = (RequestCountDocumentPagesRequestParameters) o;
    return Objects.equals(documents, requestCountDocumentPagesRequestParameters.documents) &&
        Objects.equals(dosExtension, requestCountDocumentPagesRequestParameters.dosExtension) &&
        Objects.equals(targetURL, requestCountDocumentPagesRequestParameters.targetURL);
  }

  @Override
  public int hashCode() {
    return Objects.hash(documents, dosExtension, targetURL);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class RequestCountDocumentPagesRequestParameters {\n");
    
    sb.append("    documents: ").append(toIndentedString(documents)).append("\n");
    sb.append("    dosExtension: ").append(toIndentedString(dosExtension)).append("\n");
    sb.append("    targetURL: ").append(toIndentedString(targetURL)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\RequestRetrieveFilesByZipRequestParameters.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import bnhp.dctmrest.model.OneOfstringarray;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import com.fasterxml.jackson.annotation.JsonValue;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;





@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class RequestRetrieveFilesByZipRequestParameters   {
  
  private OneOfstringarray documents = null;
  private String dosExtension;


  public enum FileNameSourceEnum {
    LEGACYDOCUMENTID("legacyDocumentId"),
    DCTMDOCUMENTID("dctmDocumentId"),
    EXPLICIT("explicit");

    private String value;

    FileNameSourceEnum(String value) {
      this.value = value;
    }

    @Override
    @JsonValue
    public String toString() {
      return value;
    }
  }

  private FileNameSourceEnum fileNameSource;
  private String targetStatusURL;
  private String targetURL;

  /**
   **/
  public RequestRetrieveFilesByZipRequestParameters documents(OneOfstringarray documents) {
    this.documents = documents;
    return this;
  }

  
  @ApiModelProperty(required = true, value = "")
  @JsonProperty("documents")
  public OneOfstringarray getDocuments() {
    return documents;
  }
  public void setDocuments(OneOfstringarray documents) {
    this.documents = documents;
  }

  /**
   * extension of content format to be retrieved
   **/
  public RequestRetrieveFilesByZipRequestParameters dosExtension(String dosExtension) {
    this.dosExtension = dosExtension;
    return this;
  }

  
  @ApiModelProperty(value = "extension of content format to be retrieved")
  @JsonProperty("dosExtension")
  public String getDosExtension() {
    return dosExtension;
  }
  public void setDosExtension(String dosExtension) {
    this.dosExtension = dosExtension;
  }

  /**
   * Source of names for zip file entries: * legacyDocumentId - from document legacyDocumentId * dctmDocumentId - from document dctmDocumentId * explicit - from the name attribute in DocumentsSourceList entries
   **/
  public RequestRetrieveFilesByZipRequestParameters fileNameSource(FileNameSourceEnum fileNameSource) {
    this.fileNameSource = fileNameSource;
    return this;
  }

  
  @ApiModelProperty(value = "Source of names for zip file entries: * legacyDocumentId - from document legacyDocumentId * dctmDocumentId - from document dctmDocumentId * explicit - from the name attribute in DocumentsSourceList entries")
  @JsonProperty("fileNameSource")
  public FileNameSourceEnum getFileNameSource() {
    return fileNameSource;
  }
  public void setFileNameSource(FileNameSourceEnum fileNameSource) {
    this.fileNameSource = fileNameSource;
  }

  /**
   * URL of file with array of document statuses. If not given the service will return the array in the response. File format is same as DocumentsStatusList
   **/
  public RequestRetrieveFilesByZipRequestParameters targetStatusURL(String targetStatusURL) {
    this.targetStatusURL = targetStatusURL;
    return this;
  }

  
  @ApiModelProperty(value = "URL of file with array of document statuses. If not given the service will return the array in the response. File format is same as DocumentsStatusList")
  @JsonProperty("targetStatusURL")
  public String getTargetStatusURL() {
    return targetStatusURL;
  }
  public void setTargetStatusURL(String targetStatusURL) {
    this.targetStatusURL = targetStatusURL;
  }

  /**
   * URL of target zip file. If not set the service will attempt to return zip in response
   **/
  public RequestRetrieveFilesByZipRequestParameters targetURL(String targetURL) {
    this.targetURL = targetURL;
    return this;
  }

  
  @ApiModelProperty(value = "URL of target zip file. If not set the service will attempt to return zip in response")
  @JsonProperty("targetURL")
  public String getTargetURL() {
    return targetURL;
  }
  public void setTargetURL(String targetURL) {
    this.targetURL = targetURL;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    RequestRetrieveFilesByZipRequestParameters requestRetrieveFilesByZipRequestParameters = (RequestRetrieveFilesByZipRequestParameters) o;
    return Objects.equals(documents, requestRetrieveFilesByZipRequestParameters.documents) &&
        Objects.equals(dosExtension, requestRetrieveFilesByZipRequestParameters.dosExtension) &&
        Objects.equals(fileNameSource, requestRetrieveFilesByZipRequestParameters.fileNameSource) &&
        Objects.equals(targetStatusURL, requestRetrieveFilesByZipRequestParameters.targetStatusURL) &&
        Objects.equals(targetURL, requestRetrieveFilesByZipRequestParameters.targetURL);
  }

  @Override
  public int hashCode() {
    return Objects.hash(documents, dosExtension, fileNameSource, targetStatusURL, targetURL);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class RequestRetrieveFilesByZipRequestParameters {\n");
    
    sb.append("    documents: ").append(toIndentedString(documents)).append("\n");
    sb.append("    dosExtension: ").append(toIndentedString(dosExtension)).append("\n");
    sb.append("    fileNameSource: ").append(toIndentedString(fileNameSource)).append("\n");
    sb.append("    targetStatusURL: ").append(toIndentedString(targetStatusURL)).append("\n");
    sb.append("    targetURL: ").append(toIndentedString(targetURL)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\RetrieveFormat.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;





@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class RetrieveFormat   {
  
  private String docFormat;
  private String dosExtension;
  private String mimeType;

  /**
   **/
  public RetrieveFormat docFormat(String docFormat) {
    this.docFormat = docFormat;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("docFormat")
  public String getDocFormat() {
    return docFormat;
  }
  public void setDocFormat(String docFormat) {
    this.docFormat = docFormat;
  }

  /**
   **/
  public RetrieveFormat dosExtension(String dosExtension) {
    this.dosExtension = dosExtension;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("dosExtension")
  public String getDosExtension() {
    return dosExtension;
  }
  public void setDosExtension(String dosExtension) {
    this.dosExtension = dosExtension;
  }

  /**
   **/
  public RetrieveFormat mimeType(String mimeType) {
    this.mimeType = mimeType;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("mimeType")
  public String getMimeType() {
    return mimeType;
  }
  public void setMimeType(String mimeType) {
    this.mimeType = mimeType;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    RetrieveFormat retrieveFormat = (RetrieveFormat) o;
    return Objects.equals(docFormat, retrieveFormat.docFormat) &&
        Objects.equals(dosExtension, retrieveFormat.dosExtension) &&
        Objects.equals(mimeType, retrieveFormat.mimeType);
  }

  @Override
  public int hashCode() {
    return Objects.hash(docFormat, dosExtension, mimeType);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class RetrieveFormat {\n");
    
    sb.append("    docFormat: ").append(toIndentedString(docFormat)).append("\n");
    sb.append("    dosExtension: ").append(toIndentedString(dosExtension)).append("\n");
    sb.append("    mimeType: ").append(toIndentedString(mimeType)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\SearchSearchCustomerDocumentsAccounts.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;





@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class SearchSearchCustomerDocumentsAccounts   {
  
  private Integer accountBankId;
  private Integer accountNumber;
  private Integer branchId;

  /**
   **/
  public SearchSearchCustomerDocumentsAccounts accountBankId(Integer accountBankId) {
    this.accountBankId = accountBankId;
    return this;
  }

  
  @ApiModelProperty(required = true, value = "")
  @JsonProperty("accountBankId")
  public Integer getAccountBankId() {
    return accountBankId;
  }
  public void setAccountBankId(Integer accountBankId) {
    this.accountBankId = accountBankId;
  }

  /**
   **/
  public SearchSearchCustomerDocumentsAccounts accountNumber(Integer accountNumber) {
    this.accountNumber = accountNumber;
    return this;
  }

  
  @ApiModelProperty(required = true, value = "")
  @JsonProperty("accountNumber")
  public Integer getAccountNumber() {
    return accountNumber;
  }
  public void setAccountNumber(Integer accountNumber) {
    this.accountNumber = accountNumber;
  }

  /**
   **/
  public SearchSearchCustomerDocumentsAccounts branchId(Integer branchId) {
    this.branchId = branchId;
    return this;
  }

  
  @ApiModelProperty(required = true, value = "")
  @JsonProperty("branchId")
  public Integer getBranchId() {
    return branchId;
  }
  public void setBranchId(Integer branchId) {
    this.branchId = branchId;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    SearchSearchCustomerDocumentsAccounts searchSearchCustomerDocumentsAccounts = (SearchSearchCustomerDocumentsAccounts) o;
    return Objects.equals(accountBankId, searchSearchCustomerDocumentsAccounts.accountBankId) &&
        Objects.equals(accountNumber, searchSearchCustomerDocumentsAccounts.accountNumber) &&
        Objects.equals(branchId, searchSearchCustomerDocumentsAccounts.branchId);
  }

  @Override
  public int hashCode() {
    return Objects.hash(accountBankId, accountNumber, branchId);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class SearchSearchCustomerDocumentsAccounts {\n");
    
    sb.append("    accountBankId: ").append(toIndentedString(accountBankId)).append("\n");
    sb.append("    accountNumber: ").append(toIndentedString(accountNumber)).append("\n");
    sb.append("    branchId: ").append(toIndentedString(branchId)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\SearchSearchCustomerDocumentsCustomers.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;





@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class SearchSearchCustomerDocumentsCustomers   {
  
  private String entityId;
  private Integer entityType;

  /**
   **/
  public SearchSearchCustomerDocumentsCustomers entityId(String entityId) {
    this.entityId = entityId;
    return this;
  }

  
  @ApiModelProperty(required = true, value = "")
  @JsonProperty("entityId")
  public String getEntityId() {
    return entityId;
  }
  public void setEntityId(String entityId) {
    this.entityId = entityId;
  }

  /**
   * Type of customer:   1 -     4 -     5 -     6 -      7 -      8 -  
   **/
  public SearchSearchCustomerDocumentsCustomers entityType(Integer entityType) {
    this.entityType = entityType;
    return this;
  }

  
  @ApiModelProperty(value = "Type of customer:   1 -     4 -     5 -     6 -      7 -      8 -  ")
  @JsonProperty("entityType")
  public Integer getEntityType() {
    return entityType;
  }
  public void setEntityType(Integer entityType) {
    this.entityType = entityType;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    SearchSearchCustomerDocumentsCustomers searchSearchCustomerDocumentsCustomers = (SearchSearchCustomerDocumentsCustomers) o;
    return Objects.equals(entityId, searchSearchCustomerDocumentsCustomers.entityId) &&
        Objects.equals(entityType, searchSearchCustomerDocumentsCustomers.entityType);
  }

  @Override
  public int hashCode() {
    return Objects.hash(entityId, entityType);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class SearchSearchCustomerDocumentsCustomers {\n");
    
    sb.append("    entityId: ").append(toIndentedString(entityId)).append("\n");
    sb.append("    entityType: ").append(toIndentedString(entityType)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\SearchSearchDocumentsByIdsSearchParameters.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import bnhp.dctmrest.model.FetchType;
import bnhp.dctmrest.model.PagingDefinition;
import bnhp.dctmrest.model.SearchSearchDocumentsByIdsSearchParametersDocumentIds;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;
import java.util.ArrayList;
import java.util.List;





@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class SearchSearchDocumentsByIdsSearchParameters   {
  
  private List<SearchSearchDocumentsByIdsSearchParametersDocumentIds> documentIds = new ArrayList<>();
  private FetchType fetchType = FetchType.CONTENT;
  private PagingDefinition pagingDefinitions = null;

  /**
   **/
  public SearchSearchDocumentsByIdsSearchParameters documentIds(List<SearchSearchDocumentsByIdsSearchParametersDocumentIds> documentIds) {
    this.documentIds = documentIds;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("documentIds")
  public List<SearchSearchDocumentsByIdsSearchParametersDocumentIds> getDocumentIds() {
    return documentIds;
  }
  public void setDocumentIds(List<SearchSearchDocumentsByIdsSearchParametersDocumentIds> documentIds) {
    this.documentIds = documentIds;
  }

  /**
   **/
  public SearchSearchDocumentsByIdsSearchParameters fetchType(FetchType fetchType) {
    this.fetchType = fetchType;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("fetchType")
  public FetchType getFetchType() {
    return fetchType;
  }
  public void setFetchType(FetchType fetchType) {
    this.fetchType = fetchType;
  }

  /**
   **/
  public SearchSearchDocumentsByIdsSearchParameters pagingDefinitions(PagingDefinition pagingDefinitions) {
    this.pagingDefinitions = pagingDefinitions;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("pagingDefinitions")
  public PagingDefinition getPagingDefinitions() {
    return pagingDefinitions;
  }
  public void setPagingDefinitions(PagingDefinition pagingDefinitions) {
    this.pagingDefinitions = pagingDefinitions;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    SearchSearchDocumentsByIdsSearchParameters searchSearchDocumentsByIdsSearchParameters = (SearchSearchDocumentsByIdsSearchParameters) o;
    return Objects.equals(documentIds, searchSearchDocumentsByIdsSearchParameters.documentIds) &&
        Objects.equals(fetchType, searchSearchDocumentsByIdsSearchParameters.fetchType) &&
        Objects.equals(pagingDefinitions, searchSearchDocumentsByIdsSearchParameters.pagingDefinitions);
  }

  @Override
  public int hashCode() {
    return Objects.hash(documentIds, fetchType, pagingDefinitions);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class SearchSearchDocumentsByIdsSearchParameters {\n");
    
    sb.append("    documentIds: ").append(toIndentedString(documentIds)).append("\n");
    sb.append("    fetchType: ").append(toIndentedString(fetchType)).append("\n");
    sb.append("    pagingDefinitions: ").append(toIndentedString(pagingDefinitions)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\SearchSearchDocumentsByIdsSearchParametersDocumentIds.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;





@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class SearchSearchDocumentsByIdsSearchParametersDocumentIds   {
  
  private String dctmDocumentId;
  private String legacyDocumentId;
  private String versionLabel;

  /**
   **/
  public SearchSearchDocumentsByIdsSearchParametersDocumentIds dctmDocumentId(String dctmDocumentId) {
    this.dctmDocumentId = dctmDocumentId;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("dctmDocumentId")
  public String getDctmDocumentId() {
    return dctmDocumentId;
  }
  public void setDctmDocumentId(String dctmDocumentId) {
    this.dctmDocumentId = dctmDocumentId;
  }

  /**
   **/
  public SearchSearchDocumentsByIdsSearchParametersDocumentIds legacyDocumentId(String legacyDocumentId) {
    this.legacyDocumentId = legacyDocumentId;
    return this;
  }

  
  @ApiModelProperty(required = true, value = "")
  @JsonProperty("legacyDocumentId")
  public String getLegacyDocumentId() {
    return legacyDocumentId;
  }
  public void setLegacyDocumentId(String legacyDocumentId) {
    this.legacyDocumentId = legacyDocumentId;
  }

  /**
   * Version label of documents to be retrieved. If unspecified CURRENT will be retrieved. * will retrieve all documents versions.
   **/
  public SearchSearchDocumentsByIdsSearchParametersDocumentIds versionLabel(String versionLabel) {
    this.versionLabel = versionLabel;
    return this;
  }

  
  @ApiModelProperty(value = "Version label of documents to be retrieved. If unspecified CURRENT will be retrieved. * will retrieve all documents versions.")
  @JsonProperty("versionLabel")
  public String getVersionLabel() {
    return versionLabel;
  }
  public void setVersionLabel(String versionLabel) {
    this.versionLabel = versionLabel;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    SearchSearchDocumentsByIdsSearchParametersDocumentIds searchSearchDocumentsByIdsSearchParametersDocumentIds = (SearchSearchDocumentsByIdsSearchParametersDocumentIds) o;
    return Objects.equals(dctmDocumentId, searchSearchDocumentsByIdsSearchParametersDocumentIds.dctmDocumentId) &&
        Objects.equals(legacyDocumentId, searchSearchDocumentsByIdsSearchParametersDocumentIds.legacyDocumentId) &&
        Objects.equals(versionLabel, searchSearchDocumentsByIdsSearchParametersDocumentIds.versionLabel);
  }

  @Override
  public int hashCode() {
    return Objects.hash(dctmDocumentId, legacyDocumentId, versionLabel);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class SearchSearchDocumentsByIdsSearchParametersDocumentIds {\n");
    
    sb.append("    dctmDocumentId: ").append(toIndentedString(dctmDocumentId)).append("\n");
    sb.append("    legacyDocumentId: ").append(toIndentedString(legacyDocumentId)).append("\n");
    sb.append("    versionLabel: ").append(toIndentedString(versionLabel)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\generated\java\bnhp\dctmrest\model\SysObjectData.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Objects;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;
import java.util.ArrayList;
import java.util.Date;
import java.util.List;





@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaUndertowServerCodegen")
public class SysObjectData   {
  
  private Date creationTime;
  private Date lastUpdateTime;
  private String objectName;
  private String objectType;
  private List<String> paths = new ArrayList<>();
  private List<String> versionLabels = new ArrayList<>();

  /**
   **/
  public SysObjectData creationTime(Date creationTime) {
    this.creationTime = creationTime;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("creationTime")
  public Date getCreationTime() {
    return creationTime;
  }
  public void setCreationTime(Date creationTime) {
    this.creationTime = creationTime;
  }

  /**
   **/
  public SysObjectData lastUpdateTime(Date lastUpdateTime) {
    this.lastUpdateTime = lastUpdateTime;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("lastUpdateTime")
  public Date getLastUpdateTime() {
    return lastUpdateTime;
  }
  public void setLastUpdateTime(Date lastUpdateTime) {
    this.lastUpdateTime = lastUpdateTime;
  }

  /**
   * Object name.
   **/
  public SysObjectData objectName(String objectName) {
    this.objectName = objectName;
    return this;
  }

  
  @ApiModelProperty(value = "Object name.")
  @JsonProperty("objectName")
  public String getObjectName() {
    return objectName;
  }
  public void setObjectName(String objectName) {
    this.objectName = objectName;
  }

  /**
   **/
  public SysObjectData objectType(String objectType) {
    this.objectType = objectType;
    return this;
  }

  
  @ApiModelProperty(required = true, value = "")
  @JsonProperty("objectType")
  public String getObjectType() {
    return objectType;
  }
  public void setObjectType(String objectType) {
    this.objectType = objectType;
  }

  /**
   * List of absolute paths of folders the object is linked to
   **/
  public SysObjectData paths(List<String> paths) {
    this.paths = paths;
    return this;
  }

  
  @ApiModelProperty(value = "List of absolute paths of folders the object is linked to")
  @JsonProperty("paths")
  public List<String> getPaths() {
    return paths;
  }
  public void setPaths(List<String> paths) {
    this.paths = paths;
  }

  /**
   **/
  public SysObjectData versionLabels(List<String> versionLabels) {
    this.versionLabels = versionLabels;
    return this;
  }

  
  @ApiModelProperty(value = "")
  @JsonProperty("versionLabels")
  public List<String> getVersionLabels() {
    return versionLabels;
  }
  public void setVersionLabels(List<String> versionLabels) {
    this.versionLabels = versionLabels;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    SysObjectData sysObjectData = (SysObjectData) o;
    return Objects.equals(creationTime, sysObjectData.creationTime) &&
        Objects.equals(lastUpdateTime, sysObjectData.lastUpdateTime) &&
        Objects.equals(objectName, sysObjectData.objectName) &&
        Objects.equals(objectType, sysObjectData.objectType) &&
        Objects.equals(paths, sysObjectData.paths) &&
        Objects.equals(versionLabels, sysObjectData.versionLabels);
  }

  @Override
  public int hashCode() {
    return Objects.hash(creationTime, lastUpdateTime, objectName, objectType, paths, versionLabels);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class SysObjectData {\n");
    
    sb.append("    creationTime: ").append(toIndentedString(creationTime)).append("\n");
    sb.append("    lastUpdateTime: ").append(toIndentedString(lastUpdateTime)).append("\n");
    sb.append("    objectName: ").append(toIndentedString(objectName)).append("\n");
    sb.append("    objectType: ").append(toIndentedString(objectType)).append("\n");
    sb.append("    paths: ").append(toIndentedString(paths)).append("\n");
    sb.append("    versionLabels: ").append(toIndentedString(versionLabels)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\ConfigurationSubtreeProvider.java
-----------------------------------------------------
package bnhp.dctmrest;

import java.util.Properties;
import java.util.Enumeration;

import org.cfg4j.provider.ConfigurationProvider;
import org.cfg4j.provider.GenericTypeInterface;


public class ConfigurationSubtreeProvider implements ConfigurationProvider {
    protected ConfigurationProvider parentProvider;
    protected String prefix;
    
    
    public ConfigurationSubtreeProvider (ConfigurationProvider parentProvider, String prefix) {
	this.parentProvider = parentProvider;
	this.prefix = prefix;
    }
    
    @Override
    public Properties allConfigurationAsProperties() {
	Properties parProps = parentProvider.allConfigurationAsProperties();
	if (null == parProps) {
	    return null;
	}
	Enumeration <String>propNamesEn = (Enumeration<String>)parProps.propertyNames();
	Properties props = new Properties();
	while (null!=propNamesEn && propNamesEn.hasMoreElements()) {
	    String parPropName  = (String) propNamesEn.nextElement();
	    if (parPropName.startsWith(prefix))  {
		String propName = parPropName.substring(prefix.length());
		props.put(propName, parProps.get(parPropName));
	    }
	}
	return props;
    }


    protected String parentKey(String key) {
	return new StringBuffer(key.length() + prefix.length())
	    .append(prefix).append(key).toString();
    }
    
    @Override
    public <T> T getProperty(String key, Class<T> type) {
	return parentProvider.getProperty(parentKey(key), type);
    }

    @Override
    public <T> T getProperty(String key, GenericTypeInterface genericType) {
	return parentProvider.getProperty(parentKey(key), genericType);
    }

    @Override
    public <T> T bind(String key, Class<T> type) {
	return parentProvider.bind(parentKey(key), type);
    }

}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\DctmRestApp.java
-----------------------------------------------------
package bnhp.dctmrest;

import java.io.File;
import java.io.InputStream;
import java.net.MalformedURLException;
import java.net.URL;
import java.net.URLClassLoader;
import java.nio.file.FileSystem;
import java.nio.file.FileSystems;
import java.nio.file.Path;
import java.util.ArrayList;
import java.util.List;
import java.util.Map;
import java.util.HashMap;
import java.util.Properties;
import java.lang.reflect.Method;

import bnhp.dctmrest.utils.CommonConstants;
import bnhp.infra.dfs.utils.basic.LoggingUtils;
import bnhp.infra.dfs.utils.basic.properties.PropertyLoader;

import org.cfg4j.provider.ConfigurationProvider;
import org.cfg4j.provider.ConfigurationProviderBuilder;
import org.cfg4j.source.ConfigurationSource;
import org.cfg4j.source.compose.MergeConfigurationSource;
import org.cfg4j.source.context.filesprovider.ConfigFilesProvider;
import org.cfg4j.source.files.FilesConfigurationSource;
import org.cfg4j.source.reload.ReloadStrategy;
import org.cfg4j.source.reload.strategy.ImmediateReloadStrategy;
import org.cfg4j.source.system.EnvironmentVariablesConfigurationSource;

import com.documentum.fc.client.impl.bof.classmgmt.URLClassLoaderEx;

import bnhp.dctmrest.msginput.MsgInput;
import bnhp.dctmrest.utils.Utils;
import bnhp.infra.dfs.init.ApplicationInitializer;
import bnhp.infra.dfs.utils.service.DfsRequestThreadAttributes;
import bnhp.infra.dfs.velocity.TemplateBasedQuery;

public class DctmRestApp {
	//private static Logger log= LoggerFactory.getLogger(DctmRestApp.class);
	final static String serviceName = DctmRestApp.class.getSimpleName();
	static String version ;
	private static LoggingUtils log;

	protected final static String PROPERTY_PATH= "/META-INF/maven/bnhp.dctmrest/DctmRestApp/pom.properties";

	final static String HANDLERS_FACTORY_PROP = "handlerFactory";
	private static final String MESSAGE_INPUTS_PROP = "messageInputs";

	protected List<MsgInput> msgInputs = new ArrayList<MsgInput>();
	ApplicationInitializer init = ApplicationInitializer.getInstance();

	public static void main(String argv[]) throws Exception
	{
		version = getAppVersion();

		DctmRestApp app = new DctmRestApp();
		app.run(argv);
	}

	private static String getAppVersion()
	{
		final String propsPath = PROPERTY_PATH;
		try (InputStream is =DctmRestApp.class.getClass().getResourceAsStream(propsPath)) {
			Properties pomProps = new Properties();
			pomProps.load(is);
			return pomProps.getProperty("version");
		} catch (Throwable t) {
			return "???: Failed to read application version: "+ t.toString();
		}
	}

	public void run(String args[]) throws Exception {

		logAppStarting();
		ConfigurationProvider cfProvider = initConfig(args);

		Utils.dfsThreadInit();
		log = new LoggingUtils("wrapper_logger_id");

		log.info(serviceName, "configEnvironment="+
				 cfProvider.getProperty("configEnvironment", String.class));
		
		Map<String,Object> context = sharedConfig(cfProvider);
		msgInputs = this.configMessageInputs(cfProvider, context);
		TemplateBasedQuery.staticInit();

		// FIXME: this ensure thingie is clearly misplaces here
		// because of separation of concerns.
		// Must be in the code that initializes the
		// appropriate compontent
		EnsureExecutorDetailsParametersExistedOnConfig();

		boolean result = init.initApplication();
		for (MsgInput input : msgInputs) {
			log.info(serviceName, "starting input " + input);
			input.start();
		}
		log.info(serviceName, "all message inputs started ");
		while(true) {
			// FIXME: update metrics
			//
			try {
				Thread.sleep(10000);
			} catch (InterruptedException iex) {
				Thread.currentThread().interrupt();
			}
		}
	}

	private Map sharedConfig(ConfigurationProvider cfg) {
		Map sharedMap = new HashMap();
		ConfigurationProvider local = new ConfigurationSubtreeProvider(cfg, HANDLERS_FACTORY_PROP + ".");
		Properties props = local.allConfigurationAsProperties();
		Map handlersMap = new HashMap();
		handlersMap.putAll(props);
		sharedMap.put(HANDLERS_FACTORY_PROP, handlersMap);
		log.info(serviceName, "Shared configuration map: "+sharedMap);
		return sharedMap;
		
	}

	public void logAppStarting() {
		System.err.println(serviceName + ": DctmRestApp version="	+ version + "is starting");
    }

	public ConfigurationProvider initConfig(String args[]) {
		// Immediate - load once on startup
		ReloadStrategy reloadStrategy = new ImmediateReloadStrategy();
		ConfigurationSource cfgsrc =
			new MergeConfigurationSource(initFilesConfigSource(args),
										 new EnvironmentVariablesConfigurationSource());
		ConfigurationProvider  cfgProvider = (new ConfigurationProviderBuilder())
			.withConfigurationSource(cfgsrc)
			.withReloadStrategy(reloadStrategy).build();

		if (cfgProvider.allConfigurationAsProperties().containsKey("extraClasspath")) {
			addToClassPath(cfgProvider.getProperty("extraClasspath", List.class));
		}
		return cfgProvider;
	}

	// Add classpath elements at runtime to classpath
	// FIXME: Very nasty hack, probbly won't work with java 9+
	// Needed to enable running with -jar and adding extra folders
	// (actually per environment resource folders).
	// 
	// Less hacky (from the java point of view) but nevertheless ugly
	// is to add to MANIFEST classpath some jar in each of aforementioned
	// folders. It will work as expected because each environment will
	// have only one folder with such a jar.
	// In essence, it sucks that one cannot youse -jar and -cp at the same time!
	private void addToClassPath(List paths) throws RuntimeException {
		final URLClassLoader ucl = (URLClassLoader)ClassLoader.getSystemClassLoader();
		final Class uclcl = URLClassLoader.class;
		Method m;
		try {
			m = uclcl.getDeclaredMethod("addURL", new Class[]{URL.class});
			m.setAccessible(true);
		} catch (NoSuchMethodException ex) {
			throw new RuntimeException("This won't happen: "+ex);
		}
		for (Object pathObj : paths) {
			final File folder = new File((String)pathObj);
			URL folderURL = null;
			try {
				folderURL = folder.toURL();
			} catch (MalformedURLException ex) {
				throw new RuntimeException("Failed to make URL out of folder '"+folder+"'");
			}
			try {
				m.invoke(ucl, new Object[]{folderURL});
			} catch (Exception ex) {
				throw new RuntimeException("Failed to add '"+folderURL+"' to system classpath");
			}
		}
	}

	protected ConfigurationSource initFilesConfigSource(String args[]) {
		final String cwd = System.getProperty("user.dir");
		final FileSystem fs = FileSystems.getDefault();
		List<Path> configFiles = new ArrayList<Path>(2);
		for (String arg : args) {
			if (arg.startsWith("-")) {
				continue;
			} 
			Path p = fs.getPath(cwd, arg);
			configFiles.add(p);
		}
		ConfigFilesProvider configFilesProvider = () -> configFiles;
		return new FilesConfigurationSource(configFilesProvider);
    }

	protected List<MsgInput> configMessageInputs(ConfigurationProvider provider, Map<String,Object> context)
	{
		List<MsgInput> inputs = (List<MsgInput>)(List) Utils.mkcomps( provider,  MESSAGE_INPUTS_PROP, context);
		log.info(serviceName, "Configured inputs: " + inputs);
		return inputs;
	}

	private static void EnsureExecutorDetailsParametersExistedOnConfig()
	{
		String elementsNameMustContains = CommonConstants.EP_ED_TAG_NAME;
		boolean result = false;

		PropertyLoader loader = PropertyLoader.getInstance();
		if(loader.hasProperty(CommonConstants.EP_ED_TAG_NAME))
			{
				String execDetFlowType = loader.getProperty(CommonConstants.EP_ED_TAG_NAME);

				switch (execDetFlowType)
					{
					case CommonConstants.EP_ED_PROVIDE:
						{
							return;
						}
					case CommonConstants.EP_ED_JWT:
						{
							elementsNameMustContains += " , " + CommonConstants.ED_JWT_EMP_CODE_MAP + " , " + CommonConstants.ED_JWT_FULLNAME_MAP;

							result  = loader.hasProperty(CommonConstants.ED_JWT_EMP_CODE_MAP) && loader.hasProperty(CommonConstants.ED_JWT_FULLNAME_MAP);
							break;
						}
					case CommonConstants.EP_ED_AUTO:
						{
							elementsNameMustContains += " , " + CommonConstants.ED_AUTO_FULLNAME_MAP + " , " + CommonConstants.ED_AUTO_EMPL_CODE_MAP + " , "
								+ CommonConstants.ED_AUTO_IP_MAP;

							result = loader.hasProperty(CommonConstants.ED_AUTO_FULLNAME_MAP) && loader.hasProperty(CommonConstants.ED_AUTO_EMPL_CODE_MAP)
								&& loader.hasProperty(CommonConstants.ED_AUTO_IP_MAP);

							break;
						}
					default:
						{
							throw new RuntimeException(String.format("Wrong value on '%s' tag.. ",
																	 CommonConstants.EP_ED_TAG_NAME));
						}
					}

				if (!result)
					{
						throw new RuntimeException(String.format("one or more from the bellow config parameter/s: %s is missing.. ",
																 elementsNameMustContains));
					}
				return;
			}
		else
			{
				throw  new RuntimeException(String.format("'%s'element is missing on envProperties file..", CommonConstants.EP_ED_TAG_NAME));
			}
	}
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\DctmRestHandlerProvider.java
-----------------------------------------------------
package bnhp.dctmrest;

import io.undertow.server.HttpHandler;
import io.undertow.server.HttpServerExchange;
import io.undertow.util.Headers;
import io.undertow.util.Methods;
import io.undertow.Handlers;
import io.undertow.io.IoCallback;

import bnhp.dctmrest.handlers.CreateDocumentById;
import bnhp.dctmrest.handlers.PutDocumentById;
import bnhp.dctmrest.handlers.Search;

import java.io.InputStream;
import java.nio.ByteBuffer;
import java.util.Map;

import bnhp.dctmrest.handlers.AppRequest;
import bnhp.dctmrest.handlers.CancelObjectById;
import bnhp.dctmrest.handlers.RetrieveDocumentById;
import bnhp.dctmrest.utils.Utils;
import bnhp.dctmrest.handlers.HandlerFactory;


public class DctmRestHandlerProvider  {
	public Map<String, Object> context;
	boolean isDumpRequests = false;

	// FIXME: dump requests must be more selective
	public DctmRestHandlerProvider(Map<String,Object> context, boolean dumpRequests) {
		this.context = context;
		this.isDumpRequests = dumpRequests;
	}

	public HttpHandler getHandler() {
		HandlerFactory factory = new HandlerFactory((Map<String,Object>)context.get("handlerFactory"), isDumpRequests);
		HttpHandler handler = Handlers.routing()
			.add(Methods.DELETE, "/{versionId}/objects/{idType}/{documentId}",
				 factory.makeHandler("cancelObjectById"))
			.add(Methods.POST, "/{versionId}/objects/{idType}/{documentId}",
				 factory.makeHandler("createDocumentById"))
			.add(Methods.PATCH, "/{versionId}/objects/{idType}/{documentId}", new HttpHandler() {
					public void handleRequest(HttpServerExchange exchange) throws Exception {
						exchange.getResponseSender().send("NOT IMPLEMENTED: patchDocumentById");
					}
				})
			.add(Methods.PUT, "/{versionId}/objects/{idType}/{documentId}",
				 factory.makeHandler("putDocumentById"))
			.add(Methods.GET, "/{versionId}/objects/{idType}/{documentId}",
				 factory.makeHandler("retrieveObjectById"))
			.add(Methods.POST, "/{versionId}/request/{requestName}",
				 factory.makeHandler("appRequest"))
			.add(Methods.POST, "/{versionId}/search/{searchName}",
				 factory.makeHandler("search"))
			.add(Methods.GET, "/{versionId}/requests/async/{requestId}/status",
				 factory.makeHandler("getAsyncRequestStatus"))
			.add(Methods.GET, "/{versionId}/WhoAmI", 
				 factory.makeHandler("whoami"))
			.add(Methods.POST, "/{versionId}/callbackExample", new HttpHandler() {
					public void handleRequest(HttpServerExchange exchange) throws Exception {
						if (exchange.isInIoThread()) {
							exchange.dispatch(this);
							return;
						}
						String ct = exchange.getRequestHeaders().getLast("Content-Type");
						Utils.setContentType(exchange, null == ct ? "application/octet-stream" : ct);
						exchange.startBlocking();
						InputStream is = exchange.getInputStream();
						byte [] bytes = new byte[1500];
						int readBytes = 0;
						while ((readBytes = is.read(bytes)) > 0) {
							ByteBuffer bb = ByteBuffer.wrap(bytes, 0 , readBytes);
							exchange.getResponseSender().send(bb);
						}
					}
				});
		return handler;
	}
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\handlers\AbstractHandler.java
-----------------------------------------------------
package bnhp.dctmrest.handlers;

import io.undertow.server.HttpHandler;

import bnhp.infra.dfs.model.business.SecurityContext;
import bnhp.dctmrest.requests.ISvcRequest;

import com.documentum.fc.common.DfException;

import bnhp.infra.dfs.exceptions.DFSDocumentumException;
import bnhp.infra.dfs.model.business.ExecutorDetails;
import bnhp.infra.dfs.utils.service.DfsRequestThreadAttributes;
//import bnhp.infra.dfs.services.utils.ServiceUtils;
import bnhp.infra.dfs.utils.service.SysUsersTable;

import io.undertow.server.HttpServerExchange;

public abstract class AbstractHandler implements HttpHandler {
	protected String operationName;
	
	public void setOperationName(String value) {
		operationName = value;
	}

	public void initSysAuth(HttpServerExchange exch) {
		final String sysUser = exch.getAttachment(AuthHandler.SYSUSER_KEY);
		DfsRequestThreadAttributes.sysUser.set(sysUser);
	}

	public void initSysAuth(ISvcRequest svcReq) {
		final String sysUser = svcReq.getSysUser();
		DfsRequestThreadAttributes.sysUser.set(sysUser);
	}
	
	public void logError(String str) {
		System.out.println("ERROR: "+str);
	}
	public void logInfo(String str) {
		System.out.println("INFO: "+ str);
	}

	public void logDebug(String str) {
		System.out.println("DEBUG: "+ str);
	}


	protected ExecutorDetails makeExecutorDetails(HttpServerExchange exch) {
		ExecutorDetails ed = new ExecutorDetails();
		ed.setIpAddress("1.2.3.4");
		ed.setExecutingEmpIdCode("1234567890");
		return ed;
	}

	protected SecurityContext makeSecurityContext(HttpServerExchange exch) throws DFSDocumentumException {
		initSysAuth(exch);
		SecurityContext sctx = new SecurityContext();
		SysUsersTable.passwordlessLogin(sctx);
		logInfo("Authentication granted as dctmUser=" + sctx.getUserName() +
				" for repository=" + sctx.getRepositoryName());
		return sctx;
	}

	protected SecurityContext makeSecurityContext(ISvcRequest svcReq) throws DFSDocumentumException {
		initSysAuth(svcReq);
		SecurityContext sctx = new SecurityContext();
		SysUsersTable.passwordlessLogin(sctx);
		logInfo("Authentication granted as dctmUser=" + sctx.getUserName() +
				" for repository=" + sctx.getRepositoryName());
		return sctx;
	}

	
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\handlers\AppRequest.java
-----------------------------------------------------
package bnhp.dctmrest.handlers;

import java.io.ByteArrayInputStream;
import java.io.File;
import java.io.FileInputStream;
import java.io.IOException;
import java.io.InputStream;
import java.nio.ByteBuffer;
import java.nio.channels.Channel;
import java.nio.channels.Channels;
import java.nio.channels.FileChannel;
import java.nio.channels.ReadableByteChannel;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;

import com.documentum.fc.client.IDfSessionManager;
import com.documentum.fc.client.IDfSysObject;
import com.documentum.fc.common.DfException;
import com.documentum.fc.client.IDfSession;
import com.emc.documentum.fs.rt.context.IServiceContext;
import com.emc.documentum.fs.rt.context.ServiceFactory;
import com.services.infra.bnhp.client.IApplicativeRequestService;

import bnhp.dctmrest.requests.AbstractSvcRequestHandler;
import bnhp.dctmrest.requests.ISvcCallback;
import bnhp.dctmrest.requests.ISvcRequest;
import bnhp.dctmrest.utils.DFS2Rest;
import bnhp.dctmrest.utils.JsonAppRequestParser;
import bnhp.dctmrest.utils.ServiceUtils;
import bnhp.dctmrest.utils.Utils;
import bnhp.infra.dfs.exceptions.DFSDocumentumException;
import bnhp.infra.dfs.exceptions.DFSValidationException;
import bnhp.infra.dfs.init.ApplicationInitializer;
import bnhp.infra.dfs.model.business.ExecutorDetails;
import bnhp.infra.dfs.model.business.SecurityContext;
import bnhp.infra.dfs.model.query.prepared.NamedQueryParam;
import bnhp.infra.dfs.model.query.prepared.PreparedQuery;
import bnhp.infra.dfs.model.query.prepared.QueryParam;
import bnhp.infra.dfs.model.query.prepared.QueryParamList;
import bnhp.infra.dfs.utils.service.DfsRequestThreadAttributes;
import bnhp.infra.dfs.utils.service.SysUsersTable;

import io.undertow.security.api.SecurityContextFactory;

public class AppRequest extends AbstractSvcRequestHandler  {
	
	@Override
	public void handleRequest(ISvcRequest svcReq) throws Exception {
		boolean success = false;
		boolean inputRead = false;
		// FIXME: only at real thread init!
		Utils.dfsThreadInit();
		try {
			String requestId = svcReq.getQueryParam( "X-RequestID");
			if (null == requestId) {
				requestId = DfsRequestThreadAttributes.dctmRequestId.get();
			}

			String requestName = svcReq.getQueryParam( "requestName");
			
			//BlockingHttpExchange bexch = exch.startBlocking();
			//super.logInfo("bech="+bexch);
			final InputStream is = svcReq.getInputStream();
			//final InputStream is = exch.getInputStream();
			super.logInfo("is="+is);
			JsonAppRequestParser jsp = new JsonAppRequestParser();
			jsp.parseAppRequestParams(is);
			ExecutorDetails ed = jsp.getExecutorDetails();
			if (null == ed) {
				ed = svcReq.getExecutorDetails();
			}
			inputRead = true;

			PreparedQuery pq = jsp.getPreparedQuery();
			if (null == pq) {
				throw new DFSValidationException("Failed to parse PreparedQuery from input");
			}
			pq.setName(requestName);
			if (null == pq.getParams()) {
				throw new DFSValidationException("Failed to get requestParameters from input");
			}
			pq.getParams().add(mkHeadersParam(svcReq));
			SecurityContext securityContext = makeSecurityContext(svcReq);
			ServiceUtils.applyDefaults(securityContext);
			IServiceContext context = ServiceUtils.createTransactionalServiceContext(securityContext);

			IApplicativeRequestService svc = (IApplicativeRequestService) ServiceFactory.getInstance()
					.getLocalService(IApplicativeRequestService.class, context);
			List<NamedQueryParam> results = svc.applicativeRequest(securityContext, pq, ed);
			if (!readPassThrough(results, svcReq, securityContext)) {
				Object restResults = DFS2Rest.toRestPQResults(results);
				byte[] bytes = Utils.toByteArray(restResults);
				svcReq.setContentType("application/json");
				svcReq.setResponseCode(200);
				svcReq.send(bytes);
			}
			success = true;
		} catch (DFSDocumentumException e) {
			logError(e.getMessage());
			e.printStackTrace();
			throw e;
		} catch (Exception e) {
			if (!inputRead) {
				e.printStackTrace();
				throw new DFSValidationException("SS:Error parsing input parameters: " + e.getMessage(), e);
			}
			//AuditUtils.logDetailedError(e, serviceName);
			//ExceptionUtils.throwECMException(e, details);
			throw new RuntimeException(e);
		} finally {
		}
	}

	/* Mapping from real headers to effective ones,
	   the last input header takes precedence.
	   This feature serves those customers that have
	   no control over standard HTTP headers (like Accept)
	   that  they need to send */
	protected final static Map<String,List<String>> headersMap =
		Utils.makeMap("Accept",Utils.list("Accept","X-DCTM-ACCEPT"));

	private NamedQueryParam mkHeadersParam(ISvcRequest svcReq) {
		QueryParamList qpl = new QueryParamList();

		for (Map.Entry<String, List<String>> header : headersMap.entrySet()) {
			NamedQueryParam param = new NamedQueryParam();
			param.setName(header.getKey());
			for (String srcHeader : header.getValue()) {
				String val = svcReq.getLastHeader(srcHeader);
				if ((null != val) && !val.trim().isEmpty()) {
					param.setParamValue(new QueryParam(val));
				}
			}
			if (null != param.getParamValue()) {
				qpl.addParam(param);
			}
		}
		NamedQueryParam qp = new NamedQueryParam();
		qp.setName("HTTP_HEADERS");
		qp.setParamValue(qpl);
		return qp;
	}

	final static String PASSTHRU = "__PASSTHRU";
	final static String PT_FILE = "FILE";
	final static String PT_RETRIEVE_PROFILE = "RETRIEVE_PROFILE";
	final static String PT_OBJECT_PATH = "OBJECT_PATH";
	final static String PT_R_OBJECT_ID = "R_OBJECT_ID";
	final static String PT_MIME = "MIMETYPE";
	final static String PT_SIZE = "SIZE";
	final static String PT_CLEANUP = "CLEANUP";


	private FileChannel getPTFileInput(String filename)
		throws IOException {
		return  new FileInputStream(filename).getChannel();
	}

	private class FileCleanupCallback implements  ISvcCallback {
		protected final boolean needCleanup;
		protected final File file;
		public FileCleanupCallback(boolean needCleanup, String fileStr) {
			this.needCleanup = needCleanup;
			this.file = new File(fileStr);
		}

		protected void cleanup() {
			if (needCleanup) {
				logInfo("deleting temp file '" + file);
				file.delete();
			}
		}

		@Override
			public void onComplete() {
			logInfo("file_send_result=OK");
			cleanup();
		}

		@Override
			public void onException(Exception ex) {
			logError("file_send_result=Error, errorMessage="+(null == ex ? "null" : ex.getMessage()));
			cleanup();
		}
		
	}
	

	private byte[] getPTContentBytes(String objectPath, SecurityContext sc)
		throws DfException, DFSDocumentumException, IOException  {
		ApplicationInitializer init = ApplicationInitializer.getInstance();
		IDfSessionManager sm = null;
		IDfSession sess = null;
		try {
			sm = init.getSessionManager();
			sess = sm.getSession(sc.getRepositoryName());
			IDfSysObject obj = (IDfSysObject) sess.getObjectByPath(objectPath);
			//obj.get
			if (null == obj) {
				throw new DFSDocumentumException("Failed to open object with path: " + objectPath);
			}
			ByteArrayInputStream is =  obj.getContent();
			byte[] bytes = new byte[(int)obj.getContentSize()];
			is.read(bytes);
			is.close();
			return bytes;
		} finally {
			if (null != sm && null != sess) {
				sm.release(sess);
			}
		}
	}


	private class ContentCleanupCallback implements  ISvcCallback {
		protected final boolean needCleanup;
		protected final String objectPath;
		public ContentCleanupCallback(boolean needCleanup, String objectPath) {
			this.needCleanup = needCleanup;
			this.objectPath = objectPath;
		}

		protected void cleanup() {
			if (needCleanup) {
				logInfo("deleting temp object '" + objectPath);
				//file.delete();
			}
		}

		@Override
			public void onComplete() {
			logInfo("file_send_result=OK");
			cleanup();
		}

		@Override
			public void onException(Exception ex) {
			logError("file_send_result=Error, errorMessage="+(null == ex ? "null" : ex.getMessage()));
			cleanup();
		}
	}



	private boolean readPassThrough(List<NamedQueryParam> results, ISvcRequest svcReq, SecurityContext sc) throws
		IOException, DfException, DFSDocumentumException   {
		// FIXME: move drill down logic to utils 
		List <NamedQueryParam> passThruList = null;
		if (null == results) {
			return false;
		}
		for (NamedQueryParam result : results) {
			if (null!=result &&
				PASSTHRU.equals(result.getName()) &&
				(result.getParamValue() instanceof QueryParamList)){
				final QueryParamList list = (QueryParamList) result.getParamValue();
				passThruList=list.getParams();
			}
		}

		if (null ==  passThruList) {
			return false;
		}
		//String fileStr = null;
		//Number fileSize = null;
		String fileStr = null;
		String objectPath = null;
		boolean cleanupFlag = false;
		//FileInputStream ios = null;
		FileChannel inputChannel = null;
		byte[] inputBytes = null;
		ISvcCallback cb = null;
		String mime = "application/octet-stream";
		for (NamedQueryParam passThru : passThruList) {
			if (null == passThru) {
				continue;
			}
			final String ptFieldName = passThru.getName();
			if (PT_FILE.equals(ptFieldName)) {
				fileStr = (String) getParamValue(passThru);
				cb = new FileCleanupCallback(cleanupFlag, fileStr);
			} else if (PT_OBJECT_PATH.equals(ptFieldName)) {
				objectPath = (String) getParamValue(passThru);
				cb = new ContentCleanupCallback(cleanupFlag, fileStr);
				// not used currently
				/*			} else if (PT_SIZE.equals(passThru.getName())) {
							fileSize = (Number) getParamValue(passThru);*/
			} else if  (PT_MIME.equals(ptFieldName)) {
				mime = (String) getParamValue(passThru);
			} else if  (PT_CLEANUP.equals(ptFieldName)) {
				cleanupFlag = Utils.isTrueValue(getParamValue(passThru));
			}
		}

		if (null == fileStr && null == objectPath) {
			return false;
		}

		if (null != fileStr) {
			inputChannel = 	getPTFileInput(fileStr);
			logInfo("PASSTHRU: file=" + fileStr + ", mime=" + mime + ", cleanupFlag=" + cleanupFlag );
		}
		if (null != objectPath) {
			inputBytes = 	getPTContentBytes(objectPath, sc);
			logInfo("PASSTHRU: object_path=" + objectPath + ", mime=" + mime + ", cleanupFlag=" + cleanupFlag );
		}
		svcReq.setContentType(null == mime ? "application/json" : mime);
		svcReq.setResponseCode(200);
		if (null != inputBytes) {
			svcReq.transferFrom(inputBytes, cb);
 		} else if (null != inputChannel) {
			svcReq.transferFrom(inputChannel, cb);
		}
		return true;
	}

	private Object getParamValue(NamedQueryParam namedParam) {
		if (null!= namedParam &&
			(namedParam.getParamValue()  instanceof QueryParam)) {
	    	return ((QueryParam)namedParam.getParamValue()).getValue();
		}
		return null;
	}
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\handlers\AsyncHandler.java
-----------------------------------------------------
package bnhp.dctmrest.handlers;

import static bnhp.dctmrest.utils.CommonConstants.H_X_CALLBACK_URL;
import static bnhp.dctmrest.utils.CommonConstants.H_X_REQUEST_ID;
import static bnhp.dctmrest.utils.CommonConstants.MIME_APPLICATION_JSON;

import com.documentum.fc.client.IDfSession;

import bnhp.dctmrest.requests.DctmSvcRequest;
import bnhp.dctmrest.utils.HttpUtils;
import bnhp.dctmrest.utils.Json;
import bnhp.dctmrest.utils.Utils;
import bnhp.infra.dfs.exceptions.DFSDocumentumException;
import bnhp.infra.dfs.init.ApplicationInitializer;
import bnhp.infra.dfs.utils.service.DfsRequestThreadAttributes;

import io.undertow.server.HttpHandler;
import io.undertow.server.HttpServerExchange;

public class AsyncHandler extends AbstractHandler {
	final HttpHandler nextHandler;
	
	protected AsyncHandler(HttpHandler nextHandler,
						   String operationName) {
		this.nextHandler = nextHandler;
		super.setOperationName(operationName);
	}

	@Override
	public void handleRequest(HttpServerExchange exch) throws Exception {
		Utils.dfsThreadInit();
		String requestId = Utils.getHeaderParam(exch, H_X_REQUEST_ID);
		if (null == requestId || requestId.isEmpty()) {
			requestId = DfsRequestThreadAttributes.generateDctmRequestId();
		} else {
			DfsRequestThreadAttributes.dctmRequestId.set(requestId);
		}
		final String callbackURL = Utils.getHeaderParam(exch, H_X_CALLBACK_URL);
		if (null != callbackURL &&	(! callbackURL.isEmpty())) {
			// existance of callback means async request
			IDfSession s = null;
			ApplicationInitializer instance = null;
			try {
				instance = ApplicationInitializer.getInstance();
				s = instance.getDocbaseSession();
				final DctmSvcRequest r = new DctmSvcRequest(s,operationName,
													  requestId,
													  callbackURL,
													  exch);
				r.submit();
			} catch (Exception ex) {
				throw new DFSDocumentumException("Failed to submit request: " + ex.getMessage(), ex);
			} finally {
				if (null!=s) {
					instance.releaseDocbaseSession(s);
				}
			}
			final byte[] bytes = Json.serializer()
				.toPrettyString(Utils.makeMap("correlationId", requestId))
				.getBytes();
			HttpUtils.sendResponse(exch, 202, MIME_APPLICATION_JSON, bytes);
			return;
		}
		nextHandler.handleRequest(exch);
	}
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\handlers\AuthHandler.java
-----------------------------------------------------
package bnhp.dctmrest.handlers;

import bnhp.dctmrest.utils.CommonConstants;
import bnhp.infra.com.utils.service.BnhpRequestThreadAttributes;
import bnhp.infra.dfs.utils.basic.properties.PropertyLoader;
import io.undertow.server.HttpHandler;
import io.undertow.server.HttpServerExchange;
import io.undertow.util.AttachmentKey;
import io.undertow.util.AttachmentList;

import java.nio.ByteBuffer;
import java.util.Arrays;
import java.util.Base64;

import bnhp.dctmrest.model.ErrorDetails;
import bnhp.dctmrest.model.ErrorDetails.ErrorTypeEnum;
import bnhp.dctmrest.utils.DFS2Rest;
import bnhp.dctmrest.utils.Utils;
import bnhp.infra.dfs.exceptions.DFSDocumentumException;
import bnhp.infra.dfs.exceptions.DFSValidationException;
import bnhp.infra.dfs.exceptions.DFSNonExistingObjectException;
import bnhp.infra.dfs.exceptions.DFSUnexpectedQueryResultException;
import bnhp.infra.dfs.exceptions.utils.ErrorInfoPropertyLoader;
import bnhp.infra.dfs.exceptions.utils.ErrorTypeLookup;
import bnhp.infra.dfs.model.service.RequestDetails;

import com.auth0.jwt.interfaces.DecodedJWT;

//import bnhp.dctmrest.utils.JWTUtils;
import com.poalim.documentum.jwtutils.JWTUtils;
import org.json.JSONObject;


public class AuthHandler extends AbstractHandler {
	
	final public static AttachmentKey<String> SYSUSER_KEY = AttachmentKey.create(String.class);
	final public static AttachmentKey<String> SYSUSER_META = AttachmentKey.create(String.class);
	final public static AttachmentKey<String> SYSUSER_TOKEN = AttachmentKey.create(String.class);
	final public static AttachmentKey<String> SYSUSER_FULLNAME = AttachmentKey.create(String.class);

	final private HttpHandler nextHandler;
	private JWTUtils jwtUtils;
	
	// FIXME: configurable JWT utils!
   	AuthHandler(HttpHandler nextHandler,
						   String operationName) {
		this.nextHandler = nextHandler;
		super.setOperationName(operationName);
		this.jwtUtils = new JWTUtils();
		jwtUtils.setUserClaim("http://wso2.org/claims/enduser");
		final String [] roleClaims = new String[] {"http://wso2.org/claims/usertype"};
		jwtUtils.setRoleClaims(Arrays.asList(roleClaims));
	}
	
	@Override
	public void handleRequest(HttpServerExchange exch) throws Exception
	{
		String JWTStr =	exch.getRequestHeaders().get("X-JWT-Assertion", 0);
		logDebug("JWT token: '"+JWTStr+"'");

		if (null == JWTStr || (JWTStr = JWTStr.trim()).length() == 0) {
			returnError(exch, 401, "Authentication token not provided");
			return;
		}

		exch.putAttachment(SYSUSER_TOKEN, JWTStr);
		String edProperty = null;

		try
		{
			DecodedJWT jwt = jwtUtils.decodeJWT(JWTStr);
			logDebug("Decoded jwt: "+ jwt);
			String user = jwtUtils.getAuthenticatedUser(jwt);
			logInfo("authenticated JWT user: "+user);
			user += !jwt.getClaim("http://wso2.org/claims/applicationname").isNull() ?
					"#" + jwt.getClaim("http://wso2.org/claims/applicationname").asString() : "";
			exch.putAttachment(SYSUSER_KEY, user);
			exch.putAttachment(SYSUSER_META, jwt.getPayload());

			// Extract the user full name from our jwt payload claims to our exchange attachment.
			// it needed when the request is not contains execution details object.
			// (only when 'EP_ED_TAG_NAME' value in the config file is JWT).
			PropertyLoader loader = PropertyLoader.getInstance();
			edProperty = loader.getProperty(CommonConstants.EP_ED_TAG_NAME);

			if(edProperty.equalsIgnoreCase(CommonConstants.EP_ED_JWT))
			{
					String decoded = new String(Base64.getDecoder().decode(jwt.getPayload()));
					JSONObject objDecoded = new JSONObject(decoded);
					String[] values = edProperty.split(",");

					String theFullName = "";

					for (int n = 0; n < values.length; ++n)
					{
						String res = (String) Utils.getJsonSimpleObject(objDecoded, values[n],
									 this.getClass().getName(),false,false);

						theFullName += res != null ? res + ' ' : "";
					}

					theFullName = !theFullName.isEmpty() ? theFullName : "emptyNameOnConfig";
					exch.putAttachment(SYSUSER_FULLNAME, theFullName);
			}

		}
		catch (Exception ex)
		{
			returnError(exch, 400, "Error parsing authentication token: "+ex.getMessage());
			return;
		}

		nextHandler.handleRequest(exch);
		return;
	}

	// FIXME: error code!
	private void returnError(HttpServerExchange exch, int statusCode, String msg) {
		ErrorDetails details = DFS2Rest.makeErrorDetails("VALIDATION:0", msg);
		byte[] bytes = Utils.toByteArray(details);
		exch.setResponseCode(statusCode);
		exch.getResponseSender().send(ByteBuffer.wrap(bytes));
	}
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\handlers\CancelObjectById.java
-----------------------------------------------------
package bnhp.dctmrest.handlers;

import com.emc.documentum.fs.rt.context.IServiceContext;
import com.emc.documentum.fs.rt.context.ServiceFactory;
import com.services.infra.bnhp.client.ICancelDocumentService;

import bnhp.dctmrest.requests.AbstractSvcRequestHandler;
import bnhp.dctmrest.requests.ISvcRequest;
import bnhp.dctmrest.utils.DFS2Rest;
import bnhp.dctmrest.utils.ServiceUtils;
import bnhp.dctmrest.utils.Utils;
import bnhp.infra.dfs.exceptions.DFSDocumentumException;
import bnhp.infra.dfs.exceptions.DFSValidationException;
import bnhp.infra.dfs.model.business.ExecutorDetails;
import bnhp.infra.dfs.model.business.SecurityContext;
import bnhp.infra.dfs.model.service.DocIdData;
import bnhp.infra.dfs.utils.service.DfsRequestThreadAttributes;


public class CancelObjectById extends AbstractSvcRequestHandler  {
	public void handleRequest(ISvcRequest svcReq) throws Exception {
		boolean success = false;
		boolean inputRead = false;
		// FIXME: only at real thread init!
		Utils.dfsThreadInit();
		try {
			String objectId = svcReq.getQueryParam( "documentId");
			String idType = Utils.getIdType(svcReq);
			String requestId = svcReq.getQueryParam( "X-RequestID");
			String versionLabel = svcReq.getQueryParam( "versionLabel");
		
			if (null == requestId) {
				requestId = DfsRequestThreadAttributes.dctmRequestId.get();
			}
			// FIXME: handle requestId

			// FIXME: check validity of id type
			// FIXME: check is is not empty!
			boolean isLegacyId = "legacyDocumentId".equals(idType);
			
			inputRead = true;
					
			SecurityContext securityContext = makeSecurityContext(svcReq);
			ExecutorDetails ed = svcReq.getExecutorDetails();
			ServiceUtils.applyDefaults(securityContext);
			IServiceContext context = ServiceUtils.createTransactionalServiceContext(securityContext);

			ICancelDocumentService svc = (ICancelDocumentService)
				ServiceFactory.getInstance()
				.getLocalService(ICancelDocumentService.class, context);

			DocIdData result = svc.cancelDocument(objectId, isLegacyId, securityContext, ed);
			bnhp.dctmrest.model.DocIdData restResult = DFS2Rest.toRest(result);
			byte [] bytes = Utils.toByteArray(restResult);
			svcReq.setContentType("application/json");
			svcReq.setResponseCode(200);
			svcReq.send(bytes);
			success = true;
		} catch (DFSDocumentumException e) {
			throw e;
		} catch (Exception e) {
			if (! inputRead ) {
				throw new DFSValidationException("Error parsing input parameters: "+e.getMessage(), e);
			}
			//AuditUtils.logDetailedError(e, serviceName);
			//ExceptionUtils.throwECMException(e, details);
			throw new RuntimeException(e);
		} finally {
		}
	}
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\handlers\CreateCustomerDocumentById.java
-----------------------------------------------------
package bnhp.dctmrest.handlers;

import bnhp.dctmrest.model.DocumentData;
import bnhp.dctmrest.requests.AbstractSvcRequestHandler;
import bnhp.dctmrest.requests.ExchSvcRequest;
import bnhp.dctmrest.requests.ISvcRequest;
import bnhp.dctmrest.utils.*;
import bnhp.infra.dfs.exceptions.DFSDocumentumException;
import bnhp.infra.dfs.exceptions.DFSNotUniqueDocKeyException;
import bnhp.infra.dfs.exceptions.DFSValidationException;
import bnhp.infra.dfs.model.business.ExecutorDetails;
import bnhp.infra.dfs.model.business.SecurityContext;
import bnhp.infra.dfs.model.service.DocDataForCreate;
import bnhp.infra.dfs.model.service.DocIdData;
import bnhp.infra.dfs.services.CreateDocumentsParameters;
import bnhp.infra.dfs.services.InputOverride;
import bnhp.infra.dfs.utils.service.DfsRequestThreadAttributes;
import com.emc.documentum.fs.rt.ServiceException;
import com.emc.documentum.fs.rt.ServiceInvocationException;
import com.emc.documentum.fs.rt.context.IServiceContext;
import com.emc.documentum.fs.rt.context.ServiceFactory;
import com.fasterxml.jackson.core.type.TypeReference;
import com.services.infra.bnhp.client.ICreateObjectServices;
import com.services.infra.bnhp.client.IUrlRequestServices;

import java.io.InputStream;
import java.lang.reflect.UndeclaredThrowableException;
import java.util.ArrayList;
import java.util.List;

public class CreateCustomerDocumentById extends AbstractSvcRequestHandler  {
	public void handleRequest(ISvcRequest svcReq) throws Exception {
		boolean success = false;
		boolean inputRead = false;
		// FIXME: only at real thread init!
		Utils.dfsThreadInit();
		try { 
			String requestId = svcReq.getRequestId();
			if (null == requestId) {
				requestId = DfsRequestThreadAttributes.dctmRequestId.get();
			} else {
				DfsRequestThreadAttributes.dctmRequestId.set(requestId);;
			}
			String objectId = svcReq.getQueryParam( "documentId");
			String idType = Utils.getIdType(svcReq);
			String metadataSourceUrl = svcReq.getQueryParam( "metadataSourceUrl");
			String cleanupPolicy = svcReq.getQueryParam( "cleanupPolicy");
		
			SecurityContext securityContext = makeSecurityContext(svcReq);
			boolean isLegacyId = "legacyDocumentId".equals(idType);
		
			if (! isLegacyId) {
				throw new DFSValidationException("Unsupported ID type for object creation: " + idType);
			}

			//fetch data from hashTable stored in tempHashMap
			DocumentData rdd =(DocumentData)((ExchSvcRequest)svcReq).getValueByKey("documentData");
			super.logInfo("DocumentData="+rdd);

			ExecutorDetails ed = Rest2DFS.toDFS(rdd.getDocCustomerData().getExecutorDetails());
			if (null == ed)
			{
				ed = svcReq.getExecutorDetails();
			}

			List<DocDataForCreate> ddfcrList = Rest2DFS.makeDocDataForCreateList(rdd);

			// FIXME: move into parent
			bnhp.dctmrest.model.ExecutorDetails executorDetails =
				null == rdd.getDocCustomerData() ? null :	rdd.getDocCustomerData().getExecutorDetails();
			// FIXME: allowed only for SYS2SYS calls
//			if (null != executorDetails &&
//				null != executorDetails.getIpAddress() &&
//				null != executorDetails.getExecutingEmpIdCode()) {
//				ed = Rest2DFS.toDFS(executorDetails);
//			}
			
			
			inputRead = true;
		
			ServiceUtils.applyDefaults(securityContext);
			IServiceContext context =
				ServiceUtils.createTransactionalServiceContext(securityContext);
			
			// FIXME?
			DocDataForCreate ddfcr = ddfcrList.get(0);
			if (null != ddfcr.getDocData() &&
				null != ddfcr.getDocData().getDocCustomerData()) {
				ddfcr.getDocData().getDocCustomerData().setExecutorDetails(ed);
			}
			if (null != cleanupPolicy) {
				ddfcr.setDocOperationFlags("cleanupPolicy="+cleanupPolicy);
			}
			if (null != metadataSourceUrl) {
				withFileInput(svcReq, context,  requestId,
							  objectId,
							  isLegacyId,
							  metadataSourceUrl,
							  cleanupPolicy,
							  securityContext,
							  ddfcrList,
							  ed);
			} else {
				withRequestInput(svcReq, context, requestId,
								 objectId, isLegacyId, cleanupPolicy, securityContext, ddfcrList, ed);
			}
			success = true;
		} catch (DFSDocumentumException e) {
			throw e;
		} catch (Exception e) {
			e.printStackTrace();
			if (! inputRead ) {
				throw new DFSValidationException("Error parsing input parameters: "+e.getMessage(), e);
			}
			//AuditUtils.logDetailedError(e, serviceName);
			//ExceptionUtils.throwECMException(e, details);
			throw new RuntimeException(e);
		} finally {
			if (success) {
				DfsRequestThreadAttributes.runPostTransactionCommitAction();
			} else {
				DfsRequestThreadAttributes.runPostTransactionAbortAction();
			}
		}
	}


	private void withFileInput(ISvcRequest svcReq,
							   IServiceContext context,
							   String requestId,
							   String objectId,
							   boolean isLegacyId,
							   String metadataSourceUrl,
							   String cleanupPolicy,
							   SecurityContext securityContext,
							   List<DocDataForCreate> inputOverride,
							   ExecutorDetails ed) throws DFSNotUniqueDocKeyException, ServiceException, DFSDocumentumException {
		IUrlRequestServices  svc = null;
		try {
			svc = ServiceFactory.getInstance().getLocalService(IUrlRequestServices.class, context);
		
			List<DocDataForCreate> ddfcList = null;
			String versionLabel = null;
		
			// FIXME: why do we need it?
			List<DocIdData> docIdData = new ArrayList(); //Utils.list();
			CreateDocumentsParameters fileParams = (CreateDocumentsParameters) svc
				.readUrlInput(metadataSourceUrl,
							  securityContext,
							  CreateDocumentsParameters.class);
			if (null == fileParams) {
				throw new DFSDocumentumException("error=FailedToLoadMethodParametersFromFile errorInfo=gotNullObject");
			}
			InputOverride.performOverride(fileParams, inputOverride);
			DfsRequestThreadAttributes.logger.get().info("CreateDocuments",
														 "inputObjectAfterOverride=" + fileParams);
			final List <DocDataForCreate> ddfcl = fileParams.getDocDataForCreateList();
			checkAndUpdateLegacyId(objectId, isLegacyId ,ddfcl);

			List<DocIdData> result = doCreateDocuments(fileParams.getDocDataForCreateList(),
													   securityContext,
													   fileParams.getVersionLabel(),
													   requestId,
													   fileParams.getSwitchRelatedDocuments());
		
		
		
			bnhp.dctmrest.model.DocIdData restResult = DFS2Rest.toRest(result.get(0));
			byte [] bytes = Utils.toByteArray(restResult);
			svcReq.setContentType("application/json");
			svcReq.setResponseCode(200);
			svcReq.send(bytes);
			
		} finally {
			if (null != svc) {
				try {
					DfsRequestThreadAttributes.
						logger.get().debug(operationName,"status=deletingInputFile");
					svc.deleteInputFile();
				} catch (ServiceException ex) {
					DfsRequestThreadAttributes
						.logger.get().error(operationName,"status=FailedToFeleteInputFile error=["																  + ex.getMessage() + "]");
				}
			}
		}

	}


	private void withRequestInput(ISvcRequest svcReq,
								  IServiceContext context,
								  String requestId,
								  String objectId,
								  boolean isLegacyId, 
								  String cleanupPolicy,
								  SecurityContext securityContext,
								  List<DocDataForCreate> ddfcList,
								  ExecutorDetails ed)
		throws DFSNotUniqueDocKeyException, ServiceException, DFSDocumentumException {
		ICreateObjectServices svc =
			ServiceFactory.getInstance().getLocalService(ICreateObjectServices.class, context);
		String versionLabel = null;
		checkAndUpdateLegacyId(objectId, isLegacyId ,ddfcList);
		// FIXME: why do we need it?
		List<DocIdData> docIdData = new ArrayList();
		List<DocIdData> result = svc.createDocumentsDfs2(ddfcList, securityContext, versionLabel, docIdData);
		bnhp.dctmrest.model.DocIdData restResult = DFS2Rest.toRest(result.get(0));
		byte[] bytes = Utils.toByteArray(restResult);
		svcReq.setContentType("application/json");
		svcReq.setResponseCode(200);
		svcReq.send(bytes);
		//success = true;
	}

	private void checkAndUpdateLegacyId(String objectId, boolean isLegacyId, List<DocDataForCreate> ddfcl)
		throws DFSValidationException{
		if (null == ddfcl || ddfcl.size() == 0 || null == ddfcl.get(0)) {
			throw new DFSValidationException("List of documents is empty");
		}
		if (ddfcl.size() > 1) {
			throw new DFSValidationException("Loading of multiple documents is not supported");
		}
		final DocDataForCreate ddfc = ddfcl.get(0);
		if (null == ddfc.getDocData()) {
			throw new DFSValidationException("DocData is empty");
		}
		if (null == ddfc.getDocData().getDocCustomerData()) {
			throw new DFSValidationException("DocCustomerData is empty");
		}
		if (null == ddfc.getDocData().getDocCustomerData().getDocDetails()) {
			throw new DFSValidationException("InvalidMethodParametersFromFile errorInfo=EmptyDocDetails");
		}
		if (isLegacyId && null != objectId && objectId.trim().length() > 0) {
			ddfc.getDocData().getDocCustomerData().getDocDetails().setLegacyDocumentId(objectId);
		}
	}

	private static List<DocIdData> doCreateDocuments(List<DocDataForCreate> docData4CreateList,
													 SecurityContext securityContext, String versionLabel,
			String requestId, Boolean switchRelatedDocuments) throws ServiceInvocationException,
			DFSValidationException, DFSDocumentumException, ServiceException {

		IServiceContext context = ServiceUtils
				.createTransactionalServiceContext(securityContext);
		ICreateObjectServices objectServices = (ICreateObjectServices) ServiceFactory
				.getInstance().getLocalService(ICreateObjectServices.class,
						context);
		List<DocIdData> resultList = null;
		List<DocIdData> outList = new ArrayList<DocIdData>();
		boolean success = false;
		try {
			resultList = objectServices.createDocumentsDfs2(docData4CreateList,
					securityContext, versionLabel, outList);
			success= true;
		} catch (UndeclaredThrowableException utex) {
			DfsRequestThreadAttributes.logger.get().warn("CreateDocuments",
					" state=gotUndeclaredThrowableException: outListSize="
							+ outList.size());
			DfsRequestThreadAttributes.runPostTransactionAbortAction();
			if (outList.size() > 0) {
				DfsRequestThreadAttributes.logger.get().warn("CreateDocuments", 
						" state=successWorkaroundUndeclaredThrowableException");
				resultList = outList;
			} else {
				DfsRequestThreadAttributes.logger.get().error("CreateDocuments", 
						"state=rethrowingException");
				throw utex;
			}
		} finally {
			if (success) {
				DfsRequestThreadAttributes.runPostTransactionCommitAction();
			} else {
				DfsRequestThreadAttributes.runPostTransactionAbortAction();
			}
		}
		return resultList;
	}
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\handlers\CreateDocumentById.java
-----------------------------------------------------
package bnhp.dctmrest.handlers;

import java.io.InputStream;
import com.fasterxml.jackson.core.type.TypeReference;
import bnhp.dctmrest.model.DocumentData;
import bnhp.dctmrest.requests.AbstractSvcRequestHandler;
import bnhp.dctmrest.requests.ExchSvcRequest;
import bnhp.dctmrest.requests.ISvcRequest;
import bnhp.dctmrest.utils.Json;

public class CreateDocumentById	 extends AbstractSvcRequestHandler
{
	private CreateCustomerDocumentById createCustomerDocumentById = new CreateCustomerDocumentById();
	private CreateGeneralDocumentById createGeneralDocumentById = new CreateGeneralDocumentById();

	@Override
	public void handleRequest(ISvcRequest svcReq) throws Exception
	{
		//get json and serialize it to DocumentData
		final TypeReference<DocumentData> tr = new TypeReference<DocumentData>() {};
		final InputStream is = svcReq.getInputStream();
		final DocumentData documentData = Json.serializer().fromInputStream(is, tr);
		super.logInfo("DocumentData=" + documentData);

		// Save the serialized object - 'documentData' to our ExchSvcRequest object for using it at CreateGeneralDoc or CreateCustomerDoc
		((ExchSvcRequest) svcReq).addKeyValue("documentData", documentData);
		String objectType = documentData.getObjectType();

		//check object type (from DocumentData)
		if (null == objectType)
		{
			createCustomerDocumentById.handleRequest(svcReq);
		}
		else
		{
			if (objectType.equalsIgnoreCase("bnhp_general_doc"))
			{
				createGeneralDocumentById.handleRequest(svcReq);
			}
			else
			{
				createCustomerDocumentById.handleRequest(svcReq);
			}
		}
	}

}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\handlers\CreateGeneralDocumentById.java
-----------------------------------------------------
package bnhp.dctmrest.handlers;

import bnhp.dctmrest.utils.*;
import bnhp.dctmrest.model.DocumentData;
import bnhp.dctmrest.requests.AbstractSvcRequestHandler;
import bnhp.dctmrest.requests.ExchSvcRequest;
import bnhp.dctmrest.requests.ISvcRequest;
import bnhp.infra.com.utils.service.BnhpRequestThreadAttributes;
import bnhp.infra.dfs.exceptions.DFSValidationException;
import bnhp.infra.ecm.exceptions.ECMDuplicateIdException;
import bnhp.infra.ecm.exceptions.ECMException;
import bnhp.infra.ecm.exceptions.ECMValidationException;
import bnhp.infra.ecm.model.DocGeneralData;
import bnhp.infra.ecm.model.DocIdData;
import bnhp.infra.ecm.services.BnhpEcmManageGeneralDoc;

public class CreateGeneralDocumentById extends AbstractSvcRequestHandler
{
	public void handleRequest(ISvcRequest svcReq) throws Exception
	{
		boolean isSuccess = false;
		boolean isPassRead = false;
		Utils.dfsThreadInit();

		try
		{
			String objectId = svcReq.getQueryParam("documentId");
			String idType = Utils.getIdType(svcReq);
			boolean isLegacyId = "legacyDocumentId".equals(idType);

			if (! isLegacyId)
			{
				throw new DFSValidationException("Unsupported ID type for object creation: " + idType);
			}

			//fetch data from hashTable stored in tempHashMap
			DocumentData documentData =(DocumentData)((ExchSvcRequest)svcReq).getValueByKey("documentData");
			super.logInfo("DocumentData="+documentData);

			bnhp.infra.ecm.model.SecurityContext ecmSecurityContext = makeGeneralSecurityContext(svcReq);

			logInfo("Authentication granted as dctmUser=" + ecmSecurityContext.getUserName() + " for repository="
					+ ecmSecurityContext.getRepositoryName());

			DocGeneralData docGeneralData = Rest2GeneralDocUtil.documentDataToDocGeneralData(documentData);
			docGeneralData.getDocDetails().setLegacyDocumentId(objectId);

			BnhpEcmManageGeneralDoc bnhpEcmManageGeneralDoc = new BnhpEcmManageGeneralDoc();
			isPassRead = true;

			// Taking the versionLabel value from the body if existing, else - put value '1'
			String versionLabel = null != documentData && null != documentData.getVersionLabels() &&
					documentData.getVersionLabels().size() > 0 ? documentData.getVersionLabels().get(0) : "1";

			DocIdData ecmDocIdData = bnhpEcmManageGeneralDoc.createDocument(docGeneralData, ecmSecurityContext,
					versionLabel);
			isSuccess = true;

			super.logInfo("CreateGeneralDocumentById:end Of Program, flag isSuccess:"+isSuccess);
			super.logInfo("CreateGeneralDocumentById:end - ecmDocIdResult : " + ecmDocIdData.getDctmDocumentId());

			bnhp.dctmrest.model.DocIdData restResult = Rest2GeneralDocUtil.toRest(ecmDocIdData);

			byte [] bytes = Utils.toByteArray(restResult);
			svcReq.setContentType("application/json");
			svcReq.setResponseCode(200);
			svcReq.send(bytes);

		}
		catch (Exception e)
		{
			e.printStackTrace();

			if (!isPassRead)
			{
				throw new ECMValidationException("Error parsing input parameters: " + e.getMessage(), e);
			}
			throw new RuntimeException(Utils.fixGeneralErrorMsgForResponse(e.getMessage()));
		}
		finally
		{
			if (isSuccess)
			{
				BnhpRequestThreadAttributes.runPostTransactionCommitAction();
			} else
			{
				BnhpRequestThreadAttributes.runPostTransactionAbortAction();
			}
		}
	}
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\handlers\DctmOpHandler.java
-----------------------------------------------------
package bnhp.dctmrest.handlers;

import bnhp.dctmrest.requests.ISvcRequest;
import bnhp.dctmrest.requests.ExchSvcRequest;
import bnhp.dctmrest.requests.ISvcRequestHandler;

import io.undertow.server.HttpServerExchange;

public class DctmOpHandler extends AbstractHandler {
	ISvcRequestHandler reqHandler;
	
	public DctmOpHandler(ISvcRequestHandler reqHandler) {
		this.reqHandler = reqHandler;
	}
		
	@Override
	public void handleRequest(HttpServerExchange exch) throws Exception {
		this.reqHandler.handleRequest(new ExchSvcRequest(exch));
	}
	
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\handlers\ErrorHandler.java
-----------------------------------------------------
package bnhp.dctmrest.handlers;

import java.nio.ByteBuffer;

import bnhp.dctmrest.utils.ErrorResponse;
import bnhp.dctmrest.utils.HttpUtils;
import bnhp.dctmrest.utils.Utils;
import bnhp.infra.dfs.exceptions.utils.ErrorInfoPropertyLoader;

import io.undertow.server.HttpHandler;
import io.undertow.server.HttpServerExchange;


public class ErrorHandler extends AbstractHandler {
	final HttpHandler nextHandler;
	
	protected ErrorHandler(HttpHandler nextHandler,
						   String operationName) {
		this.nextHandler = nextHandler;
		super.setOperationName(operationName);
	}

	@Override
	public void handleRequest(HttpServerExchange exch) throws Exception {
		if (exch.isInIoThread()) {
			exch.dispatch(this);
			return;
		}
		try {
			nextHandler.handleRequest(exch);
		} catch (Exception ex) {
			final ErrorResponse resp = new ErrorResponse(ex, operationName);
			HttpUtils.sendResponse(exch,
								   resp.getResponseCode(),
								   resp.getContentType(),
								   resp.getContent());
		}

	}
	
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\handlers\GetAsyncRequestStatus.java
-----------------------------------------------------
package bnhp.dctmrest.handlers;

import java.io.File;
import java.io.InputStream;
import java.lang.reflect.UndeclaredThrowableException;
import java.util.ArrayList;
import java.util.Date;
import java.util.List;

import bnhp.dctmrest.model.AsyncRequestStatus;

import com.documentum.fc.client.IDfSession;
import com.documentum.fc.client.IDfSessionManager;
import com.documentum.fc.client.IDfSysObject;
import com.documentum.fc.common.DfException;
import com.emc.documentum.fs.rt.ServiceException;
import com.emc.documentum.fs.rt.ServiceInvocationException;
//import com.documentum.fc.client.search.impl.generation.docbase.common.sco.definition.loading.common.SearchInterfaceFactory;
import com.emc.documentum.fs.rt.context.IServiceContext;
import com.emc.documentum.fs.rt.context.ServiceFactory;
import com.fasterxml.jackson.core.type.TypeReference;
import com.services.infra.bnhp.client.ICreateObjectServices;
import com.services.infra.bnhp.client.IUrlRequestServices;

import bnhp.dctmrest.model.DocumentData;
import bnhp.dctmrest.requests.AbstractSvcRequestHandler;
import bnhp.dctmrest.requests.DctmSvcRequest;
import bnhp.dctmrest.requests.ISvcRequest;
import bnhp.dctmrest.requests.ISvcRequestHandler;
import bnhp.dctmrest.utils.DFS2Rest;
//import bnhp.dctmrest.model.ExecutorDetails;
import bnhp.dctmrest.utils.Json;
import bnhp.dctmrest.utils.Rest2DFS;
import bnhp.dctmrest.utils.ServiceUtils;
import bnhp.dctmrest.utils.Utils;
import bnhp.infra.dfs.exceptions.DFSAuthorizationException;
import bnhp.infra.dfs.exceptions.DFSDocumentumException;
import bnhp.infra.dfs.exceptions.DFSNotUniqueDocKeyException;
import bnhp.infra.dfs.exceptions.DFSUnexpectedQueryResultException;
import bnhp.infra.dfs.exceptions.DFSValidationException;
import bnhp.infra.dfs.exceptions.utils.ErrorInfoConstants;
import bnhp.infra.dfs.init.ApplicationInitializer;
import bnhp.infra.dfs.model.business.ExecutorDetails;
import bnhp.infra.dfs.model.business.SecurityContext;
import bnhp.infra.dfs.model.service.DocDataForCreate;
import bnhp.infra.dfs.model.service.DocIdData;
import bnhp.infra.dfs.services.CreateDocumentsParameters;
import bnhp.infra.dfs.services.InputOverride;
import bnhp.infra.dfs.utils.basic.BasicQueryUtils;
import bnhp.infra.dfs.utils.dfc.DfcUtils;
import bnhp.infra.dfs.utils.service.DfsRequestThreadAttributes;

import io.undertow.server.HttpServerExchange;

public class GetAsyncRequestStatus	 extends AbstractSvcRequestHandler  {
	public void handleRequest(ISvcRequest svcReq) throws Exception {
		boolean success = false;
		boolean inputRead = false;
		// FIXME: only at real thread init!
		Utils.dfsThreadInit();
		IDfSessionManager sm = null;
		IDfSession sess = null;
		try { 
			String parRequestId = svcReq.getQueryParam("requestId");

			String requestId = svcReq.getRequestId();
			if (null == requestId) {
				requestId = DfsRequestThreadAttributes.dctmRequestId.get();
			} else {
				DfsRequestThreadAttributes.dctmRequestId.set(requestId);;
			}
			boolean needOutput = Utils.getQueryParamAsBoolean(svcReq, "returnOutput", false);
			
			SecurityContext securityContext = makeSecurityContext(svcReq);
			// FIXME: check sec cont
			ExecutorDetails ed = svcReq.getExecutorDetails();
			String sysUser = DfsRequestThreadAttributes.sysUser.get();
			
			inputRead = true;
			if (null == sysUser) {
				// will not happem
				throw new DFSAuthorizationException("Unexpected authorization error: system user not set");
			}
			AsyncRequestStatus result = new AsyncRequestStatus();
			result.setRequestId(parRequestId);

			ServiceUtils.applyDefaults(securityContext);
			ApplicationInitializer init = ApplicationInitializer.getInstance();
			sm = init.getSessionManager();
			sess = sm.getSession(securityContext.getRepositoryName());
			IDfSysObject obj = (IDfSysObject) sess.getObjectByQualification("bnhp_async_requests where s_req_id='" +
															 BasicQueryUtils.escapeQuotedString(parRequestId)+
															 "' AND s_req_owner = '" +
															 BasicQueryUtils.escapeQuotedString(sysUser)+"'");
			if (null == obj) {
				throw new DFSUnexpectedQueryResultException("Asynchronous request not found",
															ErrorInfoConstants.NON_EXISTING_OBJECT_TO_RETRIEVE);
			}

			DctmSvcRequest req = new DctmSvcRequest(obj);
			result.setFinished(req.getTSFinished());
			result.setStarted(req.getTSStarted());
			result.setReplied(req.getTSReplied());
			result.setReceived(req.getTSSubmitted());
			String objStat = req.getStatus();
			int reqRespCode = req.getResponseCode();
			AsyncRequestStatus.RequestStatusEnum reqStat = 
				DctmSvcRequest.REQ_STATUS_WAITING.equals(objStat) ?  AsyncRequestStatus.RequestStatusEnum.WAITING : 
				( DctmSvcRequest.REQ_STATUS_STARTED.equals(objStat) ? AsyncRequestStatus.RequestStatusEnum.STARTED :
				  ((DctmSvcRequest.REQ_STATUS_FINISHED.equals( objStat) || DctmSvcRequest.REQ_STATUS_REPLIED.equals(objStat)) ?
				   ((reqRespCode >= 200 && reqRespCode <=299) ?
					AsyncRequestStatus.RequestStatusEnum.SUCCESS :
					AsyncRequestStatus.RequestStatusEnum.FAILURE ) : null /* unknown status */));
			result.setRequestStatus(reqStat);
			if (reqStat ==  AsyncRequestStatus.RequestStatusEnum.SUCCESS 
				|| reqStat ==  AsyncRequestStatus.RequestStatusEnum.FAILURE) {
				result.setStatusCode(reqRespCode);
				result.setStatusMessage(reqRespCode == 200 ? "OK" : "HTTP Error "+reqRespCode);
				if (needOutput) {
					final byte[] outBytes =  req.getOutBodyBytes();
					if (null!=outBytes) {
						result.setOutput(outBytes);
						result.setOutputType(req.getOutMimeType());
					}
				}
			}
			
			byte[] bytes = Utils.toByteArray(result);
			svcReq.setContentType("application/json");
			result.setStatusCode(200);
			svcReq.send(bytes);
			success = true;
		} catch (DFSDocumentumException e) {
			throw e;
		} catch (Exception e) {
			e.printStackTrace();
			if (! inputRead ) {
				throw new DFSValidationException("Error parsing input parameters: "+e.getMessage(), e);
			}
			throw new RuntimeException(e);
		} finally {
			
			if (null != sm && null != sess) {
				sm.release(sess);
			}
		}
	}
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\handlers\HandlerFactory.java
-----------------------------------------------------
package bnhp.dctmrest.handlers;

import java.util.Map;

import bnhp.dctmrest.requests.ISvcRequest;
import bnhp.dctmrest.requests.ISvcRequestHandler;

import io.undertow.server.HttpHandler;
import io.undertow.server.handlers.RequestDumpingHandler;

public class HandlerFactory {
	private Map <String,Object> implMap;
	private boolean isDumpRequests = false;
	public HandlerFactory(Map <String,Object> implMap, boolean dumpRequests) {
		this.implMap = implMap;
		this.isDumpRequests = dumpRequests;
	}


	public ISvcRequestHandler makeSvcRequestHandler(String opName) {
		try {
			Object impl = implMap.get(opName);
			Class implClass = null;
			if (impl instanceof String) {
				String implName = (String)impl;
				implClass = this.getClass().getClassLoader().loadClass(implName);
			} else if (impl instanceof Class) {
				implClass = (Class)impl;
			}
			if (null != implClass) {
				ISvcRequestHandler handler = (ISvcRequestHandler) implClass.newInstance();
				handler.setOperationName(opName);
				return handler;
			} else {
				throw new RuntimeException("Failed to make handler for "+opName+": invalid mapping "+opName+"->"+impl); 
			}
		} catch (ClassNotFoundException|InstantiationException|IllegalAccessException  reflEx) {
			throw new RuntimeException("Failed to make handler for "+opName, reflEx); 
		}
	}
	public HttpHandler makeHandler(String operationName)  {
		ISvcRequestHandler  reqHandler = this.makeSvcRequestHandler(operationName);
		AbstractHandler opHandler = new DctmOpHandler(reqHandler);
		AbstractHandler asyncHandler = new AsyncHandler(opHandler, operationName);
		AbstractHandler errorHandler = new ErrorHandler(asyncHandler, operationName);
		AuthHandler authHandler = new AuthHandler(errorHandler, operationName);
		if (this.isDumpRequests) {
			HttpHandler dumpHandler = new io.undertow.server.handlers.RequestDumpingHandler(authHandler);
			return dumpHandler;
		} else {
			return authHandler;
		}
	}
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\handlers\PutDocumentById.java
-----------------------------------------------------
package bnhp.dctmrest.handlers;

import java.io.InputStream;
import java.util.ArrayList;
import java.util.List;

import com.emc.documentum.fs.rt.ServiceException;
import com.emc.documentum.fs.rt.ServiceInvocationException;
//import com.documentum.fc.client.search.impl.generation.docbase.common.sco.definition.loading.common.SearchInterfaceFactory;
import com.emc.documentum.fs.rt.context.IServiceContext;
import com.emc.documentum.fs.rt.context.ServiceFactory;
import com.fasterxml.jackson.core.type.TypeReference;
//import com.services.infra.bnhp.client.ICreateObjectServices;
import com.services.infra.bnhp.client.IUpdateObjectVersionServices;
import com.services.infra.bnhp.client.IUrlRequestServices;

import bnhp.dctmrest.model.DocumentData;
import bnhp.dctmrest.requests.AbstractSvcRequestHandler;
import bnhp.dctmrest.requests.ISvcRequest;
import bnhp.dctmrest.utils.DFS2Rest;
//import bnhp.dctmrest.model.ExecutorDetails;
import bnhp.dctmrest.utils.Json;
import bnhp.dctmrest.utils.Rest2DFS;
import bnhp.dctmrest.utils.ServiceUtils;
import bnhp.dctmrest.utils.Utils;
import bnhp.infra.dfs.exceptions.DFSDocumentumException;
import bnhp.infra.dfs.exceptions.DFSNotUniqueDocKeyException;
import bnhp.infra.dfs.exceptions.DFSValidationException;
import bnhp.infra.dfs.model.business.ExecutorDetails;
import bnhp.infra.dfs.model.business.SecurityContext;
//import bnhp.infra.dfs.model.service.DocDataForCreate;
import bnhp.infra.dfs.model.service.DocDataForUpdate;
import bnhp.infra.dfs.model.service.DocIdData;
import bnhp.infra.dfs.services.InputOverride;
import bnhp.infra.dfs.services.UpdateDocumentVersionParameters;
import bnhp.infra.dfs.utils.content.server_upload.FileBasedUploadUtils;
import bnhp.infra.dfs.utils.service.DfsRequestThreadAttributes;

public class PutDocumentById extends AbstractSvcRequestHandler  {

	@Override
	public void handleRequest(ISvcRequest svcReq) throws Exception {
		boolean success = false;
		boolean inputRead = false;
		// FIXME: only at real thread init!
		Utils.dfsThreadInit();
		try { 
			String requestId = svcReq.getQueryParam( "X-RequestID");
			String objectId = svcReq.getQueryParam( "documentId");
			String idType = Utils.getIdType(svcReq);
			String metadataSourceUrl = svcReq.getQueryParam( "metadataSourceUrl");
			String cleanupPolicy = svcReq.getQueryParam( "cleanupPolicy");

			SecurityContext securityContext = makeSecurityContext(svcReq);
			ExecutorDetails ed = svcReq.getExecutorDetails();
			if (null == requestId) {
				requestId = DfsRequestThreadAttributes.dctmRequestId.get();
			}
			boolean isLegacyId = "legacyDocumentId".equals(idType);
		
			if (! isLegacyId) {
				throw new DFSValidationException("Unsupported ID type for object creation: " + idType);
			}

			//BlockingHttpExchange bexch = exch.startBlocking();
			//super.logInfo("bech="+bexch);
			final TypeReference<DocumentData> tr = new TypeReference<DocumentData>() {};
			final InputStream is = svcReq.getInputStream();
			super.logInfo("is="+is);
			final DocumentData rdd = Json.serializer().fromInputStream(is, tr);
			super.logInfo("DocumentData="+rdd);

			DocDataForUpdate ddfu  = Rest2DFS.makeDocDataForUpdate(rdd, objectId, isLegacyId);

			// FIXME: move into parent
			bnhp.dctmrest.model.ExecutorDetails red =
				null == rdd.getDocCustomerData() ? null :	rdd.getDocCustomerData().getExecutorDetails();
			// FIXME: allowed only for SYS2SYS calls
			if (null != red &&
				null != red.getIpAddress() &&
				null != red.getExecutingEmpIdCode()) {
				ed = Rest2DFS.toDFS(red);
			}

			
			inputRead = true;
		
			ServiceUtils.applyDefaults(securityContext);
			IServiceContext context =
				ServiceUtils.createTransactionalServiceContext(securityContext);
			
			if (null != ddfu.getDocData() &&
				null != ddfu.getDocData().getDocCustomerData()) {
				ddfu.getDocData().getDocCustomerData().setExecutorDetails(ed);
			}
			if (null != cleanupPolicy) {
				ddfu.setDocOperationFlags("cleanupPolicy="+cleanupPolicy);
			}
			if (null != metadataSourceUrl) {
				withFileInput(svcReq, context,  requestId,
							  objectId,
							  isLegacyId,
							  metadataSourceUrl,
							  cleanupPolicy,
							  securityContext,
							  ddfu,
							  ed);
			} else {
				withRequestInput(svcReq, context, requestId,
								 objectId, isLegacyId, cleanupPolicy, securityContext, ddfu, ed);
			}
			success = true;
		} catch (DFSDocumentumException e) {
			throw e;
		} catch (Exception e) {
			e.printStackTrace();
			if (! inputRead ) {
				throw new DFSValidationException("Error parsing input parameters: "+e.getMessage(), e);
			}
			//AuditUtils.logDetailedError(e, serviceName);
			//ExceptionUtils.throwECMException(e, details);
			throw new RuntimeException(e);
		} finally {
			if (success) {
				DfsRequestThreadAttributes.runPostTransactionCommitAction();
			} else {
				DfsRequestThreadAttributes.runPostTransactionAbortAction();
			}
		}
	}


	private void withFileInput(ISvcRequest svcReq,
							   IServiceContext context,
							   String requestId,
							   String objectId,
							   boolean isLegacyId,
							   String metadataSourceUrl,
							   String cleanupPolicy,
							   SecurityContext securityContext,
							   DocDataForUpdate inputOverride,
							   ExecutorDetails ed) throws DFSNotUniqueDocKeyException, ServiceException, DFSDocumentumException {
		IUrlRequestServices  svc = null;
		boolean success = false;
		try {
			svc = ServiceFactory.getInstance().getLocalService(IUrlRequestServices.class, context);
		

			String versionLabel = null;
		
			// FIXME: why do we need it?
			List<DocIdData> docIdData = new ArrayList(); //Utils.list();
			UpdateDocumentVersionParameters fileParams = (UpdateDocumentVersionParameters) svc
					.readUrlInput(metadataSourceUrl,
							  securityContext,
							  UpdateDocumentVersionParameters.class);
			if (null == fileParams) {
				throw new DFSDocumentumException("error=FailedToLoadMethodParametersFromFile errorInfo=gotNullObject");
			}
			InputOverride.performOverride(fileParams, inputOverride);
			DfsRequestThreadAttributes.logger.get().info("CreateDocuments",
														 "inputObjectAfterOverride=" + fileParams);
			DocDataForUpdate ddfu = fileParams.getDocDataForUpdate();
			checkAndUpdateLegacyId(objectId, isLegacyId ,ddfu);

			DocIdData result = doUpdateDocuments(fileParams.getDocDataForUpdate(),
													   securityContext,
													   fileParams.getVersionLabel(),
													   requestId,
													   isLegacyId);
		
		
		
			bnhp.dctmrest.model.DocIdData restResult = DFS2Rest.toRest(result);
			byte [] bytes = Utils.toByteArray(restResult);
			svcReq.setContentType("application/json");
			svcReq.setResponseCode(200);
			svcReq.send(bytes);
			success = true;
		} finally {
			// FIXME: shared with create
			if (null != svc  ) {
				if (FileBasedUploadUtils.CLEANUP_POLICY_ALWAYS.equalsIgnoreCase(cleanupPolicy) ||
					( success &&
					  FileBasedUploadUtils.CLEANUP_POLICY_ON_SUCCESS.equalsIgnoreCase(cleanupPolicy)) ||
					null==cleanupPolicy) {
					try {
						DfsRequestThreadAttributes.
							logger.get().debug(operationName,"status=deletingInputFile");
						svc.deleteInputFile();
					} catch (ServiceException ex) {
						DfsRequestThreadAttributes
							.logger.get().error(operationName,"status=FailedToFeleteInputFile error=["																  + ex.getMessage() + "]");
					}
				}
			}
		}

	}


	private void withRequestInput(ISvcRequest svcReq,
								  IServiceContext context,
								  String requestId,
								  String objectId,
								  boolean isLegacyId, 
								  String cleanupPolicy,
								  SecurityContext securityContext,
								  DocDataForUpdate ddfu,
								  ExecutorDetails ed)
		throws DFSNotUniqueDocKeyException, ServiceException, DFSDocumentumException {
		IUpdateObjectVersionServices svc =
			ServiceFactory.getInstance().getLocalService(IUpdateObjectVersionServices.class, context);
		String versionLabel = null;
		checkAndUpdateLegacyId(objectId, isLegacyId ,ddfu);
		// FIXME: why do we need it?
		List<DocIdData> docIdData = new ArrayList();
		//List<DocIdData> result = svc.upcreateDocumentsDfs2(ddfcList, securityContext, versionLabel, docIdData);
		DocIdData result = svc.updateDocumentVersionById2(ddfu, securityContext, versionLabel, isLegacyId, true);
		
		bnhp.dctmrest.model.DocIdData restResult = DFS2Rest.toRest(result);
		byte[] bytes = Utils.toByteArray(restResult);
		svcReq.setContentType("application/json");
		svcReq.setResponseCode(200);
		svcReq.send(bytes);
		//success = true;
	}

	private void checkAndUpdateLegacyId(String objectId, boolean isLegacyId, DocDataForUpdate ddfu)
		throws DFSValidationException{
		if (null == ddfu) {
			throw new DFSValidationException("No document metadata provided for update");
		}
		if (null == ddfu.getDocData()) {
			throw new DFSValidationException("DocData is empty");
		}
		if (null == ddfu.getDocData().getDocCustomerData()) {
			throw new DFSValidationException("DocCustomerData is empty");
		}
		if (null == ddfu.getDocData().getDocCustomerData().getDocDetails()) {
			throw new DFSValidationException("InvalidMethodParametersFromFile errorInfo=EmptyDocDetails");
		}
		if (isLegacyId && null != objectId && objectId.trim().length() > 0) {
			ddfu.getDocData().getDocCustomerData().getDocDetails().setLegacyDocumentId(objectId);
		}
	}

	private static DocIdData doUpdateDocuments(DocDataForUpdate ddfu,
													 SecurityContext securityContext,
													 String versionLabel,
													 String requestId,
													 boolean isLegacyId) throws ServiceInvocationException,
			DFSValidationException, DFSDocumentumException, ServiceException {

		IServiceContext context = ServiceUtils
				.createTransactionalServiceContext(securityContext);
		IUpdateObjectVersionServices objectServices = (IUpdateObjectVersionServices) ServiceFactory
				.getInstance().getLocalService(IUpdateObjectVersionServices.class,
						context);
		List<DocIdData> resultList = null;
		DocIdData result  = null;
		boolean success = false;
		try {
			result = objectServices.updateDocumentVersionById2(ddfu,
																   securityContext,
																   versionLabel,
																   isLegacyId,
																   true /* allow create */);
			success= true;
			/*} catch (UndeclaredThrowableException utex) {
			DfsRequestThreadAttributes.logger.get().warn("updateDocuments",
														 " state=gotUndeclaredThrowableException: "+utex.getMessage());
			DfsRequestThreadAttributes.runPostTransactionAbortAction();
			DfsRequestThreadAttributes.logger.get().error("CreateDocuments", 
														  "state=rethrowingException");
				throw utex;
				}*/
		} finally {
			if (success) {
				DfsRequestThreadAttributes.runPostTransactionCommitAction();
			} else {
				DfsRequestThreadAttributes.runPostTransactionAbortAction();
			}
		}
		return result;
	}
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\handlers\RetrieveCustomerDocumentById.java
-----------------------------------------------------
package bnhp.dctmrest.handlers;

import java.util.ArrayList;
import java.util.List;
import java.util.Optional;

import javax.xml.ws.Holder;

import org.apache.commons.collections.CollectionUtils;

import com.emc.documentum.fs.rt.context.IServiceContext;
import com.emc.documentum.fs.rt.context.ServiceFactory;
import com.services.infra.bnhp.client.IRetrieveObjectServices;

import bnhp.dctmrest.model.BnhpCustomerDocData;
import bnhp.dctmrest.requests.AbstractSvcRequestHandler;
import bnhp.dctmrest.requests.ExchSvcRequest;
import bnhp.dctmrest.requests.ISvcRequest;
import bnhp.dctmrest.utils.CommonConstants;
import bnhp.dctmrest.utils.DFS2Rest;
import bnhp.dctmrest.utils.LogicalErrorDTO;
import bnhp.dctmrest.utils.ServiceUtils;
import bnhp.dctmrest.utils.Utils;
import bnhp.infra.dfs.exceptions.DFSDocumentumException;
import bnhp.infra.dfs.exceptions.DFSValidationException;
import bnhp.infra.dfs.exceptions.utils.ErrorInfoPropertyLoader;
import bnhp.infra.dfs.model.PropertyValidate;
import bnhp.infra.dfs.model.ValidateResult;
import bnhp.infra.dfs.model.ValidateStatus;
import bnhp.infra.dfs.model.business.BankAccount;
import bnhp.infra.dfs.model.business.CustomerKey;
import bnhp.infra.dfs.model.business.DocCustomerData;
import bnhp.infra.dfs.model.business.DocData;
import bnhp.infra.dfs.model.business.ExecutorDetails;
import bnhp.infra.dfs.model.business.SecurityContext;
import bnhp.infra.dfs.model.service.DocDataForRetrieve;
import bnhp.infra.dfs.model.service.DocRetrievalFlags;
import bnhp.infra.dfs.model.service.FetchTypeSet;
//import bnhp.infra.dfs.model.service.RequestDetails;
import bnhp.infra.dfs.utils.service.DfsRequestThreadAttributes;

public class RetrieveCustomerDocumentById extends AbstractSvcRequestHandler
{

	private String VALIDATION_STATUS_UNCHECK="2";
	private String VALIDATION_STATUS_VALID="0";
	private String VALIDATION_STATUS_UNVALID="1";
	private String BASE_VERSION="0.3.5";
	private String HTTP_203_SPECIAL_VERSION="0.3.6";
	
    @Override
    public void handleRequest(ISvcRequest svcReq) throws Exception {
//        boolean success = false;
        boolean inputRead = false;
        String versionId =null;
        DocDataForRetrieve docDataForRetrieve = null;
        DocData docDataCheck = null;
//        String customerAndAccountRetreiveDetails = null;
        // FIXME: only at real thread init!
        Utils.dfsThreadInit();
        try {
        	ExchSvcRequest req = (ExchSvcRequest) svcReq;
        	//req.
        	versionId = svcReq.getQueryParam( "versionId");
            String objectId = svcReq.getQueryParam( "documentId");
            String idType = svcReq.getQueryParam( "idType");
            String docFormat = svcReq.getQueryParam( "format");

            String versionLabel = svcReq.getQueryParam( "versionLabel");
            boolean retrieveSecondary =
                    Utils.asBoolean(svcReq.getQueryParam("retrieveSecondaryContent", "false"));
            String retrieveProfile = svcReq.getQueryParam( "retrieveProfile");
            String fetchType = svcReq.getQueryParam( "fetchType", DFS2Rest.META);

            docDataCheck = buildDocDataCheck(svcReq);

            //Utils.

            final DocRetrievalFlags flags = new DocRetrievalFlags();
            flags.setShouldRetrieveSecondaryFile(retrieveSecondary);
            flags.setRetrieveProfile(retrieveProfile);
            flags.setShouldRetrieveDocEventData(false);

            // FIXME: check validity of id type
            // FIXME: check is is not empty!

            boolean isLegacyId = "legacyDocumentId".equals(idType);
            FetchTypeSet fts = DFS2Rest.getFetchType(fetchType);


//            boolean retrieveContentOnly = false;


            DfsRequestThreadAttributes
                    .setOuterOperation(isLegacyId ? "retrieveDoc4LegacyDocumentId" : "retrieveDoc4DctmDocumentId");

//            Holder<List<RequestDetails>> requestDetails = new Holder<List<RequestDetails>>();
            inputRead = true;

            SecurityContext securityContext = makeSecurityContext(svcReq);
            ExecutorDetails ed = svcReq.getExecutorDetails();
            ServiceUtils.applyDefaults(securityContext);
            IServiceContext context = ServiceUtils.createTransactionalServiceContext(securityContext);

            IRetrieveObjectServices objectServices = (IRetrieveObjectServices)
                    ServiceFactory.getInstance()
                            .getLocalService(IRetrieveObjectServices.class, context);


            DfsRequestThreadAttributes.createValidateStatus(true);

            if (isLegacyId) {
            	docDataForRetrieve	= objectServices.retrieveDoc4LegacyDocumentId(objectId, docFormat, securityContext, ed,
                        fts, flags, versionLabel, docDataCheck);
            }else {
            	docDataForRetrieve	=objectServices.retrieveDoc4DctmDocumentId(objectId, docFormat, securityContext, ed,
                        fts, flags, versionLabel, docDataCheck);
            }
//            docDataForRetrieve = isLegacyId
//                    ? objectServices.retrieveDoc4LegacyDocumentId(objectId, docFormat, securityContext, ed,
//                    fts, flags, versionLabel, docDataCheck)
//                    : objectServices.retrieveDoc4DctmDocumentId(objectId, docFormat, securityContext, ed,
//                    fts, flags, versionLabel, docDataCheck);
//            success = true;

            //if (!retrieveContentOnly) {

            byte[] bytes;
            // FIXME: ugly and probebly note entirely right!
            //int responseCode = 200;
            
            if (docDataForRetrieve != null)
            {
                if ((fts.getFetchType() instanceof bnhp.infra.dfs.model.service.File) &&
                        null!=docDataForRetrieve.getDocData() &&
                        null!=docDataForRetrieve.getDocData().getDocFile() &&
                        null!=docDataForRetrieve.getDocData().getDocFile().getDocStream() &&
                        Utils.isAccepted(docDataForRetrieve.getDocData().getDocFile().getMimeType(), svcReq))	{

                    svcReq.setContentType(docDataForRetrieve.getDocData().getDocFile().getMimeType());
                    bytes = docDataForRetrieve.getDocData().getDocFile().getDocStream();
                    
                    //customerAndAccountRetreiveDetails = Utils.getCustomerAndAccount(docDataForRetrieve.getDocData());
                } else {
                    BnhpCustomerDocData bcdd = DFS2Rest.toRest(docDataForRetrieve, true);
                    bytes = Utils.toByteArray(bcdd);
                    svcReq.setContentType("application/json");
                }
                
                ValidateStatus resultValidate = DfsRequestThreadAttributes.getValidateResult();
                if (null != resultValidate )
                {
                	String valStat = VALIDATION_STATUS_UNCHECK;// "2";
                	if (resultValidate.isValidateSuccess()) {
                		valStat = VALIDATION_STATUS_VALID;// "0";
                	}else {
                		valStat = VALIDATION_STATUS_UNVALID; //"1";
                	}
                	
                    //String valStat = resultValidate.IsMissingDocData() ? "2" : resultValidate.IsValidateSuccess() ? "0" : "1";
                    ExchSvcRequest serviceRequest =(ExchSvcRequest) svcReq;
                    serviceRequest.addHeader("isValidDocument", valStat);

                    ArrayList<PropertyValidate> validatedProperties = resultValidate.getValidatedProps();
                    for (int n = 0; null != validatedProperties && n < validatedProperties.size(); ++n)
                    {
                    	serviceRequest.addHeader(n + ":validated", validatedProperties.get(n).toString());
                    }
                    //securityContext.getUserName()
                    serviceRequest.addHeader("sysUser", svcReq.getSysUser());
                    serviceRequest.addHeader("userName", securityContext.getUserName());
                    
                }

            }
            else
            {
                throw new RuntimeException(String.format(CommonConstants.ERROR_OBJECT_ID_IS_NOT_FOUND, idType, objectId));
            }
            
            svcReq.setResponseCode(200);
            svcReq.send(bytes);

        } catch (DFSDocumentumException e) {
            //AuditUtils.logDetailedError(e, serviceName);
            //ExceptionUtils.throwECMException(e, details);
        	//for 203 HTTP version ,set http 203 , and set the message in service request

        	if (BASE_VERSION.equals(versionId)) {
                throw e;
        	}
        	
        	//in case of not found doc , no m_allValidates exists
        	 if (DfsRequestThreadAttributes.getValidateResult().getValidatesType2ValidateResultMap()==null || CollectionUtils.isEmpty(DfsRequestThreadAttributes.getValidateResult().getValidatesType2ValidateResultMap().values())) {
        		 throw e;
        	 }
        	
        	doInvokeHttp203(svcReq, docDataCheck);
    		
            return;
            
        } catch (Exception e) {
            if (! inputRead ) {
                throw new DFSValidationException("Error parsing input parameters: "+e.getMessage(), e);
            }
            //AuditUtils.logDetailedError(e, serviceName);
            //ExceptionUtils.throwECMException(e, details);
            throw new RuntimeException(e);
        } finally {
        }

    }

    /**
     * from now on(verion not BASE_VERSION), check docDataCheck with the ducument medatata , if not match return HTTP 203
     * @param svcReq
     * @param docDataCheck
     */
	private void doInvokeHttp203(ISvcRequest svcReq, DocData docDataCheck) {
		List<PropertyValidate> propertyValidateList= null;
		ValidateResult validateResult = DfsRequestThreadAttributes.getValidateResult().getValidatesType2ValidateResultMap().get(bnhp.infra.dfs.model.ValidateType.META_DATA);
		if (validateResult!=null) {
			propertyValidateList= validateResult.getAllProperties();
		}
//        	List<PropertyValidate> propertryCustomerList = propertyValidateList.stream().filter(property -> property.getPropertyName().contains("CustomerId")).findFirst().get();
		//PropertyValidate propertryAccount = propertyValidateList.stream().filter(property -> property.getPropertyName().contains("acc")).findFirst().get();
		
		
		String VALIDATION_HOOK_RETREIVE_CUSTOMER_DOCUMENT_COMPARE_CUST = "validation_hook_retrieve_customer_document_compare_cust";
		String VALIDATION_HOOK_RETREIVE_CUSTOMER_DOCUMENT_COMPARE_ACCOUNT = "validation_hook_retrieve_customer_document_compare_account";
		String VALIDATION_HOOK_RETREIVE_CUSTOMER_DOCUMENT_COMPARE_CUSTOMER_AND_ACCOUNT = "validation_hook_retrieve_customer_document_compare_customer_and_account";
//    		String customerAndAccountFromDocDataCheck = Utils.getCustomerAndAccount(docDataCheck);
		
		BankAccount bankAccount = Utils.fetchBankAccount(docDataCheck);
		CustomerKey customerKey = Utils.fetchCustomer(docDataCheck);
		
		//boolean isAccountCompleteFull =bankAccount.isCompleteFull(); 
		//check if both customer and account are match to the doc Retreive
		if (customerKey!=null && bankAccount!=null) {
			
			PropertyValidate propertryCustomer = fetchCustomer(propertyValidateList);
			PropertyValidate propertryAccount = fetchAccount(propertyValidateList);
			if (propertryCustomer==null && propertryAccount==null) { //not found such customer
				handle203ErrorMessage(svcReq,VALIDATION_HOOK_RETREIVE_CUSTOMER_DOCUMENT_COMPARE_CUSTOMER_AND_ACCOUNT,203);    				
			}
		}else if (customerKey!=null) {

			PropertyValidate propertryCustomer = fetchCustomer(propertyValidateList);
			
		
			if (propertryCustomer==null) { //not found such customer
				handle203ErrorMessage(svcReq,VALIDATION_HOOK_RETREIVE_CUSTOMER_DOCUMENT_COMPARE_CUST,203);    				
			}
		}else if (bankAccount!=null ) {

			PropertyValidate propertryAccount = fetchAccount(propertyValidateList);
		
			if (propertryAccount==null) { //not found such customer
				handle203ErrorMessage(svcReq,VALIDATION_HOOK_RETREIVE_CUSTOMER_DOCUMENT_COMPARE_ACCOUNT,203);    				
			}
		}
	}

	private PropertyValidate fetchAccount(List<PropertyValidate> propertyValidateList) {
		
		if (propertyValidateList==null) {
			return null;
		}
		
		Optional<PropertyValidate> propertryAccount = propertyValidateList.stream().filter(property -> property.getPropertyName().contains("acc")).filter(property -> {
			if (bnhp.infra.dfs.utils.basic.Utils.isEmptyOrZeroField(property.getValueActual())) {
				return false;
			}
			if (bnhp.infra.dfs.utils.basic.Utils.isEmptyOrZeroField(property.getValueExpected())) {
				return false;
			}
			return property.getValueActual().equals(property.getValueExpected());
		}).findAny();
		
		PropertyValidate propertyValidateValue = propertryAccount.orElse(null);
		
		return propertyValidateValue;
	}

//	private Long fetchCustomerNumMatch(List<PropertyValidate> propertyValidateList) {
//		
//		
//		Long customerNum = propertyValidateList.stream().filter(property -> property.getPropertyName().contains("CustomerId")).filter(property -> {
//			if (property.getValueActual()==null) {
//				return false;
//			}
//			if (property.getValueExpected()==null) {
//				return false;
//			}
//			boolean b = property.getValueActual().equals(property.getValueExpected());
//			return b;
//		}).count();
//		
//		//PropertyValidate propertryCustomer = null;
//		return customerNum;
//	}

	
	private PropertyValidate fetchCustomer(List<PropertyValidate> propertyValidateList) {
		
		if (propertyValidateList==null) {
			return null;
		}
		
		Optional<PropertyValidate> propertryCustomer = propertyValidateList.stream().filter(property -> property.getPropertyName().contains("CustomerId")).filter(property -> {
			if (property.getValueActual()==null) {
				return false;
			}
			if (property.getValueExpected()==null) {
				return false;
			}
			boolean b = property.getValueActual().equals(property.getValueExpected());
			return b;
		}).findAny();
		
		PropertyValidate propertyValidateValue = propertryCustomer.orElse(null);
		//PropertyValidate propertryCustomer = null;
		return propertyValidateValue;
	}
	
    private Object[] fomratCustomerAccountData(DocData docDataCheck,DocData docDataForRetreive) {
    
    	String customerAndAccountFromDocDataCheck = Utils.getCustomerAndAccount(docDataCheck);
    	String customerAndAccountFromDocDataRetrieve = Utils.getCustomerAndAccount(docDataForRetreive);
    	return new Object[] {customerAndAccountFromDocDataCheck,customerAndAccountFromDocDataRetrieve};
    			
    }

    
	private void handle203ErrorMessage(ISvcRequest svcReq,String errorTypeKey,int responseCode) {
		svcReq.setResponseCode(responseCode);
		
		
		ErrorInfoPropertyLoader errorInfoPropertyLoader = ErrorInfoPropertyLoader.getInstance();
		String errorCodeMsg = errorInfoPropertyLoader.getErrorCode(errorTypeKey);
		String errorCode = Utils.getValueOfPairWithDelimiter(errorCodeMsg,":");
		String errorKey = Utils.getKeyOfPairWithDelimiter(errorCodeMsg,":");
		int errorCodeInt =0;
		try {
			errorCodeInt = Integer.parseInt(errorCode);
		}catch(Exception ee) {
			logError("error in parse message:"+errorCode+" message:"+ee.getMessage());
		}
		String errorMessage = errorInfoPropertyLoader.getErrorMessage(errorTypeKey);
//		errorMessage = String.format(errorMessage, valuesStrArr);
		LogicalErrorDTO logicalErrorDTO = new LogicalErrorDTO(errorCodeInt,errorMessage,errorKey);
		
		byte[] bytes = Utils.toByteArray(logicalErrorDTO);
		
		svcReq.send(bytes);
		svcReq.setContentType("application/json");
	}

	protected DocData buildDocDataCheck(ISvcRequest r) {
		DocData result = null;
		final String completeCustomerIdCode = Utils.getQueryParamAsTrimmedString(r, "completeCustomerIdCode");
		final Long customerId = Utils.getQueryParamAsLong(r, "customerId");
		final Integer customerTypeCode = Utils.getQueryParamAsInteger(r, "customerTypeCode");
		final Integer accountBankId = Utils.getQueryParamAsInteger(r, "accountBankId");
		final Integer accountBranchId = Utils.getQueryParamAsInteger(r, "accountBranchId");
		final Integer accountNbr = Utils.getQueryParamAsInteger(r, "accountNbr");

		List<CustomerKey> customers = null;
		if ((! Utils.isEmptyOrNull(completeCustomerIdCode)) ||
			Utils.isPositive(customerId)) {
			customers = new ArrayList<CustomerKey>(1);
			CustomerKey customer = new CustomerKey();
			customers.add(customer);

			if (! Utils.isEmptyOrNull(completeCustomerIdCode)) {
				customer.setCompleteCustomerIdCode(completeCustomerIdCode);
			}
			if (Utils.isPositive(customerId)) {
				customer.setCustomerId(customerId);
			}
		}

		List<BankAccount> bankAccounts = null;
		if (Utils.isNonNegative(accountBankId) ||
			Utils.isNonNegative(accountBranchId) ||
			Utils.isNonNegative(accountNbr)) {
			bankAccounts = new ArrayList<BankAccount>(1);
			BankAccount bankAccount = new BankAccount();
			bankAccounts.add(bankAccount);

			bankAccount.setAccountNbr(accountNbr);
			bankAccount.setBranchId(accountBranchId);
			bankAccount.setAccountBankId(accountBankId);
		}

		if (null != bankAccounts || null != customers) {
			final DocCustomerData dcd = new DocCustomerData();
			dcd.setBankAccounts(bankAccounts);
			dcd.setCustomerKeys(customers);
			result = new DocData();
			result.setDocCustomerData(dcd);
		}
		return result;
	}

}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\handlers\RetrieveDocumentById.java
-----------------------------------------------------
package bnhp.dctmrest.handlers;

import java.util.List;

import javax.xml.ws.Holder;

//import com.documentum.fc.client.search.impl.generation.docbase.common.sco.definition.loading.common.SearchInterfaceFactory;
import bnhp.infra.ecm.exceptions.ECMException;
import com.emc.documentum.fs.rt.context.IServiceContext;
import com.emc.documentum.fs.rt.context.ServiceFactory;
import com.services.infra.bnhp.client.IRetrieveObjectServices;

import bnhp.dctmrest.model.BnhpCustomerDocData;
import bnhp.dctmrest.requests.AbstractSvcRequestHandler;
import bnhp.dctmrest.requests.ISvcRequest;
import bnhp.dctmrest.utils.DFS2Rest;
import bnhp.dctmrest.utils.ServiceUtils;
import bnhp.dctmrest.utils.Utils;
import bnhp.infra.dfs.exceptions.DFSDocumentumException;
import bnhp.infra.dfs.exceptions.DFSValidationException;
import bnhp.infra.dfs.model.business.DocData;
import bnhp.infra.dfs.model.business.ExecutorDetails;
import bnhp.infra.dfs.model.business.SecurityContext;
import bnhp.infra.dfs.model.service.DocDataForRetrieve;
import bnhp.infra.dfs.model.service.DocRetrievalFlags;
import bnhp.infra.dfs.model.service.FetchTypeSet;
import bnhp.infra.dfs.model.service.RequestDetails;
import bnhp.infra.dfs.utils.service.DfsRequestThreadAttributes;

public class RetrieveDocumentById extends AbstractSvcRequestHandler
{
	final String OBJECT_TYPE_NOT_ALLOWD = "value '%s' is not allowed for 'ObjectType' parameter..";
	private RetrieveCustomerDocumentById custRet = new RetrieveCustomerDocumentById();
	private RetrieveGeneralDocumentById genRet = new RetrieveGeneralDocumentById();

	@Override
	public void handleRequest(ISvcRequest svcReq) throws Exception
	{
		String objectType = svcReq.getQueryParam("objectTypes");

		if ((objectType == null) || (objectType.isEmpty()))
		{
			try
			{
				custRet.handleRequest(svcReq);
			}
			catch (DFSDocumentumException ex)
			{
				// no such document or no rights
				if ("GENERAL_ERROR:800".equals(ex.getErrorCode()))
				{
					genRet.handleRequest(svcReq);
				} else {
					// FIXME: are there other exceptions when we would
					// like to skip to other service?
					throw ex;
				}
			}
			// any other exception will fail the request, and
			// this is OK
		}
		else
		{
			switch (objectType)
			{
				case "BnhpCustomerDoc":
				{
					custRet.handleRequest(svcReq);
					break;
				}
				case "BnhpGeneralDoc":
				{
					genRet.handleRequest(svcReq);
					break;
				}
				case "BnhpDocFolder":
				{
					break;
				}
				default:
				{
					throw new RuntimeException(String.format(OBJECT_TYPE_NOT_ALLOWD, objectType));
				}
			}
		}
	}
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\handlers\RetrieveGeneralDocumentById.java
-----------------------------------------------------
package bnhp.dctmrest.handlers;

import bnhp.dctmrest.model.BnhpCustomerDocData;
import bnhp.dctmrest.model.BnhpGeneralDocData;
import bnhp.dctmrest.requests.AbstractSvcRequestHandler;
import bnhp.dctmrest.requests.ExchSvcRequest;
import bnhp.dctmrest.requests.ISvcRequest;
import bnhp.dctmrest.utils.*;
import bnhp.infra.dfs.model.business.ExecutorDetails;
import bnhp.infra.dfs.model.business.SecurityContext;
import bnhp.infra.dfs.model.service.DocRetrievalFlags;
import bnhp.infra.dfs.model.service.FetchTypeSet;
import bnhp.infra.ecm.model.DocDataForRetrieve;
import bnhp.infra.ecm.services.BnhpEcmRtrvGeneralDoc;
import com.emc.documentum.fs.datamodel.core.ObjectIdentity;
import com.emc.documentum.fs.datamodel.core.content.UrlContent;
import com.emc.documentum.fs.rt.context.IServiceContext;

public class RetrieveGeneralDocumentById extends AbstractSvcRequestHandler
{
    @Override
    public void handleRequest(ISvcRequest svcReq) throws Exception
    {
        Boolean gotException = false;
        String exceptionMessage = "";

        try
        {
            //Read and validate the request parameters
            String objectId = svcReq.getQueryParam(CommonConstants.QUERY_PARAMETER_DOCUMENT_ID);
            String idType = svcReq.getQueryParam(CommonConstants.QUERY_PARAMETER_ID_TYPE);
            String docFormat = svcReq.getQueryParam(CommonConstants.QUERY_PARAMETER_FORMAT);
            String versionLabel = svcReq.getQueryParam(CommonConstants.QUERY_PARAMETER_VERSION_LABEL);
            String fetchType = svcReq.getQueryParam(CommonConstants.QUERY_PARAMETER_FETCH_TYPE, DFS2Rest.META);
            String retrieveProfile = Utils.ValidateRetrieveProfile(svcReq.getQueryParam(CommonConstants.Q_PAR_RET_PROF));
            boolean retrieveSecondary = Utils.asBoolean(svcReq.getQueryParam(CommonConstants.Q_PAR_RET__SECOND_PROF, "false"));
            ExecutorDetails ed = svcReq.getExecutorDetails();

            logInfo(String.format("ExecutorDeatails info loaded: %s ",ed.toString()));

            // -- When RetrieveProfile is not 'Stream' - FetchType can't be 'content' - so it replace to full.
            // -- content[ecm] or file[dfs] - both returns the DocStream without any details. 'So..Se..Tu' :)
            FetchTypeSet fts = ((!retrieveProfile.equalsIgnoreCase(CommonConstants.RETRIEVE_PROFILE_STREAM)) &&
                           (fetchType.equalsIgnoreCase(CommonConstants.FETCH_TYPE_CONTENT)))
                           ? DFS2Rest.getFetchType(CommonConstants.FETCH_TYPE_FULL) : DFS2Rest.getFetchType(fetchType);

            boolean isLegacyId = CommonConstants.LEGACY_DOC_ID_TEXT.equals(idType);

            final DocRetrievalFlags flags = new DocRetrievalFlags();
            flags.setShouldRetrieveSecondaryFile(retrieveSecondary);
            flags.setRetrieveProfile(retrieveProfile);
            flags.setShouldRetrieveDocEventData(false);

            // FIXME: needs to delete all the DFS uses. then, create UrlHandler and ServiceUtils that expected only ECM SecurityContext.
            bnhp.infra.ecm.model.SecurityContext genericSecurityContext = makeGeneralSecurityContext(svcReq);
            SecurityContext dfsSecurityContext = makeSecurityContext(svcReq);

            ServiceUtils.applyDefaults(dfsSecurityContext);
            IServiceContext context = ServiceUtils.createTransactionalServiceContext(dfsSecurityContext);
            UrlContentProviderUtil uriProviderHelper = new UrlContentProviderUtil(dfsSecurityContext, context);

            DocDataForRetrieve result = null;
            BnhpEcmRtrvGeneralDoc retGen = new BnhpEcmRtrvGeneralDoc();

            result = isLegacyId ? retGen.retrieveDocForLegacyDocumentId(objectId, genericSecurityContext, versionLabel) :
                    retGen.retrieveDocForDctmDocumentId(objectId, genericSecurityContext, versionLabel);

            if (result == null)
            {
                throw new RuntimeException(String.format(CommonConstants.ERROR_OBJECT_ID_IS_NOT_FOUND, idType, objectId));
            }

            if(docFormat != null && !result.getDocGeneralData().getDocFile().getDocFormat().equalsIgnoreCase(docFormat))
            {
                throw new RuntimeException(String.format(CommonConstants.ERROR_OBJECT_AS_FORMAT_IS_NOT_FOUND, idType, objectId, docFormat));
            }

            byte[] bytes = null;
            boolean inlineContent = true;

            if (retrieveProfile.equalsIgnoreCase("http"))
            {
                ObjectIdentity<?> objIdentity =
                        uriProviderHelper.GetObjIdentityByDctm(result.getDocIdData().getDctmDocumentId());

                UrlContent url = uriProviderHelper.GetUrl(objIdentity, null);

                result.getDocGeneralData().getDocFile().setDocURL(url.getUrl());

                inlineContent = false;
            }

            switch (fetchType.toLowerCase())
            {
                case CommonConstants.FETCH_TYPE_CONTENT:
                {
                    if (Utils.isAccepted(result.getDocGeneralData().getDocFile().getMimeType(), svcReq))
                    {
                        svcReq.setContentType(result.getDocGeneralData().getDocFile().getMimeType());
                        bytes = result.getDocGeneralData().getDocFile().getDocStream();
                    }
                    else
                    {
                        BnhpGeneralDocData bcdd = DFS2Rest.toRest(result, true);
                        bytes = Utils.toByteArray(bcdd);
                        svcReq.setContentType("application/json");
                    }
                    break;
                }
                case CommonConstants.FETCH_TYPE_FULL:
                {
                    BnhpGeneralDocData genDocResult = DFS2Rest.toRest(result, inlineContent);
                    bytes = Utils.toByteArray(genDocResult);
                    svcReq.setContentType(CommonConstants.MIME_APPLICATION_JSON);

                    break;
                }
                case CommonConstants.FETCH_TYPE_META:
                {
                    result.getDocGeneralData().setDocFile(null);
                    BnhpGeneralDocData genDocResult = DFS2Rest.toRest(result, false);
                    bytes = Utils.toByteArray(genDocResult);
                    svcReq.setContentType(CommonConstants.MIME_APPLICATION_JSON);
                    break;
                }
                default:
                {
                    throw new RuntimeException(String.format("fetchType parameter cant be %s ", fetchType));
                }
            }

            svcReq.setResponseCode(200);
            svcReq.send(bytes);

        }
        catch(Exception e)
        {
            throw e;
        }
    }
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\handlers\Search.java
-----------------------------------------------------
package bnhp.dctmrest.handlers;

import java.io.InputStream;
import java.nio.ByteBuffer;
import java.util.List;

import com.emc.documentum.fs.rt.context.IServiceContext;
import com.emc.documentum.fs.rt.context.ServiceFactory;
import com.services.infra.bnhp.client.ISearchObjectServices;

import bnhp.dctmrest.model.InlineResponse200;
import bnhp.dctmrest.requests.AbstractSvcRequestHandler;
import bnhp.dctmrest.requests.ISvcRequest;
import bnhp.dctmrest.requests.ISvcRequestHandler;
import bnhp.dctmrest.utils.DFS2Rest;
import bnhp.dctmrest.utils.JsonSearchParser;
import bnhp.dctmrest.utils.ServiceUtils;
import bnhp.dctmrest.utils.Utils;
import bnhp.infra.dfs.exceptions.DFSDocumentumException;
import bnhp.infra.dfs.exceptions.DFSValidationException;
import bnhp.infra.dfs.model.business.ExecutorDetails;
import bnhp.infra.dfs.model.business.SecurityContext;
import bnhp.infra.dfs.model.query.prepared.PreparedQuery;
import bnhp.infra.dfs.model.service.DocDataForRetrieve;
import bnhp.infra.dfs.model.service.DocRetrievalFlags;
import bnhp.infra.dfs.model.service.FetchTypeSet;
import bnhp.infra.dfs.model.service.SearchDefinition;
import bnhp.infra.dfs.model.service.SearchResult;
import bnhp.infra.dfs.utils.service.DfsRequestThreadAttributes;

import io.undertow.server.BlockingHttpExchange;
import io.undertow.server.HttpServerExchange;

public class Search extends AbstractSvcRequestHandler  {
	@Override
	public void handleRequest(ISvcRequest svcReq) throws Exception {
		boolean success = false;
		boolean inputRead = false;
		// FIXME: only at real thread init!
		Utils.dfsThreadInit();
		try {
			String requestId = svcReq.getQueryParam( "X-RequestID");
			if (null == requestId) {
				requestId = DfsRequestThreadAttributes.dctmRequestId.get();
			}

			String searchName = svcReq.getQueryParam( "searchName");
			
			//BlockingHttpExchange bexch = exch.startBlocking();
			//super.logInfo("bech="+bexch);
			final InputStream is = svcReq.getInputStream();
			super.logInfo("is="+is);
			JsonSearchParser jsp = new JsonSearchParser();
			jsp.parseSearchParams(is);
			FetchTypeSet fetchTypeSet = jsp.getFetchTypeSet();
			DocRetrievalFlags flags = jsp.getDocRetrievalFlags();
			SearchDefinition defs = jsp.getSearchDefinition();
			PreparedQuery pq = jsp.getPreparedQuery();
			pq.setName(searchName);
			ExecutorDetails ed = svcReq.getExecutorDetails();
			
			inputRead = true;
			SecurityContext securityContext = makeSecurityContext(svcReq);

			ServiceUtils.applyDefaults(securityContext);
			IServiceContext context = ServiceUtils.createTransactionalServiceContext(securityContext);
					
			ISearchObjectServices svc = (ISearchObjectServices)	ServiceFactory.getInstance()
				.getLocalService(ISearchObjectServices.class, context);
			
			SearchResult results = svc.preparedQueryMetaSearch(securityContext, fetchTypeSet, flags, defs, pq, ed);
			//List<DocDataForRetrieve> documents = results.getDocuments();
			// FIXME: why it's named  InlineResponse200 and not DocumentsListResponse ?
			InlineResponse200 restResults = DFS2Rest.toRest(results);
			if (null!=defs && null!=restResults.getObjects() &&
				defs.getMaxResultCount()==restResults.getObjects().size()) {
				restResults.setEstimatedTotal(defs.getStartIndex() + restResults.getObjects().size()
											  + defs.getMaxResultCount());
			} else {
				restResults.setEstimatedTotal(defs.getStartIndex() + restResults.getObjects().size());
			}

			//DocIdData result = svc.cancelDocument(objectId, isLegacyId, securityContext, ed);
			//Object result = null;
			//bnhp.dctmrest.model.DocIdData restResult = DFS2Rest.toRest(result);
			//Object restResult = null;
			byte[] bytes = Utils.toByteArray(restResults);
			svcReq.setContentType("application/json");
			svcReq.setResponseCode(200);
			svcReq.send(bytes);
			success = true;
		} catch (DFSDocumentumException e) {
			throw e;
		} catch (Exception e) {
			if (!inputRead) {
				throw new DFSValidationException("Error parsing input parameters: " + e.getMessage(), e);
			}
			//AuditUtils.logDetailedError(e, serviceName);
			//ExceptionUtils.throwECMException(e, details);
			throw new RuntimeException(e);
		} finally {
		}
	}

}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\handlers\Whoami.java
-----------------------------------------------------
package bnhp.dctmrest.handlers;

import java.util.HashMap;
import java.util.Map;

import bnhp.dctmrest.requests.AbstractSvcRequestHandler;
import bnhp.dctmrest.requests.ISvcRequest;
import bnhp.dctmrest.utils.Utils;

public class Whoami	 extends AbstractSvcRequestHandler  {
	public void handleRequest(ISvcRequest svcReq) throws Exception {
		boolean success = false;
		boolean inputRead = false;
		// FIXME: only at real thread init!
		Utils.dfsThreadInit();

		Map resultMap = new HashMap();
		resultMap.put("status", "ok");
		resultMap.put("sysUser", svcReq.getSysUser());
		resultMap.put("token", svcReq.getAuthToken());
		
		byte[] bytes = Utils.toByteArray(resultMap);
		svcReq.setContentType("application/json");
		svcReq.send(bytes);
		success = true;
	}
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\model\OneOfbnhpPaperDocbnhpCorporateDocbnhpDivisionBusiness.java
-----------------------------------------------------
package bnhp.dctmrest.model;

import java.util.Map;
import java.util.Objects;

import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;

import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;

// FIXME: make generator give it sane name
public class OneOfbnhpPaperDocbnhpCorporateDocbnhpDivisionBusiness {

	private String name;

	private Map<String, Object> properties;

	/**
	 * @return the name
	 */
	@ApiModelProperty(value = "")
	@JsonProperty("name")
	public String getName() {
		return name;
	}

	/**
	 * @param name the name to set
	 */
	public void setName(String name) {
		this.name = name;
	}

	/**
	 * @return the properties
	 */
	@ApiModelProperty(value = "")
	@JsonProperty("properties")
	public Map<String, Object> getProperties() {
		return properties;
	}

	/**
	 * @param properties the properties to set
	 */
	public void setProperties(Map<String, Object> properties) {
		this.properties = properties;
	}
	
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\model\OneOfstringarray.java
-----------------------------------------------------
package bnhp.dctmrest.model;


public class OneOfstringarray {
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\msginput\AbstractAsyncTask.java
-----------------------------------------------------
package bnhp.dctmrest.msginput;

import static bnhp.dctmrest.utils.Utils.getLogger;

import java.io.IOException;
import java.util.Map;

import org.cfg4j.provider.ConfigurationProvider;

import com.documentum.fc.client.DfQuery;
import com.documentum.fc.client.IDfCollection;
import com.documentum.fc.client.IDfQuery;
import com.documentum.fc.client.IDfSession;
import com.documentum.fc.client.IDfSessionManager;
import com.documentum.fc.client.IDfSysObject;
import com.documentum.fc.common.DfException;
import com.documentum.fc.common.DfId;

import bnhp.dctmrest.handlers.HandlerFactory;
import bnhp.dctmrest.requests.DctmSvcRequest;
import bnhp.dctmrest.utils.IConfigurable;
import bnhp.dctmrest.utils.Utils;
import bnhp.infra.dfs.exceptions.DFSDocumentumException;
import bnhp.infra.dfs.init.ApplicationInitializer;
import bnhp.infra.dfs.utils.basic.LoggingUtils;

public abstract class AbstractAsyncTask implements Runnable, IConfigurable {
	LoggingUtils logger;
	ApplicationInitializer init;
	//AsyncInput parent;
	HandlerFactory factory;
	Map<String, Object> context;
	protected ConfigurationProvider provider;
	protected String name;
	
	protected String sn() {
		return this.getClass().getSimpleName();
	}
	
	@Override
	public void run() {
		Utils.dfsThreadInit();
		logger = getLogger();
		logger.info(sn(), "starting");
		//parent = input;
		factory = new HandlerFactory((Map<String,Object>)context.get("handlerFactory"), false);
		init = ApplicationInitializer.getInstance();
		//LoggingUtils logger = getLogger();
		logger.info(sn(), "started");
		IDfSessionManager sm  = null;
		IDfSession ses = null;
		String state = "initializing session manager";
		boolean threadFailed = false;
		try {
			while (! threadFailed) {
				try {
					sm = init.getSessionManager();
					state = "initializing session";
					ses = sm.newSession(init.getDocbaseName());
				
					state = "starting transaction";
					ses.beginTrans();
					state = "reading  events";
					DctmSvcRequest req;
					while (null == (req = getEventRecord(ses))) {
						Utils.mssleep(500);
					}
					state = "handling  event";
					handleEvent(ses, req);
					state = "finished";
					ses.commitTrans();
				} catch (Throwable ex) {
					state = "failure";
					logger.error(sn(), state + ": thread got exception: ", ex);
					logger.error(sn(), "thread will be restarted");
					threadFailed = true;
				} finally {
					logger.info(sn(), "event handling result: " + state);
					try {
						if (null != sm && ses != null && ses.isTransactionActive()) {
							logger.info(sn(), "commit transaction");
							ses.commitTrans();
							logger.info(sn(), "transaction finished");
						}
					} catch (Throwable ex) {
						// there is nothing that we could do, need to keep Thread from
						// failing so it well be restarted
						ex.printStackTrace(System.err);
					}
				}
			}
		} finally {
			logger.info(sn(), "thread exiting");
			if (null != sm && ses != null) {
				logger.info(sn(), "releasing session");
				sm.release(ses);
				logger.info(sn(), "session released");
			}

		}

	}

	protected abstract void handleEvent(IDfSession ses, DctmSvcRequest req)
		throws DfException, IOException;
		
	protected abstract DctmSvcRequest getEventRecord(IDfSession ses)
		throws DfException, DFSDocumentumException;


	public static String table_BNHP_ASYNC_CURRENT_REQUEST = "BNHP_ASYNC_CURRENT_REQUEST";
	protected DctmSvcRequest getEventRecord(IDfSession s,
										  String recState) throws DfException, DFSDocumentumException {
		// FIXME: check fixed state strings, make enum?
		final String NEXT_SQL = "BEGIN  BNHP_NEXT_ASYNC_REQUEST ('" +	recState +	"',1); END;";
		
		final boolean result = s.apiExec("execsql", NEXT_SQL);
		if (! result) {
			throw new DfException("ORACLE request failed: Failed to select next '"+recState+"' entry for update");
		}
		//DfcUtils.runSQLUpdate(s, SQL);
		final String DQL = "SELECT R_OBJECT_ID, S_REQ_ID FROM BNHP_ASYNC_CURRENT_REQUEST";
		IDfQuery q = new DfQuery(DQL);
		IDfCollection col = null;
		try {
			col = q.execute(s, IDfQuery.DF_QUERY);
			int cnt = 0;
			String rid = null;
			String objid = null;
			while (col.next()) {
				rid = col.getString("s_req_id");
				objid = col.getString("r_object_id");
				logger.info(this.getClass().getName(), "Retrieving event id="+rid+" objectId="+objid);
				cnt++;
			}
			if (0 == cnt) {
				return null;
			} else if (cnt >1) {
				throw new DFSDocumentumException("Unexpected number of rows, maximum one expected ");
					
			}
			IDfSysObject obj = (IDfSysObject)s.getObject(new DfId(objid));
			logger.info(sn(), obj.dump());
			DctmSvcRequest req = new DctmSvcRequest(obj);
			return req;
			
		} finally {
			if (null != col) { 
				col.close();
			}
		}

	}

	@Override
	public void configure(ConfigurationProvider provider, String name, Map<String, Object> context) {
		this.context = context;
		this.provider = provider;
		this.name = name;
	}

	/**
	 * @return the provider
	 */
	public ConfigurationProvider getProvider() {
		return provider;
	}

	/**
	 * @param provider the provider to set
	 */
	public void setProvider(ConfigurationProvider provider) {
		this.provider = provider;
	}

	/**
	 * @return the name
	 */
	public String getName() {
		return name;
	}

	/**
	 * @param name the name to set
	 */
	public void setName(String name) {
		this.name = name;
	}
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\msginput\AsyncInput.java
-----------------------------------------------------
package bnhp.dctmrest.msginput;

import static bnhp.dctmrest.utils.Utils.getLogger;

import bnhp.dctmrest.utils.IConfigurable;
import bnhp.dctmrest.utils.Utils;

import java.util.Map;
import java.util.concurrent.Executors;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.TimeUnit;

import org.cfg4j.provider.ConfigurationProvider;


public class AsyncInput extends MsgInput {
	protected ScheduledExecutorService es;
	int numThreads = 1;
	long delayMs = 100;
	long startDelayMs = 100;

    public void shutdown() {
		es.shutdown();
    }

    public boolean isTerminated() {
		return null == es || es.isTerminated();
    }

	public String toString() {
		return "{"+this.getClass().getName() +
			" name=" + name +","+
			" threads=" + numThreads +"}";
	}

	
	@Override
	public void configure(ConfigurationProvider provider, String name, Map<String,Object> context) {
		super.configure(provider, name, context);
		this.numThreads = provider.getProperty("threads", Integer.class);
	}

	
	public void start() {
		getLogger().info(name, "Async input starting " + this);
		this.es = Executors.newScheduledThreadPool(numThreads);
		ConfigurationProvider taskProvider = this.getProvider();
		for(int i = 0; i < numThreads; i++) {
			IConfigurable taskComp =  Utils.mkcomp(provider,
													 "task",
													 getContext());
			Runnable task = (Runnable) taskComp;
			getLogger().info ("scheduling task execution for '{}'", task.toString()); 
			es.scheduleWithFixedDelay(task, startDelayMs * i , delayMs, TimeUnit.MILLISECONDS);
		}
		getLogger().info(name, "Async input started");
	}
	
	
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\msginput\AsyncReplyTask.java
-----------------------------------------------------
package bnhp.dctmrest.msginput;

import bnhp.dctmrest.handlers.HandlerFactory;
import bnhp.dctmrest.reply.IReplySender;

import java.util.concurrent.Executors;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.TimeUnit;

import org.cfg4j.provider.ConfigurationProvider;
import org.cfg4j.provider.GenericType;

import java.io.IOException;
import java.util.Map;
import java.util.List;

import com.documentum.fc.client.DfQuery;
import com.documentum.fc.client.IDfCollection;
import com.documentum.fc.client.IDfPersistentObject;
import com.documentum.fc.client.IDfQuery;
import com.documentum.fc.client.IDfSession;
import com.documentum.fc.client.IDfSessionManager;
import com.documentum.fc.client.IDfSysObject;
import com.documentum.fc.common.DfException;
import com.documentum.fc.common.DfId;

import bnhp.dctmrest.DctmRestHandlerProvider;
import bnhp.dctmrest.requests.DctmSvcRequest;
import bnhp.dctmrest.requests.ISvcRequest;
import bnhp.dctmrest.requests.ISvcRequestHandler;
import bnhp.dctmrest.utils.Utils;
import bnhp.dctmrest.utils.ErrorResponse;
import bnhp.dctmrest.utils.IConfigurable;
import bnhp.infra.dfs.exceptions.DFSDocumentumException;
import bnhp.infra.dfs.init.ApplicationInitializer;
import bnhp.infra.dfs.utils.basic.LoggingUtils;
import bnhp.infra.dfs.utils.dfc.DfcUtils;

import static bnhp.dctmrest.utils.Utils.getLogger;

public class AsyncReplyTask extends AbstractAsyncTask  {
	List<IReplySender> senders;
		
	@Override
	public void configure(ConfigurationProvider provider, String name, Map<String, Object> context) {
		super.configure(provider, name, context);
		this.senders = (List<IReplySender>)(List) Utils.mkcomps( provider, "replySenders", context);
	}
	
	protected void handleEvent(IDfSession ses, DctmSvcRequest req) throws IOException, DfException {
		boolean replied = false;
		logger.info(sn(), "sending reply...");
		String msg = null;
		int cbRespCode = 0;
		for (IReplySender sender : senders) {
			if (sender.canSendReply(req)) {
				replied = true;
				try {
					logger.info(sn(), "using sender " + sender);
					sender.sendReply(req);
				} catch (Throwable t) {
					msg ="sender "+ sender + " Failed to send reply: "+t.getMessage();
					logger.error(sn(), msg, t);
				}
				break;
			}
		}
		// 	// FIXME: need more error handling here
			
		// } catch (Exception ex) {
		// 	ErrorResponse resp = new ErrorResponse(ex, opName);
		// 	req.setContentType(resp.getContentType());
		// 	req.send(resp.getContent());
		// 	req.setResponseCode(resp.getResponseCode());
		// }
		if (null == msg && !replied) {
			msg = "no sender configured for callback URL '"+ req.getCallbackURL();
		}
		if (msg  != null )  {
			req.setCBMessage(msg);
		}
		logger.info(sn(), "saving reply state ");
		req.reply();
	}

	@Override
	protected DctmSvcRequest getEventRecord(IDfSession ses)
		throws DfException, DFSDocumentumException {
		return getEventRecord(ses, DctmSvcRequest.REQ_STATUS_FINISHED);
	}
	
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\msginput\AsyncWorkerTask.java
-----------------------------------------------------
package bnhp.dctmrest.msginput;

import java.io.IOException;

import com.documentum.fc.client.IDfSession;
import com.documentum.fc.common.DfException;

import bnhp.dctmrest.requests.DctmSvcRequest;
import bnhp.dctmrest.requests.ISvcRequestHandler;
import bnhp.dctmrest.utils.ErrorResponse;
import bnhp.infra.dfs.exceptions.DFSDocumentumException;

public class AsyncWorkerTask extends AbstractAsyncTask  {
	protected void handleEvent(IDfSession ses, DctmSvcRequest req) throws IOException, DfException {
		String opName = req.getOperationName();
		ISvcRequestHandler handler = factory.makeSvcRequestHandler(opName);
		
		try {
			req.start();
			// FIXME: need more error handling here
			ses.commitTrans();
			ses.beginTrans();
			handler.handleRequest(req);
			
		} catch (Exception ex) {
			ErrorResponse resp = new ErrorResponse(ex, opName);
			req.setContentType(resp.getContentType());
			req.send(resp.getContent());
			req.setResponseCode(resp.getResponseCode());
		}
		req.finish();
	}

	@Override
	protected DctmSvcRequest getEventRecord(IDfSession ses)
		throws DfException, DFSDocumentumException {
		return getEventRecord(ses, DctmSvcRequest.REQ_STATUS_WAITING);
	}
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\msginput\HttpInput.java
-----------------------------------------------------
package bnhp.dctmrest.msginput;


import static bnhp.dctmrest.utils.Utils.getLogger;

import java.io.FileInputStream;
import java.io.InputStream;
import java.security.KeyStore;
import java.security.SecureRandom;
import java.security.UnrecoverableKeyException;
import java.util.Map;
import bnhp.dctmrest.utils.CommonConstants;
import bnhp.dctmrest.utils.Utils;
import bnhp.infra.dfs.utils.basic.properties.PropertyLoader;
import io.undertow.UndertowOptions;
import org.cfg4j.provider.ConfigurationProvider;
import bnhp.dctmrest.DctmRestHandlerProvider;
import io.undertow.Undertow;
import org.xnio.Option;
import org.xnio.Options;
import org.xnio.SslClientAuthMode;

import javax.net.ssl.*;

public class HttpInput extends MsgInput
{
	protected String host = "127.0.0.1";
	protected Short  port = 9033;
	protected boolean isDumpRequests = false;
	private boolean m_useSSL = false;
	private String m_keyStorePath;
	private String m_keyStorePass;
	private String m_priveteKeyPass;
	private String m_trustStorePath;
	private String m_trustStorePass;
	private SslClientAuthMode m_sslAuthMode;
	private final String KEY_STORE_PATH = "ksPath";
	private final String KEY_STORE_PASS = "ksPass";
	private final String PRIVATE_KEY_PASS = "ksCertPass";
	private final String TRUST_STORE_PATH = "tsPath";
	private final String TRUST_STORE_PASS = "tsPass";
	private final String SSL_AUTH_MODE = "sslAuthMode";

	public String toString()
	{
		return 	"{"+this.getClass().getName() + " name=" + name + "," + " host=" +
				(m_useSSL == true ? "https://" : "http://") +
				host +"," + " port="+ port +" dumpRequests="+isDumpRequests+"}" ;
	}
	// FIXME: add logging for configuration process
	@Override
	public void configure(ConfigurationProvider provider, String name, Map<String,Object> context) {
		super.configure(provider, name, context);
		this.host = provider.getProperty("host", String.class);
		this.port = provider.getProperty("port", Short.class);
		m_useSSL = provider.getProperty("ssl", boolean.class);
		isDumpRequests = provider.getProperty("dumpRequests", boolean.class);

		if (m_useSSL)
		{
			this.m_keyStorePath = provider.getProperty(KEY_STORE_PATH, String.class);
			this.m_keyStorePass =  provider.allConfigurationAsProperties().containsKey(KEY_STORE_PASS) 
				? provider.getProperty(KEY_STORE_PASS, String.class)
				: null;
			this.m_trustStorePath = provider.getProperty(TRUST_STORE_PATH, String.class);
			// FIXME: move this to config provider or utils
			this.m_trustStorePass = provider.allConfigurationAsProperties().containsKey(TRUST_STORE_PASS)
				? provider.getProperty(TRUST_STORE_PASS, String.class)
				: null;
			// this one does not seem to be supported being null
			this.m_priveteKeyPass = provider.getProperty(PRIVATE_KEY_PASS, String.class);

			this.m_sslAuthMode = provider.allConfigurationAsProperties().containsKey(SSL_AUTH_MODE)
				? SslClientAuthMode.valueOf(provider.getProperty(SSL_AUTH_MODE, String.class))
				: SslClientAuthMode.NOT_REQUESTED;
		}
	}

	public void start()
	{
		final DctmRestHandlerProvider p = new DctmRestHandlerProvider(context, isDumpRequests);
		Undertow server = null;

		if (!m_useSSL)
		{
			getLogger().info(name, "Http-Input server starting: "+ this);
			server = Undertow.builder()
					.addHttpListener(port, host)
					.setHandler(p.getHandler())
					.build();

			server.start();
			getLogger().info(name, "Http-Input server started");
		}
		else
		{
			getLogger().info(name, "Https-Input server starting: "+ this);

			SSLContext serviceSslContent = serverSslContext();

			server = Undertow.builder()
				.setServerOption(UndertowOptions.ENABLE_HTTP2, true)
				.addHttpsListener(port,host,serviceSslContent)
				.setSocketOption(Options.SSL_CLIENT_AUTH_MODE, this.m_sslAuthMode)
				.setHandler(p.getHandler()).build();

			server.start();

			getLogger().info(name, "Https-Input server started");
		}
	}

	public SSLContext serverSslContext()
	{
		try
		{
			KeyStore keyStore = loadKeyStore(m_keyStorePath, m_keyStorePass);
			KeyStore trustStore = loadKeyStore(m_trustStorePath, m_trustStorePass);
			return createSSLContext(keyStore, trustStore);
		}
		catch (Exception ex)
		{
			getLogger().error(name, "got some error/s - can't start the server.. details: " + ex.getMessage(), ex);
			throw new RuntimeException(ex);
		}
	}

	private SSLContext createSSLContext(KeyStore pKeyStore, KeyStore pTrustStore)
	{
		try
		{
			KeyManagerFactory keyManagerFactory = KeyManagerFactory.getInstance(KeyManagerFactory.getDefaultAlgorithm());
			keyManagerFactory.init(pKeyStore, null != m_priveteKeyPass ? m_priveteKeyPass.toCharArray() : null );


			TrustManagerFactory trustManagerFactory = TrustManagerFactory.getInstance(KeyManagerFactory.getDefaultAlgorithm());
			trustManagerFactory.init(pTrustStore);

			SSLContext sslContext = SSLContext.getInstance("TLS");
			sslContext.init(keyManagerFactory.getKeyManagers(), trustManagerFactory.getTrustManagers(), null);

			return sslContext;
		}
		catch (UnrecoverableKeyException ex)
		{
			throw new RuntimeException("Unable to init sslContent - the secret key is wrong..", ex);
		}
		catch (Exception e)
		{
			throw new RuntimeException("Unable to create and initialise the SSLContext", e);
		}
	}

	private KeyStore loadKeyStore(String pFullName, String pKsPassword)
	{
		try(InputStream stream = new FileInputStream(pFullName))
		{
			KeyStore loadedKeystore = KeyStore.getInstance("JKS");
			loadedKeystore.load(stream, null == pKsPassword ? null : pKsPassword.toCharArray());
			return loadedKeystore;
		}
		catch (Exception ex)
		{
			throw new RuntimeException(String.format("Unable to load KeyStore %s", pFullName), ex);
		}
	}
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\msginput\MsgInput.java
-----------------------------------------------------
package bnhp.dctmrest.msginput;

import java.util.Map;

import org.cfg4j.provider.ConfigurationProvider;

import bnhp.dctmrest.utils.IConfigurable;

public abstract class MsgInput implements IConfigurable {
	protected String name;
	protected Map<String,Object> context;
	protected ConfigurationProvider provider;
		
	public void configure(ConfigurationProvider provider, String name, Map<String, Object> context) {
		this.name = name;
		this.context = context;
		this.provider = provider;
	}

	public String toString() {
		return "{"+this.getClass().getName() +
			" name=" + name +"}";
	}

	/**
	 * @return the name
	 */
	public String getName() {
		return name;
	}

	/**
	 * @param name the name to set
	 */
	public void setName(String name) {
		this.name = name;
	}

	public Map<String,Object> getContext() {
		return context;
	}

	/**
	 * @param context the context to set
	 */
	public void setContext(Map<String, Object> context) {
		this.context = context;
	}

	/**
	 * @return the provider
	 */
	public ConfigurationProvider getProvider() {
		return provider;
	}

	/**
	 * @param provider the provider to set
	 */
	public void setProvider(ConfigurationProvider provider) {
		this.provider = provider;
	}

	public abstract void start() throws Exception;
	
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\persistance\OraRequestQueue.java
-----------------------------------------------------
package bnhp.dctmrest.persistance;


import io.undertow.server.HttpServerExchange;
import io.undertow.util.HeaderMap;
import io.undertow.util.HttpString;

import java.io.InputStream;
import java.io.OutputStream;
import java.io.StringWriter;
import java.net.InetAddress;
import java.net.UnknownHostException;
import java.util.Deque;
import java.util.HashMap;
import java.util.Map;
import java.util.Map.Entry;
import java.util.Set;
import java.io.IOException;

import io.undertow.server.BlockingHttpExchange;

import bnhp.dctmrest.utils.Json;
import bnhp.dctmrest.utils.Utils;
import bnhp.infra.dfs.init.ApplicationInitializer;
import bnhp.infra.dfs.utils.dfc.DfcUtils;
import bnhp.dctmrest.handlers.AuthHandler;

import com.fasterxml.jackson.core.JsonFactory;
import com.fasterxml.jackson.core.JsonGenerator;
import com.documentum.fc.client.IDfSession;
import com.documentum.fc.common.DfException;
import com.fasterxml.jackson.annotation.JsonInclude.Include;
import com.fasterxml.jackson.core.JsonParseException;
import com.fasterxml.jackson.core.JsonParser;
import com.fasterxml.jackson.core.type.TypeReference;
import com.fasterxml.jackson.databind.DeserializationFeature;
import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.fasterxml.jackson.databind.ObjectWriter;
import com.fasterxml.jackson.databind.SerializationFeature;
import com.fasterxml.jackson.datatype.jsr310.JavaTimeModule;


public class OraRequestQueue {
	static private JsonFactory jsonFactory = new JsonFactory();

	// FIXME: not here? instanceid from config?
	static String hostid = "NOHOSTID";
	static {
		try {
			hostid = InetAddress.getLocalHost().getHostName()+":";
		} catch (UnknownHostException unex) {
			System.out.println("Failed to init host id: "+ unex.getMessage());
		}
	}
	
	final static private int MAX_INLINE_BUF = 0x2047;

	final static private String S_REQ_OWNER   = "S_REQ_OWNER";
	final static private String S_REQ_SVC     = "S_REQ_SVC";
	final static private String S_REQ_ID      = "S_REQ_ID";
	final static private String S_REQ_STATUS  = "S_REQ_STATUS";
	final static private String S_REQ_SUBM    = "S_REQ_SUBM";
	final static private String S_REQ_PROC    = "S_REQ_PROC";
	final static private String S_CB_URL      = "S_CB_URL";
	
	final static private String TS_SUBMITTED  = "TS_SUBMITTED";
	final static private String TS_STARTED    = "TS_STARTED";
	final static private String TS_FINISHED   = "TS_FINISHED";
	final static private String TS_REPLIED    = "TS_REPLIED";

	final static private String D_PRIORITY    = "D_PRIORITY";
	final static private String S_METHOD      = "S_METHOD";
	final static private String B_IN_HEADERS  = "B_IN_HEADERS";
	final static private String S_IN_PATH     = "S_IN_PATH";
	final static private String B_IN_QPARS    = "B_IN_QPARS";
	final static private String B_IN_BODY     = "B_IN_BODY";
	final static private String S_IN_BODY_REF = "S_IN_BODY_REF";
	final static private String B_IN_AUTH     = "B_IN_AUTH";
	final static private String B_OUT_HEADERS = "B_OUT_HEADERS";

	final static private String B_OUT_BODY    = "B_OUT_BODY";
	final static private String B_OUT_BODY_REF= "S_OUT_BODY_REF";
	
	final static private String S_OUT_STATUS  = "D_OUT_STATUS";
	final static private String S_CB_STATUS   = "D_CB_STATUS";

	final private static String [] IN_SAVE_HEADERS = {
		"Content-Type", "Accept", 
	};
	final private static String [] OUT_SAVE_HEADERS = {
		"Content-Type" 
	};


	final static private String REQ_STATUS_WAITING = "waiting";
	final static private String REQ_STATUS_STARTED = "started";
	final static private String REQ_STATUS_SUCCESS = "success";
	final static private String REQ_STATUS_FAILURE = "failure";

	final static private String TABLE = "BNHP_ASYNC_REQUESTS";
	
	public static void putRequest(String operationtName,
						   String requestId,
						   String callbackURL,
			HttpServerExchange exch) throws IOException, DfException {
		final Map<String,Object> fields = new HashMap<String,Object>(25);

		fields.put(S_REQ_OWNER, exch.getAttachment(AuthHandler.SYSUSER_KEY));
		// FIXME
		fields.put(S_REQ_SVC,   "bnhp-DocumentManager");
		final String method = exch.getRequestMethod().toString();

		fields.put(S_REQ_ID, requestId);
		fields.put(S_REQ_STATUS, REQ_STATUS_WAITING);
		// fixme
		fields.put(S_REQ_SUBM, hostid + ":" + Thread.currentThread().getId());
		fields.put(S_CB_URL, callbackURL);
		fields.put(TS_SUBMITTED, System.currentTimeMillis());

		// FIXME:
		fields.put(D_PRIORITY, 0);
		fields.put(S_METHOD, method);

		putBlob(fields,B_IN_HEADERS,null, serializeHeaders(exch.getRequestHeaders(), IN_SAVE_HEADERS));
		fields.put(S_IN_PATH, exch.getRequestPath());
		putBlob(fields, B_IN_QPARS, null, serializeParameters(exch.getQueryParameters()));
		String content = null;
		if (!"GET".equals(method)) {
			content = readInput(exch);
			putBlob(fields, B_IN_BODY, S_IN_BODY_REF, content);
		}

		putBlob(fields, B_IN_AUTH, null,  exch.getAttachment(AuthHandler.SYSUSER_META));
		System.out.println("queueRequest="+ fields);
		String sql = makeInsert(fields);
		//System.out.println("queueSQL=: " + sql);

		IDfSession s = null;
		ApplicationInitializer instance = null;
		try {
			instance = bnhp.infra.dfs.init.ApplicationInitializer.getInstance();
			s = instance.getDocbaseSession();
			DfcUtils.runSQLUpdate(s, sql);
			System.out.println("SQL finished=");
		} finally {
			if (null!=s) {
				instance.releaseDocbaseSession(s);
			}
		}

	}

	private static String makeInsert(Map<String, Object> fields) {
		StringBuilder buf1 = new StringBuilder(4096);
		StringBuilder buf2 = new StringBuilder(4096);
		buf1.append("INSERT INTO \"").append(TABLE).append("\" ( ");
		buf2.append(" VALUES (");
		int cnt = 0;
		for (Entry<String, Object>  entry : fields.entrySet()) {
			final String fieldName = entry.getKey();
			final Object fieldValue = entry.getValue();
			if (null == fieldValue) {
				continue;
			}
			if (cnt++ > 0) {
				buf1.append(",");
				buf2.append(",");
			}
			buf1.append(fieldName);
			if (fieldName.startsWith("D_")) {
				buf2.append(((Number)fieldValue).longValue());
			} else if (fieldName.startsWith("TS_")) {
				buf2.append("TIMESTAMP '").append(Utils.formatOraTS(((Number)fieldValue).longValue())).append("'");
			} else if (fieldName.startsWith("S_")) {
				buf2.append("'").append(Utils.oracleSQLStrEscape((String)fieldValue)).append("'");
			} else if (fieldName.startsWith("B_")) {
				buf2.append(Utils.sqlHEX((String)fieldValue));
			} else {
				buf2.append("NULL");
			}
		}
		buf1.append(") ");
		buf2.append(")");
		buf1.append(buf2);
		return buf1.toString();
	}

	private static void putBlob(Map<String, Object> fields,
								String inlineField, String refField,
								String value) {
		// FIXME: big values!
		fields.put(inlineField, value);
	}

	// FIXME: repeating code V
	private static String serializeParameters(Map<String, Deque<String>> queryParameters)
	throws IOException {
		StringWriter w = new StringWriter(300);
		JsonGenerator generator = jsonFactory.createGenerator(w);
		final Set<Entry<String, Deque<String>>> entrySet = queryParameters.entrySet();
		generator.writeStartObject();
		for (Entry<String, Deque<String>> entry : entrySet) {
			final String fieldName = entry.getKey();
			final String fieldValue = entry.getValue().getLast();
			if (null != fieldValue) {
				generator.writeStringField(fieldName,fieldValue);
			}
		}
		generator.writeEndObject();
		generator.flush();
		final String headersStr = w.getBuffer().toString();
		//System.out.println("request parameters: " + headersStr);
		return headersStr;
	}

	// FIXME: repeating code ^
	private static String serializeHeaders(HeaderMap hmap, String[] filter) throws IOException {
		//OutputStream bos =null;
		StringWriter w = new StringWriter(300);
		JsonGenerator generator = jsonFactory.createGenerator(w);
		generator.writeStartObject();
		for (String headerName : filter)  {
			String headerVal = hmap.getLast(headerName);
			if (null == headerVal) {
				continue;
			}
			generator.writeStringField(headerName, headerVal);
		}
		generator.writeEndObject();
		generator.flush();
		final String headersStr = w.getBuffer().toString();
		//System.out.println("request headers: " + headersStr);
		return headersStr;
	}

	private static String readInput(HttpServerExchange exch) throws IOException {
		final BlockingHttpExchange mBexch = exch.startBlocking();
		final InputStream is  = exch.getInputStream();
		final ObjectMapper mapper = new ObjectMapper();
		final JsonNode tree = mapper.readTree(is);
		//tree.binaryValue()
		final String inputContent = tree.toString();
		System.out.println("request body: "+inputContent);
		// TODO Auto-generated method stub
		return inputContent;
	}
	
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\reply\FileReplySender.java
-----------------------------------------------------
package bnhp.dctmrest.reply;

import java.net.MalformedURLException;
import java.net.URI;
import java.net.URL;
import java.nio.channels.FileChannel;
import java.util.HashMap;
import java.util.Map;
import java.io.File;
import java.io.FileOutputStream;
import java.io.IOException;
import java.io.InputStream;
import java.io.OutputStream;
import java.util.regex.Matcher;
import java.util.regex.Pattern;

import org.cfg4j.provider.ConfigurationProvider;

import bnhp.dctmrest.requests.DctmSvcRequest;
import bnhp.dctmrest.utils.IConfigurable;
import bnhp.infra.dfs.utils.basic.LoggingUtils;
import bnhp.infra.dfs.utils.basic.properties.PropertyLoader;
//import bnhp.infra.dfs.utils.content.server_upload.FileBasedUploadUtilsTests;
import bnhp.infra.dfs.utils.service.DfsRequestThreadAttributes;

import java.nio.file.FileSystem;
import java.nio.file.FileSystems;
import java.nio.file.Files;
import java.nio.file.Path;

import static bnhp.infra.dfs.utils.content.server_upload.FileBasedUploadUtils.LOCAL_FILE_UPLOAD_BASE_DIR;
import static bnhp.infra.dfs.utils.content.server_upload.FileBasedUploadUtils.PROP_PATH_SEPARATOR;

public class FileReplySender implements IReplySender, IConfigurable {
	protected String regexStr ;
	protected Pattern regex ;
	public void sendReply(DctmSvcRequest req) {
		final String urlStr = req.getCallbackURL();
		getLogger().info(sn(), "sending replu to '"+urlStr+"'");
		String msg = null;
		try {
			final byte[] bytes = req.getOutBodyBytes();
			writeBytesToURL(req, urlStr, bytes);
			req.setCBStatusCode(200);
			req.setCBMessage("callback reply saved to "+urlStr);
			getLogger().info(sn(),"callback reply saved");
		} catch (Throwable t) {
			getLogger().error(sn(),"Failed to save callback output", t);
			req.setCBStatusCode(500);
			req.setCBMessage("failed to save to "+urlStr+": "+t.getMessage());
		}
	}

	// FIXME: very ugly
	// ZIP only allowed at the last directory level
	private void writeBytesToURL(DctmSvcRequest req, String URLStr, byte[] bytes) {
		String uploadRoot = getUploadRoot(req);
		URL url;
		try {
			url = new URL(URLStr);
		} catch (MalformedURLException mex) {
			throw new RuntimeException("Invalid callback file url: '"+URLStr+"'", mex);
		}
		String proto = url.getProtocol();
		if (! "file".equals(proto)) {
			throw new RuntimeException("Unsupported protocol in url, only file is currently supported"+  URLStr);
		}
		FileSystem zipfs = null;
		String path = url.getPath();
		//String file = url.getFile();
		String[] components = path.split("/+");
		OutputStream os = null;
		String filepath = null;
		File fileObj = null;
		try {

			if (components.length > 1 &&
				components[components.length - 2].matches("^.*\\.[zZ][iI][pP]$")) {
				getLogger().info(sn(),"saving to zip URI");
				StringBuilder b = new StringBuilder();
				b.append(uploadRoot);
				for (int i = 0; i < components.length - 1; i++) {
					b.append("/").append(components[i]);
				}

				filepath = b.toString();
				zipfs = makeZipFS(b.toString());
				os = Files.newOutputStream(zipfs.getPath(components[components.length - 1]));
			} else {
				getLogger().info(sn(),"saving to file  URI");
				filepath = uploadRoot + File.separator + path;
				File f = new File(filepath);
				os = new FileOutputStream(f);
			}
			os.write(bytes);
			os.flush();
			getLogger().info(sn(),"save done");

			 fileObj = new File(filepath);

		} catch (Exception ex) {
			throw new RuntimeException("Failed to save output to callback file: '"+URLStr+"'", ex);
		} finally {
			try {
				if (null != os) {
					getLogger().debug(sn(),"close output file");
					try {
						os.close();
					} catch (IOException ioex) {
						getLogger().error(sn(),"Failed to close output file:"+ioex);
					}
				}
			} finally {
				if (null != zipfs) {
					getLogger().debug(sn(),"close zipfs");
					try {
						zipfs.close();
					} catch (IOException ioex) {
						getLogger().error(sn(),"Failed to close output file:"+ioex);
					}
				}
			}
		}

		try
		{
			if (null != fileObj) {
				getLogger().info(sn(),"setting w-r permission to reply file..");
				fileObj.setReadable(true, false);
				fileObj.setWritable(true, false);
			}
		}
		catch (Exception ex)
		{
			getLogger().error(sn(),"Failed changing permission to reply file",ex);
		}


	}

	private FileSystem makeZipFS(String zipfilePath)  {
		FileSystem zipFs = null;
		//String zipURLStr = String.format("jar:file:///1.jar");
		String zipURLStr = String.format("jar:file:///%s", zipfilePath);
		getLogger().info(sn(),"zip URI is '"+zipURLStr+"'");
		URI zipURI = URI.create(zipURLStr);
		Map<String,String> env = new HashMap<String,String>();
		env.put("create","true");
		try {
			FileSystem zipfs = FileSystems.newFileSystem(zipURI, env);
			return zipfs;
		} catch (IOException ioex) {
			throw new RuntimeException(ioex);
		}
	}

	@Override
	public void configure(ConfigurationProvider provider, String name, Map<String, Object> context) {
		this.regexStr = provider.getProperty("regex", String.class);
		this.regex = Pattern.compile(regexStr);
	}
	@Override
	public boolean canSendReply(DctmSvcRequest req) {
		final String url = req.getCallbackURL();
		if (null != url) {
			Matcher m = regex.matcher(url);
			return m.matches();
		}
		return false;
	}

	private static LoggingUtils getLogger() {
		return DfsRequestThreadAttributes.dfsLogger.get();
	}

	private String sn() {
		return this.getClass().getSimpleName();
	}

	protected String getUploadRoot(DctmSvcRequest req) {
		PropertyLoader loader = PropertyLoader.getInstance();
		String loginUser = req.getLoginUser();
		String [] paths = this.getPathListFromProp(LOCAL_FILE_UPLOAD_BASE_DIR,  loginUser);
		if (paths.length > 0) {
			return paths[0];
		} else {
			throw new RuntimeException("Configuration error: upload root not configured");
		}
	}

	// FIXME: make public in library
	public final static String PROP_PATH_SEPARATOR = "\\s*,\\s*";
	protected String[] getPathListFromProp(String propertyName, String userName)  {
		PropertyLoader loader = PropertyLoader.getInstance();
		String basePaths = loader.getUserProperty(propertyName, userName);
		if (null == basePaths) {
			throw new RuntimeException("Cofiguration error: '"+propertyName+"' property not configured");
		}
		basePaths = basePaths.trim();
		if (basePaths.length() == 0) {
			throw new RuntimeException("Cofiguration error: '"+propertyName+"' has empty value");
		}
		return basePaths.split(PROP_PATH_SEPARATOR);
	}

}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\reply\HttpReplySender.java
-----------------------------------------------------
package bnhp.dctmrest.reply;


import java.io.ByteArrayOutputStream;
import java.io.InputStream;
import java.io.OutputStream;
import java.net.HttpURLConnection;
import java.util.List;
import java.util.Map;
import java.util.regex.Matcher;
import java.util.regex.Pattern;

import org.cfg4j.provider.ConfigurationProvider;

import com.fasterxml.jackson.core.type.TypeReference;

import bnhp.dctmrest.model.ErrorDetails;
import bnhp.dctmrest.model.ErrorDetails.ErrorTypeEnum;
import bnhp.dctmrest.requests.DctmSvcRequest;
import bnhp.dctmrest.utils.HttpUtils;
import bnhp.dctmrest.utils.IConfigurable;
import bnhp.dctmrest.utils.Json;
import bnhp.dctmrest.utils.Utils;
import bnhp.infra.dfs.utils.basic.LoggingUtils;
import bnhp.infra.dfs.utils.service.DfsRequestThreadAttributes;

public class HttpReplySender implements IReplySender, IConfigurable {
	protected String regexStr ;
	protected Pattern regex ;
	protected List <IHttpAuth> authenticators;

	public Map<String, String> getReplyParams(DctmSvcRequest req) {
		Map <String, String> result = null;
		if (!req.isFinished()) {
			result = null;
		} else 	if (req.isResponseSuccess()) {
			result = Utils.makeMap("result", "OK");
		} else {
			try {
				final byte[] outBody = req.getOutBodyBytes();
				Map<String,Object> resultMap = null;
				if (null != outBody && outBody.length>0) {
					final TypeReference<ErrorDetails> tr = new TypeReference<ErrorDetails>() {};
					ErrorDetails errDetails   = Json.serializer().fromJson(outBody, tr);
					if (null!=errDetails && null != errDetails.getErrorType()) {
						result =  Utils.makeMap("result", convertErrorType(errDetails.getErrorType()),
												"errorDetails",	errDetails.getErrorDetails(),
												"errorCode", ""+errDetails.getErrorCode());
					}
				}
			} catch (Exception ex) {
				getLogger().warn(sn(), "Exception while trying to use ErrorDetails from method output");
			} finally {
				if (null == result) {
					getLogger().warn(sn(), "Using http code to form async reply");
					result = Utils.makeMap("result", convertStatusCode(req.getResponseCode()),
										   // FIXME
										   "errorDetails", "Service returned error code", "errorCode", ""+req.getResponseCode());
					
				}
			}
		}
		return result;
	}

	private static final String QUERY_RESULT_GENERAL_ERROR = "GeneralError";
	private static final String QUERY_RESULT_TEMPORARY_ERROR = "TemporaryError";
	private static final String QUERY_RESULT_FATAL_ERROR = "FatalError";
	private static final String QUERY_RESULT_OK = "OK";
	
	private String convertStatusCode(int responseCode) {
		return (responseCode < 500) ?  "FatalError" :
			((503 == responseCode) ? "TemporaryError" : QUERY_RESULT_GENERAL_ERROR );
			 
	}

	private String convertErrorType(ErrorTypeEnum errorType) {
		return ErrorTypeEnum.TEMPORARY == errorType ?  QUERY_RESULT_TEMPORARY_ERROR :
			(ErrorTypeEnum.VALIDATION == errorType ?  QUERY_RESULT_FATAL_ERROR :   QUERY_RESULT_GENERAL_ERROR );
			  
	}

	public void sendReply(DctmSvcRequest req) {
		final String urlStr = req.getCallbackURL();
		getLogger().info(sn(), "sending reply to "+urlStr);
		String msg = null;
		int responseCode = 0;
		String responseMessage = "Callback has not been called";
		int retries = 4;
		boolean success = false;
		// FIXME: work with stream
		final byte[] outBytes = req.getOutBodyBytes();
		boolean reauth = false;
		do {
			try {
				getLogger().info(sn(), "Calling callback, retries left: "+retries);
				retries--;
				
				String outHeaders = req.getOutHeaders();
				Map<String, Object> headersMap = Json.serializer().mapFromJson(outHeaders);
				headersMap.put("X-Correlation-ID", req.getRequestId());
				Map<String, String> replyParams = getReplyParams(req);



				OutputStream os = null;
				HttpURLConnection con = null;
				try {
					con = HttpUtils.makePOST(urlStr, replyParams, headersMap, outBytes.length);
					getLogger().info(sn(), "POST "+con.getURL().toString());
					authenticate(con, reauth);
					con.connect();
					os = con.getOutputStream();
					try {
						getLogger().debug(sn(), "sendReply:outBytes: " + new String(outBytes));
					}catch(Exception e) {
						getLogger().debug(sn(), "error in print sendReply:outBytes " + e.getMessage());
					}
					
					os.write(outBytes);
					os.flush();
				} finally {
					if (null != os) {
						os.close();
					}
				}
				responseCode = con.getResponseCode();
				getLogger().info(sn(), "result response code: " + responseCode);
				responseMessage = con.getResponseMessage();
				getLogger().info(sn(), "result response message: " + responseMessage);
				if (null == responseMessage) {
					responseMessage = "";
				}
				/// FIXME: limit size of response message
				InputStream is = (responseCode >= 400) ? con.getErrorStream() : con.getInputStream();
				if (null != is) {
					ByteArrayOutputStream bos = new ByteArrayOutputStream();
					HttpUtils.copyStream(is, bos);
					byte[] respBytes = bos.toByteArray();
					if (respBytes.length > 0) {
						String replyTxt = null;
						String outEncoding = HttpUtils.getEncoding(con, "UTF-8");
						try {
							replyTxt = bos.toString(outEncoding);
						} catch (Exception ex) {
							replyTxt = "failed to convert callback reply message: " + ex.toString();
						}
						responseMessage += ": " + replyTxt;
					}
				}
				reauth =  (401 == responseCode);
				if (responseCode >= 200 && responseCode<=299) {
					getLogger().info(sn(), "callback call succeeded, response code=" + responseCode);
					success = true;
				}
			} catch (Throwable t) {
				getLogger().error(sn(), "Failed to call callback", t);
				req.setCBStatusCode(-1);
				req.setCBMessage("Failed to call " + urlStr + ": " + t.getMessage());
			}
		} while ((!success) && retries > 0);
		req.setCBStatusCode(responseCode);
		req.setCBMessage(responseMessage);
		getLogger().info(sn(), "callback reply saved");
	}

	private void authenticate(HttpURLConnection con, boolean reauth) {
		if (null != authenticators) {
			for (IHttpAuth auth : authenticators) {
				if (auth.canAuthenticate(con)) {
					if ( reauth ) {
						getLogger().info(sn(), "Performing re-authentication");
						auth.refresh(con);
					}
					auth.authenticate(con);
					getLogger().info(sn(), "Authentication finished");
					return;
				}
			}
		}
		getLogger().info(sn(), "No matching authenticators found");

	}

	@Override
	public void configure(ConfigurationProvider provider, String name, Map<String, Object> context) {
		this.regexStr = provider.getProperty("regex", String.class);
		this.regex = Pattern.compile(regexStr);
		this.authenticators = (List<IHttpAuth>)(List)Utils.mkcomps(provider, "authenticators" ,context);
	}
	@Override
	public boolean canSendReply(DctmSvcRequest req) {
		final String url = req.getCallbackURL();
		if (null != url) {
			Matcher m = regex.matcher(url);
			return m.matches();
		}
		return false;
	}

	private static LoggingUtils getLogger() {
		return DfsRequestThreadAttributes.dfsLogger.get();
	}

	private String sn() {
		return this.getClass().getSimpleName();
	}
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\reply\IHttpAuth.java
-----------------------------------------------------
package bnhp.dctmrest.reply;

import java.net.HttpURLConnection;

public interface IHttpAuth {
	public boolean canAuthenticate(HttpURLConnection con);
	public void authenticate(HttpURLConnection con);
	public void refresh(HttpURLConnection con);
}




file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\reply\IReplySender.java
-----------------------------------------------------
package bnhp.dctmrest.reply;

import bnhp.dctmrest.requests.DctmSvcRequest;

public interface IReplySender {
	public void sendReply(DctmSvcRequest req);
	public boolean canSendReply(DctmSvcRequest req);
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\reply\NOPReplySender.java
-----------------------------------------------------
package bnhp.dctmrest.reply;

import java.util.Map;

import org.cfg4j.provider.ConfigurationProvider;

import bnhp.dctmrest.requests.DctmSvcRequest;
import bnhp.dctmrest.utils.IConfigurable;

public class NOPReplySender implements IReplySender, IConfigurable {
	public void sendReply(DctmSvcRequest req) {
		req.setCBMessage("OK: reply sent to /dev/null");
		req.setCBStatusCode(200);
	}
	@Override
	public void configure(ConfigurationProvider provider, String name, Map<String, Object> context) {
		// nothing to do!
	}
	@Override
	public boolean canSendReply(DctmSvcRequest req) {
		final String url = req.getCallbackURL();
		return  null!= url && url.startsWith("null:");
	}
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\reply\Oauth2Auth.java
-----------------------------------------------------
package bnhp.dctmrest.reply;

import com.fasterxml.jackson.core.JsonParseException;

import bnhp.infra.dfs.utils.basic.LoggingUtils;
import bnhp.infra.dfs.utils.service.DfsRequestThreadAttributes;
import bnhp.dctmrest.utils.HttpUtils;

import java.io.IOException;
import java.io.InputStream;
import java.io.OutputStream;
import java.io.UnsupportedEncodingException;
import java.net.HttpURLConnection;
import java.net.MalformedURLException;
import java.util.Base64;
import java.util.Map;

import bnhp.dctmrest.utils.Utils;
import bnhp.dctmrest.utils.Json;

import org.cfg4j.provider.ConfigurationProvider;

import bnhp.dctmrest.utils.IConfigurable;

public class Oauth2Auth implements IHttpAuth, IConfigurable {
	protected String consumerKey;
	protected String consumerSecret;
	protected String content;
	protected String authUrl;
	protected String token;
		
	@Override
	public void configure(ConfigurationProvider provider, String name, Map<String, Object> context) {
		this.consumerKey = provider.getProperty("consumerKey", String.class);
		this.consumerSecret = provider.getProperty("consumerSecret", String.class);
		this.content = provider.getProperty("content", String.class);
		this.authUrl = provider.getProperty("authURL", String.class);
	}

	@Override
	public boolean canAuthenticate(HttpURLConnection con) {
		return true;
	}

	@Override
	public void authenticate(HttpURLConnection con) {
		if (null==this.token) {
			refresh(con);
		}
		con.setRequestProperty("Authorization", token);
	}

	@Override
	public void refresh(HttpURLConnection con) {
		try {
			this.token = getNewToken();
		} catch (Exception ex) {
			throw new RuntimeException("Failed to refresh token", ex);
		}
	}

	private String base64(String src) {
		try {
			return Base64.getEncoder().encodeToString(src.getBytes("UTF-8"));
		} catch (UnsupportedEncodingException ex) {
			throw new RuntimeException("UTF-8 not supported");
		}
	}
	
	private String getNewToken() throws MalformedURLException, IOException {
		try {
			final byte[] content = this.content.getBytes();
			getLogger().info(sn(), "performing token refresh using " + this.authUrl);
			
			Map headers = Utils.makeMap("Content-Type", "application/x-www-form-urlencoded",
										"Accept", "*/*",
										"Authorization",
										"Basic "+base64(this.consumerKey+":"+this.consumerSecret));
			

			OutputStream os = null;
			HttpURLConnection con;
			try {
				con = HttpUtils.makePOST(this.authUrl, null, headers, content.length);
				con.connect();
				con.getOutputStream().write(content);
				con.getOutputStream().flush();
			} finally {
				if (null!=os) {
					os.close();
				}
			}
			getLogger().info(sn(), "refresh request sent " + this.authUrl);
			int responseCode = con.getResponseCode();
			getLogger().info(sn(), "refresh response code: " + responseCode);
			String responseMessage = con.getResponseMessage();
			getLogger().info(sn(), "refresh response message: " + responseMessage);
		
			if (responseCode == 200) {
				InputStream is = con.getInputStream();
				if (null == is) {
					throw new IOException("null input stream from auth server");
				}
				Map<String, Object> map = Json.serializer().mapFromJson(is);
				getLogger().debug(sn(), "retrieved token "+ map);
				if (null==map || (! map.containsKey("token_type")) ||
					(! map.containsKey("access_token"))) {
					throw new IOException("invalid tokeb retrieved");
				}
				String token = map.get("token_type") + " " + map.get("access_token");
				return token;
			} else {
				getLogger().error(sn(),"responseCode: "+responseCode );
				throw new IOException("Failed to refresh tocken, auth server reply: status="
									  +responseCode +" message="+ responseMessage);
			}
		} catch (IOException  ex) {
			getLogger().error(sn(),ex.getMessage(),ex);
			ex.printStackTrace();
			throw new RuntimeException("Failed to refresh oauth2 token", ex);
		}

	}

	
	private static LoggingUtils getLogger() {
		return DfsRequestThreadAttributes.dfsLogger.get();
	}

	private String sn() {
		return this.getClass().getSimpleName();
	}

}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\requests\AbstractSvcRequestHandler.java
-----------------------------------------------------
package bnhp.dctmrest.requests;

import bnhp.infra.dfs.utils.service.DfsRequestThreadAttributes;
import bnhp.infra.dfs.utils.service.SysUsersTable;
import bnhp.infra.ecm.model.DocDetails;
import bnhp.infra.ecm.model.DocFile;
import bnhp.infra.dfs.exceptions.DFSDocumentumException;

public abstract class AbstractSvcRequestHandler  implements ISvcRequestHandler {
	protected String operationName;

	public void setOperationName(String value) {
		operationName = value;
	}

	public void initSysAuth(ISvcRequest svcReq) {
		final String sysUser = svcReq.getSysUser();
		DfsRequestThreadAttributes.sysUser.set(sysUser);
	}

	protected bnhp.infra.dfs.model.business.SecurityContext makeSecurityContext(ISvcRequest svcReq) throws DFSDocumentumException {
		initSysAuth(svcReq);
		bnhp.infra.dfs.model.business.SecurityContext sctx = new bnhp.infra.dfs.model.business.SecurityContext();
		SysUsersTable.passwordlessLogin(sctx);
		logInfo("Authentication granted as dctmUser=" + sctx.getUserName() +
				" for repository=" + sctx.getRepositoryName());
		return sctx;
	}

	protected bnhp.infra.ecm.model.DocFile convertToGeneralDocFile(bnhp.infra.dfs.model.business.DocFile pDocFile) {
		bnhp.infra.ecm.model.DocFile docFile = new DocFile();

		docFile.setDocFormat(pDocFile.getDocFormat());
		docFile.setDocSize(pDocFile.getDocSize());
		docFile.setDocStream(pDocFile.getDocStream());
		docFile.setDocURL(pDocFile.getDocURL());
		
		return docFile;
	}
	
	protected bnhp.infra.ecm.model.DocDetails convertToGeneralDocDetails(bnhp.infra.dfs.model.business.DocDetails pDocDet)  {
		bnhp.infra.ecm.model.DocDetails docDetails = new DocDetails();

		docDetails.setDocumentFormId(pDocDet.getDocumentFormId());
		docDetails.setLegacyDocumentEntryDttm(pDocDet.getLegacyDocumentEntryDttm());
		docDetails.setObjectName(pDocDet.getObjectName());
		docDetails.setSystemCode(pDocDet.getSystemCode());
		docDetails.setLegacyDocumentId(pDocDet.getLegacyDocumentId());
		
		return docDetails;
	}
	
	protected bnhp.infra.ecm.model.SecurityContext makeGeneralSecurityContext(ISvcRequest svcReq) throws DFSDocumentumException
	{
		initSysAuth(svcReq);
		bnhp.infra.dfs.model.business.SecurityContext sctx = new bnhp.infra.dfs.model.business.SecurityContext();
		SysUsersTable.passwordlessLogin(sctx);
		logInfo("Authentication granted as dctmUser=" + sctx.getUserName() +
				" for repository=" + sctx.getRepositoryName());

		bnhp.infra.ecm.model.SecurityContext genSec = new bnhp.infra.ecm.model.SecurityContext();
		genSec.setUserName(sctx.getUserName());
		genSec.setPassword(sctx.getPassword());
		genSec.setRepositoryName(sctx.getRepositoryName());

		return genSec;
	}
	
	public void logError(String str) {
		System.out.println("ERROR: "+str);
	}
	public void logInfo(String str) {
		System.out.println("INFO: "+ str);
	}

	public void logDebug(String str) {
		System.out.println("DEBUG: "+ str);
	}


	
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\requests\DctmSvcRequest.java
-----------------------------------------------------
package bnhp.dctmrest.requests;


import java.io.ByteArrayInputStream;
import java.io.ByteArrayOutputStream;
import java.io.IOException;
import java.io.InputStream;
import java.io.StringWriter;
import java.io.UnsupportedEncodingException;
import java.nio.ByteBuffer;
import java.nio.channels.FileChannel;
import java.nio.channels.Channel;
import java.util.Date;
import java.util.Deque;
import java.util.HashMap;
import java.util.Map;
import java.util.Map.Entry;
import java.util.Set;

import com.documentum.fc.client.IDfSession;
import com.documentum.fc.client.IDfSysObject;
import com.documentum.fc.common.DfException;
import com.documentum.fc.common.DfTime;
import com.documentum.fc.common.IDfTime;
import com.fasterxml.jackson.core.JsonFactory;
import com.fasterxml.jackson.core.JsonGenerator;
import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.sun.xml.messaging.saaj.util.ByteInputStream;

import bnhp.dctmrest.handlers.AuthHandler;
import static bnhp.dctmrest.utils.CommonConstants.*;
import bnhp.dctmrest.utils.Json;
import bnhp.dctmrest.utils.Utils;
import bnhp.infra.dfs.model.business.ExecutorDetails;
import bnhp.infra.dfs.utils.basic.LoggingUtils;
import bnhp.infra.dfs.utils.service.DfsRequestThreadAttributes;

import io.undertow.server.BlockingHttpExchange;
import io.undertow.server.HttpServerExchange;
import io.undertow.util.HeaderMap;



public class DctmSvcRequest implements ISvcRequest {
	static private JsonFactory jsonFactory = new JsonFactory();

	final static private String S_REQ_ID      = "s_req_id";
	final static private String S_REQ_OWNER   = "s_req_owner";
	final static private String S_REQ_SVC     = "s_req_svc";

	final static private String S_REQ_STATUS  = "s_req_status";
	final static private String S_REQ_SUBM    = "s_req_subm";
	final static private String S_REQ_PROC    = "s_req_proc";
	final static private String S_CB_URL      = "s_cb_url";
	
	final static private String TS_SUBMITTED  = "ts_submitted";
	final static private String TS_STARTED    = "ts_started";
	final static private String TS_FINISHED   = "ts_finished";
	final static private String TS_REPLIED    = "ts_replied";

	final static private String D_PRIORITY    = "d_priority";
	final static private String S_METHOD      = "s_method";
	final static private String S_OP_NAME     = "s_op_name";
	final static private String S_IN_HEADERS  = "s_in_headers";
	final static private String S_IN_PATH     = "s_in_path";
	final static private String S_IN_QPARS    = "s_in_qpars";
	final static private String S_IN_BODY     = "s_in_body";
	final static private String S_IN_AUTH     = "s_in_auth";
	final static private String S_OUT_HEADERS = "s_out_headers";

	final static private String S_OUT_BODY    = "s_out_body";
	final static private String D_OUT_STATUS  = "d_out_status";
	final static private String D_CB_STATUS   = "d_cb_status";
	final static private String S_CB_MESSAGE  = "s_cb_message";

	final private static String [] IN_SAVE_HEADERS = {
		"Content-Type", "Accept", 
	};
	final private static String [] OUT_SAVE_HEADERS = {
		"Content-Type" 
	};

	// FIXME: move from here?
	final static public String REQ_STATUS_WAITING  = "waiting";
	final static public String REQ_STATUS_STARTED  = "started";
	final static public String REQ_STATUS_FINISHED = "finished";
	final static public String REQ_STATUS_REPLIED  = "replied";

	final static private String TYPE = "bnhp_async_requests";
	final static private String INPUT_TYPE =	"INPUT_TYPE";

	// max length for documentum string field in bytes
	final static int MAX_TEXT_BYTES=2000;
	final static String IN_FORMAT = "text";
	
	// member veriables
	// all state is in the sysobject
	public IDfSysObject mObj = null;

	/****** BUILDING FROM Exchange ********/
	public  DctmSvcRequest(IDfSession s,
						   String operationName,
						   String requestId,
						   String callbackURL,
						   HttpServerExchange exch) throws IOException, DfException {
		final IDfSysObject obj = (IDfSysObject) s.newObject(TYPE);
		int page = 0;
		obj.setString(S_REQ_ID, requestId);
		obj.setString(S_REQ_OWNER, exch.getAttachment(AuthHandler.SYSUSER_KEY));
		obj.setString(S_OP_NAME, operationName);
		// FIXME
		obj.setString(S_REQ_SVC,   "bnhp-DocumentManager");
		final String method = exch.getRequestMethod().toString();
		obj.setString(S_REQ_STATUS, REQ_STATUS_WAITING);
		// FIXME: Utils?
		obj.setString(S_REQ_SUBM, Utils.getHostId() + ":" + Thread.currentThread().getId());
		obj.setString(S_CB_URL, callbackURL);
		obj.setTime(TS_SUBMITTED, new DfTime(new Date(System.currentTimeMillis())));
		// FIXME:
		obj.setInt(D_PRIORITY, 0);
		obj.setString(S_METHOD, method);
		page = putBlob(obj, page, S_IN_HEADERS, IN_FORMAT,  serializeHeaders(exch.getRequestHeaders(), IN_SAVE_HEADERS));
		page = putBlob(obj, page, S_IN_PATH,    IN_FORMAT,  exch.getRequestPath());
		page = putBlob(obj, page, S_IN_QPARS,   IN_FORMAT,  serializeParameters(exch.getQueryParameters()));
		String content = null;
		if (!"GET".equals(method)) {
			content = readInput(exch);
			page = putBlob(obj, page, S_IN_BODY, IN_FORMAT,  content);
		} else {
			//putBlob(fields, S_IN_BODY, content);
		}
		page = putBlob(obj, page, S_IN_AUTH, IN_FORMAT,  exch.getAttachment(AuthHandler.SYSUSER_META));
		mObj = obj;
	}

	public DctmSvcRequest(IDfSysObject obj) {
		mObj = obj;
	}

	private static String safeBytes2Str(byte[] bytes) {
		try {
			return new String(bytes, "UTF-8");
		} catch (Exception ex) {
			return null;
		}
	}
	
	private static int putBlob(IDfSysObject obj,
							   int page,
							   String inlineField,
							   String format,
							   byte[] value) throws DfException, IOException  {
		String strval = null;
		if (null != value) {
			if ((value.length < MAX_TEXT_BYTES)  &&
				(null != (strval=safeBytes2Str(value)))) {
				obj.setString(inlineField, strval);
			} else {
				ByteArrayOutputStream bas = new ByteArrayOutputStream();
				bas.write(value);
				bas.flush();
				obj.setContentEx(bas, format, page);
				obj.setStringContentAttribute(INPUT_TYPE, inlineField, format, page, null);
				page ++;
			} 
		} 
		return page;
	}
	
	private static int putBlob(IDfSysObject obj,
							   int page,
							   String inlineField,
							   String format,
							   String value) throws DfException, IOException  {
		if (null != value) {
			try {
				if ((value.length() > MAX_TEXT_BYTES  ||
					 value.getBytes("UTF-8").length > MAX_TEXT_BYTES)) {
					ByteArrayOutputStream bas = new ByteArrayOutputStream();
					bas.write(value.getBytes("UTF-8"));
					bas.flush();
					obj.setContentEx(bas, format, page);
					obj.setStringContentAttribute(INPUT_TYPE, inlineField, format, page, null);
					page ++;
				} else {
					obj.setString(inlineField, value);
				}
			} catch ( UnsupportedEncodingException unex) {
				// won't happen
				throw new RuntimeException(unex);
			}
		} else {
			obj.setString(inlineField, value);
		}
		return page;
	}

	// FIXME: repeating code V
	private static String serializeMap(Map<String, String> map)
		throws IOException {
		JsonNode n = Json.serializer().nodeFromObject(map);
		//StringWriter w = new StringWriter(300);
		//JsonGenerator generator = jsonFactory.createGenerator(w);
		//generator.writeObject(map);
		final String headersStr = n.toString();
		//getLogger().info(sn(),"request parameters: " + headersStr);
		return headersStr;
	}
	private static String serializeParameters(Map<String, Deque<String>> queryParameters)
		throws IOException {
		StringWriter w = new StringWriter(300);
		JsonGenerator generator = jsonFactory.createGenerator(w);
		final Set<Entry<String, Deque<String>>> entrySet = queryParameters.entrySet();
		generator.writeStartObject();
		for (Entry<String, Deque<String>> entry : entrySet) {
			final String fieldName = entry.getKey();
			final String fieldValue = entry.getValue().getLast();
			if (null != fieldValue) {
				generator.writeStringField(fieldName,fieldValue);
			}
		}
		generator.writeEndObject();
		generator.flush();
		final String headersStr = w.getBuffer().toString();
		//getLogger().info(sn(),"request parameters: " + headersStr);
		return headersStr;
	}

	// FIXME: repeating code ^
	private static String serializeHeaders(HeaderMap hmap, String[] filter) throws IOException {
		//OutputStream bos =null;
		StringWriter w = new StringWriter(300);
		JsonGenerator generator = jsonFactory.createGenerator(w);
		generator.writeStartObject();
		for (String headerName : filter)  {
			String headerVal = hmap.getLast(headerName);
			if (null == headerVal) {
				continue;
			}
			generator.writeStringField(headerName, headerVal);
		}
		generator.writeEndObject();
		generator.flush();
		final String headersStr = w.getBuffer().toString();
		//getLogger().info(sn(),"request headers: " + headersStr);
		return headersStr;
	}

	private static String readInput(HttpServerExchange exch) throws IOException {
		final BlockingHttpExchange mBexch = exch.startBlocking();
		final InputStream is  = exch.getInputStream();
		final ObjectMapper mapper = new ObjectMapper();
		final JsonNode tree = mapper.readTree(is);
		//tree.binaryValue()
		final String inputContent = tree.toString();
		getLogger().info(DctmSvcRequest.class.getSimpleName(),"request body: "+inputContent);
		// TODO Auto-generated method stub
		return inputContent;
	}

	
	
	/********  ISvcRequest implementation **************/
	private Map queryParamsMap = null;
	private Map outHeadersMap = null;
	private Map inHeadersMap = null;
	private byte[] outContent = null;
	
	private void initQueryParamMap() {
		this.queryParamsMap = Json.serializer().mapFromJson( this.getBlob(S_IN_QPARS) );
	}

	private void initInHeadersMap() {
		this.inHeadersMap = Json.serializer().mapFromJson( this.getBlob(S_IN_HEADERS) );
	}
	
	public void setOutHeader(String header, String value) {
		if (null != value) {
			if (null == outHeadersMap) {
				this.outHeadersMap = new HashMap();
			}
			this.outHeadersMap.put(header,value);
		}
	}
	
	
	@Override
	public String getQueryParam(String name) {
		if (null == queryParamsMap) {
			initQueryParamMap();
		}
		if (null != queryParamsMap) {
			return (String) queryParamsMap.get(name);
		} else {
			return null;
		}
	}

	@Override
	public String getQueryParam(String name, String defVal) {
		final String val = getQueryParam(name);
		return null == val ? defVal : val;
	}

	@Override
	public String getSysUser() {
		try {
			return mObj.getString(S_REQ_OWNER);
		}	catch (DfException ex) {
			throw new RuntimeException(ex);
		}
	}

	@Override
	public ExecutorDetails getExecutorDetails() {
		// FIXME: real code
		ExecutorDetails ed = new ExecutorDetails();
		ed.setIpAddress("1.2.3.4");
		ed.setExecutingEmpIdCode("1234567890");
		return ed;
	}

	@Override
	public void setContentType(String value) {
		this.setOutHeader(H_CONTENT_TYPE, value);
	}

	@Override
	public void send(byte bytes[]) {
		this.outContent = bytes;
		return ;
	}

	@Override
	public InputStream getInputStream() {
		try {
			final int page = getFieldPage(S_IN_BODY);
			getLogger().info(sn(),"PAGE s_in_body='"+page+"'"); //first check in S_IN_BODY(page), if exists take the json from there(content) 
			if (page >= 0) {
				ByteArrayInputStream is = mObj.getContentEx(IN_FORMAT, page);
				getLogger().info(sn(),"PAGE IS='"+is+"'");
				return is;
			} else { //else take it from the attribute (S_IN_BODY)
				final String str = mObj.getString(S_IN_BODY);
				getLogger().info(sn(),"ATTRIBUTE s_in_body='"+str+"'");
				final byte bytes[] = Utils.getStrBytes(str);
				return new ByteArrayInputStream(bytes);
			}
		} catch (DfException dfex) {
			throw new RuntimeException(dfex);
		}
	}

	private int getFieldPage(String fieldName) throws DfException {
		for (int i = 0; i < mObj.getPageCount(); i++) {
			String contField  = mObj.getStringContentAttr(INPUT_TYPE, IN_FORMAT, i, null);
			if (fieldName.equals(contField)) {
				return i;
			}
		}
		return -1;
	}

	@Override
	public String  getLastHeader(String headerName) {
		if (null == this.inHeadersMap) {
			initInHeadersMap();
		}
		return null != this.inHeadersMap ? (String)this.inHeadersMap.get(headerName) : null;
	}

	@Override
	public void transferFrom(final byte[] bytes, ISvcCallback cb) {
		if (null == bytes) {
			throw new RuntimeException("Unexpectedly got null byte array");
		}
		this.outContent = bytes;
	}

	@Override
	public void transferFrom(FileChannel ch,  ISvcCallback cb) {
		byte[] bytes = new byte[MAX_TEXT_BYTES];
		ByteBuffer bb = ByteBuffer.wrap(bytes);
		try {
			ByteArrayOutputStream bs = new ByteArrayOutputStream();
			int readBytes = -1;
			while ((readBytes = ch.read(bb))>0) {
				bs.write(bytes, 0, readBytes);
				bb.rewind();
			}
			this.outContent = bs.toByteArray();
		} catch (IOException  ex) {
			throw new RuntimeException(ex);
		}
	}
	

	public boolean isFinished() {
		return REQ_STATUS_REPLIED.equals(this.getStatus()) ||
			REQ_STATUS_FINISHED.equals(this.getStatus());
	}

	public boolean isResponseSuccess() {
		int responseCode = this.getResponseCode();
		return responseCode >=200 && responseCode <=299;
	}
	
	
	/***************** Async request handling handling ********************/
	public void submit() throws DfException {
		mObj.save();
		getLogger().info(sn(),"submitted requestId=" + mObj.getString(S_REQ_ID));
	}

	public void start() throws DfException, IOException  {
		mObj.setTime(TS_STARTED, new DfTime(new Date()));
		mObj.setString(S_REQ_STATUS, DctmSvcRequest.REQ_STATUS_STARTED);
		mObj.save();
	}
	
	public void finish() throws DfException, IOException  {
		int page = mObj.getPageCount();
		page = putBlob(mObj, page, S_OUT_HEADERS, IN_FORMAT,  serializeMap(this.outHeadersMap));
		page = putBlob(mObj, page, S_OUT_BODY,    IN_FORMAT,  this.outContent);
		mObj.setString(S_REQ_STATUS, DctmSvcRequest.REQ_STATUS_FINISHED);
		mObj.setTime(TS_FINISHED, new DfTime(new Date()));
		// FIXME
		System.err.println(mObj.dump());
		mObj.save();
		getLogger().info(sn(),"finished requestId=" + mObj.getString(S_REQ_ID));
	}



	public void reply() throws DfException, IOException  {
		mObj.setTime(TS_REPLIED, new DfTime(new Date()));
		mObj.setString(S_REQ_STATUS, DctmSvcRequest.REQ_STATUS_REPLIED);
		mObj.save();
		getLogger().info(sn(),"replied requestId=" + mObj.getString(S_REQ_ID));
	}

	public byte[] getOutBodyBytes() {
		byte[] bytes = this.getBlobBytes(S_OUT_BODY);
		return bytes;
		//ByteArrayInputStream bis = new ByteArrayInputStream(bytes);
		//return bis;
	}

	public String getOutHeaders() {
		return getBlob(S_OUT_HEADERS);
	}
	
	/****************** Utility methods *****************/
	private String  getBlob(String  fieldName) {
		final byte [] bytes =  getBlobBytes(fieldName);
		if (null!=bytes) {
			try {
				return new String(bytes, "UTF-8");
			} catch (UnsupportedEncodingException ex) {
				throw new RuntimeException(ex);
			}
		}
		return null;
	}


	/****************** Utility methods *****************/
	private byte[]  getBlobBytes(String fieldName) {
		try {
			int pageCount = mObj.getPageCount();
			for (int i = 0; i < pageCount; i++) {
				String contField  = mObj.getStringContentAttr(INPUT_TYPE, IN_FORMAT, i, null);
				if (fieldName.equals(contField)) {
					ByteArrayInputStream is = mObj.getContentEx(IN_FORMAT, i);
					long size = mObj.getContentSize(i, IN_FORMAT, null);
					if (size > Integer.MAX_VALUE) {
						throw new RuntimeException("Content is too BIG: "+size +" bytes");
					}
					byte[] contentBuf = new byte[(int)size];
					is.read(contentBuf);
					getLogger().info(sn(),"getBlobBytes:size of "+ fieldName + " ,length is:"+ contentBuf.length);
					return contentBuf;
				}
			}
			String val =  mObj.getString(fieldName);
			if (null != val) {
				getLogger().info(sn(),"getBlobBytes:size of key:"+ fieldName + "is:"+ val);
				//getLogger().info(sn(),"getBlobBytes;size of val->"+val.length());				
				return val.getBytes("UTF-8");
			}
			// FIXME: won't happen need to return error here?
			return null;
		} catch (DfException dfex) {
			throw new RuntimeException(dfex);
		} catch (IOException ioex) {
			throw new RuntimeException(ioex);			
		}
	}

	public String getOperationName() {
		try {
			return mObj.getString( S_OP_NAME);
		} catch (DfException dfex) {
			throw new RuntimeException(dfex);
		}
	}

	@Override
	public String getRequestId() {
		try {
			return mObj.getString(S_REQ_ID);
		} catch (DfException dfex) {
			throw new RuntimeException(dfex);
		}
	}

	@Override
	public void setResponseCode(int code) {
		try {
			mObj.setInt(D_OUT_STATUS, code);
		} catch (DfException dfex) {
			throw new RuntimeException(dfex);
		}
	}

	public int getResponseCode() {
		try {
			return mObj.getInt(D_OUT_STATUS);
		} catch (DfException dfex) {
			throw new RuntimeException(dfex);
		}
	}
	
	public Date getTS(String fname) {
		try {
			IDfTime tm =  mObj.getTime(fname);
			return (null == tm || tm.isNullDate()) ?  null : tm.getDate();
		} catch (DfException dfex) {
			throw new RuntimeException(dfex);
		}
	}

	public Date getTSFinished() {
		return getTS(TS_FINISHED);
	}

	public Date getTSStarted() {
		return getTS(TS_STARTED);
	}

	public Date getTSReplied() {
		return getTS(TS_REPLIED);
	}

	public Date getTSSubmitted() {
		return getTS(TS_SUBMITTED);
	}

	public String getStatus() {
		try {
			return mObj.getString(S_REQ_STATUS);
		} catch (DfException ex) {
			throw new RuntimeException();
		}
	}
	
	public String getCallbackURL() {
		try {
			return mObj.getString(S_CB_URL);
		} catch (DfException ex) {
			throw new RuntimeException();
		}
	}

	public void setCBMessage(String msg) {
		if (null != msg && msg.getBytes().length > MAX_TEXT_BYTES) {
			// FIXME: may trim 50% more than needed
			msg = msg.substring(0, MAX_TEXT_BYTES / 2 );
		}
		try {
			mObj.setString(S_CB_MESSAGE, msg);
		} catch (DfException ex) {
			throw new RuntimeException();
		}
	}

	public void setCBStatusCode(int code) {
		try {
			mObj.setInt(D_CB_STATUS, code);
		} catch (DfException dfex) {
			throw new RuntimeException(dfex);
		}
	}

	public String getLoginUser() {
		// FIXME: save user
		return "dctm";
	}
	public String getOutHeader(String header) {
		String headers = this.getOutHeaders();
		if (null != headers && headers.length()>0) {
			Map <String,Object>map = Json.serializer().mapFromJson(headers);
			return (String)map.get(header);
		}
		return null;
	}
	
	public String getOutMimeType() {
		return getOutHeader("Content-Type");
        }

	@Override
	public String getAuthToken() {
		return getBlob(S_IN_AUTH);
	}
	
	private static LoggingUtils getLogger() {
		return DfsRequestThreadAttributes.dfsLogger.get();
	}

	private String sn() {
		return this.getClass().getSimpleName();
	}
	
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\requests\ExchSvcRequest.java
-----------------------------------------------------
package bnhp.dctmrest.requests;

import java.io.IOException;
import java.io.InputStream;
import java.nio.ByteBuffer;
import java.nio.channels.FileChannel;
import java.nio.channels.ReadableByteChannel;
import java.nio.channels.Channel;
import java.util.HashMap;
import java.util.Map;

import bnhp.dctmrest.utils.CommonConstants;
import bnhp.dctmrest.utils.Json;
import bnhp.infra.com.utils.service.BnhpRequestThreadAttributes;
import bnhp.infra.dfs.exceptions.DFSValidationException;
import bnhp.infra.dfs.utils.basic.properties.PropertyLoader;
import io.undertow.util.HttpString;
import org.json.JSONObject;
import org.python.antlr.ast.Str;
import org.python.modules._json._json;
import org.python.netty.buffer.ByteBuf;

import io.undertow.io.IoCallback;

import  bnhp.dctmrest.handlers.AuthHandler;
import bnhp.dctmrest.utils.Utils;
import bnhp.infra.dfs.model.business.ExecutorDetails;

import io.undertow.server.HttpServerExchange;
import io.undertow.util.HeaderMap;
import io.undertow.io.Sender;
import io.undertow.server.BlockingHttpExchange;

public class ExchSvcRequest implements ISvcRequest {
	private HttpServerExchange mExch;
	private BlockingHttpExchange mBexch ;
	private HashMap<String,Object> dataHolderMap = new HashMap<>();

	public ExchSvcRequest(HttpServerExchange exch) {
		mExch = exch;
	}

	@Override
	public String getQueryParam(String name, String defVal) {
		return Utils.getQueryParam(mExch, name, defVal);
	}

	@Override
	public String getQueryParam(String name) {
		return Utils.getQueryParam(mExch, name);
	}

	public String getLastHeader(String headerName) {
		final HeaderMap hm = mExch.getRequestHeaders();
		String ct = hm.getLast(headerName);
		return ct;
	}

	@Override
	public String getSysUser() {
		return mExch.getAttachment(AuthHandler.SYSUSER_KEY);
	}

	@Override
	public ExecutorDetails getExecutorDetails() throws DFSValidationException
	{
		ExecutorDetails ed = new ExecutorDetails();
		PropertyLoader loader = PropertyLoader.getInstance();

		if (loader.hasProperty(CommonConstants.EP_ED_TAG_NAME))
		{
			String edProperty = loader.getProperty(CommonConstants.EP_ED_TAG_NAME);

			switch (edProperty)
			{
				case CommonConstants.EP_ED_PROVIDE:
				{
					ed = Utils.getExecutorDetails(getQueryParam(CommonConstants.QUERY_PARAMETER_EXECUTION_DETAILS));
					break;
				}
				case CommonConstants.EP_ED_JWT:
				{
					//TODO: take the ip from JWT - as configure at the 'EnvProperties.properties'
					//The token not contain this value (ipAddres) needs ask EvgeniDudin(the honor master of DU system) or DoronMarcus(wso2)
					ed.setIpAddress("1.2.3.4");

					ed.setExecutingEmpIdCode(mExch.getAttachment(AuthHandler.SYSUSER_FULLNAME));
					ed.setExecutingEmpFullName(getSysUser());
					break;
				}
				case CommonConstants.EP_ED_AUTO:
				{
					//ed = Utils.getExecutorDetails(getQueryParam("executorDetails"));
					//if (ed==null) {
						ed.setIpAddress(loader.getProperty(CommonConstants.ED_AUTO_IP_MAP));
						ed.setExecutingEmpIdCode(loader.getProperty(CommonConstants.ED_AUTO_EMPL_CODE_MAP));
						ed.setExecutingEmpFullName(loader.getProperty(CommonConstants.ED_AUTO_FULLNAME_MAP));
					//}

					break;
				}
				/* Actuailly 'default' case cant never happend. becouse we check that at DctmRestApp.java when starting the server */
				default:
				{
					BnhpRequestThreadAttributes.errLogger.get().info("ExecutionDetailsLoader","Property 'executor_details@user contains a wrong value. so try to get this values from the request params.." );
					ed = Utils.getExecutorDetails(getQueryParam(CommonConstants.QUERY_PARAMETER_EXECUTION_DETAILS));

					break;
				}
			}
		}
		/* like wroted before this cant happend - just for case - until we decide to delete this codes*/
		else
		{
			BnhpRequestThreadAttributes.errLogger.get().info("ExecutionDetailsLoader","Property 'executor_details@user is empty. so try to get this values from the request params.." );

			ed = Utils.getExecutorDetails(getQueryParam(CommonConstants.QUERY_PARAMETER_EXECUTION_DETAILS));
		}

		return ed;
	}

	@Override
	public void setContentType(String value) {
		Utils.setContentType( mExch, value);
	}

	@Override
	public void send(byte[] bytes) {
		mExch.getResponseSender().send(ByteBuffer.wrap(bytes));
	}

	@Override
	public InputStream getInputStream() {
		if (null == mBexch) {
			mBexch = mExch.startBlocking();
		}
		return mExch.getInputStream();
	}

	@Override
	public void transferFrom(FileChannel ch, ISvcCallback cb) {
		final Sender sender = mExch.getResponseSender();
		final IoCallback iocb = new IoCallback() {
			public void onComplete(HttpServerExchange exch, Sender sender) {
				cb.onComplete();
			}

			public void onException(HttpServerExchange exch, Sender sender, IOException ioex) {
				cb.onException(ioex);
			}
		};
		sender.transferFrom((FileChannel)ch, iocb);
	}

	@Override
	public void transferFrom(byte[] bytes, ISvcCallback cb) {
		final Sender sender = mExch.getResponseSender();
		final IoCallback iocb = new IoCallback() {
			public void onComplete(HttpServerExchange exch, Sender sender) {
				cb.onComplete();
			}

			public void onException(HttpServerExchange exch, Sender sender, IOException ioex) {
				cb.onException(ioex);
			}
		};
		ByteBuffer bb = ByteBuffer.wrap(bytes);
		sender.send(bb, iocb);
	}

	@Override
	public String getRequestId() {
		return Utils.getHeaderParam(mExch, "X-RequestID");
	}

	@Override
	public void setResponseCode(int code) {
		mExch.setStatusCode(code);
	}

	@Override
	public String getAuthToken() {
		return mExch.getAttachment(AuthHandler.SYSUSER_TOKEN);
	}

	public void addHeader(String pName, String pVal)
	{
		mExch.getResponseHeaders().put(new HttpString(pName),pVal);
	}

	public void addKeyValue(String pKey, Object pValue)
	{
		dataHolderMap.put(pKey,pValue);
	}

	public Object getValueByKey(String pKey)
	{
		return dataHolderMap.get(pKey);
	}
}






file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\requests\ISvcCallback.java
-----------------------------------------------------
package bnhp.dctmrest.requests;



public interface ISvcCallback {
	public void onComplete();
	public void onException(Exception ex);
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\requests\ISvcRequest.java
-----------------------------------------------------
package bnhp.dctmrest.requests;

import java.io.InputStream;
import java.nio.ByteBuffer;
import java.nio.channels.Channel;
import java.nio.channels.FileChannel;
//import io.undertow.io.IoCallback;
import bnhp.infra.dfs.exceptions.DFSValidationException;
import bnhp.infra.dfs.model.business.ExecutorDetails;

public interface ISvcRequest {
	public String getRequestId();
	public String getQueryParam(String name);
	public String getQueryParam(String name, String defVal);
	public String getSysUser();
	public String getAuthToken();

	public ExecutorDetails getExecutorDetails() throws DFSValidationException;
	public void setContentType(String value);

	public void send(byte bytes[]);
	public InputStream getInputStream();

	public String  getLastHeader(String headerName);
	public void transferFrom(FileChannel ch,  ISvcCallback cb);
	public void transferFrom(byte[] bb, ISvcCallback cb);
	public void setResponseCode(int code);
	
}






file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\requests\ISvcRequestHandler.java
-----------------------------------------------------
package bnhp.dctmrest.requests;

public interface ISvcRequestHandler {
	public void handleRequest(ISvcRequest svcReq) throws Exception;
	public void setOperationName(String operationName);
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\utils\CommonConstants.java
-----------------------------------------------------
package  bnhp.dctmrest.utils;

import bnhp.infra.dfs.model.service.FetchTypeSet;
import org.python.antlr.ast.Str;

public class CommonConstants
{
	public final static String H_CONTENT_TYPE = "Content-Type";
	public final static String MIME_APPLICATION_JSON = "application/json";

	public final static String H_X_CALLBACK_URL = "X-Callback-URL";
	public final static String H_X_REQUEST_ID = "X-Request-ID";

	public final static String QUERY_PARAMETER_DOCUMENT_ID = "documentId";
	public final static String QUERY_PARAMETER_ID_TYPE = "idType";
	public final static String QUERY_PARAMETER_FORMAT = "format";
	public final static String QUERY_PARAMETER_EXECUTION_DETAILS = "executorDetails";
	public final static String QUERY_PARAMETER_VERSION_LABEL = "versionLabel";
	public final static String QUERY_PARAMETER_FETCH_TYPE = "fetchType";
	public final static String Q_PAR_RET_PROF = "retrieveProfile";
	public final static String Q_PAR_RET__SECOND_PROF = "retrieveSecondaryContent";
	public final static String RETRIEVE_PROFILE_HTTP = "HTTP";
	public final static String RETRIEVE_PROFILE_STREAM = "STREAM";
	public final static String RETRIEVE_PROFILE_HTTPS = "HTTPS";
	public final static String RETRIEVE_PROFILE_SAFE_CYBERARK = "SAFE";
	public final static String FETCH_TYPE_CONTENT = "content";
	public final static String DFS_FETCH_TYPE_CONTENT = "file";
	public final static String FETCH_TYPE_FULL = "full";
	public final static String FETCH_TYPE_META = "meta";
	public final static String LEGACY_DOC_ID_TEXT = "legacyDocumentId";

	//ExecutorDetails strings:
	public final static String EXECUTION_DETAILS = "Execution Details";
	public final static String EXECUTION_DETAILS_PARAMETERS_BANCOL_ID = "bankolId";
	public final static String EXECUTION_DETAILS_PARAMETERS_EMPL_DOC_TYPE_CODE = "empIdDocumentTypeCode";
	public final static String EXECUTION_DETAILS_PARAMETERS_EXE_BANK_ID = "executingBankId";
	public final static String EXECUTION_DETAILS_PARAMETERS_EXE_BRANCH_ID = "executingBranchId";
	public final static String EXECUTION_DETAILS_PARAMETERS_EXE_EMPL_FULL_NAME = "executingEmpFullName";
	public final static String EXECUTION_DETAILS_PARAMETERS_EXE_EMPL_ID_CODE = "executingEmpIdCode";
	public final static String EXECUTION_DETAILS_PARAMETERS_INST_RECEIVE_TYPE_CODE = "instructionReceiveTypeCode";
	public final static String EXECUTION_DETAILS_PARAMETERS_IP_ADDRESS = "ipAddress";
	public final static String EXECUTION_DETAILS_PARAMETERS_TERMINAL_CHANEEL_ID_CODE = "terminalChannelId";

	//Errors:
	public final static String ERROR_OBJECT_ID_IS_NOT_FOUND = "can't find document with %s %s.. ";
	public final static String ERROR_OBJECT_AS_FORMAT_IS_NOT_FOUND = "can't find document with %s '%s' As %s format.. ";

	public final static String ERROR_GET_REQUEST_INNER_PARAMETER_MISSING = "The parameter '%s' must contains '%s' parameter.";
	public final static String ERROR_GET_REQUEST_INNER_PARSE_FORMAT_EXCEPTION = "Format exception: the value of '%s' can contain only '%s' type";

	public final static  String ERROR_PARAMETER_NOT_EXIST = "The parameter '%s' not exist..";

	//EnvProperties.properties:
	//ExecutorDetails properties:
	public final static String EP_ED_TAG_NAME = "executor_details@user";
	public final static String EP_ED_PROVIDE = "PROVIDE";
	public final static String EP_ED_JWT = "JWT";
	public final static String EP_ED_AUTO = "AUTO";

	public final static String ED_JWT_EMP_CODE_MAP = "executor_details@Jwt@executingEmpIdCode";
	public final static String ED_JWT_FULLNAME_MAP = "executor_details@Jwt@fullName";

	public final static String ED_AUTO_EMPL_CODE_MAP = "executor_details@Auto@executingEmpIdCode";
	public final static String ED_AUTO_FULLNAME_MAP = "executor_details@Auto@fullName";
	public final static String ED_AUTO_IP_MAP = "executor_details@Auto@ipAddress";

}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\utils\DFS2Rest.java
-----------------------------------------------------
package bnhp.dctmrest.utils;

import java.util.List;
import java.util.Map;
import java.util.stream.Collectors;
import java.util.stream.Stream;
import java.util.Date;

import bnhp.dctmrest.model.*;
import bnhp.infra.ecm.model.DocGeneralData;
import com.emc.documentum.fs.datamodel.core.schema.DataType;
import com.emc.documentum.fs.datamodel.core.schema.PropertyInfo;

import java.util.ArrayList;
import java.util.HashMap;

import bnhp.infra.dfs.model.service.RequestDetails;
import bnhp.infra.dfs.model.service.SearchResult;
import bnhp.infra.dfs.utils.business.DctmPropertyNamesHolder;
import bnhp.dctmrest.model.ErrorDetails.ErrorTypeEnum;
import bnhp.dctmrest.utils.SecondaryDocFileSupport;
import bnhp.infra.dfs.exceptions.DFSValidationException;
import bnhp.infra.dfs.model.business.CustomerKey;
import bnhp.infra.dfs.model.business.DocData;
import bnhp.infra.dfs.model.business.DocProperties;
import bnhp.infra.dfs.model.business.DocPropertyExtension;
import bnhp.infra.dfs.model.business.PropertyKeyValue;
import bnhp.infra.dfs.model.business.SecondaryDocFile;
import bnhp.infra.dfs.model.query.prepared.AbstractParam;
import bnhp.infra.dfs.model.query.prepared.NamedQueryParam;
import bnhp.infra.dfs.model.query.prepared.QueryParam;
import bnhp.infra.dfs.model.service.DocDataForRetrieve;
import bnhp.infra.dfs.model.service.DocIdData;
import bnhp.infra.dfs.model.service.FetchTypeSet;
import bnhp.infra.dfs.model.service.File;
import bnhp.infra.dfs.model.service.Full;
import bnhp.infra.dfs.model.service.Meta;

import com.emc.documentum.fs.datamodel.core.schema.PropertyInfo;

import bnhp.infra.dfs.model.query.prepared.MultivalueQueryParam;
import bnhp.infra.dfs.model.query.prepared.NamedQueryParam;
import bnhp.infra.dfs.model.query.prepared.QueryParamList;

	

public class DFS2Rest {
	private static Map<String, PropertyInfo> infoMap =
		DctmPropertyNamesHolder.getInstance().getAspectPropertyInfoMap();
	
	public static List<String> makeVersionLabels(String vNumber, String vLabel) {
		List<String> versionLabels = new ArrayList<String>(2);
		if (null != vNumber) {
			versionLabels.add(vNumber);
		}
		if (null != vLabel) {
			versionLabels.add(vLabel);
		}
		return versionLabels;
	}

	public static BnhpCustomerDocData toRest(DocDataForRetrieve result,
											 boolean inlineContent /*, List<RequestDetails> details*/) {
		BnhpCustomerDocData rbcdd = new BnhpCustomerDocData();


		// FIXME
		rbcdd.setCreationTime(result.getCreationDate());
		rbcdd.setLastUpdateTime(result.getModifyDate());
		rbcdd.setObjectType("BnhpCustomerDoc");

		
		DocIdData did = result.getDocIdData();
		if (null != did) {
			rbcdd.setVersionLabels(makeVersionLabels(did.getVersionNumber(),
													 did.getVersionLabel()));		
		}

		if (null!=result.getDocData()) {
			DocData dd = result.getDocData();
			if (null!=dd.getDocCustomerData() &&
				null!=dd.getDocCustomerData().getDocDetails()) {
				rbcdd.setObjectName(dd.getDocCustomerData().getDocDetails().getObjectName());
			}
			rbcdd.setDocFiles(addDocFile(rbcdd.getDocFiles(),
										 dd.getDocFile(),
										 inlineContent,
										 null, // classifier
										 null  // attrs
										 ));
			rbcdd.setDocFiles(addDocFile(rbcdd.getDocFiles(),
										 dd.getSecondaryDocFile(),
										 inlineContent));

			rbcdd.setDocCustomerData(toRest(dd.getDocCustomerData()));

			if (null!=did &&
				null!=rbcdd.getDocCustomerData() &&
				null!=rbcdd.getDocCustomerData().getDocDetails()) {
				rbcdd.getDocCustomerData().getDocDetails().setDctmDocumentId(did.getDctmDocumentId());
			}
			//if (null != dd.getDocPropertyExtensions()) {
			rbcdd.setExtensions(toRest(dd.getDocPropertyExtensions()));
			//}

		}

		// if (null!=details) {
		// 	for(RequestDetails det: details) {
		// 		det.get
		// 		List<String> versions = null;
		// 		rbcdd.setVersionLabels(versions);
		// 	}
		// }

		return rbcdd;

	}

	public static BnhpGeneralDocData toRest(bnhp.infra.ecm.model.DocDataForRetrieve result,
											boolean inlineContent /* , List<RequestDetails> details */)
	{
		BnhpGeneralDocData rbcdd = new BnhpGeneralDocData();

		if (null != result.getDocIdData()) {
			DocIdData did = new DocIdData();
			did.setVersionLabel(result.getDocIdData().getVersionLabel());
			did.setDctmDocumentId(result.getDocIdData().getDctmDocumentId());
			rbcdd.setVersionLabels(makeVersionLabels(did.getVersionNumber(), result.getDocIdData().getVersionLabel()));
		}
		rbcdd.setCreationTime(result.getDocGeneralData().getDocDetails().getLegacyDocumentEntryDttm());
		rbcdd.setLastUpdateTime(result.getDocGeneralData().getDocDetails().getLegacyDocumentEntryDttm());
		rbcdd.setObjectType("BnhpGeneralDoc");

		rbcdd.setObjectName(result.getDocGeneralData().getDocDetails().getObjectName());
		rbcdd.setLegacyDocumentId(result.getDocGeneralData().getDocDetails().getLegacyDocumentId());

		if (null != result.getDocGeneralData().getDocFile())
		{

			rbcdd.setDocFiles(addDocFile(rbcdd.getDocFiles(), result.getDocGeneralData().getDocFile(), inlineContent,
					null, null));

		}
		return rbcdd;
	}

	private static List<OneOfbnhpPaperDocbnhpCorporateDocbnhpDivisionBusiness>
		toRest(List<DocPropertyExtension> exts) {
		return null == exts ? null : exts.stream().
			map(ext -> toRest(ext)).collect(Collectors.toList());
	}

	private static OneOfbnhpPaperDocbnhpCorporateDocbnhpDivisionBusiness toRest(DocPropertyExtension ext) {
		if (null == ext) {
			return null;
		}
		// FIXME: non-string properties, repeatings
		OneOfbnhpPaperDocbnhpCorporateDocbnhpDivisionBusiness rext =
			new  OneOfbnhpPaperDocbnhpCorporateDocbnhpDivisionBusiness();
		final String name = ext.getExtensionName();
		rext.setName(name);
		if (null != ext.getPropertyKeyValues()) {

			Map<String,Object> map = new HashMap<String,Object>(10);
			for (PropertyKeyValue pkv : ext.getPropertyKeyValues()) {
				if (null != pkv) {
					final String key = pkv.getKey();
					if (null != key) {
						map.put(key, toRest(name, pkv));
					}
				}
			}
			rext.setProperties(map);
		}

		return rext;
	}

	private static Object toRest(String extName, PropertyKeyValue pkv) {
		if (null == pkv) {
			return null;
		}
		Object result = null;
		PropertyInfo pinfo = infoMap.get(extName +"." + pkv.getKey());
		String valueStr = pkv.getValue();
		if (null!=pinfo && null != valueStr ) {
			// FIXME: repeating
			//if (pinfo.isArray()) {
			//result = new ArrayList();
			DataType dt = pinfo.getDataType();
			if (DataType.BOOLEAN == dt) {
				result = Boolean.parseBoolean(valueStr);
			} else if (DataType.DOUBLE == dt) {
				result = Double.parseDouble(valueStr);
			} else if (DataType.INTEGER == dt ||
					   DataType.LONG == dt||
					   DataType.SHORT == dt) {
				result = Long.parseLong(valueStr);
			} else if (DataType.STRING == dt) {
				result = valueStr;
			} else if (DataType.DATE == dt) {
				// Fixme! date format check?
				result = valueStr;
			}
		} else {
			// FIXME: fail on unknown attr? it must not happen with proper config
			result = valueStr;
		}
		return result;
	}

	private static DocCustomerData toRest(bnhp.infra.dfs.model.business.DocCustomerData dcd) {
		if (null == dcd) {
			return null;
		}
		DocCustomerData rdcd = new DocCustomerData();

		if (null != dcd.getBankAccounts()) {
			rdcd.setBankAccounts(dcd.getBankAccounts().stream()
								 .map(acc -> toRest(acc))
								 .collect(Collectors.toList()));
		}

		if (null != dcd.getCustomerKeys()) {
			rdcd.setCustomers(dcd.getCustomerKeys().stream()
							  .map(cust -> toRest(cust))
							  .collect(Collectors.toList()));
		}
		rdcd.setPensionFund(toRest(dcd.getPensionFund()));

		rdcd.setDocDetails(toRest(dcd.getDocDetails()));
		rdcd.setExecutorDetails(toRest(dcd.getExecutorDetails()));

		return rdcd;
	}

	public static ExecutorDetails toRest(bnhp.infra.dfs.model.business.ExecutorDetails ed) {
		ExecutorDetails red = new ExecutorDetails();

		red.setBankolId(ed.getBankolId());
		red.setEmpIdDocumentTypeCode(ed.getEmpIdDocumentTypeCode());
		red.setExecutingBankId(ed.getExecutingBankId());
		red.setExecutingBranchId(ed.getExecutingBranchId());
		red.setExecutingEmpFullName(ed.getExecutingEmpFullName());
		red.setExecutingEmpIdCode(ed.getExecutingEmpIdCode());
		//red.setExecutingUserName(ed.getExecutingUserName());
		red.setInstructionReceiveTypeCode(ed.getInstructionReceiveTypeCode());
		red.setIpAddress(ed.getIpAddress());
		red.setTerminalChannelId(ed.getTerminalChannelId());

		return red;
	}

	/*private static CustomerType toRestCustomerType(Integer code) {
		if (null != code) {
			try {
				CustomerType ct = CustomerType.valueOf("NUMBER_"+code.toString());
				return ct;
			} catch (Exception ex) {
				return null;
			}
		} else {
			return null;
		}
		}*/

	private static DocDetails toRest(bnhp.infra.dfs.model.business.DocDetails dd) {
		if (null == dd) {
			return null;
		}
		DocDetails rdd = new DocDetails();
		rdd.setTransactionAmt(dd.getTransactionAmt());
		rdd.setTemplateDataExistsInd(dd.getTemplateDataExistsInd());
		rdd.setSystemCode(dd.getSystemCode());
		rdd.setSignatureStatusCode(dd.getSignatureStatusCode());
		rdd.setScanStatusCode(dd.getScanStatusCode());
		rdd.setProjectId(dd.getProjectId());
		rdd.setOngoingOrHistoryCode(dd.getOngoingOrHistoryCode());
		//rdd.setObjectName(dd.getObjectName());
		rdd.setLegacyDocumentId(dd.getLegacyDocumentId());
		rdd.setLegacyDocumentEntryDttm(dd.getLegacyDocumentEntryDttm());
		rdd.setDocumentGroupIds(dd.getDocumentGroupIds());
		rdd.setDocumentFormId(dd.getDocumentFormId());
		rdd.setDocumentEditionNbr(dd.getDocumentEditionNbr());
		rdd.setDocDeliveryNum(dd.getDocDeliveryNum());
		rdd.setDocCompletenessCode(dd.getDocCompletenessCode());
		rdd.setCurrencyCode(dd.getCurrencyCode());
		rdd.setChannelId(dd.getChannelId());
		rdd.setBusinessSubAreaCode(dd.getBusinessSubAreaCode());
		rdd.setBusinessProcessId(dd.getBusinessProcessId());
		rdd.setBusinessAreaCode(dd.getBusinessAreaCode());
		rdd.setConcatenatedEventIds(dd.getConcatenatedEventIds());
		return rdd;
	}

	private static PensionFund toRest(bnhp.infra.dfs.model.business.PensionFund pf) {
		if (null == pf) {
			return null;
		}
		PensionFund rpf = new PensionFund();
		rpf.setPensionFundNbr(pf.getPensionFundNbr());
		rpf.setPlanholderNumber(pf.getPlanholderNumber());
		return rpf;
	}

	private static Customer toRest(CustomerKey ck) {
		if (null == ck) {
			return null;
		}
		Customer c = new Customer();
		c.setOccasionalCustomerInd(ck.getOccasionalCustomerInd());
		c.setCustomerSerialNbr(ck.getCustomerSerialNbr());
		c.setCustomerIdDocTypeCode(ck.getCustomerIdDocTypeCode());
		c.setCustomerId(ck.getCustomerId());
		c.setCustomerFullName(ck.getCustomerFullName());
		c.setCompleteCustomerIdCode(ck.getCompleteCustomerIdCode());
		return c;
	}

	private static BankAccount toRest(bnhp.infra.dfs.model.business.BankAccount ba) {
		if (null == ba) {
			return null;
		}
		BankAccount rba = new BankAccount();
		rba.setSpecialHandlingCode(ba.getSpecialHandlingCode());
		rba.setDivisionId(ba.getDivisionId());
		rba.setBranchId(ba.getBranchId());
		rba.setAccountType(ba.getAccountType());
		rba.setAccountNbr(ba.getAccountNbr());
		rba.setAccountBankId(ba.getAccountBankId());
		return rba;
	}

	private static List<DocFile> addDocFile(List<DocFile> docFiles,
											SecondaryDocFile secondaryDocFile,
											boolean inlineContent) {
		if (null == secondaryDocFile || null==secondaryDocFile.getDocFile()) {
			return docFiles;
		}
		return addDocFile(docFiles,
						  secondaryDocFile.getDocFile(),
						  inlineContent,
						  SecondaryDocFileSupport.SECONDARY_DOCILE_CLASSIFIER,
						  (null==secondaryDocFile.getTemplateSourceCode()) ? null
						  : Utils.makeMap(SecondaryDocFileSupport.SECONDARY_DOCILE_TEMPLATE_SOURCE_CODE_ATTR,
										  secondaryDocFile.getTemplateSourceCode()));
	}

	private static List<DocFile> addDocFile(List<DocFile> docFiles,
											bnhp.infra.dfs.model.business.DocFile df,
											boolean inlineContent,
											String classifier,
											Map<String,Object> attributes) {
		if (null == df) {
			return docFiles;
		}
		if (null == docFiles) {
			docFiles = new ArrayList<DocFile>(2);
		}
		DocFile rdf = new DocFile();
		rdf.setDocFormat(df.getDocFormat());
		rdf.setDosExtension(df.getDosExtension());
		rdf.setCheckSum(df.getCheckSum());
		rdf.setMimeType(df.getMimeType());
		rdf.setDocSize(df.getDocSize());
		rdf.setDocURL(df.getDocURL());
		if (inlineContent) {
			rdf.setDocStream(df.getDocStream());
		}
		rdf.setClassifier(classifier);
		rdf.setAttributes(attributes);
		docFiles.add(rdf);
		return docFiles;
	}

	private static List<DocFile> addDocFile(List<DocFile> docFiles, bnhp.infra.ecm.model.DocFile df,
											boolean inlineContent, String classifier, Map<String, Object> attributes)
	{
		if (null == df) { return docFiles; }
		if (null == docFiles)
		{
			docFiles = new ArrayList<DocFile>(2);
		}
		DocFile rdf = new DocFile();
		rdf.setDocFormat(df.getDocFormat());
		rdf.setCheckSum(df.getCheckSum());
		rdf.setMimeType(df.getMimeType());
		rdf.setDocSize(df.getDocSize());
		rdf.setDocURL(df.getDocURL());
		rdf.setDosExtension(df.getDosExtension());
		if (inlineContent)
		{
			rdf.setDocStream(df.getDocStream());
		}
		rdf.setClassifier(classifier);
		rdf.setAttributes(attributes);
		docFiles.add(rdf);
		return docFiles;
	}

	final public static String META = "meta";
	final public  String FULL = "full";
	final public  String CONTENT = "content";

	
	public static FetchTypeSet getFetchType(String fetchTypeStr) {
		FetchTypeSet fts = new FetchTypeSet();
		if (null == fetchTypeStr || "".equals(fetchTypeStr.trim())) {
			fts.setFetchType(new Meta());
		}
		FetchType ft = FetchType.fromValue(fetchTypeStr);
		if (ft == FetchType.FULL) {
			fts.setFetchType(new Full());
		} else if (ft==FetchType.META) {
			fts.setFetchType(new Meta());
		} else if (ft==FetchType.CONTENT) {
			fts.setFetchType(new File());
		} else {
			throw new IllegalArgumentException("unexpected fetchType value "+fetchTypeStr);
		}
		return fts;
	}


	public static ErrorDetails makeErrorDetails(String dfsErrorCode, String message) {
		ErrorDetails details = new ErrorDetails();
		details.setErrorDetails(message);
		int errorCode = 0;
		ErrorDetails.ErrorTypeEnum errType = ErrorDetails.ErrorTypeEnum.GENERAL;
		if (null != dfsErrorCode) {
			String parts [] = dfsErrorCode.split(":",2);
			if (parts.length > 0) {
				try {
					final String restErrTypeStr = parts[0]
						.toUpperCase()
						.replaceFirst("_ERROR$","");
					//details.
					//errType =
					//details.ErrorTypeEnum(restErrTypeStr);
					errType = ErrorDetails.ErrorTypeEnum.valueOf(restErrTypeStr);
				} catch (Exception ex) {
					errType = ErrorDetails.ErrorTypeEnum.GENERAL;
				}
				if (parts.length > 1) {
					try {
						errorCode = Integer.parseInt(parts[1]);
					} catch (NumberFormatException nex) {
						errorCode=0;
					}
				}
			}
		}
		details.setErrorType(errType);
		details.setErrorCode(errorCode);
		return details;
	}

	public static bnhp.dctmrest.model.DocIdData toRest(DocIdData src) {
		bnhp.dctmrest.model.DocIdData result = new bnhp.dctmrest.model.DocIdData();
		result.setDctmDocumentId(src.getDctmDocumentId());
		result.setVersionNumber(src.getVersionNumber());
		result.setVersionLabels(makeVersionLabels(src.getVersionNumber(),
												  src.getVersionLabel()));
		return result;
	}

	public static InlineResponse200 toRest(SearchResult results) {
		InlineResponse200 rr = new InlineResponse200();
		long startIndex = 0L;
		if (null != results.getSearchStatus()) {
			rr.setStartIndex(results.getSearchStatus().getStartIndex());
		}
		if (null != results.getDocuments()) {
			List<DocDataForRetrieve> ddfrl = results.getDocuments();
			List restItems = new ArrayList(ddfrl.size());
			//List<DocumentData>objects = new ArrayList<DocumentData>(ddfrl.size());
			//List<DocumentData>objects = new ArrayList<DocumentData>(ddfrl.size());
			for (DocDataForRetrieve ddfr : ddfrl) {
				BnhpCustomerDocData customerDoc = toRest(ddfr, false);
				restItems.add(customerDoc);
			}
			rr.setObjects(restItems);
			
			//rr.setObjects(objects);
		}
		return rr;
	}

	public static Object toRestPQResults(List<NamedQueryParam> results) {
		Map<String,Object> map = toMap(results);
		final String listKey = "RESULTLIST";
		if (null != map && map.containsKey(listKey)) {
			return map.get(listKey);
		} else {
			return  map;
		}
	}
	
	private static Map<String,Object> toMap(List<NamedQueryParam> paramList) {
		if (null == paramList) {
			return null;
		}
		Map map = new HashMap(paramList.size());
		for (NamedQueryParam param : paramList) {
			map.put(param.getName(), toMap(param.getParamValue()));
		}
		return map;
	}


	private static Object toMapValue (Object val)  {
			if ( (val instanceof Number ) ||
				 (val instanceof String)) {
				return val;
			} else if (null != val) {
				return val.toString();
			} else {
				return null;
			}
		
	}
	
	private static Object toMap(AbstractParam paramValue) {
		if (paramValue instanceof QueryParam) {
			QueryParam qp = (QueryParam) paramValue;
			return toMapValue(qp.getValue());
		} else if (paramValue instanceof QueryParamList) {
			QueryParamList qpl = (QueryParamList) paramValue;
			return toMap(qpl.getParams());
		} else if (paramValue instanceof MultivalueQueryParam) {
			MultivalueQueryParam mvp = (MultivalueQueryParam)paramValue;
			List<Object> values =	mvp.getValues();
			if (null == values) {
				return null;
			}
			List<Object> convertedValues = new ArrayList<Object>();
			for (Object value : values) {
				if (value instanceof AbstractParam) {
					value = toMap((AbstractParam)value);
				} else {
					value = toMapValue(value);
				}
				convertedValues.add(value);
			}
			return convertedValues;
		} else {
			return null;
		}
	}
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\utils\ErrorResponse.java
-----------------------------------------------------
package bnhp.dctmrest.utils;

import bnhp.dctmrest.model.ErrorDetails;
import bnhp.infra.dfs.exceptions.DFSAuthorizationException;
import bnhp.infra.dfs.exceptions.DFSDocumentumException;
import bnhp.infra.dfs.exceptions.DFSUnexpectedQueryResultException;
import bnhp.infra.dfs.exceptions.utils.ErrorInfoPropertyLoader;


public class ErrorResponse {
	private int responseCode = 500;
	private byte[] content = null;
	private String contentType = null;


	public ErrorResponse(Exception exception, String operationName) {
		ErrorInfoPropertyLoader errLoader = ErrorInfoPropertyLoader.getInstance();
		String code = errLoader.getErrorCode(exception);
		exception.printStackTrace();
		String message = exception.getMessage();
		contentType = CommonConstants.MIME_APPLICATION_JSON;
		ErrorDetails details = DFS2Rest.makeErrorDetails(code, message);
		content = Utils.toByteArray(details);
		if (ErrorDetails.ErrorTypeEnum.VALIDATION == details.getErrorType()) {
			if (exception instanceof DFSAuthorizationException) {
				responseCode = 403;
			} else {
				responseCode = 400;
			}
		} else if (ErrorDetails.ErrorTypeEnum.TEMPORARY == details.getErrorType()) {
			responseCode = 503;
			//FIXME: lots of special cases, checks on response messages:
			//       SERVICE SHOULD THROW PROPER EXCEPTION!
		} 	else if (((exception instanceof DFSUnexpectedQueryResultException) ||
				  (exception.getCause() instanceof DFSUnexpectedQueryResultException)) &&
				 ("retrieveObjectById".equals(operationName) ||
				  "updateObjectById".equals(operationName) ||
				  "cancelObjectById".equals(operationName) ||
				  "getAsyncRequestStatus".equals(operationName))) {
			responseCode = 404;
		} else if ((exception instanceof DFSDocumentumException) &&
				   (exception.getMessage().contains("ORA-00001:") ||
					exception.getMessage().contains("in field legacyId but different customer data. The existing id is"))) {
			responseCode = 409;
		}
	}
	
	/**
	 * @return the responseCode
	 */
	public int getResponseCode() {
		return responseCode;
	}

	/**
	 * @param responseCode the responseCode to set
	 */
	public void setResponseCode(int responseCode) {
		this.responseCode = responseCode;
	}

	/**
	 * @return the content
	 */
	public byte[] getContent() {
		return content;
	}

	/**
	 * @param content the content to set
	 */
	public void setContent(byte[] content) {
		this.content = content;
	}

	/**
	 * @return the contentType
	 */
	public String getContentType() {
		return contentType;
	}

	/**
	 * @param contentType the contentType to set
	 */
	public void setContentType(String contentType) {
		this.contentType = contentType;
	}
	
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\utils\HttpUtils.java
-----------------------------------------------------
package bnhp.dctmrest.utils;

import io.undertow.server.HttpServerExchange;
import java.nio.ByteBuffer;
import java.io.IOException;
import java.io.InputStream;
import java.io.OutputStream;
import java.io.UnsupportedEncodingException;
import java.net.HttpURLConnection;
import java.net.MalformedURLException;
import java.net.ProtocolException;
import java.net.URL;
import java.net.URLEncoder;
import java.util.Map;
import java.util.Map.Entry;

import javax.activation.MimeType;
import javax.activation.MimeTypeParameterList;
import javax.activation.MimeTypeParseException;

import com.documentum.fc.client.acs.impl.common.config.cache.common.UrlEntry;
import com.documentum.xml.xalan.utils.URI.MalformedURIException;

import bnhp.infra.dfs.utils.basic.LoggingUtils;
import bnhp.infra.dfs.utils.service.DfsRequestThreadAttributes;

public class HttpUtils {
	public static String getEncoding(HttpURLConnection con, String def) {
		String result = con.getContentEncoding();
		if (null == result) {
			String contentType = con.getContentType();
			if (null != contentType && contentType.length() > 0) {
				try {
					MimeType m = new MimeType(contentType);
					MimeTypeParameterList plist = m.getParameters();
					if (null != plist) {
						result =  plist.get("charset");
					}
				} catch (MimeTypeParseException e) {
					getLogger().error(sn(), "Invalid mime type returned: " +  contentType);
				}
			}
		}
		return null == result ? def : result;
    }

	private static String sn() {
		return HttpUtils.class.getSimpleName();
	}
	
	private static LoggingUtils getLogger() {
		return DfsRequestThreadAttributes.dfsLogger.get();
	}


	public static long copyStream(InputStream is, OutputStream os) 
		throws IOException {
		try {
			byte[] buf= new byte[64 * 1024];
			int readBytes;
			long total = 0;
			while( (readBytes = is.read(buf)) > 0) {
				os.write(buf, 0, readBytes);
				total += readBytes;
			}
			os.flush();
			return total;
		} finally {
			os.close();
		}
	}


	public static String urlencode(String str) {
		try {
			return URLEncoder.encode(null == str ? "" : str, "UTF-8");
		} catch (UnsupportedEncodingException ex) {
			throw new RuntimeException("UTF-8 not supported!", ex);
		}
	}
	
	public static HttpURLConnection makePOST(String urlStr,
											 Map <String, String>queryParams,
											 Map <String, Object>headers,
											 long contentLen) 
		throws MalformedURLException, IOException  {
		URL url = new URL(urlStr);
		if (null != queryParams) {
			url = appendQueryParams(url, queryParams);
		}
		HttpURLConnection con = (HttpURLConnection) url.openConnection();
		setConnProperties(con);
		con.setFixedLengthStreamingMode(contentLen);
		headers.forEach((key, value) -> con.setRequestProperty(key, (String) value));
		return con;
	}

	private static URL appendQueryParams(URL url, Map<String, String> map) throws MalformedURLException {
		if (null != map &&  map.size()>0) {
			String urlStr = url.toString();
			String sep = "?";
			StringBuilder buf = new StringBuilder();
			buf.append(url);
			for(Entry<String,String> entry : map.entrySet()) {
				if (null!=entry.getKey() && entry.getKey().length()>0) {
					buf.append(sep);
					buf.append(urlencode(entry.getKey()));
					buf.append('=');
					buf.append(urlencode(entry.getValue()));
					sep = "&";
				}
			}
			return new URL(buf.toString());
		} else {
			return url;
		}
	}

	public static void setConnProperties(HttpURLConnection con) throws ProtocolException {
		con.setConnectTimeout(20000);
		con.setRequestMethod("POST");
		con.setUseCaches(false);
		con.setRequestProperty("Accept", "application/json");
		con.setInstanceFollowRedirects(false);
		con.setAllowUserInteraction(false);
		// needed to get response status
		con.setDoInput(true);
		// needed for post
		con.setDoOutput(true);
		//con.setChunkedStreamingMode(1024);
    }

	public static void sendResponse(final HttpServerExchange exch,
									final int statusCode,
									final String mimeType,
									final byte[] bytes) {
		Utils.setContentType(exch, mimeType);
		exch.setResponseCode(statusCode);
		exch.getResponseSender().send(ByteBuffer.wrap(bytes));
	}
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\utils\IConfigurable.java
-----------------------------------------------------
package bnhp.dctmrest.utils;

import java.util.Map;

import org.cfg4j.provider.ConfigurationProvider;

public interface IConfigurable {

	public void configure(ConfigurationProvider provider, String name, Map<String,Object> context);
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\utils\Json.java
-----------------------------------------------------
package bnhp.dctmrest.utils;

import java.io.IOException;
import java.io.InputStream;
import java.util.Map;
import java.util.concurrent.TimeUnit;

import com.fasterxml.jackson.annotation.JsonInclude.Include;
import com.fasterxml.jackson.core.JsonParseException;
import com.fasterxml.jackson.core.JsonParser;
import com.fasterxml.jackson.core.type.TypeReference;
import com.fasterxml.jackson.databind.DeserializationFeature;
import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.fasterxml.jackson.databind.ObjectWriter;
import com.fasterxml.jackson.databind.SerializationFeature;
import com.fasterxml.jackson.datatype.jsr310.JavaTimeModule;

public class Json {


    private static final Json DEFAULT_SERIALIZER;
    static {
        ObjectMapper mapper = new ObjectMapper();

        // Don't throw an exception when json has extra fields you are
        // not serializing on. This is useful when you want to use a pojo
        // for deserialization and only care about a portion of the json
        mapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false);

        // Ignore null values when writing json.
        mapper.configure(SerializationFeature.WRITE_NULL_MAP_VALUES, false);
        mapper.setSerializationInclusion(Include.NON_NULL);

        // Write times as a String instead of a Long so its human readable.
        mapper.configure(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS, false);
        mapper.registerModule(new JavaTimeModule());

       

        DEFAULT_SERIALIZER = new Json(mapper);
    }
 

    public static Json serializer() {
        return DEFAULT_SERIALIZER;
    }

    private final ObjectMapper mapper;
    private final ObjectWriter writer;
    private final ObjectWriter prettyWriter;

    // Only let this be called statically. Hide the constructor
    private Json(ObjectMapper mapper) {
        this.mapper = mapper;
        this.writer = mapper.writer();
        this.prettyWriter = mapper.writerWithDefaultPrettyPrinter();
    }

    public ObjectMapper mapper() {
        return mapper;
    }

    public ObjectWriter writer() {
        return writer;
    }

    public ObjectWriter prettyWriter() {
        return prettyWriter;
    }

    // {{start:fromBytes}}
    public <T> T fromJson(byte[] bytes, TypeReference<T> typeRef) {
        try {
            return mapper.readValue(bytes, typeRef);
        } catch (IOException e) {
            throw new JsonException(e);
        }
    }
    // {{end:fromBytes}}

    // {{start:readJson}}
    public <T> T fromJson(String json, TypeReference<T> typeRef) {
        try {
            return mapper.readValue(json, typeRef);
        } catch (IOException e) {
            throw new JsonException(e);
        }
    }
    // {{end:readJson}}

    // {{start:fromNode}}
    public <T> T fromNode(JsonNode node, TypeReference<T> typeRef) {
        try {
            return mapper.readValue(node.toString(), typeRef);
        } catch (IOException e) {
            throw new JsonException(e);
        }
    }
    // {{end:fromNode}}

    public <T> T fromObject(Object obj, TypeReference<T> typeRef) {
        try {
            return mapper.readValue(toString(obj), typeRef);
        } catch (IOException e) {
            throw new JsonException(e);
        }
    }

	public JsonParser makeParser(InputStream is) {
		try {
			return mapper.getFactory().createParser(is);
		} catch (JsonParseException e) {
			throw new JsonException(e);
		} catch (IOException e) {
            throw new JsonException(e);
        } 
	}
	
    // {{start:fromInputStream}}
    public <T> T fromInputStream(InputStream is, TypeReference<T> typeRef) {
        try {
            return mapper.readValue(is, typeRef);
        } catch (IOException e) {
            throw new JsonException(e);
        }
    }
    // {{end:fromInputStream}}

    // {{start:writeJson}}
    public String toString(Object obj) {
        try {
            return writer.writeValueAsString(obj);
        } catch (IOException e) {
            throw new JsonException(e);
        }
    }
    // {{end:writeJson}}

    // {{start:toPrettyString}}
    public String toPrettyString(Object obj) {
        try {
            return prettyWriter.writeValueAsString(obj);
        } catch (IOException e) {
            throw new JsonException(e);
        }
    }
    // {{end:toPrettyString}}

    // {{start:toByteArray}}
    public byte[] toByteArray(Object obj) {
        try {
            return prettyWriter.writeValueAsBytes(obj);
        } catch (IOException e) {
            throw new JsonException(e);
        }
    }
    // {{end:toByteArray}}

    public Map<String, Object> mapFromJson(byte[] bytes) {
        try {
            return mapper.readValue(bytes, new TypeReference<Map<String, Object>>() {
            });
        } catch (IOException e) {
            throw new JsonException(e);
        }
    }

	public Map<String, Object> mapFromJson(InputStream is) {
        try {
            return mapper.readValue(is, new TypeReference<Map<String, Object>>() {
            });
        } catch (IOException e) {
            throw new JsonException(e);
        }
    }
	

    public Map<String, Object> mapFromJson(String json) {
        try {
            return mapper.readValue(json, new TypeReference<Map<String, Object>>() {
            });
        } catch (IOException e) {
            throw new JsonException(e);
        }
    }

    // {{start:jsonNode}}
    public JsonNode nodeFromJson(String json) {
        try {
            return mapper.readTree(json);
        } catch (IOException e) {
            throw new JsonException(e);
        }
    }
    // {{end:jsonNode}}

    public JsonNode nodeFromObject(Object obj) {
        try {
            return mapper.readTree(toString(obj));
        } catch (IOException e) {
            throw new JsonException(e);
        }
    }

    public static class JsonException extends RuntimeException {
        private JsonException(Exception ex) {
            super(ex);
        }
    }
}



file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\utils\JsonAppRequestParser.java
-----------------------------------------------------
package bnhp.dctmrest.utils;

import java.io.IOException;
import java.io.InputStream;
import java.util.Iterator;
import java.util.List;

import com.fasterxml.jackson.core.JsonFactory;
import com.fasterxml.jackson.core.JsonParser;
import com.fasterxml.jackson.core.TreeNode;
import com.fasterxml.jackson.databind.ObjectMapper;

import bnhp.infra.dfs.exceptions.DFSValidationException;
import bnhp.infra.dfs.model.query.prepared.AbstractParam;
import bnhp.infra.dfs.model.query.prepared.NamedQueryParam;
import bnhp.infra.dfs.model.query.prepared.PreparedQuery;
import bnhp.infra.dfs.model.query.prepared.QueryParamList;


public class JsonAppRequestParser extends JsonPQParser {
	public static final String REQ_FIELD_REQUEST_PARAMETERS = "requestParameters";
	
	
	public void parseAppRequestParams(InputStream is)
		throws IOException, DFSValidationException {
		ObjectMapper mapper = Json.serializer().mapper();
		JsonFactory f = Json.serializer().mapper().getFactory();
		JsonParser parser = f.createParser(is);
		TreeNode t = parser.getCodec().readTree(parser);
		if (t==null) { 
			throw new DFSValidationException("parseAppRequestParams:requestParameters must be not null");
		}
		if (!t.isObject()) {
			throw new DFSValidationException("parseAppRequestParams:requestParameters must be an object");
		}
		List<NamedQueryParam> params =  Utils.list();
		this.pq = new PreparedQuery();
		for (Iterator<String> iter = t.fieldNames(); iter.hasNext();) {
			String fieldName = iter.next();
			TreeNode field = t.get(fieldName);
			if (SEARCH_FLD_EXECUTOR_DETAILS.equals(fieldName)) {
				bnhp.dctmrest.model.ExecutorDetails red =
					mapper.treeToValue(field,  bnhp.dctmrest.model.ExecutorDetails.class);
				this.ed = Rest2DFS.toDFS(red);
			} else if (REQ_FIELD_REQUEST_PARAMETERS.equals(fieldName)) {
				AbstractParam paramValue = parseSearchParam(mapper, field);
				if (paramValue instanceof QueryParamList) {
					pq.setParams(((QueryParamList)paramValue).getParams());
				} else {
					throw new DFSValidationException(REQ_FIELD_REQUEST_PARAMETERS +" value must be an object");
				}
				//NamedQueryParam param = new NamedQueryParam();
				//param.setName(fieldName);
				//param.setParamValue(parseSearchParam(mapper, field));				
				//params.add(param);
			}


		}
	}

	
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\utils\JsonPQParser.java
-----------------------------------------------------
package bnhp.dctmrest.utils;

import java.util.ArrayList;
import java.util.Iterator;
import java.util.List;

import com.fasterxml.jackson.core.JsonParser.NumberType;
import com.fasterxml.jackson.core.JsonProcessingException;
import com.fasterxml.jackson.core.TreeNode;
import com.fasterxml.jackson.databind.ObjectMapper;

import bnhp.infra.dfs.exceptions.DFSValidationException;
import bnhp.infra.dfs.model.business.ExecutorDetails;
import bnhp.infra.dfs.model.query.prepared.AbstractParam;
import bnhp.infra.dfs.model.query.prepared.MultivalueQueryParam;
import bnhp.infra.dfs.model.query.prepared.NamedQueryParam;
import bnhp.infra.dfs.model.query.prepared.PreparedQuery;
import bnhp.infra.dfs.model.query.prepared.QueryParam;
import bnhp.infra.dfs.model.query.prepared.QueryParamList;



public abstract class JsonPQParser {
	public static String SEARCH_FLD_EXECUTOR_DETAILS = "executorDetails";
	
	protected ExecutorDetails ed;
	protected PreparedQuery pq;

	public ExecutorDetails getExecutorDetails() {
		return ed;
	}
	
	public PreparedQuery getPreparedQuery() {
		return  pq;
	}

	protected List<NamedQueryParam> parseObject(ObjectMapper mapper,TreeNode t)
		throws DFSValidationException, JsonProcessingException {

		@SuppressWarnings("unchecked")
		List<NamedQueryParam> params = Utils.list();
		
		for (Iterator<String> iter = t.fieldNames(); iter.hasNext();) {
			String fieldName = iter.next();
			TreeNode field = t.get(fieldName);
			NamedQueryParam param = new NamedQueryParam();
				param.setName(fieldName);
				param.setParamValue(parseSearchParam(mapper, field));				
				params.add(param);
		}
		return params;
	}

	protected AbstractParam parseSearchParam(ObjectMapper mapper, TreeNode tn)
		throws  JsonProcessingException, DFSValidationException  {
		AbstractParam aParam = null;
		if (tn.isValueNode()) {
			aParam = parseValue(mapper, tn);
		} else if (tn.isObject()) {
			List<NamedQueryParam> list = parseObject(mapper, tn);
			final QueryParamList qpl = new QueryParamList();
			for (NamedQueryParam nqp : list) {
				qpl.addParam(nqp);
			}
			aParam = qpl;
		} else if (tn.isArray()) {
			aParam = parseArray(mapper, tn);
		}
		return aParam;
	}

	private AbstractParam parseArray(ObjectMapper mapper, TreeNode tn)
		throws JsonProcessingException, DFSValidationException  {
		MultivalueQueryParam mvqp = new MultivalueQueryParam();
		QueryParamList qpl = new QueryParamList();
		List<Object> list = new ArrayList<Object>();
		for (int i = 0; i < tn.size(); i++) {
			TreeNode itemNode = tn.get(i);
			AbstractParam value = parseSearchParam(mapper, itemNode);
			NamedQueryParam itemParam = new NamedQueryParam("Item",value);
			qpl.addParam(itemParam);
			//mvqp.
			list.add(value);
		}

		mvqp.setValues(list);

		//qpl.addParam(NamedQueryParam param)
		//return qpl;
		return mvqp;
	}



	private AbstractParam parseValue(ObjectMapper mapper, TreeNode tn)
		throws JsonProcessingException {
		QueryParam param = new QueryParam();		
		NumberType nt;
		if (null != (nt = tn.numberType())) {
			if (NumberType.BIG_INTEGER.equals(nt) ||
				NumberType.INT.equals(nt) ||
				NumberType.LONG.equals(nt)) {
				// FIXME: will LONG, BIGINT -> INT mapping work?
				Integer val = mapper.treeToValue(tn, Integer.class);
				param.setValue(val);
			} else if  (NumberType.DOUBLE.equals(nt) ||
						NumberType.FLOAT.equals(nt)) {
				mapper.treeToValue(tn, Integer.class);
				// FIXME: will Double -> Float work
				Double val = mapper.treeToValue(tn, Double.class);
				param.setValue(val);
			} else {
				// FIXME
				throw new RuntimeException("unexpected not numeric type");
			}
		} else {
			String val = mapper.treeToValue(tn, String.class);
			param.setValue(val);
		}
		// TODO Auto-generated method stub
		return param;
	}
	
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\utils\JsonSearchParser.java
-----------------------------------------------------
package bnhp.dctmrest.utils;

import com.fasterxml.jackson.core.JsonFactory;
import com.fasterxml.jackson.core.JsonParser;
import com.fasterxml.jackson.core.JsonParser.NumberType;
import com.fasterxml.jackson.core.JsonProcessingException;
import com.fasterxml.jackson.core.TreeNode;
import com.fasterxml.jackson.databind.ObjectMapper;

import bnhp.infra.dfs.model.service.DocDataForRetrieve;
import bnhp.infra.dfs.model.service.DocIdData;
import bnhp.infra.dfs.model.business.ExecutorDetails;
import bnhp.infra.dfs.model.service.DocRetrievalFlags;
import bnhp.infra.dfs.model.service.FetchTypeSet;
import bnhp.infra.dfs.model.service.File;
import bnhp.infra.dfs.model.service.Full;
import bnhp.infra.dfs.model.service.RequestDetails;
import bnhp.infra.dfs.model.service.SearchDefinition;
import bnhp.infra.dfs.model.service.SearchResult;
import bnhp.dctmrest.model.FetchType;
import bnhp.dctmrest.model.PagingDefinition;
import bnhp.infra.dfs.exceptions.DFSValidationException;
import bnhp.infra.dfs.model.query.prepared.AbstractParam;
import bnhp.infra.dfs.model.query.prepared.NamedQueryParam;
import bnhp.infra.dfs.model.query.prepared.QueryParamList;
import bnhp.infra.dfs.model.query.prepared.PreparedQuery;
import bnhp.infra.dfs.model.query.prepared.QueryParam;
import bnhp.infra.dfs.model.query.prepared.MultivalueQueryParam;


import java.io.InputStream;
import java.util.ArrayList;
import java.util.Iterator;
import java.util.List;




import java.io.IOException;



public class JsonSearchParser extends JsonPQParser {
	public static String SEARCH_FLD_SORT_DEFINITIONS = "sortDefinitions";
	public static String SEARCH_FLD_PAGING_DEFINITION = "pagingDefinition";
	public static String SEARCH_FLD_FETCH_TYPE = "fetchType";
	
	protected FetchTypeSet fts;
	protected SearchDefinition sd;

	
	public Object getSortDefinition() {
		return null;
	}
	
	public FetchTypeSet getFetchTypeSet() {
		return fts;
	}
	
	public DocRetrievalFlags getDocRetrievalFlags() {
		return null;
	}

	public SearchDefinition getSearchDefinition() {
		return sd;
	}

	public void parseSearchParams(InputStream is)
		throws IOException, DFSValidationException {
		ObjectMapper mapper = Json.serializer().mapper();
		JsonFactory f = Json.serializer().mapper().getFactory();
		JsonParser parser = f.createParser(is);
		TreeNode t = parser.getCodec().readTree(parser);
		if (! t.isObject()) {
			throw new DFSValidationException("Search parameters must be an object");
		}
		List<NamedQueryParam> params =  Utils.list();

		for (Iterator<String> iter = t.fieldNames(); iter.hasNext();) {
			String fieldName = iter.next();
			TreeNode field = t.get(fieldName);
			if (SEARCH_FLD_EXECUTOR_DETAILS.equals(fieldName)) {
				bnhp.dctmrest.model.ExecutorDetails red =
					mapper.treeToValue(field,  bnhp.dctmrest.model.ExecutorDetails.class);
				this.ed = Rest2DFS.toDFS(red);
			} else if (SEARCH_FLD_FETCH_TYPE.equals(fieldName)) {
				bnhp.dctmrest.model.FetchType rft =
					mapper.treeToValue(field,  bnhp.dctmrest.model.FetchType.class);
				this.fts = Rest2DFS.toDFS(rft);				
			} else if (SEARCH_FLD_PAGING_DEFINITION.equals(fieldName)) {
				bnhp.dctmrest.model.PagingDefinition rpd =
					mapper.treeToValue(field, bnhp.dctmrest.model.PagingDefinition.class);
				this.sd = Rest2DFS.toDFS(rpd);
			} else if (SEARCH_FLD_SORT_DEFINITIONS.equals(fieldName)) {
			} else {
				NamedQueryParam param = new NamedQueryParam();
				param.setName(fieldName);
				param.setParamValue(parseSearchParam(mapper, field));				
				params.add(param);
			}

			this.pq = new PreparedQuery();
			pq.setParams(params);
		}
	}

}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\utils\LogicalErrorDTO.java
-----------------------------------------------------
package bnhp.dctmrest.utils;

public class LogicalErrorDTO {

	int errorCode;
	String errorDetails;
	String errorType;
	
	public LogicalErrorDTO(int errorCode, String errorDetails, String errorType) {
		super();
		this.errorCode = errorCode;
		this.errorDetails = errorDetails;
		this.errorType = errorType;
	}
	public int getErrorCode() {
		return errorCode;
	}
	public void setErrorCode(int errorCode) {
		this.errorCode = errorCode;
	}
	public String getErrorDetails() {
		return errorDetails;
	}
	public void setErrorDetails(String errorDetails) {
		this.errorDetails = errorDetails;
	}
	public String getErrorType() {
		return errorType;
	}
	public void setErrorType(String errorType) {
		this.errorType = errorType;
	}
	
	
	
	
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\utils\Rest2DFS.java
-----------------------------------------------------
package bnhp.dctmrest.utils;

import java.util.List;
import java.util.Map;
import java.util.stream.Collectors;
import java.util.ArrayList;

import bnhp.infra.dfs.model.service.RequestDetails;
import bnhp.dctmrest.model.BankAccount;
import bnhp.dctmrest.model.BnhpCustomerDocData;
import bnhp.dctmrest.model.Customer;
import bnhp.dctmrest.model.DocCustomerData;
import bnhp.dctmrest.model.DocDetails;
import bnhp.dctmrest.model.DocFile;
import bnhp.dctmrest.model.DocumentData;
import bnhp.dctmrest.model.ErrorDetails;

import bnhp.dctmrest.model.ErrorDetails.ErrorTypeEnum;
import bnhp.dctmrest.model.OneOfbnhpPaperDocbnhpCorporateDocbnhpDivisionBusiness;
import bnhp.dctmrest.model.PagingDefinition;
import bnhp.dctmrest.model.PensionFund;
import bnhp.infra.dfs.exceptions.DFSValidationException;
import bnhp.infra.dfs.model.business.CustomerKey;
import bnhp.infra.dfs.model.business.DocData;
import bnhp.infra.dfs.model.business.DocPropertyExtension;
import bnhp.infra.dfs.model.business.PropertyKeyValue;
import bnhp.infra.dfs.model.business.SecondaryDocFile;
import bnhp.infra.dfs.model.business.ExecutorDetails;
import bnhp.infra.dfs.model.service.DocDataForCreate;
import bnhp.infra.dfs.model.service.SearchDefinition;
import bnhp.infra.dfs.model.service.DocDataForRetrieve;
import bnhp.infra.dfs.model.service.DocDataForUpdate;
import bnhp.infra.dfs.model.service.DocIdData;
import bnhp.infra.dfs.model.service.FetchTypeSet;
import bnhp.infra.dfs.model.service.FetchType;
import bnhp.infra.dfs.model.service.File;
import bnhp.infra.dfs.model.service.Full;
import bnhp.infra.dfs.model.service.Meta;

public class Rest2DFS {

	public static SearchDefinition toDFS(bnhp.dctmrest.model.PagingDefinition rpd) {
		if (null == rpd) {
			return null;
		}
		SearchDefinition sd  = new SearchDefinition();
		sd.setMaxResultCount(null == rpd.getMaxResultCount() ? 0 : rpd.getMaxResultCount());
		sd.setStartIndex(null == rpd.getStartIndex() ? 0 : rpd.getStartIndex());
		sd.setShouldReturnTotalResults(null == rpd.getShouldReturnTotalResults() ? false : rpd.getShouldReturnTotalResults());
		return sd;
	}
	
	public static FetchTypeSet toDFS(bnhp.dctmrest.model.FetchType rft) {
		if (null == rft) {
			return null;
		}
		FetchTypeSet fts = new FetchTypeSet();
		

		FetchType fetchType = rft.META.equals(rft) ? new Meta() :
			( rft.FULL.equals(rft) ? new Full() :
			  (rft.CONTENT.equals(rft) ? new File() : null));
		fts.setFetchType( fetchType);
		return fts;
	}
	
	public static ExecutorDetails toDFS(bnhp.dctmrest.model.ExecutorDetails red) {
		if (null == red) {
			return null;
		}
		ExecutorDetails ed =  new ExecutorDetails();
		ed.setBankolId(red.getBankolId());
		ed.setEmpIdDocumentTypeCode(null == red.getEmpIdDocumentTypeCode() ? null : red.getEmpIdDocumentTypeCode());
		ed.setExecutingBankId(red.getExecutingBankId());
		ed.setExecutingBranchId(red.getExecutingBranchId());
		//ed.setExecutingDivisionId(red.getExecuting)
		ed.setExecutingEmpFullName(red.getExecutingEmpFullName());
		ed.setExecutingEmpIdCode(red.getExecutingEmpIdCode());
		ed.setInstructionReceiveTypeCode(red.getInstructionReceiveTypeCode());
		ed.setIpAddress(red.getIpAddress());
		ed.setTerminalChannelId(red.getTerminalChannelId());
		return ed;
	}
	
	public static DocData toDFS(DocumentData rdd) throws DFSValidationException {
		if (null == rdd) {
			return null;
		}
		DocData dd = new DocData();
		dd.setDocCustomerData(toDFS(rdd.getDocCustomerData()));
		
		setDocFiles(dd, rdd.getDocFiles());
		//dd.setSecondaryDocFile(SecondaryDocFile secondaryDocFile)
		//dd.setDocPropertyExtensions(List<DocPropertyExtension> docPropertyExtensions);
		dd.setTypeName(rdd.getObjectType());
		if (null != dd.getDocCustomerData() && null != dd.getDocCustomerData().getDocDetails()) {
			dd.getDocCustomerData().getDocDetails().setObjectName(rdd.getObjectName());
		}
		dd.setDocPropertyExtensions(toDFS(rdd.getExtensions()));
		return dd;
	}

	
	// FIXME: clean the mess!
	private static void setDocFiles(DocData dd, List<DocFile> rDocFiles) throws DFSValidationException {
		for (DocFile rDocFile : rDocFiles) {
			if (null == rDocFile) {
				continue;
			}
			bnhp.infra.dfs.model.business.DocFile df = toDFS(rDocFile);
			String clsf = (null == rDocFile.getClassifier() ? null : rDocFile.getClassifier().trim());
			if (null == clsf || clsf.isEmpty()) {
				if (null == dd.getDocFile()) {
					dd.setDocFile(df);
				} else {
					throw new DFSValidationException("There is more than one primary DocFile in the array");
				}
			} else if (SecondaryDocFileSupport.SECONDARY_DOCILE_CLASSIFIER.equalsIgnoreCase(rDocFile.getClassifier().trim())) {
				if (null == dd.getSecondaryDocFile()) {
					bnhp.infra.dfs.model.business.SecondaryDocFile sdf =
						new bnhp.infra.dfs.model.business.SecondaryDocFile();
					sdf.setDocFile(df);
					dd.setSecondaryDocFile(sdf);
					Object tscObj = null;
					Map<String, Object> attrs = null;
					if ((null != (attrs = rDocFile.getAttributes())) &&
						(null != (tscObj = attrs.get(SecondaryDocFileSupport.SECONDARY_DOCILE_TEMPLATE_SOURCE_CODE_ATTR)))) {
						if (tscObj instanceof String) {
							try {
								Integer tsc = Integer.parseInt(((String)tscObj).trim());
								sdf.setTemplateSourceCode(tsc);
							} catch (NumberFormatException nex) {
								throw new DFSValidationException("Invalid  value for DocFile attribute " +
																 SecondaryDocFileSupport.SECONDARY_DOCILE_TEMPLATE_SOURCE_CODE_ATTR +": "+tscObj);
							}
						} else if (tscObj instanceof Number) {
							sdf.setTemplateSourceCode(((Number)tscObj).intValue());
						} else {
							throw new DFSValidationException("Invalid  value for DocFile attribute " +
															 SecondaryDocFileSupport.SECONDARY_DOCILE_TEMPLATE_SOURCE_CODE_ATTR +": "+tscObj);		
						}
					}
				} else {
					throw new DFSValidationException("There is more than one secondary DocFile in the array");
				}
				
			} else {
				throw new DFSValidationException("Unsupported content classifier: '" + clsf + "'");
			}
			
		}
	}

	private static bnhp.infra.dfs.model.business.DocFile toDFS(DocFile rDocFile) {
		if (null == rDocFile) {
			return null;
		}
		bnhp.infra.dfs.model.business.DocFile df = new bnhp.infra.dfs.model.business.DocFile();
		df.setMimeType(rDocFile.getMimeType());
		df.setDosExtension(rDocFile.getDosExtension());
		df.setDocFormat(rDocFile.getDocFormat());
		df.setDocStream(rDocFile.getDocStream());
		df.setDocURL(rDocFile.getDocURL());
		df.setDocSize(rDocFile.getDocSize());
		df.setCheckSum(rDocFile.getCheckSum());
		return df;
	}

	private static bnhp.infra.dfs.model.business.DocCustomerData toDFS(DocCustomerData rdcd) {
		if (null == rdcd) {
			return null;
		}
		bnhp.infra.dfs.model.business.DocCustomerData dcd =
			new bnhp.infra.dfs.model.business.DocCustomerData();

		if (null != rdcd.getBankAccounts()) {
		 	dcd.setBankAccounts(rdcd.getBankAccounts().stream()
								.map(acc -> toDFS(acc))
		 						.collect(Collectors.toList()));
		}

		if (null != rdcd.getCustomers()) {
		 	dcd.setCustomerKeys(rdcd.getCustomers().stream()
							 .map(cust -> toDFS(cust))
							 .collect(Collectors.toList()));
		}
		dcd.setPensionFund(toDFS(rdcd.getPensionFund()));

		dcd.setDocDetails(toDFS(rdcd.getDocDetails()));
		
		return dcd;
	}

	private static bnhp.infra.dfs.model.business.PensionFund toDFS(PensionFund rpf) {
		if (null == rpf) {
			return null;
		}
		bnhp.infra.dfs.model.business.PensionFund pf =
			new bnhp.infra.dfs.model.business.PensionFund();
		pf.setPensionFundNbr(rpf.getPensionFundNbr());
		pf.setPlanholderNumber(rpf.getPlanholderNumber());
		return pf;
	}

	
	public static bnhp.infra.dfs.model.business.CustomerKey toDFS(Customer rc) {
		if (null == rc) {
			return null;
		}
		bnhp.infra.dfs.model.business.CustomerKey c =
			new bnhp.infra.dfs.model.business.CustomerKey();
		c.setOccasionalCustomerInd(rc.getOccasionalCustomerInd());
		c.setCustomerSerialNbr(rc.getCustomerSerialNbr());
		c.setCustomerIdDocTypeCode(null == rc.getCustomerIdDocTypeCode() ?
								   null :
								   rc.getCustomerIdDocTypeCode());

		c.setCustomerId(rc.getCustomerId());
		c.setCustomerFullName(rc.getCustomerFullName());
		c.setCompleteCustomerIdCode(rc.getCompleteCustomerIdCode());
		return c;
	}


	private static bnhp.infra.dfs.model.business.DocDetails  toDFS(DocDetails rdd) {
		if (null == rdd) {
			return null;
		}
		bnhp.infra.dfs.model.business.DocDetails dd =
			new bnhp.infra.dfs.model.business.DocDetails();
		dd.setTransactionAmt(rdd.getTransactionAmt());
		dd.setTemplateDataExistsInd(rdd.getTemplateDataExistsInd());
		dd.setSystemCode(rdd.getSystemCode());
		dd.setSignatureStatusCode(rdd.getSignatureStatusCode());
		dd.setScanStatusCode(rdd.getScanStatusCode());
		dd.setProjectId(rdd.getProjectId());
		dd.setOngoingOrHistoryCode(rdd.getOngoingOrHistoryCode());
		//dd.setObjectName(dd.getObjectName());
		dd.setLegacyDocumentId(rdd.getLegacyDocumentId());
		dd.setLegacyDocumentEntryDttm(rdd.getLegacyDocumentEntryDttm());
		dd.setDocumentGroupIds(rdd.getDocumentGroupIds());
		dd.setDocumentFormId(rdd.getDocumentFormId());
		dd.setDocumentEditionNbr(rdd.getDocumentEditionNbr());
		dd.setDocDeliveryNum(rdd.getDocDeliveryNum());
		dd.setDocCompletenessCode(rdd.getDocCompletenessCode());
		dd.setCurrencyCode(rdd.getCurrencyCode());
		dd.setChannelId(rdd.getChannelId());
		dd.setBusinessSubAreaCode(rdd.getBusinessSubAreaCode());
		dd.setBusinessProcessId(rdd.getBusinessProcessId());
		dd.setBusinessAreaCode(rdd.getBusinessAreaCode());
		dd.setConcatenatedEventIds(rdd.getConcatenatedEventIds());
		return dd;
	}

	
	public static bnhp.infra.dfs.model.business.BankAccount toDFS(BankAccount rba) {
		if (null == rba) {
			return null;
		}
		bnhp.infra.dfs.model.business.BankAccount ba =
			new bnhp.infra.dfs.model.business.BankAccount();
		ba.setSpecialHandlingCode(rba.getSpecialHandlingCode());
		ba.setDivisionId(rba.getDivisionId());
		ba.setBranchId(rba.getBranchId());
		ba.setAccountType(rba.getAccountType());
		ba.setAccountNbr(rba.getAccountNbr());
		ba.setAccountBankId(rba.getAccountBankId());
		return ba;
	}

	public static List<DocDataForCreate> makeDocDataForCreateList(DocumentData rdd) throws DFSValidationException {
		List<DocDataForCreate> ddfcl = new ArrayList<DocDataForCreate>();
		DocDataForCreate ddfc = new DocDataForCreate();
		ddfcl.add(ddfc);
		ddfc.setDocData(toDFS(rdd));
		return ddfcl;
	}

	public static DocDataForUpdate makeDocDataForUpdate(DocumentData rdd, String id, boolean isLegacyId)
		throws DFSValidationException {

		
		DocDataForUpdate ddfu = new DocDataForUpdate();
		ddfu.setDocData(toDFS(rdd));
		DocData dd = toDFS(rdd);
		if (isLegacyId) {
			ddfu.setLegacyDocumentId(id);
		} else {
			ddfu.setDctmDocumentId(id);
		}
		return ddfu;
	}


	public static List<DocPropertyExtension>
		toDFS(List<OneOfbnhpPaperDocbnhpCorporateDocbnhpDivisionBusiness> exts) {
		return null == exts ? null : exts.stream().
				map(ext -> toDFS(ext)).collect(Collectors.toList());
	}

	private static DocPropertyExtension toDFS(OneOfbnhpPaperDocbnhpCorporateDocbnhpDivisionBusiness rext) {
		if (null == rext) {
			return null;
		}
		DocPropertyExtension  ext = new DocPropertyExtension();
		ext.setExtensionName(rext.getName());
		if (null != rext.getProperties()) {
			final List<PropertyKeyValue> pkvs = new ArrayList<PropertyKeyValue>(16);
			ext.setPropertyKeyValues(pkvs);
			rext.getProperties().forEach( (key,value) -> {
					final PropertyKeyValue pkv = new PropertyKeyValue();
					pkv.setKey(key);
					pkv.setValue(null == value ?  null : value.toString());
					pkvs.add(pkv);
				});
		}
		return ext;
	}


}







file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\utils\Rest2GeneralDocUtil.java
-----------------------------------------------------
package bnhp.dctmrest.utils;

import bnhp.dctmrest.model.DocFile;
import bnhp.dctmrest.model.DocumentData;
import bnhp.infra.dfs.exceptions.DFSValidationException;

import bnhp.infra.ecm.model.DocGeneralData;
import bnhp.infra.ecm.model.DocIdData;

public class Rest2GeneralDocUtil {

	public static DocGeneralData documentDataToDocGeneralData(DocumentData documentData) throws DFSValidationException
	{
		if (null == documentData)
		{
			return null;
		}

		DocGeneralData docGeneralData = new DocGeneralData();

		bnhp.infra.ecm.model.DocFile docFile = new bnhp.infra.ecm.model.DocFile();
		DocFile docFileSource = documentData.getDocFiles().get(0);
		docFile.setCheckSum(docFileSource.getCheckSum());
		docFile.setDocStream(docFileSource.getDocStream());
		docFile.setDocFormat(docFileSource.getDocFormat());
		docFile.setMimeType(docFileSource.getMimeType());
		docFile.setDosExtension(docFileSource.getDosExtension());
		docFile.setDocURL(docFileSource.getDocURL());
		docFile.setDocSize(docFileSource.getDocSize());
		docGeneralData.setDocFile(docFile);

		bnhp.infra.ecm.model.DocDetails docDetails = new bnhp.infra.ecm.model.DocDetails();
		docDetails.setLegacyDocumentId(documentData.getLegacyDocumentId());
		docDetails.setLegacyDocumentEntryDttm(documentData.getDocCustomerData().getDocDetails().getLegacyDocumentEntryDttm());
		docDetails.setDocumentFormId(documentData.getDocCustomerData().getDocDetails().getDocumentFormId());
		docDetails.setSystemCode(documentData.getDocCustomerData().getDocDetails().getSystemCode());



		docDetails.setObjectName(documentData.getObjectName());
		docGeneralData.setDocDetails(docDetails);

		return docGeneralData;
	}

	public static bnhp.dctmrest.model.DocIdData toRest(DocIdData src)
	{
		bnhp.dctmrest.model.DocIdData result = new bnhp.dctmrest.model.DocIdData();
		result.setDctmDocumentId(src.getDctmDocumentId());
		result.setVersionNumber(src.getVersionLabel());
		result.getVersionLabels().add(src.getVersionLabel());

		return result;
	}

}







file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\utils\SecondaryDocFileSupport.java
-----------------------------------------------------
package bnhp.dctmrest.utils;


public class SecondaryDocFileSupport {
	public static final String SECONDARY_DOCILE_CLASSIFIER = "secondary";
	public static final String SECONDARY_DOCILE_TEMPLATE_SOURCE_CODE_ATTR = "templateSourceCode";
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\utils\ServiceUtils.java
-----------------------------------------------------

package bnhp.dctmrest.utils;

import java.util.ArrayList;
import java.util.List;
import java.util.UUID;

import javax.xml.ws.Holder;

import bnhp.infra.dfs.exceptions.DFSDocumentumException;
import bnhp.infra.dfs.exceptions.DFSValidationException;
import bnhp.infra.dfs.model.business.SecurityContext;
import bnhp.infra.dfs.model.service.RequestDetails;
//import bnhp.infra.dfs.services.exceptions.ECMValidationException;
import bnhp.infra.dfs.utils.basic.BnhpAudit;
import bnhp.infra.dfs.utils.basic.IsDataEmptyUtils;
import bnhp.infra.dfs.utils.basic.properties.PropertyLoader;

import com.documentum.fc.common.DfException;
import com.documentum.fc.impl.util.StringUtil;
import com.emc.documentum.fs.datamodel.core.content.ContentTransferMode;
import com.emc.documentum.fs.datamodel.core.context.RepositoryIdentity;
import com.emc.documentum.fs.datamodel.core.profiles.ContentTransferProfile;
import com.emc.documentum.fs.datamodel.core.profiles.SchemaProfile;
import com.emc.documentum.fs.rt.context.ContextFactory;
import com.emc.documentum.fs.rt.context.IServiceContext;

public final class ServiceUtils {
	private final static String DEFAULT_DOCBASE_PROP = "default_docbase";
	private final static String DOCBASE_OVERRIDE_PROP = "docbase_override";
	private final static String USER_OVERRIDE_PROP = "user_override";
	private final static String DEFAULT_USER_PROP = "default_user_name";
	private final static String DEFAULT_PASS_PROP = "default_user_pass";

	private ServiceUtils() {
	}

	public static SecurityContext applyDefaults(SecurityContext pContext)
			throws DFSValidationException, DFSDocumentumException {
		PropertyLoader loader = PropertyLoader.getInstance();

		if (loader.hasProperty(USER_OVERRIDE_PROP)
				&& loader.getBoolean(DOCBASE_OVERRIDE_PROP)) {
			if (null == pContext) {
				pContext = new SecurityContext();
			}
			pContext.setUserName(loader.getProperty(DEFAULT_USER_PROP));
			String encPass = loader.getProperty(DEFAULT_PASS_PROP);
			String pass = null;
			;
			try {
				pass = com.documentum.fc.tools.RegistryPasswordUtils
						.decrypt(encPass);
			} catch (DfException e) {
				throw new DFSDocumentumException(
						"failed to decrypt default user password", e);
			}
			pContext.setPassword(pass);
		}
		if (pContext == null) {
			// FIXME: after the PoalimFault is out, change this to throw the
			// fault with the code
			throw new DFSValidationException("SecurityContext must exist");
		}

		boolean docbaseOverride = loader.getBoolean(DOCBASE_OVERRIDE_PROP);
		if (docbaseOverride
				|| IsDataEmptyUtils.isEmptyOrNull(pContext.getRepositoryName())) {
			String defaultDocbase = loader.getProperty(DEFAULT_DOCBASE_PROP);
			if (!IsDataEmptyUtils.isEmptyOrNull(defaultDocbase)) {
				pContext.setRepositoryName(defaultDocbase);
			} else if (docbaseOverride) {
				throw new DFSDocumentumException(
						"Cannot assign default docbase: default_docbase is not set in the app. configuration");
			}
		}

		return pContext;
	}

	/**
	 * @param securityContext
	 * @return
	 * @throws ECMValidationException
	 */
	private static RepositoryIdentity createRepIdentity(
			SecurityContext securityContext)  {
		RepositoryIdentity repIdentity = new RepositoryIdentity();
		if (securityContext == null) {
			// FIXME: after the PoalimFault is out, change this to throw the
			// fault with the code
			throw new RuntimeException("SecurityContext must exist");
		}
		repIdentity.setUserName(securityContext.getUserName());
		repIdentity.setPassword(securityContext.getPassword());
		repIdentity.setRepositoryName(securityContext.getRepositoryName());

		return repIdentity;
	}

	public static IServiceContext createTransactionalServiceContext(
			SecurityContext securityContext)  {
		IServiceContext context = createServiceContext(securityContext);
		context.setRuntimeProperty(IServiceContext.USER_TRANSACTION_HINT,
				IServiceContext.TRANSACTION_REQUIRED);
		return context;
	}

	/**
	 * @param securityContext
	 * @return
	 * @throws ECMValidationException
	 */
	public static IServiceContext createServiceContext(
			SecurityContext securityContext)  {
		RepositoryIdentity repIdentity = ServiceUtils
				.createRepIdentity(securityContext);
		IServiceContext serviceContext = ContextFactory.getInstance()
				.newContext();
		ContentTransferProfile transferProfile = new ContentTransferProfile();
		transferProfile.setTransferMode(ContentTransferMode.MTOM);
		serviceContext.setProfile(transferProfile);
		SchemaProfile schemaProfile = new SchemaProfile(
				StringUtil.EMPTY_STRING, true, true, true);
		serviceContext.setProfile(schemaProfile);
		serviceContext.addIdentity(repIdentity);
		return serviceContext;
	}

	public static RequestDetails buildRequestDetails(
			String requestId, String status, String auditedObjId, Holder<List<RequestDetails>> requestDetails) {
		RequestDetails details = null;
		if ((requestId != null) && (requestId.length() > 0)) {
			details = new RequestDetails();
			details.setRequestId(requestId);
			details.setRequestStatus(status);
			// if real auditing was not performed, return dummy id
			if (auditedObjId == null) {
				auditedObjId = UUID.randomUUID().toString().substring(0, 18)
						.replace("-", "");
			}
			details.setRequestObjectId(auditedObjId);
			requestDetails.value = new ArrayList<RequestDetails>(1);
			requestDetails.value.add(details);
		}
		return details;
	}

	public static void setRequestStatus(String requestId, boolean success,
			Holder<List<RequestDetails>> requestDetails) {
		if (requestId != null && requestId.trim().length() > 0) {
			String requestStatus = success == true ? BnhpAudit.STATUS_SUCCESS
					: BnhpAudit.STATUS_FAILED;
			requestDetails.value.get(0).setRequestStatus(requestStatus);
		}
	}
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\utils\UrlContentProviderUtil.java
-----------------------------------------------------
package bnhp.dctmrest.utils;

import bnhp.infra.dfs.exceptions.utils.ErrorInfoConstants;
import bnhp.infra.dfs.model.business.SecurityContext;
import bnhp.infra.dfs.utils.basic.ServiceUtils;
import bnhp.infra.dfs.utils.business.BusinessQueryUtils;
import bnhp.infra.dfs.utils.content.*;
import bnhp.infra.dfs.utils.dfc.DfcUtils;
import bnhp.infra.dfs.utils.dfc.ServerMethodUtils;
import bnhp.infra.dfs.utils.service.DfsRequestThreadAttributes;
import com.documentum.fc.client.*;
import com.documentum.fc.client.acs.IDfAcsRequest;
import com.documentum.fc.client.acs.IDfAcsTransferPreferences;
import com.documentum.fc.client.acs.impl.DfAcsTransferPreferences;
import com.documentum.fc.common.DfException;
import com.emc.documentum.fs.datamodel.core.ObjectIdentity;
import com.emc.documentum.fs.datamodel.core.content.RenditionType;
import com.emc.documentum.fs.datamodel.core.content.UrlContent;
import com.emc.documentum.fs.rt.ServiceException;
import com.emc.documentum.fs.rt.context.IServiceContext;
import com.emc.documentum.fs.services.core.client.IObjectService;

import java.util.ArrayList;
import java.util.Collections;
import java.util.List;
import java.util.regex.Pattern;

public class UrlContentProviderUtil
{
    public static final String REQUEST_ID_PARAMETER = "dctmRequestId";

    private SecurityContext m_dfsSecurityContext = null;
    private IServiceContext m_serviceContext = null;
    private Pattern m_uriFilter = null;
    private int m_unduplicateRetries = 0;
    private final String m_serviceName = "UrlContentProviderUtil";
    private boolean m_addRequestIdToURL = false;

    public boolean isAddRequestIdToURL() {
        return m_addRequestIdToURL;
    }
    public void setAddRequestIdToURL(boolean addRequestIdToURL) {
        this.m_addRequestIdToURL = addRequestIdToURL;
    }

    private SecurityContext GetDfsSecurityContent()
    {
        //ToDo create instance if null
        return m_dfsSecurityContext;
    }

    private IServiceContext GetServiceContext()
    {
        //ToDo - handle null scenario
        return m_serviceContext;
    }

    public void setUnduplicateRetries(int value)
    {
        m_unduplicateRetries = value;
    }

    public int getUnduplicateRetries()
    {
        return m_unduplicateRetries;
    }

    public Pattern getUriFilter()
    {
        return m_uriFilter;
    }

    public void setUriFilter(Pattern uriFilter)
    {
        this.m_uriFilter = uriFilter;
    }

    public boolean isUnduplicateEnabled()
    {
        return m_unduplicateRetries > 0;
    }

    public UrlContentProviderUtil(SecurityContext pSec, IServiceContext pServiceContext)
    {
        m_dfsSecurityContext = pSec;
        m_serviceContext = pServiceContext;
    }

    public UrlContentProviderUtil(bnhp.infra.ecm.model.SecurityContext pSec,IServiceContext pServiceContext)
    {
        m_dfsSecurityContext = new SecurityContext();
        m_dfsSecurityContext.setRepositoryName(pSec.getRepositoryName());
        m_dfsSecurityContext.setUserName(pSec.getUserName());
        m_dfsSecurityContext.setPassword(pSec.getPassword());

        m_serviceContext = pServiceContext;
    }

    public ObjectIdentity<?> GetObjIdentityByDctm(String pDctmId) throws ServiceException
    {
        ObjectIdentity<?> objId = BusinessQueryUtils
                .getObjectId4DctmDocumentId(pDctmId,
                        "bnhp_general_doc",
                        GetDfsSecurityContent().getRepositoryName());
        return objId;
    }

    public UrlContent GetUrl(ObjectIdentity pObjectId, String pRequestedFormat) throws ServiceException, DfException, ContentURIProviderException
    {
        IObjectService svc = ServiceUtils.getService(IObjectService.class,GetServiceContext());
        String repo = GetDfsSecurityContent().getRepositoryName();
        IDfSessionManager sessionManager = DfcUtils.getSessionManager(repo);
        IDfSession session =sessionManager.getSession(repo);

        IDfSysObject sysObj = (IDfSysObject)DfcUtils.getObjectByIdentity(pObjectId,session);

        if (null == pRequestedFormat)
        {
            pRequestedFormat = sysObj.getFormat().getName();
        }

        UrlContent result = null;
        int retries = getUnduplicateRetries();

        do {
            // now we know that object has content, so if we
            // cannot get it here, it's an exception
            List <UrlContent> requestsList = getURLRequests(sysObj, session, pRequestedFormat);
            if (requestsList.isEmpty()) {
                break;
            }

            // select random URI from list to balance load on ACS servers
            if (requestsList.size()>1)
            {
                Collections.shuffle(requestsList);
            }
            // positive retries means as well that unduplicate is enabled
            if (isUnduplicateEnabled())
            {
                for (int index = 0; result == null &&  index < requestsList.size(); index++) {
                    result =  ACSURLUnduplicator.unduplicate(requestsList.get(index));
                }
                if (null == result) {
                    waitForNextSecond();
                }
                retries --;
            } else {
                result = requestsList.get(0);
            }
            //
        } while (null == result && isUnduplicateEnabled() && retries >= 0);

        if (null == result || null == result.getUrl())
        {
            throw new ContentURIProviderException(ErrorInfoConstants.ACS_URIPROVIDER_FAILURE,
                m_serviceName + ": getURI: failed to get URI for object that has content: "+ pObjectId);
    }
        if (null != result && isAddRequestIdToURL()) {
            addRequestId(result);
        }
        return result;
    }

    public UrlContent GetUrl(String pDctmId, String pRequestedFormat) throws ServiceException, DfException, ContentURIProviderException {
        return GetUrl(GetObjIdentityByDctm(pDctmId), pRequestedFormat);
    }

    private void waitForNextSecond() {
        final long cTime = System.currentTimeMillis();
        try {
            final long sleepTimeMS = 1000 - (cTime % 1000L) ;

            DfsRequestThreadAttributes.dfsLogger.get().warn(
                    m_serviceName,"Deduplication sleep: sleepTime= "+sleepTimeMS + " ms");
            Thread.sleep(sleepTimeMS);

        } catch (InterruptedException iex) {
            Thread.currentThread().interrupt();
        }
    }

    private void addRequestId(UrlContent urlContent) {
        if (null != urlContent && null != urlContent.getUrl()) {
            String requestId = DfsRequestThreadAttributes.dctmRequestId.get();
            if (null!=requestId) {
                StringBuilder buf = new StringBuilder(urlContent.getUrl());
                buf.append("&").append(REQUEST_ID_PARAMETER).append("=");
                buf.append(ServerMethodUtils.encodeArg(requestId));
                urlContent.setUrl(buf.toString());
            }

        }
    }
    private List <UrlContent> getURLRequests(IDfSysObject pObj,
                                             IDfSession pSession, String pFormat) throws DfException
    {
        List <UrlContent> requestsList= new ArrayList<UrlContent>(10);
        IDfAcsTransferPreferences prefs = pSession.getAcsTransferPreferences();
        if (null == prefs) {
            prefs = new DfAcsTransferPreferences();
        }
        prefs.preferAcsTransfer(true);

        IDfEnumeration requestsEnumeration = pObj.getAcsRequests(pFormat,
                0 /*page number always 0*/,
                null /*no page modifiers*/,
                prefs /* default IDfAcsTransferPreferences */);

        int contentUnacceptable = 0;
        while (requestsEnumeration.hasMoreElements())
        {
            IDfAcsRequest request = (IDfAcsRequest)requestsEnumeration.nextElement();
            UrlContent urlContent = makeUrlContent(request,pFormat);
            if (this.isURIContentOk(urlContent)) {
                requestsList.add(urlContent);
            } else {
                contentUnacceptable++;
            }
        }

        if (requestsList.isEmpty())
        {
            //TODO: handle this exception
        }

        return requestsList;
    }

    protected UrlContent makeUrlContent(IDfAcsRequest request, String format)
    {
        UrlContent urlContent = new UrlContent();
        urlContent.setFormat(format);
        urlContent.setUrl(request.makeURL());
        urlContent.setRenditionType(RenditionType.PRIMARY);
        urlContent.setPageNumber(0);
        return urlContent;
    }

    public boolean isURIContentOk(UrlContent content) {
        if (null == content || null == content.getUrl()) {
            return false;
        }
        if (null == getUriFilter()) {
            return true;
        }
        boolean result =  getUriFilter().matcher(content.getUrl()).matches();
        return result;
    }
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\main\java\bnhp\dctmrest\utils\Utils.java
-----------------------------------------------------
package bnhp.dctmrest.utils;

import bnhp.dctmrest.model.ExecutorDetails;
import bnhp.infra.com.utils.service.BnhpRequestThreadAttributes;
import bnhp.infra.dfs.init.ApplicationInitializer;
import bnhp.infra.dfs.model.business.BankAccount;
import bnhp.infra.dfs.model.business.CustomerKey;
import bnhp.infra.dfs.model.business.DocData;
import bnhp.infra.dfs.utils.basic.properties.PropertyLoader;
import org.cfg4j.provider.GenericType;
import org.cfg4j.provider.GenericTypeInterface;

import io.undertow.server.HttpHandler;
import io.undertow.server.HttpServerExchange;
import io.undertow.util.Headers;
import io.undertow.util.Methods;
import io.undertow.Handlers;

import java.lang.invoke.ConstantCallSite;
import java.util.Deque;
import java.util.Arrays;
import java.util.Map;
import java.util.List;
import java.io.UnsupportedEncodingException;
import java.net.InetAddress;
import java.net.UnknownHostException;
import java.sql.Date;
import java.text.SimpleDateFormat;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.Optional;
import java.util.logging.Logger;
import java.util.stream.Collectors;

import org.cfg4j.provider.ConfigurationProvider;

import bnhp.dctmrest.ConfigurationSubtreeProvider;
import bnhp.dctmrest.requests.ISvcRequest;
import bnhp.infra.dfs.exceptions.DFSValidationException;
import bnhp.infra.dfs.utils.basic.LoggingUtils;
import bnhp.infra.dfs.utils.service.DfsRequestThreadAttributes;
import bnhp.infra.dfs.utils.service.NumericVersionSpec;
import org.json.JSONObject;
import org.python.antlr.ast.Str;

public class Utils {
	// FIXME: not here? instanceid from config?
	private static String hostid = "NOHOSTID";

	static {
		try {
			hostid = InetAddress.getLocalHost().getHostName() + ":";
		} catch (UnknownHostException unex) {
			System.out.println("Failed to init host id: " + unex.getMessage());
		}
	}

	public static String getHostId() {
		return hostid;
	}


	public  static Integer getQueryParamAsInteger(final ISvcRequest r,final  String name) {
		String val;
		return null != (val = r.getQueryParam(name)) ? Integer.parseInt(val) : null;
	}
	public static Long getQueryParamAsLong(final ISvcRequest r,final  String name) {
		String val;
		return null != (val = r.getQueryParam(name)) ? Long.parseLong(val) : null;
	}
	public static  String getQueryParamAsTrimmedString(final ISvcRequest r,final  String name) {
		String val;
		return null != (val = r.getQueryParam(name)) ? val.trim() : null;
	}


	public static Boolean getQueryParamAsBoolean(HttpServerExchange exch, String name, Boolean defVal) {
		final String resultStr = getQueryParam(exch, name, null == defVal ? null : defVal.toString());
		return null == resultStr ? null : Boolean.parseBoolean(resultStr);
	}

	public static Object getJsonSimpleObject(JSONObject pObj, String pParameterName, String pBaseObjectName, boolean pIsNumber, boolean pIsMustFound) throws DFSValidationException {
		try {
			if (pIsNumber) {
				return pObj.getInt(pParameterName);
			} else {
				return pObj.getString(pParameterName);
			}
		} catch (NumberFormatException ex) {
			String errorMessage = String.format(CommonConstants.ERROR_GET_REQUEST_INNER_PARSE_FORMAT_EXCEPTION,
					pBaseObjectName + "." + pParameterName, pIsNumber ? "number.." : "string..");

			BnhpRequestThreadAttributes.errLogger.get().error(pBaseObjectName, errorMessage, ex);

			throw new DFSValidationException(errorMessage, ex);
		} catch (org.json.JSONException ex) {

			if (pIsMustFound) {
				String errorMessage = String.format(CommonConstants.ERROR_GET_REQUEST_INNER_PARAMETER_MISSING,
						pBaseObjectName, pParameterName);

				BnhpRequestThreadAttributes.errLogger.get().error(pBaseObjectName, errorMessage, ex);

				throw new DFSValidationException(errorMessage, ex);
			} else {
				return null;
			}
		}
	}

	public static bnhp.infra.dfs.model.business.ExecutorDetails getExecutorDetails(String pExeDetailsAsJson) throws DFSValidationException {
		bnhp.infra.dfs.model.business.ExecutorDetails exDet = new bnhp.infra.dfs.model.business.ExecutorDetails();

		if (pExeDetailsAsJson != null) {
			JSONObject obj = new JSONObject(pExeDetailsAsJson);

			exDet.setBankolId((Integer) getJsonSimpleObject(obj, CommonConstants.EXECUTION_DETAILS_PARAMETERS_BANCOL_ID, CommonConstants.EXECUTION_DETAILS, true, true));
			exDet.setEmpIdDocumentTypeCode((Integer) getJsonSimpleObject(obj, CommonConstants.EXECUTION_DETAILS_PARAMETERS_EMPL_DOC_TYPE_CODE, CommonConstants.EXECUTION_DETAILS, true, true));
			exDet.setExecutingBankId((Integer) getJsonSimpleObject(obj, CommonConstants.EXECUTION_DETAILS_PARAMETERS_EXE_BANK_ID, CommonConstants.EXECUTION_DETAILS, true, true));
			exDet.setExecutingBranchId((Integer) getJsonSimpleObject(obj, CommonConstants.EXECUTION_DETAILS_PARAMETERS_EXE_BRANCH_ID, CommonConstants.EXECUTION_DETAILS, true, true));
			exDet.setExecutingEmpFullName((String) getJsonSimpleObject(obj, CommonConstants.EXECUTION_DETAILS_PARAMETERS_EXE_EMPL_FULL_NAME, CommonConstants.EXECUTION_DETAILS, false, true));
			exDet.setExecutingEmpIdCode((String) getJsonSimpleObject(obj, CommonConstants.EXECUTION_DETAILS_PARAMETERS_EXE_EMPL_ID_CODE, CommonConstants.EXECUTION_DETAILS, false, true));
			exDet.setInstructionReceiveTypeCode((Integer) getJsonSimpleObject(obj, CommonConstants.EXECUTION_DETAILS_PARAMETERS_INST_RECEIVE_TYPE_CODE, CommonConstants.EXECUTION_DETAILS, true, true));
			exDet.setIpAddress((String) getJsonSimpleObject(obj, CommonConstants.EXECUTION_DETAILS_PARAMETERS_IP_ADDRESS, CommonConstants.EXECUTION_DETAILS, false, true));
			exDet.setTerminalChannelId((Integer) getJsonSimpleObject(obj, CommonConstants.EXECUTION_DETAILS_PARAMETERS_TERMINAL_CHANEEL_ID_CODE, CommonConstants.EXECUTION_DETAILS, true, true));
		} else {
			throw new DFSValidationException(String.format(CommonConstants.ERROR_PARAMETER_NOT_EXIST, CommonConstants.EXECUTION_DETAILS));
		}

		return exDet;
	}

	public static Boolean getQueryParamAsBoolean(ISvcRequest req, String name, Boolean defVal) {
		final String resultStr = req.getQueryParam(name, null == defVal ? null : defVal.toString());
		return null == resultStr ? null : Boolean.parseBoolean(resultStr);
	}


	public static Boolean asBoolean(String value) {
		if (null != value) {
			return Boolean.parseBoolean(value);
		} else {
			return false;
		}
	}

	public static byte[] toByteArray(Object obj) {
		return Json.serializer().toByteArray(obj);
	}

	public static void setContentType(HttpServerExchange exch, String contentType) {
		exch.getResponseHeaders().put(Headers.CONTENT_TYPE, contentType);
	}


	public static Map makeMap(Object... objs) {
		final Map map = new HashMap(objs.length << 1);
		for (int i = 0; i < objs.length; i += 2) {
			map.put(objs[i], objs[i + 1]);
		}
		return map;
	}

	public static List list(Object... objs) {
		List list = new ArrayList(objs.length);
		list.addAll(Arrays.asList(objs));
		return list;

	}

	public static void setUp() {
		BnhpRequestThreadAttributes.safVersion.set(new bnhp.infra.com.utils.service.NumericVersionSpec("5.0"));
		BnhpRequestThreadAttributes.generateDctmRequestId();

		if (BnhpRequestThreadAttributes.logger.get() == null) {
			BnhpRequestThreadAttributes.logger.set(new bnhp.infra.com.utils.basic.LoggingUtils("wrapper_logger_id"));
		}

		if (BnhpRequestThreadAttributes.bsLogger.get() == null) {
			BnhpRequestThreadAttributes.bsLogger.set(new bnhp.infra.com.utils.basic.LoggingUtils("business_logger_id"));
		}

		if (BnhpRequestThreadAttributes.errLogger.get() == null) {
			BnhpRequestThreadAttributes.errLogger.set(new bnhp.infra.com.utils.basic.LoggingUtils("err_logger_id"));
		}

		if (BnhpRequestThreadAttributes.opLogger.get() == null) {
			BnhpRequestThreadAttributes.opLogger.set(new bnhp.infra.com.utils.basic.LoggingUtils("operator_logger_id"));
		}

		//TemplateBasedQuery.staticInit();
	}

	public static void dfsThreadInit() {
		setUp();
		DfsRequestThreadAttributes.safVersion.set(new NumericVersionSpec("5.0"));
		DfsRequestThreadAttributes.generateDctmRequestId();

		if (DfsRequestThreadAttributes.dfsLogger.get() == null) {
			DfsRequestThreadAttributes.dfsLogger.set(new LoggingUtils(
					"dfs_logger_id"));
		}
		if (DfsRequestThreadAttributes.logger.get() == null) {
			DfsRequestThreadAttributes.logger.set(new LoggingUtils(
					"wrapper_logger_id"));
		}
		if (DfsRequestThreadAttributes.bsLogger.get() == null) {
			DfsRequestThreadAttributes.bsLogger.set(new LoggingUtils(
					"business_logger_id"));
		}
		if (DfsRequestThreadAttributes.errLogger.get() == null) {
			DfsRequestThreadAttributes.errLogger.set(new LoggingUtils(
					"err_logger_id"));
		}
		if (DfsRequestThreadAttributes.opLogger.get() == null) {
			DfsRequestThreadAttributes.opLogger.set(new LoggingUtils(
					"operator_logger_id"));
		}
	}

	public static boolean ValidateConfigParamsExisted(String[] pValuesToCheck)
	{
		String currentVal = null;
		try
		{
			PropertyLoader loader = PropertyLoader.getInstance();

			for(int n = 0; n < pValuesToCheck.length; ++ n)
			{
				currentVal = pValuesToCheck[n];
				loader.getProperty(currentVal);
			}

			return true;
		}
		catch (Exception ex)
		{
			BnhpRequestThreadAttributes.errLogger.get().error("Validate config params",String.format("Element '%s' is missing in the config file",currentVal),ex);

			return false;
		}
	}


	public static String getQueryParam(HttpServerExchange exch, String name, String defStr) {
		return Optional.ofNullable(exch.getQueryParameters().get(name))
			.map(Deque::getFirst).orElse(defStr);
	}

	public static String getHeaderParam(HttpServerExchange exch, String name /*, String defStr*/) {
		return exch.getRequestHeaders().getLast(name);
	}

	
	public static String getQueryParam(HttpServerExchange exch, String name) {
		return getQueryParam(exch, name, null);
	}

	public static boolean isEmptyOrNull(String str) {
		return null == str || str.trim().length()==0;
	}

	public static boolean isPositive(Integer val) {
		return null != val && val > 0;
	}

	public static boolean isNonNegative(Integer val) {
		return null != val && val >= 0;
	}

	public static boolean isPositive(Long val) {
		return null != val && val > 0;
	}

	public static boolean isNonNegative(Long val) {
		return null != val && val >= 0;
	}

	
	public static boolean isTrueValue(Object obj) {
		return (null != obj)  && 
			(((obj instanceof Boolean) && ((Boolean)obj).booleanValue()) ||
			 ((obj instanceof Number) && ((Number)obj).longValue() != 0L) ||
			 ((obj instanceof String) && ("true".equalsIgnoreCase(((String)obj)))));
	}
	
	// FIXME: real accept header  parsing
	public static boolean isAccepted(String mimeType, HttpServerExchange exch) {
		final String accept = exch.getRequestHeaders().get(Headers.ACCEPT_STRING).getLast();
		return isAccepted(mimeType, accept);
	}

	// FIXME: real accept header  parsing
	public static boolean isAccepted(String mimeType, ISvcRequest svcReq) {
		final String accept = svcReq.getLastHeader(Headers.ACCEPT_STRING);
		return isAccepted(mimeType, accept);
	}

	
	// FIXME: real accept header  parsing
	public static boolean isAccepted(String mimeType, String accept) {
		if (Utils.isEmptyOrNull(accept) || 
			accept.contains("*") ||
			accept.contains(mimeType)) {
			return true;
		} else {
			return false;
		}
	}

	public static String getIdType(ISvcRequest svcReq)
		throws DFSValidationException {
		String idType = svcReq.getQueryParam("idType");
		if ("legacyDocumentId".equals(idType) ||
			"dctmDocumentId".equals(idType)) {
			return idType;
		} else {
			throw new DFSValidationException("Invalid value for idType: can be legacyDocumentId or dctmDocumentId");
		}
	}

	public static String getIdType(HttpServerExchange exch)
		throws DFSValidationException {
		String idType = Utils.getQueryParam(exch, "idType");
		if ("legacyDocumentId".equals(idType) ||
			"dctmDocumentId".equals(idType)) {
			return idType;
		} else {
			throw new DFSValidationException("Invalid value for idType: can be legacyDocumentId or dctmDocumentId");
		}
	}

	public static Object sqlHEX(String fieldValue) {
		// FIXME: split characters
		//try {
			StringBuilder buf = new StringBuilder(fieldValue.length() * 2 + 20);
			int count = 0;
			for (int i = 0; i < fieldValue.length() ; i+=2000) {
				if (i > 0) {
					buf.append(" || ");
				}
				buf.append("TO_CLOB('");
				buf.append(fieldValue.substring(i , i + 2000 < fieldValue.length() ? i+2000: fieldValue.length())
						   .replaceAll("'", "''"));
				buf.append("')");
			}
			return buf.toString();
			//} catch (UnsupportedEncodingException ex) {
			// won't happen
			//throw new RuntimeException(ex);
			//}
	}

	public static Object oracleSQLStrEscape(String fieldValue) {
		if (null != fieldValue) {
			return fieldValue.replaceAll("'", "''");
		}
		return null;
	}

	public static String formatOraTS(long longValue) {
		// FIXME: TZ
		SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss.SSS");
		return sdf.format(new Date(longValue));
	}

	public static LoggingUtils getLogger() {
		return DfsRequestThreadAttributes.dfsLogger.get();
	}

	public static void mssleep(long ms) {
		try {
			Thread.sleep(ms);
		} catch (InterruptedException iex) {
			Thread.currentThread().interrupt();
		}
	}

	public static  IConfigurable  mkcomp(ConfigurationProvider provider, String name, Map<String,Object> context)   {
		try {
			final String serviceName = "mkcomp";
			ConfigurationProvider local = new ConfigurationSubtreeProvider(provider, name + ".");
			String implClassStr = local.getProperty("implementation", String.class);
			if (null == implClassStr) {
				throw new RuntimeException("No implementation defined for" + name);
			}
			Class implClass = Utils.class.getClassLoader().loadClass(implClassStr);
			//log.info(, "loading input class " + implClass);
			IConfigurable  input = (IConfigurable)implClass.newInstance();
			//log.info(serviceName, "loading input class " + implClass);
			input.configure(local, name, context);
			//log.info(serviceName, "configuring input class " + implClass);
			return input;
		}  catch(ClassNotFoundException| InstantiationException |IllegalAccessException ex) {
			throw new RuntimeException("Failed to create component " + name + ": ", ex);
		}
	}

	public static List<IConfigurable>  mkcomps(ConfigurationProvider provider, String name, Map<String,Object> context)   {
		final List<String> compsNames = provider.getProperty(name,  new GenericType<List<String>>() {});
		final List<IConfigurable> lst = compsNames.stream()
			.map(compName -> Utils.mkcomp(provider, compName, context)).collect(Collectors.toList());
		return lst;
	}
	

	public static  byte[] getStrBytes(String str) {
		try {
			return null == str ? null : str.getBytes("UTF-8");
		} catch (UnsupportedEncodingException ex) {
			throw new RuntimeException("UTF-8 not supported! this cannot happen: ", ex);
		}
	}

	public static String ValidateRetrieveProfile(String pRetrieve)
	{
		return pRetrieve == null ? "HTTP" : ((!pRetrieve.equalsIgnoreCase("HTTP")) &&
											(!pRetrieve.equalsIgnoreCase("SAFE")) &&
											(!pRetrieve.equalsIgnoreCase("STREAM"))) ?  "HTTP" : pRetrieve;
	}

	public static String fixGeneralErrorMsgForResponse(String pInputMsg) {
		try {
			if (pInputMsg.contains("error: ")) {
				pInputMsg = pInputMsg.split("error: ")[1];
			} else if (pInputMsg.contains("MSG")) {
				pInputMsg = pInputMsg.split("MSG:")[1];

			}

			if (pInputMsg.contains("; ERR")) {
				pInputMsg = pInputMsg.split("; ERR")[0];
			}

			if (pInputMsg.contains("Exception:")) {
				pInputMsg = pInputMsg.split("Exception:")[1];
			}
		} catch (Exception ex)
		{
			pInputMsg = "the ex msg parsing fail... Origin msg: " + pInputMsg;
		}
		return pInputMsg;
	}

	/**
	 * get the second value of message split by delimiter
	 * @param msgKeyValue
	 * @param delimiter
	 * @return
	 */
	public static String getValueOfPairWithDelimiter(String msgKeyValue,String delimiter) {
		String[] msgArr = msgKeyValue.split(delimiter);
		if (msgArr!=null && msgArr.length>1) {
			return msgArr[1];
		}
		return msgKeyValue;
	}
	
	/**
	 * get the first value of message split by delimiter
	 * @param msgKeyValue
	 * @param delimiter
	 * @return
	 */
	public static String getKeyOfPairWithDelimiter(String msgKeyValue,String delimiter) {
		String[] msgArr = msgKeyValue.split(delimiter);
		if (msgArr!=null && msgArr.length>0) {
			return msgArr[0];
		}
		return msgKeyValue;
	}
	
	public static String getCustomerIdAsString(CustomerKey customerKey) {
		if (customerKey==null) {
			return "";
		}
		if (customerKey.getCompleteCustomerIdCode() !=null) {
			return customerKey.getCompleteCustomerIdCode();
		}
		if (customerKey.getCustomerId() !=null) {
			return String.valueOf(customerKey.getCustomerId());
		}
		return "";
	}
	
	
	
	public static String getAccountAsString(BankAccount bankAccount) {
		if (bankAccount ==null) {
			return "";
		}
		String accountNumber = bankAccount.getAccountBankId() + "-" + bankAccount.getBranchId() + "-" + bankAccount.getAccountNbr();  
		return accountNumber;
	}

	
	public static CustomerKey fetchCustomer(DocData docData) {
		CustomerKey customerKey =null;
		if (docData.getDocCustomerData().getCustomerKeys()!=null) {
			customerKey = docData.getDocCustomerData().getCustomerKeys().get(0);
		}
		return customerKey;
	}
	
	public static BankAccount fetchBankAccount(DocData docData) {
		BankAccount bankAccount =null;
		if (docData.getDocCustomerData().getBankAccounts()!=null) {
			bankAccount = docData.getDocCustomerData().getBankAccounts().get(0);
		}
		return bankAccount;
	}
	
	public static String getCustomerAndAccount(DocData docData) {
		CustomerKey customerKey =null;
		if (docData.getDocCustomerData().getCustomerKeys()!=null) {
			customerKey = docData.getDocCustomerData().getCustomerKeys().get(0);
		}
		BankAccount bankAccount = null;
		if (docData.getDocCustomerData().getBankAccounts()!=null) {
			 bankAccount = docData.getDocCustomerData().getBankAccounts().get(0);
		}
		String cusomerIdStr = getCustomerIdAsString(customerKey);
		String accountIdStr=getAccountAsString(bankAccount);
		String customerAndAccountStr = cusomerIdStr + ":" + accountIdStr;
		return customerAndAccountStr;
	}
	

	
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\test\java\bnhp\dctmrest\utils\JsonSearchParserTest.java
-----------------------------------------------------
package bnhp.dctmrest.utils;


import static org.junit.Assert.fail;

import java.io.ByteArrayInputStream;
import java.io.IOException;
import java.io.InputStream;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Date;
import java.util.List;
import java.util.Map;


import org.junit.AfterClass;
import org.junit.Assert;
import org.junit.BeforeClass;
import org.junit.Ignore;
import org.junit.Test;

import com.fasterxml.jackson.core.JsonProcessingException;

import bnhp.infra.dfs.model.business.ExecutorDetails;
import bnhp.infra.dfs.model.query.prepared.AbstractParam;
import bnhp.infra.dfs.model.query.prepared.NamedQueryParam;
import bnhp.infra.dfs.model.query.prepared.QueryParamList;
import bnhp.infra.dfs.model.query.prepared.QueryParam;
import bnhp.infra.dfs.model.query.prepared.PreparedQuery;
import bnhp.infra.dfs.model.service.FetchTypeSet;
import bnhp.infra.dfs.model.service.SearchDefinition;

import static bnhp.dctmrest.utils.Utils.makeMap;
import static bnhp.dctmrest.utils.RestTestUtils.*;


public class JsonSearchParserTest {
	/*
		"  accounts: 
                  items:
                    properties:
                      accountBankId:
                        format: int32
                        type: integer
                      accountNumber:
                        format: int32
                        type: integer
                      branchId:
                        format: int32
                        type: integer
                    required:
                      - accountNumber
                      - accountBankId
                      - branchId
                    type: object
                  type: array
                customers:
                  items:
                    properties:
                      entityId:
                        type: string
                      entityType:
                        $ref: '#/components/schemas/CustomerType'
                    required:
                      - entityId
                    type: object
                  type: array
                dosExtension:
                  type: string
                endDate:
                  format: date
                  type: string
	*/
	//public final static Map TESTMSGMAP =

	

	public final static Map TESTMSGMAP
		= Utils.makeMap("fetchType" , "meta",
						"dosExtension", "pdf",
						"fulltext","blabla",
						"executorDetails", makeTestExecutorDetails(),
						"pagingDefinition", makeTestPagingDefinition(),
						"startDate", new Date(System.currentTimeMillis() - 3600 * 24 * 31),
						"accounts", Utils.list(makeTestAccountMap()),
						"customers", Utils.list(makeTestCustomersMap()),
						"endtDate",	new Date(System.currentTimeMillis()),
						"systemCode",	1,
						"sortDefinitions", makeSortDefinitions());
	
	public final static String TESTMSG = toJsonString(TESTMSGMAP);

	protected JsonSearchParser parseString(String s) throws Exception {
		InputStream is = new ByteArrayInputStream(s.getBytes());
		JsonSearchParser jsp = new JsonSearchParser();
		jsp.parseSearchParams(is);
		Assert.assertNotNull(jsp);
		return jsp;
	}

	private static String toJsonString(Map testmsgmap2) {
		try {
			return Json.serializer().prettyWriter().writeValueAsString(TESTMSGMAP);
		} catch ( JsonProcessingException ex) {
			throw new RuntimeException(ex);
		}
	}

	@Test
	public void testParseStream() throws Exception {
		System.out.println(TESTMSG);
		JsonSearchParser jsp = parseString(TESTMSG);
		
		
	}

	@Test
	public void testParseStreamFetchTypeSet() throws Exception {
		JsonSearchParser jsp = parseString(TESTMSG);
		FetchTypeSet fts = jsp.getFetchTypeSet();
		Assert.assertNotNull(fts);
		System.out.println(fts);
	}

	@Test
	public void testParseStreamExecutorDetails() throws Exception {
		JsonSearchParser jsp = parseString(TESTMSG);
		ExecutorDetails ed = jsp.getExecutorDetails();
		Assert.assertNotNull(ed);
		System.out.println(ed);
	}

	@Test
	public void testParseStreamSearchDefinition() throws Exception {
		JsonSearchParser jsp = parseString(TESTMSG);
		SearchDefinition sd = jsp.getSearchDefinition();
		Assert.assertNotNull(sd);
		System.out.println(sd);
	}

	@Test
	public void testParsePreparedQuery() throws Exception {
		JsonSearchParser jsp = parseString(TESTMSG);
		PreparedQuery pq = jsp.getPreparedQuery();
		Assert.assertNotNull(pq);
		System.out.println(pq);
		// extracted externally from path variable
		Assert.assertNull(pq.getName());
		Assert.assertNotNull(pq.getParams());
		// fetchType, executorDetails, pagingDefinition SortDefinitions have own fixed structures
		Assert.assertEquals( TESTMSGMAP.size() -  4, pq.getParams().size());
		checkParams(TESTMSGMAP, pq.getParams());
	}


	protected void checkParams(Map map, List<NamedQueryParam> params) {
		for (NamedQueryParam nqp : params) {
			Assert.assertNotNull(nqp.getName());
			Assert.assertNotNull(nqp.getParamValue());
			
			Object checkValue = map.get(nqp.getName());
			Assert.assertNotNull(checkValue);
			
			AbstractParam paramValue = nqp.getParamValue();
			if (paramValue instanceof QueryParam) {
				checkParam(checkValue, (QueryParam) paramValue);
			} else if (paramValue instanceof QueryParamList) {
				// FIXME
				QueryParamList qpl = (QueryParamList)paramValue;
				Assert.assertTrue( checkValue instanceof List);
				checkParams((List)checkValue,  qpl.getParams());
				//System.out.println(paramValue.getClass());
			}

		}
	}
	
	protected void checkParams(List list, List<NamedQueryParam> params) {
		Assert.assertEquals(list.size(), params.size());
		for (int i = 0; i < list.size();  i++) {
			NamedQueryParam nqp = params.get(i);
			Assert.assertNotNull(nqp.getName());
			Assert.assertNotNull(nqp.getParamValue());
			
			Object checkValue = list.get(i);
			Assert.assertNotNull(checkValue);
			
			AbstractParam paramValue = nqp.getParamValue();
			if (paramValue instanceof QueryParam) {
				checkParam(checkValue, (QueryParam) paramValue);
			} else if (paramValue instanceof QueryParamList) {
				// FIXME
				QueryParamList qpl = (QueryParamList)paramValue;
				System.out.println(checkValue);
				if (checkValue instanceof List) {
					checkParams((List)checkValue,  qpl.getParams());
				} else if (checkValue instanceof Map) {
					checkParams((Map)checkValue,  qpl.getParams());
				} else {
					throw new RuntimeException("unexpected type of value "+ checkValue);
				}
			}
		}
		
	}
	
	protected void checkParam(Object checkValue, QueryParam paramValue) {
		Object value = ((QueryParam)paramValue).getValue();
		if (checkValue instanceof Date) {
			// FIXME
		} else {
			Assert.assertEquals(checkValue, value);
		}
	}
}


file Read:C:\Users\AP068\git\documentum\rest-cd-prod\src\test\java\bnhp\dctmrest\utils\RestTestUtils.java
-----------------------------------------------------
package  bnhp.dctmrest.utils;

import java.util.Date;
import java.util.List;
import java.util.Map;
import java.util.HashMap;

import bnhp.dctmrest.model.PagingDefinition;
import bnhp.dctmrest.model.ExecutorDetails;
import bnhp.dctmrest.model.BankAccount;
import bnhp.dctmrest.model.Customer;

import bnhp.infra.dfs.services.DataInitializer;


public class RestTestUtils {

	
	public static List<Map<String,String>> makeSortDefinitions() {
		List<Map<String,String>> list =
			Utils.list(Utils.makeMap("name","legacyDocumentId",
									 "order", "ASC"),
					   Utils.makeMap("name","legacyDocumentEntryDttm",
									 "order", "DESC"));
		
		return list;
	}

	public static PagingDefinition  makeTestPagingDefinition() {
		bnhp.dctmrest.model.PagingDefinition p = new bnhp.dctmrest.model.PagingDefinition();
		p.setMaxResultCount(50);
		p.setStartIndex(0L);
		p.setShouldReturnTotalResults(false);
		return p;
	}

	public static ExecutorDetails makeTestExecutorDetails() {
		return DFS2Rest.toRest(DataInitializer.createFullExecutorDetails());
	}

	public static Customer makeTestCustomers() {
		Customer cu = new Customer();
		cu.setCustomerIdDocTypeCode(1);
		cu.setCompleteCustomerIdCode("3325599900");
		return cu;
	}

	public static Map  makeTestCustomersMap() {
		Map  cu = new HashMap();
		cu.put("customerIdDocTypeCode",1);
		cu.put("completeCustomerIdCode","3325599900");
		return cu;
	}


	public static BankAccount makeTestAccount() {
		BankAccount ba = new BankAccount();
		ba.setAccountBankId(12);
		ba.setBranchId(822);
		ba.setAccountNbr(222333);
		return ba;
	}

	public static Map makeTestAccountMap() {
		Map ba = new HashMap();
		ba.put("accountBankId", 12);
		ba.put("branchId", 822);
		ba.put("accountNbr", 222333);
		return ba;
	}

	
	
}
total files:221



-----------------------------------




file Read:C:\Users\AP068\git\documentum\dctm-build-base\.git\config
-----------------------------------------------------
[core]
	repositoryformatversion = 0
	filemode = false
	bare = false
	logallrefupdates = true
	symlinks = false
	ignorecase = true
[remote "origin"]
	url = ssh://git@gitlab.devops.poalim.bank:31007/m28008doc/dctm-build-base.git
	fetch = +refs/heads/*:refs/remotes/origin/*
[branch "master"]
	remote = origin
	merge = refs/heads/master


file Read:C:\Users\AP068\git\documentum\dctm-build-base\.git\hooks\applypatch-msg.sample
-----------------------------------------------------
#!/bin/sh
#
# An example hook script to check the commit log message taken by
# applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.  The hook is
# allowed to edit the commit message file.
#
# To enable this hook, rename this file to "applypatch-msg".

. git-sh-setup
commitmsg="$(git rev-parse --git-path hooks/commit-msg)"
test -x "$commitmsg" && exec "$commitmsg" ${1+"$@"}
:


file Read:C:\Users\AP068\git\documentum\dctm-build-base\.git\hooks\commit-msg.sample
-----------------------------------------------------
#!/bin/sh
#
# An example hook script to check the commit log message.
# Called by "git commit" with one argument, the name of the file
# that has the commit message.  The hook should exit with non-zero
# status after issuing an appropriate message if it wants to stop the
# commit.  The hook is allowed to edit the commit message file.
#
# To enable this hook, rename this file to "commit-msg".

# Uncomment the below to add a Signed-off-by line to the message.
# Doing this in a hook is a bad idea in general, but the prepare-commit-msg
# hook is more suited to it.
#
# SOB=$(git var GIT_AUTHOR_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
# grep -qs "^$SOB" "$1" || echo "$SOB" >> "$1"

# This example catches duplicate Signed-off-by lines.

test "" = "$(grep '^Signed-off-by: ' "$1" |
	 sort | uniq -c | sed -e '/^[ 	]*1[ 	]/d')" || {
	echo >&2 Duplicate Signed-off-by lines.
	exit 1
}


file Read:C:\Users\AP068\git\documentum\dctm-build-base\.git\hooks\fsmonitor-watchman.sample
-----------------------------------------------------
#!/usr/bin/perl

use strict;
use warnings;
use IPC::Open2;

# An example hook script to integrate Watchman
# (https://facebook.github.io/watchman/) with git to speed up detecting
# new and modified files.
#
# The hook is passed a version (currently 1) and a time in nanoseconds
# formatted as a string and outputs to stdout all files that have been
# modified since the given time. Paths must be relative to the root of
# the working tree and separated by a single NUL.
#
# To enable this hook, rename this file to "query-watchman" and set
# 'git config core.fsmonitor .git/hooks/query-watchman'
#
my ($version, $time) = @ARGV;

# Check the hook interface version

if ($version == 1) {
	# convert nanoseconds to seconds
	$time = int $time / 1000000000;
} else {
	die "Unsupported query-fsmonitor hook version '$version'.\n" .
	    "Falling back to scanning...\n";
}

my $git_work_tree;
if ($^O =~ 'msys' || $^O =~ 'cygwin') {
	$git_work_tree = Win32::GetCwd();
	$git_work_tree =~ tr/\\/\//;
} else {
	require Cwd;
	$git_work_tree = Cwd::cwd();
}

my $retry = 1;

launch_watchman();

sub launch_watchman {

	my $pid = open2(\*CHLD_OUT, \*CHLD_IN, 'watchman -j --no-pretty')
	    or die "open2() failed: $!\n" .
	    "Falling back to scanning...\n";

	# In the query expression below we're asking for names of files that
	# changed since $time but were not transient (ie created after
	# $time but no longer exist).
	#
	# To accomplish this, we're using the "since" generator to use the
	# recency index to select candidate nodes and "fields" to limit the
	# output to file names only. Then we're using the "expression" term to
	# further constrain the results.
	#
	# The category of transient files that we want to ignore will have a
	# creation clock (cclock) newer than $time_t value and will also not
	# currently exist.

	my $query = <<"	END";
		["query", "$git_work_tree", {
			"since": $time,
			"fields": ["name"],
			"expression": ["not", ["allof", ["since", $time, "cclock"], ["not", "exists"]]]
		}]
	END

	print CHLD_IN $query;
	close CHLD_IN;
	my $response = do {local $/; <CHLD_OUT>};

	die "Watchman: command returned no output.\n" .
	    "Falling back to scanning...\n" if $response eq "";
	die "Watchman: command returned invalid output: $response\n" .
	    "Falling back to scanning...\n" unless $response =~ /^\{/;

	my $json_pkg;
	eval {
		require JSON::XS;
		$json_pkg = "JSON::XS";
		1;
	} or do {
		require JSON::PP;
		$json_pkg = "JSON::PP";
	};

	my $o = $json_pkg->new->utf8->decode($response);

	if ($retry > 0 and $o->{error} and $o->{error} =~ m/unable to resolve root .* directory (.*) is not watched/) {
		print STDERR "Adding '$git_work_tree' to watchman's watch list.\n";
		$retry--;
		qx/watchman watch "$git_work_tree"/;
		die "Failed to make watchman watch '$git_work_tree'.\n" .
		    "Falling back to scanning...\n" if $? != 0;

		# Watchman will always return all files on the first query so
		# return the fast "everything is dirty" flag to git and do the
		# Watchman query just to get it over with now so we won't pay
		# the cost in git to look up each individual file.
		print "/\0";
		eval { launch_watchman() };
		exit 0;
	}

	die "Watchman: $o->{error}.\n" .
	    "Falling back to scanning...\n" if $o->{error};

	binmode STDOUT, ":utf8";
	local $, = "\0";
	print @{$o->{files}};
}


file Read:C:\Users\AP068\git\documentum\dctm-build-base\.git\hooks\post-update.sample
-----------------------------------------------------
#!/bin/sh
#
# An example hook script to prepare a packed repository for use over
# dumb transports.
#
# To enable this hook, rename this file to "post-update".

exec git update-server-info


file Read:C:\Users\AP068\git\documentum\dctm-build-base\.git\hooks\pre-applypatch.sample
-----------------------------------------------------
#!/bin/sh
#
# An example hook script to verify what is about to be committed
# by applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-applypatch".

. git-sh-setup
precommit="$(git rev-parse --git-path hooks/pre-commit)"
test -x "$precommit" && exec "$precommit" ${1+"$@"}
:


file Read:C:\Users\AP068\git\documentum\dctm-build-base\.git\hooks\pre-commit.sample
-----------------------------------------------------
#!/bin/sh
#
# An example hook script to verify what is about to be committed.
# Called by "git commit" with no arguments.  The hook should
# exit with non-zero status after issuing an appropriate message if
# it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-commit".

if git rev-parse --verify HEAD >/dev/null 2>&1
then
	against=HEAD
else
	# Initial commit: diff against an empty tree object
	against=$(git hash-object -t tree /dev/null)
fi

# If you want to allow non-ASCII filenames set this variable to true.
allownonascii=$(git config --bool hooks.allownonascii)

# Redirect output to stderr.
exec 1>&2

# Cross platform projects tend to avoid non-ASCII filenames; prevent
# them from being added to the repository. We exploit the fact that the
# printable range starts at the space character and ends with tilde.
if [ "$allownonascii" != "true" ] &&
	# Note that the use of brackets around a tr range is ok here, (it's
	# even required, for portability to Solaris 10's /usr/bin/tr), since
	# the square bracket bytes happen to fall in the designated range.
	test $(git diff --cached --name-only --diff-filter=A -z $against |
	  LC_ALL=C tr -d '[ -~]\0' | wc -c) != 0
then
	cat <<\EOF
Error: Attempt to add a non-ASCII file name.

This can cause problems if you want to work with people on other platforms.

To be portable it is advisable to rename the file.

If you know what you are doing you can disable this check using:

  git config hooks.allownonascii true
EOF
	exit 1
fi

# If there are whitespace errors, print the offending file names and fail.
exec git diff-index --check --cached $against --


file Read:C:\Users\AP068\git\documentum\dctm-build-base\.git\hooks\pre-push.sample
-----------------------------------------------------
#!/bin/sh

# An example hook script to verify what is about to be pushed.  Called by "git
# push" after it has checked the remote status, but before anything has been
# pushed.  If this script exits with a non-zero status nothing will be pushed.
#
# This hook is called with the following parameters:
#
# $1 -- Name of the remote to which the push is being done
# $2 -- URL to which the push is being done
#
# If pushing without using a named remote those arguments will be equal.
#
# Information about the commits which are being pushed is supplied as lines to
# the standard input in the form:
#
#   <local ref> <local sha1> <remote ref> <remote sha1>
#
# This sample shows how to prevent push of commits where the log message starts
# with "WIP" (work in progress).

remote="$1"
url="$2"

z40=0000000000000000000000000000000000000000

while read local_ref local_sha remote_ref remote_sha
do
	if [ "$local_sha" = $z40 ]
	then
		# Handle delete
		:
	else
		if [ "$remote_sha" = $z40 ]
		then
			# New branch, examine all commits
			range="$local_sha"
		else
			# Update to existing branch, examine new commits
			range="$remote_sha..$local_sha"
		fi

		# Check for WIP commit
		commit=`git rev-list -n 1 --grep '^WIP' "$range"`
		if [ -n "$commit" ]
		then
			echo >&2 "Found WIP commit in $local_ref, not pushing"
			exit 1
		fi
	fi
done

exit 0


file Read:C:\Users\AP068\git\documentum\dctm-build-base\.git\hooks\pre-rebase.sample
-----------------------------------------------------
#!/bin/sh
#
# Copyright (c) 2006, 2008 Junio C Hamano
#
# The "pre-rebase" hook is run just before "git rebase" starts doing
# its job, and can prevent the command from running by exiting with
# non-zero status.
#
# The hook is called with the following parameters:
#
# $1 -- the upstream the series was forked from.
# $2 -- the branch being rebased (or empty when rebasing the current branch).
#
# This sample shows how to prevent topic branches that are already
# merged to 'next' branch from getting rebased, because allowing it
# would result in rebasing already published history.

publish=next
basebranch="$1"
if test "$#" = 2
then
	topic="refs/heads/$2"
else
	topic=`git symbolic-ref HEAD` ||
	exit 0 ;# we do not interrupt rebasing detached HEAD
fi

case "$topic" in
refs/heads/??/*)
	;;
*)
	exit 0 ;# we do not interrupt others.
	;;
esac

# Now we are dealing with a topic branch being rebased
# on top of master.  Is it OK to rebase it?

# Does the topic really exist?
git show-ref -q "$topic" || {
	echo >&2 "No such branch $topic"
	exit 1
}

# Is topic fully merged to master?
not_in_master=`git rev-list --pretty=oneline ^master "$topic"`
if test -z "$not_in_master"
then
	echo >&2 "$topic is fully merged to master; better remove it."
	exit 1 ;# we could allow it, but there is no point.
fi

# Is topic ever merged to next?  If so you should not be rebasing it.
only_next_1=`git rev-list ^master "^$topic" ${publish} | sort`
only_next_2=`git rev-list ^master           ${publish} | sort`
if test "$only_next_1" = "$only_next_2"
then
	not_in_topic=`git rev-list "^$topic" master`
	if test -z "$not_in_topic"
	then
		echo >&2 "$topic is already up to date with master"
		exit 1 ;# we could allow it, but there is no point.
	else
		exit 0
	fi
else
	not_in_next=`git rev-list --pretty=oneline ^${publish} "$topic"`
	/usr/bin/perl -e '
		my $topic = $ARGV[0];
		my $msg = "* $topic has commits already merged to public branch:\n";
		my (%not_in_next) = map {
			/^([0-9a-f]+) /;
			($1 => 1);
		} split(/\n/, $ARGV[1]);
		for my $elem (map {
				/^([0-9a-f]+) (.*)$/;
				[$1 => $2];
			} split(/\n/, $ARGV[2])) {
			if (!exists $not_in_next{$elem->[0]}) {
				if ($msg) {
					print STDERR $msg;
					undef $msg;
				}
				print STDERR " $elem->[1]\n";
			}
		}
	' "$topic" "$not_in_next" "$not_in_master"
	exit 1
fi

<<\DOC_END

This sample hook safeguards topic branches that have been
published from being rewound.

The workflow assumed here is:

 * Once a topic branch forks from "master", "master" is never
   merged into it again (either directly or indirectly).

 * Once a topic branch is fully cooked and merged into "master",
   it is deleted.  If you need to build on top of it to correct
   earlier mistakes, a new topic branch is created by forking at
   the tip of the "master".  This is not strictly necessary, but
   it makes it easier to keep your history simple.

 * Whenever you need to test or publish your changes to topic
   branches, merge them into "next" branch.

The script, being an example, hardcodes the publish branch name
to be "next", but it is trivial to make it configurable via
$GIT_DIR/config mechanism.

With this workflow, you would want to know:

(1) ... if a topic branch has ever been merged to "next".  Young
    topic branches can have stupid mistakes you would rather
    clean up before publishing, and things that have not been
    merged into other branches can be easily rebased without
    affecting other people.  But once it is published, you would
    not want to rewind it.

(2) ... if a topic branch has been fully merged to "master".
    Then you can delete it.  More importantly, you should not
    build on top of it -- other people may already want to
    change things related to the topic as patches against your
    "master", so if you need further changes, it is better to
    fork the topic (perhaps with the same name) afresh from the
    tip of "master".

Let's look at this example:

		   o---o---o---o---o---o---o---o---o---o "next"
		  /       /           /           /
		 /   a---a---b A     /           /
		/   /               /           /
	       /   /   c---c---c---c B         /
	      /   /   /             \         /
	     /   /   /   b---b C     \       /
	    /   /   /   /             \     /
    ---o---o---o---o---o---o---o---o---o---o---o "master"


A, B and C are topic branches.

 * A has one fix since it was merged up to "next".

 * B has finished.  It has been fully merged up to "master" and "next",
   and is ready to be deleted.

 * C has not merged to "next" at all.

We would want to allow C to be rebased, refuse A, and encourage
B to be deleted.

To compute (1):

	git rev-list ^master ^topic next
	git rev-list ^master        next

	if these match, topic has not merged in next at all.

To compute (2):

	git rev-list master..topic

	if this is empty, it is fully merged to "master".

DOC_END


file Read:C:\Users\AP068\git\documentum\dctm-build-base\.git\hooks\pre-receive.sample
-----------------------------------------------------
#!/bin/sh
#
# An example hook script to make use of push options.
# The example simply echoes all push options that start with 'echoback='
# and rejects all pushes when the "reject" push option is used.
#
# To enable this hook, rename this file to "pre-receive".

if test -n "$GIT_PUSH_OPTION_COUNT"
then
	i=0
	while test "$i" -lt "$GIT_PUSH_OPTION_COUNT"
	do
		eval "value=\$GIT_PUSH_OPTION_$i"
		case "$value" in
		echoback=*)
			echo "echo from the pre-receive-hook: ${value#*=}" >&2
			;;
		reject)
			exit 1
		esac
		i=$((i + 1))
	done
fi


file Read:C:\Users\AP068\git\documentum\dctm-build-base\.git\hooks\prepare-commit-msg.sample
-----------------------------------------------------
#!/bin/sh
#
# An example hook script to prepare the commit log message.
# Called by "git commit" with the name of the file that has the
# commit message, followed by the description of the commit
# message's source.  The hook's purpose is to edit the commit
# message file.  If the hook fails with a non-zero status,
# the commit is aborted.
#
# To enable this hook, rename this file to "prepare-commit-msg".

# This hook includes three examples. The first one removes the
# "# Please enter the commit message..." help message.
#
# The second includes the output of "git diff --name-status -r"
# into the message, just before the "git status" output.  It is
# commented because it doesn't cope with --amend or with squashed
# commits.
#
# The third example adds a Signed-off-by line to the message, that can
# still be edited.  This is rarely a good idea.

COMMIT_MSG_FILE=$1
COMMIT_SOURCE=$2
SHA1=$3

/usr/bin/perl -i.bak -ne 'print unless(m/^. Please enter the commit message/..m/^#$/)' "$COMMIT_MSG_FILE"

# case "$COMMIT_SOURCE,$SHA1" in
#  ,|template,)
#    /usr/bin/perl -i.bak -pe '
#       print "\n" . `git diff --cached --name-status -r`
# 	 if /^#/ && $first++ == 0' "$COMMIT_MSG_FILE" ;;
#  *) ;;
# esac

# SOB=$(git var GIT_COMMITTER_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
# git interpret-trailers --in-place --trailer "$SOB" "$COMMIT_MSG_FILE"
# if test -z "$COMMIT_SOURCE"
# then
#   /usr/bin/perl -i.bak -pe 'print "\n" if !$first_line++' "$COMMIT_MSG_FILE"
# fi


file Read:C:\Users\AP068\git\documentum\dctm-build-base\.git\hooks\update.sample
-----------------------------------------------------
#!/bin/sh
#
# An example hook script to block unannotated tags from entering.
# Called by "git receive-pack" with arguments: refname sha1-old sha1-new
#
# To enable this hook, rename this file to "update".
#
# Config
# ------
# hooks.allowunannotated
#   This boolean sets whether unannotated tags will be allowed into the
#   repository.  By default they won't be.
# hooks.allowdeletetag
#   This boolean sets whether deleting tags will be allowed in the
#   repository.  By default they won't be.
# hooks.allowmodifytag
#   This boolean sets whether a tag may be modified after creation. By default
#   it won't be.
# hooks.allowdeletebranch
#   This boolean sets whether deleting branches will be allowed in the
#   repository.  By default they won't be.
# hooks.denycreatebranch
#   This boolean sets whether remotely creating branches will be denied
#   in the repository.  By default this is allowed.
#

# --- Command line
refname="$1"
oldrev="$2"
newrev="$3"

# --- Safety check
if [ -z "$GIT_DIR" ]; then
	echo "Don't run this script from the command line." >&2
	echo " (if you want, you could supply GIT_DIR then run" >&2
	echo "  $0 <ref> <oldrev> <newrev>)" >&2
	exit 1
fi

if [ -z "$refname" -o -z "$oldrev" -o -z "$newrev" ]; then
	echo "usage: $0 <ref> <oldrev> <newrev>" >&2
	exit 1
fi

# --- Config
allowunannotated=$(git config --bool hooks.allowunannotated)
allowdeletebranch=$(git config --bool hooks.allowdeletebranch)
denycreatebranch=$(git config --bool hooks.denycreatebranch)
allowdeletetag=$(git config --bool hooks.allowdeletetag)
allowmodifytag=$(git config --bool hooks.allowmodifytag)

# check for no description
projectdesc=$(sed -e '1q' "$GIT_DIR/description")
case "$projectdesc" in
"Unnamed repository"* | "")
	echo "*** Project description file hasn't been set" >&2
	exit 1
	;;
esac

# --- Check types
# if $newrev is 0000...0000, it's a commit to delete a ref.
zero="0000000000000000000000000000000000000000"
if [ "$newrev" = "$zero" ]; then
	newrev_type=delete
else
	newrev_type=$(git cat-file -t $newrev)
fi

case "$refname","$newrev_type" in
	refs/tags/*,commit)
		# un-annotated tag
		short_refname=${refname##refs/tags/}
		if [ "$allowunannotated" != "true" ]; then
			echo "*** The un-annotated tag, $short_refname, is not allowed in this repository" >&2
			echo "*** Use 'git tag [ -a | -s ]' for tags you want to propagate." >&2
			exit 1
		fi
		;;
	refs/tags/*,delete)
		# delete tag
		if [ "$allowdeletetag" != "true" ]; then
			echo "*** Deleting a tag is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/tags/*,tag)
		# annotated tag
		if [ "$allowmodifytag" != "true" ] && git rev-parse $refname > /dev/null 2>&1
		then
			echo "*** Tag '$refname' already exists." >&2
			echo "*** Modifying a tag is not allowed in this repository." >&2
			exit 1
		fi
		;;
	refs/heads/*,commit)
		# branch
		if [ "$oldrev" = "$zero" -a "$denycreatebranch" = "true" ]; then
			echo "*** Creating a branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/heads/*,delete)
		# delete branch
		if [ "$allowdeletebranch" != "true" ]; then
			echo "*** Deleting a branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/remotes/*,commit)
		# tracking branch
		;;
	refs/remotes/*,delete)
		# delete tracking branch
		if [ "$allowdeletebranch" != "true" ]; then
			echo "*** Deleting a tracking branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	*)
		# Anything else (is there anything else?)
		echo "*** Update hook: unknown type of update to ref $refname of type $newrev_type" >&2
		exit 1
		;;
esac

# --- Finished
exit 0


file Read:C:\Users\AP068\git\documentum\dctm-build-base\.gitignore
-----------------------------------------------------
*~
*.swp
\#*\#



file Read:C:\Users\AP068\git\documentum\dctm-build-base\.gitlab-ci.yml
-----------------------------------------------------
stages:
  - dockerize
services:
  - docker-external.repo.devops.poalim.bank/docker:18.09-dind


before_script:
  - echo "Before script started"
  - DOCKER_HOST="tcp://localhost:2375"
  - export DOCKER_HOST



docker:
  image: docker-external.repo.devops.poalim.bank/docker:18.09-dind
  stage: dockerize
  script:
    - DOCKERTAG=$(cat .tag)
    - IMAGENAME=${DOCKER_REPO}/${DOCKERTAG}
    - docker build --build-arg ARTIFACTORY_PASSWORD=${ARTIFACTORY_PASSWORD} -t "${IMAGENAME}" .
    - docker login -u "${ARTIFACTORY_USER}" -p "${ARTIFACTORY_PASSWORD}" "${DOCKER_REPO}"
    - docker push "${IMAGENAME}"
  tags:
    - k8s



file Read:C:\Users\AP068\git\documentum\dctm-build-base\.tag
-----------------------------------------------------
dctm-build-base:0.0.3


file Read:C:\Users\AP068\git\documentum\dctm-build-base\Dockerfile
-----------------------------------------------------
FROM docker-38027-repo.repo.devops.poalim.bank/ubi7/bnhp-ubi7-python36-wo-entrypoint:7.7-310.1-3

RUN yum install -y git glibc.i686 && yum clean all

ENV HOME=/root

WORKDIR ${HOME}

RUN mkdir ${HOME}/java

ADD  java/jdk-1.6.0_27.tgz ${HOME}/java/
ADD  java/jdk1.8.0_152.tgz ${HOME}/java/
COPY java/org.apache.ant_1.8.3.v20120321-1730 ${HOME}/java/org.apache.ant_1.8.3.v20120321-1730
COPY java/apache-maven-3.3.9 ${HOME}/java/apache-maven-3.3.9
ADD dctm/HeadlessComposer-7.1.tgz install/composer/ComposerHeadless/7.1

ENV PATH="${HOME}/java/jdk1.8.0_152/bin:${HOME}/java/org.apache.ant_1.8.3.v20120321-1730/bin:${HOME}/java/apache-maven-3.3.9/bin:${PATH}"

ENV LANG=en_US.UTF-8

# REMOVE IT!
#COPY ssh ${HOME}/.ssh
#RUN chmod 700 ${HOME}/.ssh



file Read:C:\Users\AP068\git\documentum\dctm-build-base\docker_dsfScript.sh
-----------------------------------------------------
#!/bin/bash 
#set -x
echo "* job build_and_deploy duecmcustomerdfservices started"
echo "* change chmod to ssh"
cp -R /root/sshDoc /root/.ssh
chmod -c 700 /root/.ssh
#chmod go-rwx /root/.ssh/id_rsa
chmod -c 600 /root/.ssh/id_rsa
ls -l /root/.ssh
#chmod 600 /root/.ssh/id_rsa
echo "* git clone"
git clone ssh://git@gitlab.devops.poalim.bank:31007/m28008doc/duecmcustomerdfservices.git
echo "* finish git clone duecmcustomerdfservices"
cd duecmcustomerdfservices
git checkout fix/dfs-build-errors

cd \Web Services\bin
mkdir gen-src
cd ../../..
echo "* cd to duecmcustomerdfservices"
mvn clean deploy  -DskipTests
echo "* job build_and_deploy duecmcustomerdfservices finished"


file Read:C:\Users\AP068\git\documentum\dctm-build-base\docker_dsfScript_without_pull.sh
-----------------------------------------------------
#!/bin/bash 
#set -x
echo "* job build_and_deploy duecmcustomerdfservices started"
echo "* finish git clone duecmcustomerdfservices"
cd /root/documentum
echo "* cd to documentum"
#cd duecmcustomerdfservices
#echo "* cd to duecmcustomerdfservices"
#mvn clean deploy  -DskipTests
#echo "* job build_and_deploy duecmcustomerdfservices finished"


file Read:C:\Users\AP068\git\documentum\dctm-build-base\docker_sshKeyGen.sh
-----------------------------------------------------
#!/bin/bash 
cd ~
ssh-keygen

chmod 700 /root/.ssh
#chmod go-rwx /root/.ssh/id_rsa
chmod  600 /root/.ssh/id_rsa
ls -l /root/.ssh/
cat /root/.ssh/id_rsa.pub
echo "* ssh keygen finished"


file Read:C:\Users\AP068\git\documentum\dctm-build-base\fixFiles.sh
-----------------------------------------------------
#!/bin/bash
#sed -i -e "s/\r//g" ./docker_dsf.sh
#sed -e "s/\r//g" ./docker_sshKeyGen.sh
#sed -e "s/\r//g" ./docker_dsfScript_without_pull.sh
sed -i -e "s/\r//g" ./docker_dsfScript.sh
sed -i -e "s/\r//g" ./docker_dsfScript_without_pull.sh
sed -i -e "s/\r//g" ./*.sh




file Read:C:\Users\AP068\git\documentum\dctm-build-base\java\apache-maven-3.3.9\bin\mvn.cmd
-----------------------------------------------------
@REM ----------------------------------------------------------------------------
@REM Licensed to the Apache Software Foundation (ASF) under one
@REM or more contributor license agreements.  See the NOTICE file
@REM distributed with this work for additional information
@REM regarding copyright ownership.  The ASF licenses this file
@REM to you under the Apache License, Version 2.0 (the
@REM "License"); you may not use this file except in compliance
@REM with the License.  You may obtain a copy of the License at
@REM
@REM    http://www.apache.org/licenses/LICENSE-2.0
@REM
@REM Unless required by applicable law or agreed to in writing,
@REM software distributed under the License is distributed on an
@REM "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
@REM KIND, either express or implied.  See the License for the
@REM specific language governing permissions and limitations
@REM under the License.
@REM ----------------------------------------------------------------------------

@REM ----------------------------------------------------------------------------
@REM Maven2 Start Up Batch script
@REM
@REM Required ENV vars:
@REM JAVA_HOME - location of a JDK home dir
@REM
@REM Optional ENV vars
@REM M2_HOME - location of maven2's installed home dir
@REM MAVEN_BATCH_ECHO - set to 'on' to enable the echoing of the batch commands
@REM MAVEN_BATCH_PAUSE - set to 'on' to wait for a key stroke before ending
@REM MAVEN_OPTS - parameters passed to the Java VM when running Maven
@REM     e.g. to debug Maven itself, use
@REM set MAVEN_OPTS=-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=8000
@REM MAVEN_SKIP_RC - flag to disable loading of mavenrc files
@REM ----------------------------------------------------------------------------

@REM Begin all REM lines with '@' in case MAVEN_BATCH_ECHO is 'on'
@echo off
@REM enable echoing my setting MAVEN_BATCH_ECHO to 'on'
@if "%MAVEN_BATCH_ECHO%" == "on"  echo %MAVEN_BATCH_ECHO%

@REM set %HOME% to equivalent of $HOME
if "%HOME%" == "" (set "HOME=%HOMEDRIVE%%HOMEPATH%")

@REM Execute a user defined script before this one
if not "%MAVEN_SKIP_RC%" == "" goto skipRcPre
@REM check for pre script, once with legacy .bat ending and once with .cmd ending
if exist "%HOME%\mavenrc_pre.bat" call "%HOME%\mavenrc_pre.bat"
if exist "%HOME%\mavenrc_pre.cmd" call "%HOME%\mavenrc_pre.cmd"
:skipRcPre

@setlocal

set ERROR_CODE=0

@REM To isolate internal variables from possible post scripts, we use another setlocal
@setlocal

@REM ==== START VALIDATION ====
if not "%JAVA_HOME%" == "" goto OkJHome

echo.
echo Error: JAVA_HOME not found in your environment. >&2
echo Please set the JAVA_HOME variable in your environment to match the >&2
echo location of your Java installation. >&2
echo.
goto error

:OkJHome
if exist "%JAVA_HOME%\bin\java.exe" goto chkMHome

echo.
echo Error: JAVA_HOME is set to an invalid directory. >&2
echo JAVA_HOME = "%JAVA_HOME%" >&2
echo Please set the JAVA_HOME variable in your environment to match the >&2
echo location of your Java installation. >&2
echo.
goto error

:chkMHome
if not "%M2_HOME%"=="" goto valMHome

SET "M2_HOME=%~dp0.."
if not "%M2_HOME%"=="" goto valMHome

echo.
echo Error: M2_HOME not found in your environment. >&2
echo Please set the M2_HOME variable in your environment to match the >&2
echo location of the Maven installation. >&2
echo.
goto error

:valMHome

:stripMHome
if not "_%M2_HOME:~-1%"=="_\" goto checkMCmd
set "M2_HOME=%M2_HOME:~0,-1%"
goto stripMHome

:checkMCmd
if exist "%M2_HOME%\bin\mvn.cmd" goto init

echo.
echo Error: M2_HOME is set to an invalid directory. >&2
echo M2_HOME = "%M2_HOME%" >&2
echo Please set the M2_HOME variable in your environment to match the >&2
echo location of the Maven installation >&2
echo.
goto error
@REM ==== END VALIDATION ====

:init

set MAVEN_CMD_LINE_ARGS=%*

@REM Find the project base dir, i.e. the directory that contains the folder ".mvn".
@REM Fallback to current working directory if not found.

set MAVEN_PROJECTBASEDIR=%MAVEN_BASEDIR%
IF NOT "%MAVEN_PROJECTBASEDIR%"=="" goto endDetectBaseDir

set EXEC_DIR=%CD%
set WDIR=%EXEC_DIR%
:findBaseDir
IF EXIST "%WDIR%\.mvn" goto baseDirFound
cd ..
IF "%WDIR%"=="%CD%" goto baseDirNotFound
set WDIR=%CD%
goto findBaseDir

:baseDirFound
set MAVEN_PROJECTBASEDIR=%WDIR%
cd "%EXEC_DIR%"
goto endDetectBaseDir

:baseDirNotFound
if "_%EXEC_DIR:~-1%"=="_\" set EXEC_DIR=%EXEC_DIR:~0,-1%

set MAVEN_PROJECTBASEDIR=%EXEC_DIR%
cd "%EXEC_DIR%"

:endDetectBaseDir

IF NOT EXIST "%MAVEN_PROJECTBASEDIR%\.mvn\jvm.config" goto endReadAdditionalConfig

@setlocal EnableExtensions EnableDelayedExpansion
for /F "usebackq delims=" %%a in ("%MAVEN_PROJECTBASEDIR%\.mvn\jvm.config") do set JVM_CONFIG_MAVEN_PROPS=!JVM_CONFIG_MAVEN_PROPS! %%a
@endlocal & set JVM_CONFIG_MAVEN_PROPS=%JVM_CONFIG_MAVEN_PROPS%

:endReadAdditionalConfig

SET MAVEN_JAVA_EXE="%JAVA_HOME%\bin\java.exe"

for %%i in ("%M2_HOME%"\boot\plexus-classworlds-*) do set CLASSWORLDS_JAR="%%i"

set CLASSWORLDS_LAUNCHER=org.codehaus.plexus.classworlds.launcher.Launcher

%MAVEN_JAVA_EXE% %JVM_CONFIG_MAVEN_PROPS% %MAVEN_OPTS% %MAVEN_DEBUG_OPTS% -classpath %CLASSWORLDS_JAR% "-Dclassworlds.conf=%M2_HOME%\bin\m2.conf" "-Dmaven.home=%M2_HOME%" "-Dmaven.multiModuleProjectDirectory=%MAVEN_PROJECTBASEDIR%" %CLASSWORLDS_LAUNCHER% %MAVEN_CMD_LINE_ARGS%
if ERRORLEVEL 1 goto error
goto end

:error
set ERROR_CODE=1

:end
@endlocal & set ERROR_CODE=%ERROR_CODE%

if not "%MAVEN_SKIP_RC%" == "" goto skipRcPost
@REM check for post script, once with legacy .bat ending and once with .cmd ending
if exist "%HOME%\mavenrc_post.bat" call "%HOME%\mavenrc_post.bat"
if exist "%HOME%\mavenrc_post.cmd" call "%HOME%\mavenrc_post.cmd"
:skipRcPost

@REM pause the script if MAVEN_BATCH_PAUSE is set to 'on'
if "%MAVEN_BATCH_PAUSE%" == "on" pause

if "%MAVEN_TERMINATE_CMD%" == "on" exit %ERROR_CODE%

exit /B %ERROR_CODE%


file Read:C:\Users\AP068\git\documentum\dctm-build-base\java\apache-maven-3.3.9\bin\mvnDebug.cmd
-----------------------------------------------------
@REM ----------------------------------------------------------------------------
@REM Licensed to the Apache Software Foundation (ASF) under one
@REM or more contributor license agreements.  See the NOTICE file
@REM distributed with this work for additional information
@REM regarding copyright ownership.  The ASF licenses this file
@REM to you under the Apache License, Version 2.0 (the
@REM "License"); you may not use this file except in compliance
@REM with the License.  You may obtain a copy of the License at
@REM
@REM    http://www.apache.org/licenses/LICENSE-2.0
@REM
@REM Unless required by applicable law or agreed to in writing,
@REM software distributed under the License is distributed on an
@REM "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
@REM KIND, either express or implied.  See the License for the
@REM specific language governing permissions and limitations
@REM under the License.
@REM ----------------------------------------------------------------------------

@REM ----------------------------------------------------------------------------
@REM Maven2 Start Up Batch script to run mvn.cmd with the following additional
@REM Java VM settings:
@REM
@REM     -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=8000
@REM
@REM ----------------------------------------------------------------------------

@setlocal
@set MAVEN_DEBUG_OPTS=-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=8000

@call "%~dp0"mvn.cmd %*


file Read:C:\Users\AP068\git\documentum\dctm-build-base\java\apache-maven-3.3.9\conf\logging\simplelogger.properties
-----------------------------------------------------
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

org.slf4j.simpleLogger.defaultLogLevel=debug
org.slf4j.simpleLogger.showDateTime=false
org.slf4j.simpleLogger.showThreadName=false
org.slf4j.simpleLogger.showLogName=false
org.slf4j.simpleLogger.logFile=System.out
org.slf4j.simpleLogger.levelInBrackets=true
org.slf4j.simpleLogger.log.Sisu=debug
org.slf4j.simpleLogger.warnLevelString=WARNING

.level=DEBUG

handlers=java.util.logging.ConsoleHandler
java.util.logging.ConsoleHandler.level=ALL
java.util.logging.ConsoleHandler.formatter=java.util.logger.SimpleFormatter
sun.net.www.level=DEBUG

org.apache.http.level=DEBUG
org.apache.http.wire.level=DEBUG
org.apache.http.impl.conn.level=DEBUG
org.apache.http.impl.client.level=DEBUG
org.apache.http.client.level=DEBUG
org.apache.commons.httpclient.level=DEBUG
httpclient.wire.header.level=DEBUG
org.apache.maven.wagon.providers.http.httpclient.level=DEBUG
org.apache.maven.wagon.providers.http.httpclient.wire.level=DEBUG

org.slf4j.simplelogger.log.org.apache.http=DEBUG
org.slf4j.simplelogger.log.org.apache.maven.wagon.providers.http=DEBUG
org.slf4j.simplelogger.log.org.apache.maven.wagon.providers.http.httpclient.wire=DEBUG


file Read:C:\Users\AP068\git\documentum\dctm-build-base\java\apache-maven-3.3.9\conf\settings.xml
-----------------------------------------------------
<?xml version="1.0" encoding="UTF-8"?>
<settings xsi:schemaLocation="http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd" xmlns="http://maven.apache.org/SETTINGS/1.0.0"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">
  <servers>
    <server>
      <username>s-28008-user</username>
      <password>s-28008-user</password>
      <id>central</id>
      <configuration>
	<httpConfiguration>
		<get>
			<usePreemptive>true</usePreemptive>
		</get>
	</httpConfiguration>
      </configuration>
    </server>
    <server>
      <username>s-28008-user</username>
      <password>s-28008-user</password>
      <id>snapshots</id>
      <configuration>
	<httpConfiguration>
		<get>
			<usePreemptive>true</usePreemptive>
		</get>
	</httpConfiguration>
      </configuration>
    </server>
    <server>
      <username>s-28008-user</username>
      <password>s-28008-user</password>
      <id>artifactory</id>
      <configuration>
	<httpConfiguration>
		<get>
			<usePreemptive>true</usePreemptive>
		</get>
	</httpConfiguration>
      </configuration>
    </server>
    <server>
      <username>s-28008-user</username>
      <password>s-28008-user</password>
      <id>poalim-core</id>
      <configuration>
	<httpConfiguration>
		<get>
			<usePreemptive>true</usePreemptive>
		</get>
	</httpConfiguration>
      </configuration>
    </server>
  </servers>
  <profiles>
    <profile>
      <repositories>
        <repository>
          <snapshots>
            <enabled>true</enabled>
			<updatePolicy>always</updatePolicy>
          </snapshots>
          <id>central</id>
          <name>libs-release</name>
          <url>https://repo.devops.poalim.bank/artifactory/s-28008-repo</url>
        </repository>
        <repository>
          <snapshots />
          <id>snapshots</id>
          <name>libs-snapshot</name>
          <url>https://repo.devops.poalim.bank/artifactory/s-28008-repo</url>
        </repository>
        <repository>
          <snapshots />
          <id>poalim_core</id>
          <name>poalim-core</name>
          <url>https://repo.devops.poalim.bank/artifactory/poalim-core</url>
        </repository>
      </repositories>
      <pluginRepositories>
        <pluginRepository>
          <snapshots>
            <enabled>false</enabled>
          </snapshots>
          <id>central</id>
          <name>plugins-release</name>
          <url>https://repo.devops.poalim.bank/artifactory/s-28008-repo</url>
        </pluginRepository>
        <pluginRepository>
          <snapshots />
          <id>snapshots</id>
          <name>plugins-snapshot</name>
          <url>https://repo.devops.poalim.bank/artifactory/s-28008-repo</url>
        </pluginRepository>
      </pluginRepositories>
      <id>artifactory</id>
      <properties>
        <headlesscomposer.location>/root/install/composer/ComposerHeadless</headlesscomposer.location>
        <java.home.for.dfs.build>/root/java/jdk-1.6.0_27</java.home.for.dfs.build>
        <downloadSources>true</downloadSources>
        <downloadJavadocs>true</downloadJavadocs>
      </properties>
    </profile>
  </profiles>
  <activeProfiles>
    <activeProfile>artifactory</activeProfile>
  </activeProfiles>
</settings>




file Read:C:\Users\AP068\git\documentum\dctm-build-base\java\apache-maven-3.3.9\conf\toolchains.xml
-----------------------------------------------------
<?xml version="1.0" encoding="UTF-8"?>

<!--
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
-->

<!--
 | This is the toolchains file for Maven. It can be specified at two levels:
 |
 |  1. User Level. This toolchains.xml file provides configuration for a single user,
 |                 and is normally provided in ${user.home}/.m2/toolchains.xml.
 |
 |                 NOTE: This location can be overridden with the CLI option:
 |
 |                 -t /path/to/user/toolchains.xml
 |
 |  2. Global Level. This toolchains.xml file provides configuration for all Maven
 |                 users on a machine (assuming they're all using the same Maven
 |                 installation). It's normally provided in
 |                 ${maven.home}/conf/toolchains.xml.
 |
 |                 NOTE: This location can be overridden with the CLI option:
 |
 |                 -gt /path/to/global/toolchains.xml
 |
 | The sections in this sample file are intended to give you a running start at
 | getting the most out of your Maven installation.
 |-->
<toolchains xmlns="http://maven.apache.org/TOOLCHAINS/1.1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xsi:schemaLocation="http://maven.apache.org/TOOLCHAINS/1.1.0 http://maven.apache.org/xsd/toolchains-1.1.0.xsd">

  <!-- 
   | With toolchains you can refer to installations on your system. This 
   | way you don't have to hardcode paths in your pom.xml. 
   | 
   | Every toolchain consist of 3 elements: 
   | * type: the type of tool. An often used value is 'jdk'. Toolchains-aware 
   |   plugins should document which type you must use. 
   | 
   | * provides: A list of key/value-pairs. 
   |   Based on the toolchain-configuration in the pom.xml Maven will search for 
   |   matching <provides/> configuration. You can decide for yourself which key-value 
   |   pairs to use. Often used keys are 'version', 'vendor' and 'arch'. By default 
   |   the version has a special meaning. If you configured in the pom.xml '1.5' 
   |   Maven will search for 1.5 and above.
   |   
   | * configuration: Additional configuration for this tool.
   |   Look for documentation of the toolchains-aware plugin which configuration elements
   |   can be used.   
   |
   | See also http://maven.apache.org/guides/mini/guide-using-toolchains.html
   |
   | General example

  <toolchain>
    <type/>
    <provides> 
      <version>1.0</version> 
    </provides> 
    <configuration/>
  </toolchain>
   
   | JDK examples

  <toolchain>
    <type>jdk</type>
    <provides>
      <version>1.5</version>
      <vendor>sun</vendor>
    </provides>
    <configuration>
      <jdkHome>/path/to/jdk/1.5</jdkHome>
    </configuration>
  </toolchain>
  <toolchain>
    <type>jdk</type>
    <provides>
      <version>1.6</version>
      <vendor>sun</vendor>
    </provides>
    <configuration>
      <jdkHome>/path/to/jdk/1.6</jdkHome>
    </configuration>
  </toolchain>
   
  -->

</toolchains>


file Read:C:\Users\AP068\git\documentum\dctm-build-base\java\apache-maven-3.3.9\lib\ext\README.txt
-----------------------------------------------------
Use this directory to contribute 3rd-party extensions to the Maven core. These extensions can either extend or override
Maven's default implementation.


file Read:C:\Users\AP068\git\documentum\dctm-build-base\java\apache-maven-3.3.9\README.txt
-----------------------------------------------------

                          Apache Maven

  What is it?
  -----------

  Maven is a software project management and comprehension tool. Based on
  the concept of a Project Object Model (POM), Maven can manage a project's
  build, reporting and documentation from a central piece of information.

  Documentation
  -------------

  The most up-to-date documentation can be found at http://maven.apache.org/.

  Release Notes
  -------------

  The full list of changes can be found at http://maven.apache.org/release-notes.html.

  System Requirements
  -------------------

  JDK:
    1.7 or above (this is to execute Maven - it still allows you to build against 1.3
    and prior JDK's).
  Memory:
    No minimum requirement.
  Disk:
    Approximately 10MB is required for the Maven installation itself. In addition to
    that, additional disk space will be used for your local Maven repository. The size
    of your local repository will vary depending on usage but expect at least 500MB.
  Operating System:
    Windows:
      Windows 2000 or above.
    Unix based systems (Linux, Solaris and Mac OS X) and others:
      No minimum requirement.

  Installing Maven
  ----------------

  1) Unpack the archive where you would like to store the binaries, eg:

    Unix-based operating systems (Linux, Solaris and Mac OS X)
      tar zxvf apache-maven-3.x.y.tar.gz
    Windows
      unzip apache-maven-3.x.y.zip

  2) A directory called "apache-maven-3.x.y" will be created.

  3) Add the bin directory to your PATH, eg:

    Unix-based operating systems (Linux, Solaris and Mac OS X)
      export PATH=/usr/local/apache-maven-3.x.y/bin:$PATH
    Windows
      set PATH="c:\program files\apache-maven-3.x.y\bin";%PATH%

  4) Make sure JAVA_HOME is set to the location of your JDK

  5) Run "mvn --version" to verify that it is correctly installed.

  For complete documentation, see http://maven.apache.org/download.html#Installation

  Licensing
  ---------

  Please see the file called LICENSE.

  Maven URLS
  ----------

  Home Page:          http://maven.apache.org/
  Downloads:          http://maven.apache.org/download.html
  Release Notes:      http://maven.apache.org/release-notes.html
  Mailing Lists:      http://maven.apache.org/mail-lists.html
  Source Code:        https://git-wip-us.apache.org/repos/asf/maven.git/apache-maven
  Issue Tracking:     http://jira.codehaus.org/browse/MNG
  Wiki:               https://cwiki.apache.org/confluence/display/MAVEN/
  Available Plugins:  http://maven.apache.org/plugins/index.html


file Read:C:\Users\AP068\git\documentum\dctm-build-base\java\org.apache.ant_1.8.3.v20120321-1730\about.html
-----------------------------------------------------
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<title>About</title>
</head>
<body lang="EN-US">
<h2>About This Content</h2>
 
<p>March, 2012</p>	
<h3>License</h3>

<p>The Eclipse Foundation makes available all content in this plug-in (&quot;Content&quot;).  Unless otherwise 
indicated below, the Content is provided to you under the terms and conditions of the
Eclipse Public License Version 1.0 (&quot;EPL&quot;).  A copy of the EPL is available 
at <a href="http://www.eclipse.org/legal/epl-v10.html">http://www.eclipse.org/legal/epl-v10.html</a>.
For purposes of the EPL, &quot;Program&quot; will mean the Content.</p>

<p>If you did not receive this Content directly from the Eclipse Foundation, the Content is 
being redistributed by another party (&quot;Redistributor&quot;) and different terms and conditions may
apply to your use of any object code in the Content.  Check the Redistributor's license that was 
provided with the Content.  If no such license exists, contact the Redistributor.  Unless otherwise
indicated below, the terms and conditions of the EPL still apply to any source code in the Content
and such source code may be obtained at <a href="http://www.eclipse.org">http://www.eclipse.org</a>.</p>

<h3>Third Party Content</h3>

<p>
The Content includes items that have been sourced from third parties as set out below. If you 
did not receive this Content directly from the Eclipse Foundation, the following is provided 
for informational purposes only, and you should look to the Redistributor&rsquo;s license for 
terms and conditions of use.
</p>

<h4>Ant 1.8.3</h4>

<p>
Information about what changed in Ant 1.8.3 from Ant 1.8.2 can be found in the <a href="http://www.apache.org/dist/ant/RELEASE-NOTES-1.8.3.html" alt="Ant 1.8.3 release notes">release notes</a>.
</p>
<p>
The plug-in includes software developed by The Apache Software Foundation as part of the Ant project.
</p>

<p>
The Ant binary code in ant.jar and the scripts ant, ant.bat, ant.cmd, antenv.cmd, antRun, antRun.bat, antRun.pl, complete-ant-cmd.pl, envset.cmd, lcp.bat, runant.pl, runant.py and runrc.cmd are included with the plug-in with no modifications.
</p>

<p>
Your use of the Ant code and the scripts is subject to the terms and conditions of the Apache License, Version 2.0.  A copy of the license is contained
in the file <a href="about_files/ASL-LICENSE-2.0.txt" target="_blank">ASL-LICENSE-2.0.txt</a> and is also available at <a href="http://www.apache.org/licenses/LICENSE-2.0.html" target="_blank">http://www.apache.org/licenses/LICENSE-2.0.html</a>.
</p>
<p>
The names &quot;Ant&quot; and &quot;Apache Software Foundation&quot; must not be used to endorse or promote products derived from this 
software without prior written permission.  For written permission, please contact <a href="mailto:apache@apache.org">apache@apache.org</a>.
</p>

<p>
The Apache attribution <a href="about_files/NOTICE" target="_blank">NOTICE</a> file is included with the Content in accordance with 4d of the Apache License, Version 2.0.
</p>

<p>Ant includes the following software:</p>

<blockquote>
	<h4>DOM</h4>
	<p>
	DOM is developed by the World Wide Web Consortium.  Your use of DOM is subject to the terms and conditions of the license found in the
	file <a href="about_files/DOM-LICENSE.html" target="_blank">DOM-LICENSE.html</a> which is included with this plug-in and can also be found at
	<a href="http://www.w3.org/Consortium/Legal/2002/copyright-software-20021231" target="_blank">http://www.w3.org/Consortium/Legal/2002/copyright-software-20021231</a>.
	</p>
	
	<h4>SAX</h4>
	
	<p>SAX is developed by the SAX project (<a href="http://www.saxproject.org" target="_blank">http://www.saxproject.org</a>).  Your use of SAX is subject to the
	terms and conditions of the license found in the file <a href="about_files/SAX-LICENSE.html" target="_blank">SAX-LICENSE.html</a> which is included with this plug-in.</p>
</blockquote>
</body>
</html>


file Read:C:\Users\AP068\git\documentum\dctm-build-base\java\org.apache.ant_1.8.3.v20120321-1730\about_files\ASL-LICENSE-2.0.txt
-----------------------------------------------------

                                 Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

   1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS

   APPENDIX: How to apply the Apache License to your work.

      To apply the Apache License to your work, attach the following
      boilerplate notice, with the fields enclosed by brackets "[]"
      replaced with your own identifying information. (Don't include
      the brackets!)  The text should be enclosed in the appropriate
      comment syntax for the file format. We also recommend that a
      file or class name and description of purpose be included on the
      same "printed page" as the copyright notice for easier
      identification within third-party archives.

   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.


file Read:C:\Users\AP068\git\documentum\dctm-build-base\java\org.apache.ant_1.8.3.v20120321-1730\about_files\DOM-LICENSE.html
-----------------------------------------------------
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="Content-Type" content=
"text/html; charset=utf-8" />
<meta name="generator" content=
"HTML Tidy for Linux/x86 (vers 25 March 2009), see www.w3.org" />
<title>DOM License</title>
<link rel="stylesheet" href="./DOM-LICENSE_files/minimum" type=
"text/css" media="all" />
<style type="text/css" media="all" xml:space="preserve">
/*<![CDATA[*/
     @import url("/2008/site/css/advanced");
/*]]>*/
</style>
<link href="./DOM-LICENSE_files/minimum" rel="stylesheet" type=
"text/css" media=
"handheld, only screen and (max-device-width: 480px)" disabled=
"disabled" />
<meta name="viewport" content="width=device-width" />
<link rel="stylesheet" href="./DOM-LICENSE_files/print" type=
"text/css" media="all" />
<link rel="shortcut icon" href=
"http://www.w3.org/2008/site/images/favicon.ico" type=
"image/x-icon" />
</head>
<body id="www-w3-org" class="w3c_public w3c_javascript w3c_print">
<div id="w3c_container">
<div id="w3c_main">
<h1 class="title">W3C Software Notice and License</h1>
<div id="w3c_content_body">
<div class="line">
<p class="intro tPadding">This work (and included software,
documentation such as READMEs, or other related items) is being
provided by the copyright holders under the following license.</p>
<h2>License</h2>
<p class="tPadding">By obtaining, using and/or copying this work,
you (the licensee) agree that you have read, understood, and will
comply with the following terms and conditions.</p>
<p>Permission to copy, modify, and distribute this software and its
documentation, with or without modification,&nbsp;for any purpose
and without fee or royalty is hereby granted, provided that you
include the following on ALL copies of the software and
documentation or portions thereof, including modifications:</p>
<ul class="show_items">
<li>The full text of this NOTICE in a location viewable to users of
the redistributed or derivative work.</li>
<li>Any pre-existing intellectual property disclaimers, notices, or
terms and conditions. If none exist, the <a href=
"http://www.w3.org/Consortium/Legal/2002/copyright-software-short-notice-20021231.html">
W3C Software Short Notice</a> should be included (hypertext is
preferred, text is permitted) within the body of any redistributed
or derivative code.</li>
<li>Notice of any changes or modifications to the files, including
the date changes were made. (We recommend you provide URIs to the
location from which the code is derived.)</li>
</ul>
<h2>Disclaimers</h2>
<p>THIS SOFTWARE AND DOCUMENTATION IS PROVIDED "AS IS," AND
COPYRIGHT HOLDERS MAKE NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO, WARRANTIES OF
MERCHANTABILITY OR FITNESS FOR ANY PARTICULAR PURPOSE OR THAT THE
USE OF THE SOFTWARE OR DOCUMENTATION WILL NOT INFRINGE ANY THIRD
PARTY PATENTS, COPYRIGHTS, TRADEMARKS OR OTHER RIGHTS.</p>
<p>COPYRIGHT HOLDERS WILL NOT BE LIABLE FOR ANY DIRECT, INDIRECT,
SPECIAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF ANY USE OF THE
SOFTWARE OR DOCUMENTATION.</p>
<p>The name and trademarks of copyright holders may NOT be used in
advertising or publicity pertaining to the software without
specific, written prior permission. Title to copyright in this
software and any associated documentation will at all times remain
with copyright holders.</p>
<h2>Notes</h2>
<p>This version:
http://www.w3.org/Consortium/Legal/2002/copyright-software-20021231</p>
<p>This formulation of W3C's notice and license became active on
December 31 2002. This version removes the copyright ownership
notice such that this license can be used with materials other than
those owned by the W3C, reflects that ERCIM is now a host of the
W3C, includes references to this specific dated version of the
license, and removes the ambiguous grant of "use". Otherwise, this
version is the same as the <a href=
"http://www.w3.org/Consortium/Legal/copyright-software-19980720">previous
version</a> and is written so as to preserve the <a href=
"http://www.gnu.org/philosophy/license-list.html#GPLCompatibleLicenses">
Free Software Foundation's assessment of GPL compatibility</a> and
<a href="http://www.opensource.org/licenses/W3C.php">OSI's
certification</a> under the <a href=
"http://www.opensource.org/docs/definition.php">Open Source
Definition</a>.</p>
</div>
</div>
</div>
</div>
<p class="copyright">Copyright  2009 W3C <sup></sup> ( <a href=
"http://www.csail.mit.edu/"><acronym title=
"Massachusetts Institute of Technology">MIT</acronym></a> ,
<a href="http://www.ercim.org/"><acronym title=
"European Research Consortium for Informatics and Mathematics">ERCIM</acronym></a>
, <a href="http://www.keio.ac.jp/">Keio</a>) <a href=
"http://www.w3.org/Consortium/Legal/2002/ipr-notice-20021231">Usage
policies apply</a>.</p>
<!-- Generated from data/scripts.php, ../../smarty/{scripts.tpl} --><!-- At the bottom for performance reasons -->
<div id="w3c_scripts"><script type="text/javascript" src=
"./DOM-LICENSE_files/main" xml:space="preserve">
//<![CDATA[
<!-- -->
//]]>
</script></div>
</body>
</html>


file Read:C:\Users\AP068\git\documentum\dctm-build-base\java\org.apache.ant_1.8.3.v20120321-1730\about_files\SAX-LICENSE.html
-----------------------------------------------------
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta name="generator" content=
"HTML Tidy for Linux/x86 (vers 25 March 2009), see www.w3.org" />
<meta http-equiv="Content-Type" content=
"text/html; charset=utf-8" />
<title>SAX License</title>

<style type="text/css">
/*<![CDATA[*/
<!--
        h1, h2, h3, h4, h5, h6 { color: maroon; }
        /* make sure that goes OK with the nav column background
         * net-friendly colors include: yellow/ffffcc, blue/ccccff
         */
    -->
/*]]>*/
</style>
</head>
<body color="#000000">
<h2>Origin</h2>
<p>This page was originally taken from: <a href=
"http://www.saxproject.org/copying.html">http://www.saxproject.org/copying.html</a>
with the navigation links remove from the left-hand-side of the
page.</p>
<h2>Copyright Status</h2>
<div>
<p><em>SAX is free!</em></p>
<p>In fact, it's not possible to own a license to SAX, since it's
been placed in the public domain.</p>
<h2>No Warranty</h2>
<p>Because SAX is released to the public domain, there is no
warranty for the design or for the software implementation, to the
extent permitted by applicable law. Except when otherwise stated in
writing the copyright holders and/or other parties provide SAX "as
is" without warranty of any kind, either expressed or implied,
including, but not limited to, the implied warranties of
merchantability and fitness for a particular purpose. The entire
risk as to the quality and performance of SAX is with you. Should
SAX prove defective, you assume the cost of all necessary
servicing, repair or correction.</p>
<p>In no event unless required by applicable law or agreed to in
writing will any copyright holder, or any other party who may
modify and/or redistribute SAX, be liable to you for damages,
including any general, special, incidental or consequential damages
arising out of the use or inability to use SAX (including but not
limited to loss of data or data being rendered inaccurate or losses
sustained by you or third parties or a failure of the SAX to
operate with any other programs), even if such holder or other
party has been advised of the possibility of such damages.</p>
<h2>Copyright Disclaimers</h2>
<p>This page includes statements to that effect by David Megginson,
who would have been able to claim copyright for the original
work.</p>
<!-- MAYBE:  link to archived copies of the messages? -->
<h3>SAX 1.0</h3>
<p>Version 1.0 of the Simple API for XML (SAX), created
collectively by the membership of the XML-DEV mailing list, is
hereby released into the public domain.</p>
<p>No one owns SAX: you may use it freely in both commercial and
non-commercial applications, bundle it with your software
distribution, include it on a CD-ROM, list the source code in a
book, mirror the documentation at your own web site, or use it in
any other way you see fit.</p>
<p><em>David Megginson, <a href=
"http://www.megginson.com/">Megginson Technologies Ltd.</a><br />
1998-05-11</em></p>
<h3>SAX 2.0</h3>
<p>I hereby abandon any property rights to SAX 2.0 (the Simple API
for XML), and release all of the SAX 2.0 source code, compiled
code, and documentation contained in this distribution into the
Public Domain. SAX comes with NO WARRANTY or guarantee of fitness
for any purpose.</p>
<p><em>David Megginson, <a href=
"http://www.megginson.com/">Megginson Technologies Ltd.</a><br />
2000-05-05</em></p>
</div>
<br />
</body>
</html>


file Read:C:\Users\AP068\git\documentum\dctm-build-base\java\org.apache.ant_1.8.3.v20120321-1730\bin\ant.cmd
-----------------------------------------------------
/* 
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
 
    Run ant
*/

'@echo off'
parse arg mode envarg '::' antarg

if mode\='.' & mode\='..' & mode\='/' then do
  envarg = mode envarg
  mode = ''
end

if antarg = '' then do
  antarg = envarg
  envarg = ''
end

x = setlocal()

env="OS2ENVIRONMENT"
antenv = _getenv_('antenv')
if _testenv_() = 0 then interpret 'call "' || antenv || '"' '"' || envarg || '"'

if mode = '' then mode = _getenv_('ANT_MODE' '..')
if mode \= '/' then do
  runrc = _getenv_('runrc')
  antrc = _getenv_('antrc' 'antrc.cmd')
  if mode = '..' then mode = '-r'
  else mode = ''
  interpret 'call "' || runrc || '"' antrc '"' || mode || '"'
end

if _testenv_() = 0 then do
  say 'Ant environment is not set properly'
  x = endlocal()
  exit 16
end

settings = '-Dant.home=' || ANT_HOME '-Djava.home=' || JAVA_HOME

java = _getenv_('javacmd' 'java')
opts = value('ANT_OPTS',,env)
args = value('ANT_ARGS',,env)
lcp = value('LOCALCLASSPATH',,env)
cp = value('CLASSPATH',,env)
if value('ANT_USE_CP',,env) \= '' then do
  if lcp \= '' & right(lcp, 1) \= ';' then lcp = lcp || ';'
  lcp = lcp || cp
  'SET CLASSPATH='
end
if lcp\='' then lcp = '-classpath' lcp

cmd = java opts lcp '-jar' ANT_HOME ||'\lib\ant-launcher.jar' settings args antarg
launcher = stream(ANT_HOME ||'\lib\ant-launcher.jar', 'C', 'query exists')
if launcher = '' then entry = 'org.apache.tools.ant.Main'
else entry = 'org.apache.tools.ant.launch.Launcher'
java opts lcp entry settings args antarg

x = endlocal()

return rc

_testenv_: procedure expose env ANT_HOME JAVA_HOME
ANT_HOME = value('ANT_HOME',,env)
if ANT_HOME = '' then return 0
JAVA_HOME = value('JAVA_HOME',,env)
if JAVA_HOME = '' then return 0
cp = translate(value('CLASSPATH',,env))
if pos(translate(ANT_HOME), cp) = 0 then return 0
if pos(translate(JAVA_HOME), cp) = 0 then return 0
return 1

_getenv_: procedure expose env
parse arg envar default
if default = '' then default = envar
var = value(translate(envar),,env)
if var = '' then var = default
return var


file Read:C:\Users\AP068\git\documentum\dctm-build-base\java\org.apache.ant_1.8.3.v20120321-1730\bin\antenv.cmd
-----------------------------------------------------
/* 
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
*/

'@echo off'
call RxFuncAdd "SysLoadFuncs", "RexxUtil", "SysLoadFuncs"
call SysLoadFuncs

/* Prepare the parameters for later use */
parse arg argv
mode = ''
args = ''
opts = ''
cp = ''
lcp = ''

do i = 1 to words(argv)
  param = word(argv, i)
  select
    when param='-lcp' then mode = 'l'
    when param='-cp' | param='-classpath' then mode = 'c'
    when abbrev('-opts', param, 4) then mode = 'o'
    when abbrev('-args', param, 4) then mode = 'a'
  otherwise
    select
      when mode = 'a' then args = space(args param, 1)
      when mode = 'c' then cp = space(cp param, 1)
      when mode = 'l' then lcp = space(lcp param, 1)
      when mode = 'o' then opts = space(opts param, 1)
    otherwise
      say 'Option' param 'ignored'
    end
  end
end

env="OS2ENVIRONMENT"
antconf = _getenv_('antconf' 'antconf.cmd')
runrc = _getenv_('runrc')
interpret 'call "' || runrc || '"' '"' || antconf || '"' 'ETC'
ANT_HOME = value('ANT_HOME',,env)
JAVA_HOME = value('JAVA_HOME',,env)
classpath = value('CLASSPATH',,env)
classes = stream(JAVA_HOME || "\lib\classes.zip", "C", "QUERY EXISTS")
if classes \= '' then classpath = prepend(classpath classes)
classes = stream(JAVA_HOME || "\lib\tools.jar", "C", "QUERY EXISTS")
if classes \= '' then classpath = prepend(classpath classes)

classpath = prepend(classpath ANT_HOME || '\lib\ant-launcher.jar')
'SET CLASSPATH=' || classpath

/* Setting classpathes, options and arguments */
envset = _getenv_('envset')
if cp\=''   then interpret 'call "' || envset || '"' '"; CLASSPATH"' '"' || cp || '"'
if lcp\=''  then interpret 'call "' || envset || '"' '"; LOCALCLASSPATH"' '"' || lcp || '"'
if opts\='' then interpret 'call "' || envset || '"' '"-D ANT_OPTS"' '"' || opts || '"'
if args\='' then interpret 'call "' || envset || '"' '"ANT_ARGS"' '"' || args || '"'

exit 0

addpath: procedure
parse arg path elem
if elem = '' then do
  if path\='' & right(path, 1)\=';' then path = path || ';'
  return path
end
if substr(path, length(path)) = ';' then glue = ''
else glue = ';'
if pos(translate(elem), translate(path)) = 0 then path = path || glue || elem || ';'
return path

prepend: procedure
parse arg path elem
if elem = '' then do
  if path\='' & right(path, 1)\=';' then path = path || ';'
  return path
end
if pos(translate(elem), translate(path)) = 0 then path = elem || ';' || path
return path

_getenv_: procedure expose env
parse arg envar default
if default = '' then default = envar
var = value(translate(envar),,env)
if var = '' then var = default
return var


file Read:C:\Users\AP068\git\documentum\dctm-build-base\java\org.apache.ant_1.8.3.v20120321-1730\bin\envset.cmd
-----------------------------------------------------
/*

   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

SET environment variables
First optional parameter:
   ;     parameters are considered parts of a path variable, semicolons are
         appended to each element if not already present
   -D    parameters are properties for Java or Makefile etc., -D will be
         prepended and the parameters will be separated by a space
   =D    the same as above but equal sign is not required
   ,     parameters should be comma separated in the environment variable
   -     parameters should be separated by the next parameter
   Other values mean that the first parameter is missing and the environment
   variable will be set to the space separated parameters

Second parameter: name of the environment variable

Next parameters: values
; implies that the equal sign is considered a part of the parameter and is
not interpreted

-D requires parameters in the form name=value. If the equal sign is not found,
the parameters are changed to name=expanded_name

Other options have optional equal sign. If it is found, only the part after
the equal sign will be oprionally expanded.

If the parameter is the minus sign, the next parameter will not be expanded.
If the parameter is a single dot, it will be replaced with the value of the
environment variable as it existed before envset was invoked.

For other parameters the batch looks for the environment variable with the
same name (in uppercase). If it is found, it forms the expanded_name. If
the environment variable with such a name does not exist, the expanded_name
will hold the parameter name without case conversion.
*/

parse arg mode envar args

equal = 0
sep = ' '

/* Parse command line parameters */
select
  when mode='-' then do
    sep = envar
    parse var args envar args
  end
  when mode=';' then do
    sep = ''
    equal = -1
  end
  when mode='-D' then equal = 1
  when mode='=D' then mode = '-D'
  when mode=',' then sep = ','
otherwise
  args = envar args
  envar = mode
  mode = ''
end

env = 'OS2ENVIRONMENT'
envar = translate(envar)
orig = value(envar,,env)
newval = ''
expand = 1

/* for each parameter... */
do i = 1 to words(args)
  if expand > 0 & word(args, i) = '-' then expand = 0
  else call addval word(args, i)
end

/* Optionally enclose path variable by quotes */
if mode = ';' & pos(' ', newval) > 0 then newval = '"' || newval || '"'

/* Set the new value, 'SET' cannot be used since it does not allow '=' */
x = value(envar, newval, env)
exit 0

addval: procedure expose sep equal orig expand newval mode env
parse arg var

if var = '.' then expvar = orig
else do
  if equal >= 0 then do
    parse var var name '=' val
    if val = '' then var = name
    else var = val
  end
  if expand = 0 then expvar = var
  else expvar = value(translate(var),,env)
  if expvar = '' then expvar = var
  if equal >= 0 then do
    if val = '' then do
      parse var expvar key '=' val
      if val <> '' then name = key
      else do
        if equal > 0 then val = key
        else name = key
      end
    end
    else val = expvar
    if pos(' ', val) > 0 | pos('=', val) > 0 then val = '"' || val || '"'
    if val = '' then expvar = name
    else expvar = name || '=' || val
  end
  if mode = '-D' then expvar = '-D' || expvar
  if mode = ';' then do
    if right(expvar, 1) <> ';' then expvar = expvar || ';'
  end
end

if newval = '' then newval = expvar
else newval = newval || sep || expvar
expand = 1
return


file Read:C:\Users\AP068\git\documentum\dctm-build-base\java\org.apache.ant_1.8.3.v20120321-1730\bin\runant.py
-----------------------------------------------------
#!/usr/bin/python
# Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the "License"); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

"""

 runant.py

    This script is a translation of the runant.pl written by Steve Loughran.
    It runs ant with/out arguments, it should be quite portable (thanks to
    the python os library)
    This script has been tested with Python2.0/Win2K

 created:         2001-04-11
 author:          Pierre Dittgen pierre.dittgen@criltelecom.com

 Assumptions:

 - the "java" executable/script is on the command path
"""
import os, os.path, string, sys

# Change it to 1 to get extra debug information
debug = 0

#######################################################################

# If ANT_HOME is not set default to script's parent directory
if os.environ.has_key('ANT_HOME'):
    ANT_HOME = os.environ['ANT_HOME']
else:
    ANT_HOME = os.path.dirname(os.path.dirname(os.path.abspath(sys.argv[0])))

# set ANT_LIB location
ANT_LIB = os.path.join(ANT_HOME, 'lib')

# set JAVACMD (check variables JAVACMD and JAVA_HOME)
JAVACMD = None
if not os.environ.has_key('JAVACMD'):
    if os.environ.has_key('JAVA_HOME'):
        if not os.path.exists(os.environ['JAVA_HOME']):
            print "Warning: JAVA_HOME is not defined correctly."
        else:
            JAVACMD = os.path.join(os.environ['JAVA_HOME'], 'bin', 'java')
    else:
        print "Warning: JAVA_HOME not set."
else:
    JAVACMD = os.environ['JAVACMD']
if not JAVACMD:
    JAVACMD = 'java'

launcher_jar = os.path.join(ANT_LIB, 'ant-launcher.jar')
if not os.path.exists(launcher_jar):
    print 'Warning: Unable to locate ant-launcher.jar. Expected to find it in %s' % \
        ANT_LIB

# Build up standard classpath (LOCALCLASSPATH)
LOCALCLASSPATH = launcher_jar
if os.environ.has_key('LOCALCLASSPATH'):
    LOCALCLASSPATH += os.pathsep + os.environ['LOCALCLASSPATH']

ANT_OPTS = ""
if os.environ.has_key('ANT_OPTS'):
    ANT_OPTS = os.environ['ANT_OPTS']

OPTS = ""
if os.environ.has_key('JIKESPATH'):
    OPTS = '-Djikes.class.path=\"%s\"' % os.environ['JIKESPATH']

ANT_ARGS = ""
if os.environ.has_key('ANT_ARGS'):
    ANT_ARGS = os.environ['ANT_ARGS']

CLASSPATH = ""
if os.environ.has_key('CLASSPATH'):
    CLASSPATH = "-lib " + os.environ['CLASSPATH']

# Builds the commandline
cmdline = ('%s %s -classpath %s -Dant.home=%s %s ' + \
    'org.apache.tools.ant.launch.Launcher %s %s %s') \
     % (JAVACMD, ANT_OPTS, LOCALCLASSPATH, ANT_HOME, OPTS, ANT_ARGS, \
        CLASSPATH, string.join(sys.argv[1:], ' '))

if debug:
    print '\n%s\n\n' % (cmdline)
sys.stdout.flush()

# Run the biniou!
os.system(cmdline)


file Read:C:\Users\AP068\git\documentum\dctm-build-base\java\org.apache.ant_1.8.3.v20120321-1730\bin\runrc.cmd
-----------------------------------------------------
/* 
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

   Run RC file, name is in the first arg, second arg is either PATH
   ENV  or -r or nothing 
*/

parse arg name path rest

if name = '' then do
  say 'RC file name is missing'
  exit 1
end

if rest \= '' then do
  say 'Too many parameters'
  exit 1
end

call runit name path
exit 0

runit: procedure
parse arg name path dir

if path \= '' & path \= '-r' then do
  dir = value(translate(path),,'OS2ENVIRONMENT')
  if dir = '' then return
  dir = translate(dir, '\', '/') /* change UNIX-like path to OS/2 */
end

if dir = '' then dir = directory()

if path = '-r' then do /* recursive call */
  subdir = filespec('path', dir)
  if subdir \= '\' then do
    subdir = left(subdir, length(subdir)-1)
    call runit name path filespec('drive', dir) || subdir
  end
end

/* Look for the file and run it */
if right(dir, 1) \= '\' then dir = dir || '\'
rcfile = stream(dir || name, 'c', 'query exists')
if rcfile \= '' then interpret 'call "' || rcfile || '"'

return


file Read:C:\Users\AP068\git\documentum\dctm-build-base\java\org.apache.ant_1.8.3.v20120321-1730\plugin.properties
-----------------------------------------------------
###############################################################################
# Copyright (c) 2012 IBM Corporation and others.
# All rights reserved. This program and the accompanying materials 
# are made available under the terms of the Eclipse Public License v1.0
# which accompanies this distribution, and is available at
# http://www.eclipse.org/legal/epl-v10.html
# 
# Contributors:
#     IBM Corporation - initial API and implementation
###############################################################################
pluginName = Apache Ant
providerName = Eclipse Orbit
total files:37

